{"cells":[{"cell_type":"markdown","metadata":{"id":"cqWXXYRFuDEy"},"source":["# Import"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"s8ELJIgkXsBG"},"outputs":[],"source":["import pandas as pd\n","import random\n","import os\n","import numpy as np\n","from sklearn.metrics import mean_squared_error\n","from tqdm import tqdm\n","import math\n","from filterpy.kalman import KalmanFilter\n","from filterpy.common import Q_discrete_white_noise\n","\n","import itertools\n","import math\n"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"fuNqIm91XsDz"},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","seed_everything(1422) # Seed 고정"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"Z2pp9fBhXsM-"},"outputs":[],"source":["train_df = pd.read_csv('./data/train.csv')"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"NSyImCAPXsPu"},"outputs":[],"source":["train_x = train_df.filter(regex='X') # Input : X Featrue\n","train_y = train_df.filter(regex='Y') # Output : Y Feature"]},{"cell_type":"markdown","metadata":{"id":"XYFTwVZcueUz"},"source":["# train 칼만 + 각종 피쳐 생성"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"BcbRG6vogzwZ"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33403/2090849507.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_x.drop([\"X_10\",\"X_11\"], axis =1 ,inplace =True)\n","  0%|          | 0/54 [00:00<?, ?it/s]/tmp/ipykernel_33403/2090849507.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_x.loc[:,'kf_X_'+str(i)]=sum_c\n","  2%|▏         | 1/54 [00:01<01:16,  1.44s/it]/tmp/ipykernel_33403/2090849507.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_x.loc[:,'kf_X_'+str(i)]=sum_c\n","  4%|▎         | 2/54 [00:02<01:14,  1.44s/it]/tmp/ipykernel_33403/2090849507.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_x.loc[:,'kf_X_'+str(i)]=sum_c\n","  6%|▌         | 3/54 [00:04<01:13,  1.44s/it]/tmp/ipykernel_33403/2090849507.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_x.loc[:,'kf_X_'+str(i)]=sum_c\n","  7%|▋         | 4/54 [00:05<01:12,  1.45s/it]/tmp/ipykernel_33403/2090849507.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_x.loc[:,'kf_X_'+str(i)]=sum_c\n","  9%|▉         | 5/54 [00:07<01:10,  1.44s/it]/tmp/ipykernel_33403/2090849507.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_x.loc[:,'kf_X_'+str(i)]=sum_c\n"," 11%|█         | 6/54 [00:08<01:08,  1.44s/it]/tmp/ipykernel_33403/2090849507.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_x.loc[:,'kf_X_'+str(i)]=sum_c\n"," 13%|█▎        | 7/54 [00:10<01:07,  1.43s/it]/tmp/ipykernel_33403/2090849507.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_x.loc[:,'kf_X_'+str(i)]=sum_c\n"," 15%|█▍        | 8/54 [00:11<01:05,  1.43s/it]/tmp/ipykernel_33403/2090849507.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_x.loc[:,'kf_X_'+str(i)]=sum_c\n"," 17%|█▋        | 9/54 [00:12<01:04,  1.43s/it]/tmp/ipykernel_33403/2090849507.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_x.loc[:,'kf_X_'+str(i)]=sum_c\n"," 19%|█▊        | 10/54 [00:14<01:02,  1.43s/it]/tmp/ipykernel_33403/2090849507.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_x.loc[:,'kf_X_'+str(i)]=sum_c\n"," 20%|██        | 11/54 [00:15<01:01,  1.43s/it]/tmp/ipykernel_33403/2090849507.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_x.loc[:,'kf_X_'+str(i)]=sum_c\n"," 22%|██▏       | 12/54 [00:17<01:00,  1.43s/it]/tmp/ipykernel_33403/2090849507.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_x.loc[:,'kf_X_'+str(i)]=sum_c\n"," 24%|██▍       | 13/54 [00:18<00:58,  1.43s/it]/tmp/ipykernel_33403/2090849507.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_x.loc[:,'kf_X_'+str(i)]=sum_c\n"," 26%|██▌       | 14/54 [00:20<00:57,  1.43s/it]/tmp/ipykernel_33403/2090849507.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_x.loc[:,'kf_X_'+str(i)]=sum_c\n"," 28%|██▊       | 15/54 [00:21<00:55,  1.44s/it]/tmp/ipykernel_33403/2090849507.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_x.loc[:,'kf_X_'+str(i)]=sum_c\n","100%|██████████| 54/54 [01:17<00:00,  1.44s/it]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>X_01</th>\n","      <th>X_02</th>\n","      <th>X_03</th>\n","      <th>X_04</th>\n","      <th>X_05</th>\n","      <th>X_06</th>\n","      <th>X_07</th>\n","      <th>X_08</th>\n","      <th>X_09</th>\n","      <th>X_12</th>\n","      <th>...</th>\n","      <th>kf_X_44</th>\n","      <th>kf_X_45</th>\n","      <th>kf_X_46</th>\n","      <th>kf_X_47</th>\n","      <th>kf_X_48</th>\n","      <th>kf_X_49</th>\n","      <th>kf_X_50</th>\n","      <th>kf_X_51</th>\n","      <th>kf_X_52</th>\n","      <th>kf_X_53</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>70.544</td>\n","      <td>103.320</td>\n","      <td>67.47</td>\n","      <td>1</td>\n","      <td>101.892</td>\n","      <td>74.983</td>\n","      <td>29.45</td>\n","      <td>62.38</td>\n","      <td>245.71</td>\n","      <td>4.34</td>\n","      <td>...</td>\n","      <td>1.002494</td>\n","      <td>1.002494</td>\n","      <td>9681.830424</td>\n","      <td>136.706824</td>\n","      <td>135.026652</td>\n","      <td>147.474282</td>\n","      <td>133.983516</td>\n","      <td>125.297184</td>\n","      <td>136.385461</td>\n","      <td>124.721452</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>69.524</td>\n","      <td>103.321</td>\n","      <td>65.17</td>\n","      <td>1</td>\n","      <td>101.944</td>\n","      <td>72.943</td>\n","      <td>28.73</td>\n","      <td>61.23</td>\n","      <td>233.61</td>\n","      <td>4.38</td>\n","      <td>...</td>\n","      <td>0.995193</td>\n","      <td>0.995193</td>\n","      <td>10463.125216</td>\n","      <td>134.417826</td>\n","      <td>136.614816</td>\n","      <td>150.605471</td>\n","      <td>124.370038</td>\n","      <td>128.465304</td>\n","      <td>143.906278</td>\n","      <td>125.470122</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>72.583</td>\n","      <td>103.320</td>\n","      <td>64.07</td>\n","      <td>1</td>\n","      <td>103.153</td>\n","      <td>72.943</td>\n","      <td>28.81</td>\n","      <td>105.77</td>\n","      <td>272.20</td>\n","      <td>4.36</td>\n","      <td>...</td>\n","      <td>0.996717</td>\n","      <td>0.996717</td>\n","      <td>11008.959730</td>\n","      <td>132.863430</td>\n","      <td>132.432688</td>\n","      <td>148.165211</td>\n","      <td>126.714975</td>\n","      <td>127.943775</td>\n","      <td>142.420532</td>\n","      <td>123.066148</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>71.563</td>\n","      <td>103.320</td>\n","      <td>67.57</td>\n","      <td>1</td>\n","      <td>101.971</td>\n","      <td>77.022</td>\n","      <td>28.92</td>\n","      <td>115.21</td>\n","      <td>255.36</td>\n","      <td>4.33</td>\n","      <td>...</td>\n","      <td>0.997523</td>\n","      <td>0.997523</td>\n","      <td>14001.464930</td>\n","      <td>133.319729</td>\n","      <td>132.551377</td>\n","      <td>142.332612</td>\n","      <td>129.976112</td>\n","      <td>130.279945</td>\n","      <td>146.807645</td>\n","      <td>131.078737</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>69.524</td>\n","      <td>103.320</td>\n","      <td>63.57</td>\n","      <td>1</td>\n","      <td>101.981</td>\n","      <td>70.904</td>\n","      <td>29.68</td>\n","      <td>103.38</td>\n","      <td>241.46</td>\n","      <td>4.35</td>\n","      <td>...</td>\n","      <td>0.998013</td>\n","      <td>0.998013</td>\n","      <td>12899.355654</td>\n","      <td>138.704302</td>\n","      <td>134.670775</td>\n","      <td>136.901889</td>\n","      <td>132.935585</td>\n","      <td>128.206028</td>\n","      <td>143.653289</td>\n","      <td>127.597410</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>39602</th>\n","      <td>66.465</td>\n","      <td>103.320</td>\n","      <td>62.27</td>\n","      <td>1</td>\n","      <td>103.150</td>\n","      <td>66.825</td>\n","      <td>30.20</td>\n","      <td>77.83</td>\n","      <td>298.05</td>\n","      <td>4.36</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>56282.257274</td>\n","      <td>129.604506</td>\n","      <td>125.719101</td>\n","      <td>137.318833</td>\n","      <td>124.581296</td>\n","      <td>125.063380</td>\n","      <td>137.602621</td>\n","      <td>128.758425</td>\n","    </tr>\n","    <tr>\n","      <th>39603</th>\n","      <td>66.465</td>\n","      <td>103.321</td>\n","      <td>62.77</td>\n","      <td>1</td>\n","      <td>102.021</td>\n","      <td>66.825</td>\n","      <td>29.21</td>\n","      <td>102.25</td>\n","      <td>270.67</td>\n","      <td>4.40</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>58640.674456</td>\n","      <td>129.265428</td>\n","      <td>124.683345</td>\n","      <td>138.073689</td>\n","      <td>124.194959</td>\n","      <td>124.566170</td>\n","      <td>138.298172</td>\n","      <td>127.727242</td>\n","    </tr>\n","    <tr>\n","      <th>39604</th>\n","      <td>68.504</td>\n","      <td>103.320</td>\n","      <td>64.67</td>\n","      <td>1</td>\n","      <td>103.144</td>\n","      <td>68.864</td>\n","      <td>29.96</td>\n","      <td>102.61</td>\n","      <td>198.07</td>\n","      <td>4.38</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>52616.608456</td>\n","      <td>129.711401</td>\n","      <td>126.340585</td>\n","      <td>137.494041</td>\n","      <td>124.875757</td>\n","      <td>125.353904</td>\n","      <td>138.545457</td>\n","      <td>126.227423</td>\n","    </tr>\n","    <tr>\n","      <th>39605</th>\n","      <td>66.465</td>\n","      <td>103.320</td>\n","      <td>63.67</td>\n","      <td>1</td>\n","      <td>102.025</td>\n","      <td>67.845</td>\n","      <td>30.30</td>\n","      <td>112.60</td>\n","      <td>275.52</td>\n","      <td>4.33</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>55226.707986</td>\n","      <td>129.456898</td>\n","      <td>125.494027</td>\n","      <td>138.027848</td>\n","      <td>125.665171</td>\n","      <td>125.255583</td>\n","      <td>138.178005</td>\n","      <td>125.697982</td>\n","    </tr>\n","    <tr>\n","      <th>39606</th>\n","      <td>66.465</td>\n","      <td>103.320</td>\n","      <td>65.67</td>\n","      <td>1</td>\n","      <td>102.004</td>\n","      <td>69.884</td>\n","      <td>30.16</td>\n","      <td>112.90</td>\n","      <td>276.06</td>\n","      <td>4.38</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>57515.806414</td>\n","      <td>130.294870</td>\n","      <td>124.957717</td>\n","      <td>138.634630</td>\n","      <td>125.401073</td>\n","      <td>125.970258</td>\n","      <td>138.325766</td>\n","      <td>127.122784</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>39607 rows × 108 columns</p>\n","</div>"],"text/plain":["         X_01     X_02   X_03  X_04     X_05    X_06   X_07    X_08    X_09  \\\n","0      70.544  103.320  67.47     1  101.892  74.983  29.45   62.38  245.71   \n","1      69.524  103.321  65.17     1  101.944  72.943  28.73   61.23  233.61   \n","2      72.583  103.320  64.07     1  103.153  72.943  28.81  105.77  272.20   \n","3      71.563  103.320  67.57     1  101.971  77.022  28.92  115.21  255.36   \n","4      69.524  103.320  63.57     1  101.981  70.904  29.68  103.38  241.46   \n","...       ...      ...    ...   ...      ...     ...    ...     ...     ...   \n","39602  66.465  103.320  62.27     1  103.150  66.825  30.20   77.83  298.05   \n","39603  66.465  103.321  62.77     1  102.021  66.825  29.21  102.25  270.67   \n","39604  68.504  103.320  64.67     1  103.144  68.864  29.96  102.61  198.07   \n","39605  66.465  103.320  63.67     1  102.025  67.845  30.30  112.60  275.52   \n","39606  66.465  103.320  65.67     1  102.004  69.884  30.16  112.90  276.06   \n","\n","       X_12  ...   kf_X_44   kf_X_45       kf_X_46     kf_X_47     kf_X_48  \\\n","0      4.34  ...  1.002494  1.002494   9681.830424  136.706824  135.026652   \n","1      4.38  ...  0.995193  0.995193  10463.125216  134.417826  136.614816   \n","2      4.36  ...  0.996717  0.996717  11008.959730  132.863430  132.432688   \n","3      4.33  ...  0.997523  0.997523  14001.464930  133.319729  132.551377   \n","4      4.35  ...  0.998013  0.998013  12899.355654  138.704302  134.670775   \n","...     ...  ...       ...       ...           ...         ...         ...   \n","39602  4.36  ...  1.000000  1.000000  56282.257274  129.604506  125.719101   \n","39603  4.40  ...  1.000000  1.000000  58640.674456  129.265428  124.683345   \n","39604  4.38  ...  1.000000  1.000000  52616.608456  129.711401  126.340585   \n","39605  4.33  ...  1.000000  1.000000  55226.707986  129.456898  125.494027   \n","39606  4.38  ...  1.000000  1.000000  57515.806414  130.294870  124.957717   \n","\n","          kf_X_49     kf_X_50     kf_X_51     kf_X_52     kf_X_53  \n","0      147.474282  133.983516  125.297184  136.385461  124.721452  \n","1      150.605471  124.370038  128.465304  143.906278  125.470122  \n","2      148.165211  126.714975  127.943775  142.420532  123.066148  \n","3      142.332612  129.976112  130.279945  146.807645  131.078737  \n","4      136.901889  132.935585  128.206028  143.653289  127.597410  \n","...           ...         ...         ...         ...         ...  \n","39602  137.318833  124.581296  125.063380  137.602621  128.758425  \n","39603  138.073689  124.194959  124.566170  138.298172  127.727242  \n","39604  137.494041  124.875757  125.353904  138.545457  126.227423  \n","39605  138.027848  125.665171  125.255583  138.178005  125.697982  \n","39606  138.634630  125.401073  125.970258  138.325766  127.122784  \n","\n","[39607 rows x 108 columns]"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["train_x.drop([\"X_10\",\"X_11\"], axis =1 ,inplace =True)\n","\n","basic_col = train_x.columns\n","\n","#for i in range(2,44):\n","for i in tqdm(range(len(train_x.columns))):\n","    current=0\n","    sum_c=[]\n","    z = train_x.loc[:, train_x.columns[i]]\n","    a = []           #필터링 된 피쳐(after)\n","    b = []           #필터링 전 피쳐(before)\n","    my_filter = KalmanFilter(dim_x=2,dim_z=1) #create kalman filter\n","    my_filter.x = np.array([[2.],[0.]])       # initial state (location and velocity)\n","    my_filter.F = np.array([[1.,1.], [0.,1.]])    # state transition matrix\n","    my_filter.H = np.array([[1.,0.]])    # Measurement function\n","    my_filter.P *= 1000.                 # covariance matrix\n","    my_filter.R = 5                      # state uncertainty\n","    my_filter.Q = Q_discrete_white_noise(dim = 2,dt=.1,var=.1) # process uncertainty   \n","    for k in z.values:\n","        my_filter.predict()\n","        my_filter.update(k)\n","        # do something with the output\n","        x = my_filter.x\n","        a.extend(x[0])\n","        b.append(k)\n","    #dataset.loc[dataset.num == num, dataset.columns[i]] = a\n","    sum_c=sum_c+a\n","    train_x.loc[:,'kf_X_'+str(i)]=sum_c\n","train_x"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33403/1330450477.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x[col+\"_log\"] = train_x[col].apply(lambda x : math.log(x))\n","/tmp/ipykernel_33403/1330450477.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x[col+\"_log\"] = train_x[col].apply(lambda x : math.log(x))\n","/tmp/ipykernel_33403/1330450477.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x[col+\"_log\"] = train_x[col].apply(lambda x : math.log(x))\n","/tmp/ipykernel_33403/1330450477.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x[col+\"_log\"] = train_x[col].apply(lambda x : math.log(x))\n","/tmp/ipykernel_33403/1330450477.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x[col+\"_log\"] = train_x[col].apply(lambda x : math.log(x))\n","/tmp/ipykernel_33403/1330450477.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x[col+\"_log\"] = train_x[col].apply(lambda x : math.log(x))\n","/tmp/ipykernel_33403/1330450477.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","/tmp/ipykernel_33403/1330450477.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","/tmp/ipykernel_33403/1330450477.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['PCB_sum_1'] = train_x['X_01']+train_x['X_02']\n","/tmp/ipykernel_33403/1330450477.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['PCB_sum_2'] = train_x['X_05']+train_x['X_06']\n","/tmp/ipykernel_33403/1330450477.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['radi_sum_area'] = train_x['X_07'] + train_x['X_08']+ train_x['X_09']\n","/tmp/ipykernel_33403/1330450477.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['radi_1_weight_per_area'] = train_x['X_03'] / train_x['X_07']\n","/tmp/ipykernel_33403/1330450477.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['abs_X_41X_14'] =abs(train_x[\"X_41\"]- train_x['X_14'])\n","/tmp/ipykernel_33403/1330450477.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['abs_X_42X_15'] =abs(train_x[\"X_42\"]- train_x['X_15'])\n","/tmp/ipykernel_33403/1330450477.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['abs_X_43X_16'] =abs(train_x[\"X_43\"]- train_x['X_16'])\n","/tmp/ipykernel_33403/1330450477.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_x['abs_X_44X_17'] =abs(train_x[\"X_44\"]- train_x['X_17'])\n"]}],"source":["temp_1 = ['X_14','X_15','X_16','X_17','X_18']\n","temp_2 = ['X_19','X_20','X_21','X_22']\n","temp_3 = ['X_30','X_31','X_32','X_33']\n","\n","# 0값이 있는 피쳐 제외하고 log 변환 (log1p 사용 안함)\n","for col in basic_col:\n","    if col in ['X_38','X_39',\"X_40\",\"X_45\"]:\n","        continue\n","    train_x[col+\"_log\"] = train_x[col].apply(lambda x : math.log(x))\n","\n","# 가설 1. 안테나 패드 위치 간의 차이가 공정예측에 영향을 미칠 것임\n","for a,b in itertools.combinations(temp_1,2):\n","    train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","    train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","    \n","# 가설 2. 스크류 삽입 깊이의 차이가 공정예측에 영향을 미칠 것임 \n","for a,b in itertools.combinations(temp_2,2):\n","    train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","    train_x['dif_'+b+a] = train_x[b]-train_x[a]\n"," \n"," # 가설 3. 스크류 삽입 깊이의 차이가 공정예측에 영향을 미칠 것임 \n","for a,b in itertools.combinations(temp_3,2):\n","    train_x['dif_'+a+b] = train_x[a]-train_x[b]\n","    train_x['dif_'+b+a] = train_x[b]-train_x[a]\n","    \n","# 가설 4. PCB 체결시 단계별 누름량 1,2의 총합이 공정예측에 영향을 미칠 것임\n","train_x['PCB_sum_1'] = train_x['X_01']+train_x['X_02']\n","\n","# 가설 5. PCB 체결시 단계별 누름량 3,4의 총합이 공정예측에 영향을 미칠 것임\n","train_x['PCB_sum_2'] = train_x['X_05']+train_x['X_06']\n","\n","# 가설 6. 방열재료의 총면적이 공정예측에 영향을 미칠 것임\n","train_x['radi_sum_area'] = train_x['X_07'] + train_x['X_08']+ train_x['X_09']\n","\n","# 가설 7. 방열재료 면적당 무게가 공정예측에 영향을 미칠 것임\n","train_x['radi_1_weight_per_area'] = train_x['X_03'] / train_x['X_07']\n","\n","# 가설 8. 레이돔 치수와 안테나 위치의 거리가 공정예측에 영향을 미칠 것임\n","train_x['abs_X_41X_14'] =abs(train_x[\"X_41\"]- train_x['X_14'])\n","train_x['abs_X_42X_15'] =abs(train_x[\"X_42\"]- train_x['X_15'])\n","train_x['abs_X_43X_16'] =abs(train_x[\"X_43\"]- train_x['X_16'])\n","train_x['abs_X_44X_17'] =abs(train_x[\"X_44\"]- train_x['X_17'])\n","\n","# 가설 9. 안테나패드 위치, 스크류삽입깊이, 커넥터 핀 치수, 스크류삽입깊이의 편차(분산 또는 표준편차)가 공정예측에 영향을 미칠 것임\n","train_x['var_antena_loc'] = train_x[['X_14','X_15','X_16','X_17',\"X_18\"]].apply(lambda x : np.var(x), axis =1)\n","train_x['std_nthscrew_depth'] = train_x[['X_19','X_20','X_21','X_22']].apply(lambda x : np.std(x), axis =1)\n","train_x['std_connector'] = train_x[['X_24','X_25','X_26','X_27',\"X_28\",\"X_29\"]].apply(lambda x : np.std(x), axis =1)\n","train_x['std_screw_depth'] = train_x[['X_30','X_31','X_32','X_33']].apply(lambda x : np.std(x), axis =1)"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["train_x.to_csv('./data/train_x_no_mean_median.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"8tkM1DehuxqB"},"source":["# test 칼만 + 각종 피쳐 생성"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"0j2YICIHYKyc"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 54/54 [01:17<00:00,  1.44s/it]\n","/tmp/ipykernel_33403/4171542990.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x[col+\"_log\"] = submit_x[col].apply(lambda x : math.log(x))\n","/tmp/ipykernel_33403/4171542990.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x[col+\"_log\"] = submit_x[col].apply(lambda x : math.log(x))\n","/tmp/ipykernel_33403/4171542990.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x[col+\"_log\"] = submit_x[col].apply(lambda x : math.log(x))\n","/tmp/ipykernel_33403/4171542990.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x[col+\"_log\"] = submit_x[col].apply(lambda x : math.log(x))\n","/tmp/ipykernel_33403/4171542990.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x[col+\"_log\"] = submit_x[col].apply(lambda x : math.log(x))\n","/tmp/ipykernel_33403/4171542990.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x[col+\"_log\"] = submit_x[col].apply(lambda x : math.log(x))\n","/tmp/ipykernel_33403/4171542990.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","/tmp/ipykernel_33403/4171542990.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","/tmp/ipykernel_33403/4171542990.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['PCB_sum_1'] = submit_x['X_01']+submit_x['X_02']\n","/tmp/ipykernel_33403/4171542990.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['PCB_sum_2'] = submit_x['X_05']+submit_x['X_06']\n","/tmp/ipykernel_33403/4171542990.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['radi_sum_area'] = submit_x['X_07'] + submit_x['X_08']+ submit_x['X_09']\n","/tmp/ipykernel_33403/4171542990.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['radi_1_weight_per_area'] = submit_x['X_03'] / submit_x['X_07']\n","/tmp/ipykernel_33403/4171542990.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['abs_X_41X_14'] =abs(submit_x[\"X_41\"]- submit_x['X_14'])\n","/tmp/ipykernel_33403/4171542990.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['abs_X_42X_15'] =abs(submit_x[\"X_42\"]- submit_x['X_15'])\n","/tmp/ipykernel_33403/4171542990.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['abs_X_43X_16'] =abs(submit_x[\"X_43\"]- submit_x['X_16'])\n","/tmp/ipykernel_33403/4171542990.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  submit_x['abs_X_44X_17'] =abs(submit_x[\"X_44\"]- submit_x['X_17'])\n"]}],"source":["submit_x = pd.read_csv('./data/test.csv')\n","submit_x.drop([\"ID\",\"X_10\",\"X_11\"],axis =1 ,inplace =True)\n","submit_df = pd.read_csv('./data/sample_submission.csv')\n","\n","basic_col = submit_x.columns\n","\n","\n","from tqdm import tqdm\n","\n","for i in tqdm(range(len(submit_x.columns))):\n","    current=0\n","    sum_c=[]\n","    z = submit_x.loc[:, submit_x.columns[i]]\n","    a = []           #필터링 된 피쳐(after)\n","    b = []           #필터링 전 피쳐(before)\n","    my_filter = KalmanFilter(dim_x=2,dim_z=1) #create kalman filter\n","    my_filter.x = np.array([[2.],[0.]])       # initial state (location and velocity)\n","    my_filter.F = np.array([[1.,1.], [0.,1.]])    # state transition matrix\n","    my_filter.H = np.array([[1.,0.]])    # Measurement function\n","    my_filter.P *= 1000.                 # covariance matrix\n","    my_filter.R = 5                      # state uncertainty\n","    my_filter.Q = Q_discrete_white_noise(dim = 2,dt=.1,var=.1) # process uncertainty   \n","    for k in z.values:\n","        my_filter.predict()\n","        my_filter.update(k)\n","        # do something with the output\n","        x = my_filter.x\n","        a.extend(x[0])\n","        b.append(k)\n","    #dataset.loc[dataset.num == num, dataset.columns[i]] = a\n","    sum_c=sum_c+a\n","    submit_x.loc[:,'kf_X_'+str(i)]=sum_c\n","\n","\n","for col in basic_col:\n","    if col in ['X_38','X_39',\"X_40\",\"X_45\"]:\n","        continue\n","    submit_x[col+\"_log\"] = submit_x[col].apply(lambda x : math.log(x))\n","\n","\n","for a,b in itertools.combinations(temp_1,2):\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","\n","for a,b in itertools.combinations(temp_2,2):\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","\n","\n","for a,b in itertools.combinations(temp_3,2):\n","  submit_x['dif_'+a+b] = submit_x[a]-submit_x[b]\n","  submit_x['dif_'+b+a] = submit_x[b]-submit_x[a]\n","\n","submit_x['PCB_sum_1'] = submit_x['X_01']+submit_x['X_02']\n","submit_x['PCB_sum_2'] = submit_x['X_05']+submit_x['X_06']\n","submit_x['radi_sum_area'] = submit_x['X_07'] + submit_x['X_08']+ submit_x['X_09']\n","submit_x['radi_1_weight_per_area'] = submit_x['X_03'] / submit_x['X_07']\n","\n","submit_x['abs_X_41X_14'] =abs(submit_x[\"X_41\"]- submit_x['X_14'])\n","submit_x['abs_X_42X_15'] =abs(submit_x[\"X_42\"]- submit_x['X_15'])\n","submit_x['abs_X_43X_16'] =abs(submit_x[\"X_43\"]- submit_x['X_16'])\n","submit_x['abs_X_44X_17'] =abs(submit_x[\"X_44\"]- submit_x['X_17'])\n","\n","\n","submit_x['var_antena_loc'] = submit_x[['X_14','X_15','X_16','X_17',\"X_18\"]].apply(lambda x : np.var(x), axis =1)\n","submit_x['std_nthscrew_depth'] = submit_x[['X_19','X_20','X_21','X_22']].apply(lambda x : np.std(x), axis =1)\n","submit_x['std_connector'] = submit_x[['X_24','X_25','X_26','X_27',\"X_28\",\"X_29\"]].apply(lambda x : np.std(x), axis =1)\n","submit_x['std_screw_depth'] = submit_x[['X_30','X_31','X_32','X_33']].apply(lambda x : np.std(x), axis =1)"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["submit_x.to_csv('./data/test_x_no_mean_median.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# 평균, 중간값 생성"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["The mean and median of X_02 is making:   2%|▏         | 1/54 [00:01<01:03,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_03 is making:   4%|▎         | 2/54 [00:02<01:01,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_04 is making:   6%|▌         | 3/54 [00:03<01:00,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_05 is making:   7%|▋         | 4/54 [00:04<00:54,  1.10s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_06 is making:   9%|▉         | 5/54 [00:05<00:55,  1.13s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_07 is making:  11%|█         | 6/54 [00:06<00:55,  1.15s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_08 is making:  13%|█▎        | 7/54 [00:08<00:54,  1.16s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_09 is making:  15%|█▍        | 8/54 [00:09<00:53,  1.17s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_12 is making:  17%|█▋        | 9/54 [00:10<00:52,  1.17s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_13 is making:  19%|█▊        | 10/54 [00:11<00:51,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_14 is making:  20%|██        | 11/54 [00:12<00:51,  1.20s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_15 is making:  22%|██▏       | 12/54 [00:14<00:50,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_16 is making:  24%|██▍       | 13/54 [00:15<00:48,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_17 is making:  26%|██▌       | 14/54 [00:16<00:48,  1.20s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_18 is making:  28%|██▊       | 15/54 [00:17<00:46,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_19 is making:  30%|██▉       | 16/54 [00:18<00:45,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_20 is making:  31%|███▏      | 17/54 [00:20<00:44,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_21 is making:  33%|███▎      | 18/54 [00:21<00:42,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_22 is making:  35%|███▌      | 19/54 [00:22<00:41,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_23 is making:  37%|███▋      | 20/54 [00:23<00:40,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_24 is making:  39%|███▉      | 21/54 [00:24<00:37,  1.13s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_25 is making:  41%|████      | 22/54 [00:25<00:36,  1.14s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_26 is making:  43%|████▎     | 23/54 [00:26<00:35,  1.16s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_27 is making:  44%|████▍     | 24/54 [00:28<00:35,  1.17s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_28 is making:  46%|████▋     | 25/54 [00:29<00:34,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_29 is making:  48%|████▊     | 26/54 [00:30<00:33,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_30 is making:  50%|█████     | 27/54 [00:31<00:32,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_31 is making:  52%|█████▏    | 28/54 [00:32<00:30,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_32 is making:  54%|█████▎    | 29/54 [00:34<00:29,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_33 is making:  56%|█████▌    | 30/54 [00:35<00:28,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_34 is making:  57%|█████▋    | 31/54 [00:36<00:27,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_35 is making:  59%|█████▉    | 32/54 [00:37<00:26,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_36 is making:  61%|██████    | 33/54 [00:38<00:25,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_37 is making:  63%|██████▎   | 34/54 [00:40<00:23,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_38 is making:  65%|██████▍   | 35/54 [00:41<00:22,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_39 is making:  67%|██████▋   | 36/54 [00:42<00:21,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_40 is making:  69%|██████▊   | 37/54 [00:43<00:20,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_41 is making:  70%|███████   | 38/54 [00:44<00:19,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_42 is making:  72%|███████▏  | 39/54 [00:46<00:17,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_43 is making:  74%|███████▍  | 40/54 [00:47<00:16,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_44 is making:  76%|███████▌  | 41/54 [00:48<00:15,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_45 is making:  78%|███████▊  | 42/54 [00:49<00:14,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_46 is making:  80%|███████▉  | 43/54 [00:50<00:13,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_47 is making:  81%|████████▏ | 44/54 [00:51<00:11,  1.13s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_48 is making:  83%|████████▎ | 45/54 [00:52<00:09,  1.08s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_49 is making:  85%|████████▌ | 46/54 [00:53<00:08,  1.05s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_50 is making:  87%|████████▋ | 47/54 [00:54<00:07,  1.09s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_51 is making:  89%|████████▉ | 48/54 [00:56<00:06,  1.12s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_52 is making:  91%|█████████ | 49/54 [00:57<00:05,  1.14s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33403/1104968906.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_mean_{set_amount}'] = meanArr\n","/tmp/ipykernel_33403/1104968906.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_median_{set_amount}'] = medianArr\n","The mean and median of X_53 is making:  93%|█████████▎| 50/54 [00:58<00:04,  1.16s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33403/1104968906.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_mean_{set_amount}'] = meanArr\n","/tmp/ipykernel_33403/1104968906.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_median_{set_amount}'] = medianArr\n","The mean and median of X_54 is making:  94%|█████████▍| 51/54 [00:59<00:03,  1.17s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33403/1104968906.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_mean_{set_amount}'] = meanArr\n","/tmp/ipykernel_33403/1104968906.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_median_{set_amount}'] = medianArr\n","The mean and median of X_55 is making:  96%|█████████▋| 52/54 [01:00<00:02,  1.17s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33403/1104968906.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_mean_{set_amount}'] = meanArr\n","/tmp/ipykernel_33403/1104968906.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_median_{set_amount}'] = medianArr\n","The mean and median of X_56 is making:  98%|█████████▊| 53/54 [01:02<00:01,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33403/1104968906.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_mean_{set_amount}'] = meanArr\n","/tmp/ipykernel_33403/1104968906.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_median_{set_amount}'] = medianArr\n","The mean and median of X_56 is making: 100%|██████████| 54/54 [01:03<00:00,  1.17s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39607\n","median_arr:39607\n"]},{"name":"stderr","output_type":"stream","text":["\n","The mean and median of X_02 is making:   2%|▏         | 1/54 [00:01<01:04,  1.22s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_03 is making:   4%|▎         | 2/54 [00:02<01:05,  1.25s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_04 is making:   6%|▌         | 3/54 [00:03<01:02,  1.23s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_05 is making:   7%|▋         | 4/54 [00:04<00:56,  1.13s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_06 is making:   9%|▉         | 5/54 [00:05<00:57,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_07 is making:  11%|█         | 6/54 [00:07<00:57,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_08 is making:  13%|█▎        | 7/54 [00:08<00:55,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_09 is making:  15%|█▍        | 8/54 [00:09<00:55,  1.20s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_12 is making:  17%|█▋        | 9/54 [00:10<00:53,  1.20s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_13 is making:  19%|█▊        | 10/54 [00:11<00:52,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_14 is making:  20%|██        | 11/54 [00:13<00:51,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_15 is making:  22%|██▏       | 12/54 [00:14<00:49,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_16 is making:  24%|██▍       | 13/54 [00:15<00:48,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_17 is making:  26%|██▌       | 14/54 [00:16<00:47,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_18 is making:  28%|██▊       | 15/54 [00:17<00:46,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_19 is making:  30%|██▉       | 16/54 [00:19<00:44,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_20 is making:  31%|███▏      | 17/54 [00:20<00:43,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_21 is making:  33%|███▎      | 18/54 [00:21<00:42,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_22 is making:  35%|███▌      | 19/54 [00:22<00:41,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_23 is making:  37%|███▋      | 20/54 [00:23<00:40,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_24 is making:  39%|███▉      | 21/54 [00:24<00:36,  1.12s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_25 is making:  41%|████      | 22/54 [00:25<00:36,  1.14s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_26 is making:  43%|████▎     | 23/54 [00:27<00:35,  1.15s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_27 is making:  44%|████▍     | 24/54 [00:28<00:34,  1.16s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_28 is making:  46%|████▋     | 25/54 [00:29<00:33,  1.17s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_29 is making:  48%|████▊     | 26/54 [00:30<00:32,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_30 is making:  50%|█████     | 27/54 [00:31<00:31,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_31 is making:  52%|█████▏    | 28/54 [00:33<00:30,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_32 is making:  54%|█████▎    | 29/54 [00:34<00:29,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_33 is making:  56%|█████▌    | 30/54 [00:35<00:28,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_34 is making:  57%|█████▋    | 31/54 [00:36<00:27,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_35 is making:  59%|█████▉    | 32/54 [00:37<00:26,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_36 is making:  61%|██████    | 33/54 [00:39<00:24,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_37 is making:  63%|██████▎   | 34/54 [00:40<00:23,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_38 is making:  65%|██████▍   | 35/54 [00:41<00:22,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_39 is making:  67%|██████▋   | 36/54 [00:42<00:21,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_40 is making:  69%|██████▊   | 37/54 [00:43<00:20,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_41 is making:  70%|███████   | 38/54 [00:44<00:18,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_42 is making:  72%|███████▏  | 39/54 [00:46<00:17,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_43 is making:  74%|███████▍  | 40/54 [00:47<00:16,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_44 is making:  76%|███████▌  | 41/54 [00:48<00:15,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_45 is making:  78%|███████▊  | 42/54 [00:49<00:14,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_46 is making:  80%|███████▉  | 43/54 [00:50<00:13,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_47 is making:  81%|████████▏ | 44/54 [00:51<00:11,  1.14s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_48 is making:  83%|████████▎ | 45/54 [00:52<00:09,  1.10s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_49 is making:  85%|████████▌ | 46/54 [00:53<00:08,  1.06s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_50 is making:  87%|████████▋ | 47/54 [00:55<00:07,  1.10s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_51 is making:  89%|████████▉ | 48/54 [00:56<00:06,  1.15s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["The mean and median of X_52 is making:  91%|█████████ | 49/54 [00:57<00:05,  1.16s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33403/1104968906.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_mean_{set_amount}'] = meanArr\n","/tmp/ipykernel_33403/1104968906.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_median_{set_amount}'] = medianArr\n","The mean and median of X_53 is making:  93%|█████████▎| 50/54 [00:58<00:04,  1.17s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33403/1104968906.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_mean_{set_amount}'] = meanArr\n","/tmp/ipykernel_33403/1104968906.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_median_{set_amount}'] = medianArr\n","The mean and median of X_54 is making:  94%|█████████▍| 51/54 [00:59<00:03,  1.17s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33403/1104968906.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_mean_{set_amount}'] = meanArr\n","/tmp/ipykernel_33403/1104968906.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_median_{set_amount}'] = medianArr\n","The mean and median of X_55 is making:  96%|█████████▋| 52/54 [01:01<00:02,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33403/1104968906.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_mean_{set_amount}'] = meanArr\n","/tmp/ipykernel_33403/1104968906.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_median_{set_amount}'] = medianArr\n","The mean and median of X_56 is making:  98%|█████████▊| 53/54 [01:02<00:01,  1.19s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33403/1104968906.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_mean_{set_amount}'] = meanArr\n","/tmp/ipykernel_33403/1104968906.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  df[f'{column}_median_{set_amount}'] = medianArr\n","The mean and median of X_56 is making: 100%|██████████| 54/54 [01:03<00:00,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["mean_arr:39608\n","median_arr:39608\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","\n","# import matplotlib.pyplot as plt\n","import time\n","class CFG:\n","    seed = 42\n","    fold_num = 10\n","\n","    trainPath = './data/train_x_no_mean_median.csv'\n","    testPath = './data/test_x_no_mean_median.csv'\n","    \n","    \n","train_df = pd.read_csv(CFG.trainPath)\n","test_df = pd.read_csv(CFG.testPath)\n","\n","\n","train_new_df = train_df.copy()\n","test_new_df = test_df.copy()\n","\n","def make_mean_median(column_list, set_amount):\n","    mean_arr = []\n","    median_arr = []\n","    \n","    # 첫 set_amount까지는 본래값 사용\n","    for i in range(set_amount):\n","        mean_arr.append(column_list[i])\n","        median_arr.append(column_list[i])\n","    \n","    # set_amount만큼의 mean, median 생성\n","    for i in range(set_amount, len(column_list)):\n","        mean_arr.append(float(np.mean(column_list[i-set_amount:i])))\n","        median_arr.append(float(np.median(column_list[i-set_amount:i])))\n","        \n","    print(f'mean_arr:{len(mean_arr)}')\n","    print(f'median_arr:{len(median_arr)}')\n","    return mean_arr.copy(), median_arr.copy()\n","\n","def make_move_avg_median(df, save_file_name, type=None, set_amount=30):\n","    # set_amount 조절가능\n","    # trainX -> X_10, X_11을 제외한 54개의 이동평균\n","    pbar = tqdm(df.columns[:54])\n","    for column in pbar:\n","        column_list = df[column].to_list()\n","        pbar.set_description(f\"The mean and median of {column} is making\")\n","        meanArr, medianArr = make_mean_median(column_list, set_amount)\n","        \n","        df[f'{column}_mean_{set_amount}'] = meanArr\n","        df[f'{column}_median_{set_amount}'] = medianArr\n","        \n","    df.to_csv(save_file_name, index=False)\n","\n","\n","make_move_avg_median(train_df, save_file_name='./data/train_x_engineered.csv', type='train')\n","make_move_avg_median(test_df, save_file_name='./data/test_x_engineered.csv', type='test')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Aimers_best_beautified.ipynb","provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"a0249340583af603c9d7ee44d66ed27a127a6ef7cdc35d1bf3f1a7a446f95f07"}}},"nbformat":4,"nbformat_minor":0}
