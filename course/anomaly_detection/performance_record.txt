
epochs: 0 train loss: 0.9802783567514  train f1: 0.20952  seed: 0 
epochs: 0 val loss: 1.9855957031249996  val f1:0.27315  seed: 0
epochs: 1 train loss: 0.44033950122434684  train f1: 0.43546  seed: 0 
epochs: 1 val loss: 1.3213106043198526  val f1:0.45193  seed: 0
epochs: 2 train loss: 0.2852605563491139  train f1: 0.62745  seed: 0 
epochs: 2 val loss: 1.0079812442555145  val f1:0.57092  seed: 0
epochs: 3 train loss: 0.1850547221169543  train f1: 0.75179  seed: 0 
epochs: 3 val loss: 0.8799043543198531  val f1:0.64574  seed: 0
epochs: 4 train loss: 0.1199803138846782  train f1: 0.82943  seed: 0 
epochs: 4 val loss: 0.825967227711397  val f1:0.69786  seed: 0
epochs: 5 train loss: 0.0819056816955111  train f1: 0.88637  seed: 0 
epochs: 5 val loss: 0.9713062959558822  val f1:0.68948  seed: 0
epochs: 6 train loss: 0.06187769192368235  train f1: 0.92995  seed: 0 
epochs: 6 val loss: 0.768497242647059  val f1:0.71405  seed: 0
epochs: 7 train loss: 0.057894507450843916  train f1: 0.93405  seed: 0 
epochs: 7 val loss: 0.8754200654871325  val f1:0.72787  seed: 0
epochs: 8 train loss: 0.040672978358482235  train f1: 0.94703  seed: 0 
epochs: 8 val loss: 0.9687607709099263  val f1:0.68649  seed: 0
epochs: 9 train loss: 0.030052651220293183  train f1: 0.95590  seed: 0 
epochs: 9 val loss: 0.8562693876378676  val f1:0.71338  seed: 0
epochs: 10 train loss: 0.04141774284305858  train f1: 0.95505  seed: 0 
epochs: 10 val loss: 0.787427116842831  val f1:0.73774  seed: 0
epochs: 11 train loss: 0.04532747838034561  train f1: 0.95362  seed: 0 
epochs: 11 val loss: 0.9313174977022061  val f1:0.71124  seed: 0
epochs: 12 train loss: 0.0507356978174466  train f1: 0.95425  seed: 0 
epochs: 12 val loss: 0.9317373387953813  val f1:0.72026  seed: 0
epochs: 13 train loss: 0.027644641363798673  train f1: 0.96431  seed: 0 
epochs: 13 val loss: 0.9730655445772055  val f1:0.70223  seed: 0
epochs: 14 train loss: 0.024599365334012635  train f1: 0.96528  seed: 0 
epochs: 14 val loss: 0.898386786965763  val f1:0.74129  seed: 0
epochs: 0 train loss: 0.9402730002332094  train f1: 0.22107  seed: 1 
epochs: 0 val loss: 1.8665268841911762  val f1:0.26190  seed: 1
epochs: 1 train loss: 0.4303597976912314  train f1: 0.46980  seed: 1 
epochs: 1 val loss: 1.5306899126838234  val f1:0.43266  seed: 1
epochs: 2 train loss: 0.27337897001807365  train f1: 0.63362  seed: 1 
epochs: 2 val loss: 1.0714075425091916  val f1:0.59028  seed: 1
epochs: 3 train loss: 0.1758045082661643  train f1: 0.76388  seed: 1 
epochs: 3 val loss: 1.0180951286764703  val f1:0.63439  seed: 1
epochs: 4 train loss: 0.1271190358631647  train f1: 0.83573  seed: 1 
epochs: 4 val loss: 1.0400067497702208  val f1:0.61864  seed: 1
epochs: 5 train loss: 0.08299720821095934  train f1: 0.87765  seed: 1 
epochs: 5 val loss: 0.9712883444393384  val f1:0.66333  seed: 1
epochs: 6 train loss: 0.07973854577363429  train f1: 0.89026  seed: 1 
epochs: 6 val loss: 1.0175440171185666  val f1:0.68359  seed: 1
epochs: 7 train loss: 0.05796062412546644  train f1: 0.92980  seed: 1 
epochs: 7 val loss: 0.8194903205422795  val f1:0.71117  seed: 1
epochs: 8 train loss: 0.036807956980235534  train f1: 0.95752  seed: 1 
epochs: 8 val loss: 0.8049783145680147  val f1:0.73553  seed: 1
epochs: 9 train loss: 0.026176893889014393  train f1: 0.96703  seed: 1 
epochs: 9 val loss: 0.8829794491038601  val f1:0.73485  seed: 1
epochs: 10 train loss: 0.02788456874107247  train f1: 0.97648  seed: 1 
epochs: 10 val loss: 0.8825916963465074  val f1:0.74012  seed: 1
epochs: 11 train loss: 0.024385280573546  train f1: 0.98233  seed: 1 
epochs: 11 val loss: 1.0064051011029411  val f1:0.70196  seed: 1
epochs: 12 train loss: 0.040035827835993985  train f1: 0.96796  seed: 1 
epochs: 12 val loss: 0.9588515337775737  val f1:0.73332  seed: 1
epochs: 0 train loss: 4.5296816914498095  train f1: 0.00956  seed: 0 
epochs: 0 val loss: 4.492130055147058  val f1:0.00263  seed: 0
epochs: 0 train loss: 0.9773167852145521  train f1: 0.22675  seed: 0 
epochs: 0 val loss: 1.594152113970588  val f1:0.29277  seed: 0
epochs: 1 train loss: 0.4515681480293844  train f1: 0.43292  seed: 0 
epochs: 1 val loss: 1.3253461052389703  val f1:0.49174  seed: 0
epochs: 2 train loss: 0.2995042943242771  train f1: 0.59580  seed: 0 
epochs: 2 val loss: 1.1900527056525738  val f1:0.50395  seed: 0
epochs: 0 train loss: 0.9404861677938436  train f1: 0.22853  seed: 0 
epochs: 0 val loss: 1.8178280101102937  val f1:0.27252  seed: 0
epochs: 1 train loss: 0.42110340630830245  train f1: 0.49339  seed: 0 
epochs: 1 val loss: 1.4204460592830879  val f1:0.44375  seed: 0
epochs: 2 train loss: 0.25783140267898785  train f1: 0.65181  seed: 0 
epochs: 2 val loss: 1.0173662971047797  val f1:0.57949  seed: 0
epochs: 3 train loss: 0.16495878305008163  train f1: 0.79590  seed: 0 
epochs: 3 val loss: 0.9545683019301471  val f1:0.64201  seed: 0
epochs: 4 train loss: 0.12466123210850046  train f1: 0.84852  seed: 0 
epochs: 4 val loss: 0.8300386316636027  val f1:0.67549  seed: 0
epochs: 5 train loss: 0.07779944120947987  train f1: 0.88100  seed: 0 
epochs: 5 val loss: 0.8918816061580881  val f1:0.70382  seed: 0
epochs: 6 train loss: 0.057302289934300664  train f1: 0.92972  seed: 0 
epochs: 6 val loss: 0.915118049172794  val f1:0.70449  seed: 0
epochs: 7 train loss: 0.05404589069423391  train f1: 0.93343  seed: 0 
epochs: 7 val loss: 0.9369470932904412  val f1:0.70627  seed: 0
epochs: 8 train loss: 0.03927355381979871  train f1: 0.95072  seed: 0 
epochs: 8 val loss: 0.953390682444853  val f1:0.69703  seed: 0
epochs: 9 train loss: 0.04550382628369689  train f1: 0.95415  seed: 0 
epochs: 9 val loss: 0.9573777142693014  val f1:0.71307  seed: 0
epochs: 10 train loss: 0.036238293149578035  train f1: 0.95719  seed: 0 
epochs: 10 val loss: 0.9874465044806985  val f1:0.74675  seed: 0
epochs: 11 train loss: 0.03991094987783859  train f1: 0.95193  seed: 0 
epochs: 11 val loss: 1.1127606560202206  val f1:0.68263  seed: 0
epochs: 12 train loss: 0.027522939354626103  train f1: 0.96496  seed: 0 
epochs: 12 val loss: 1.057254566865809  val f1:0.72483  seed: 0
epochs: 13 train loss: 0.02169543504714965  train f1: 0.97382  seed: 0 
epochs: 13 val loss: 0.9465978285845585  val f1:0.72644  seed: 0
epochs: 14 train loss: 0.018100363105090698  train f1: 0.97213  seed: 0 
epochs: 14 val loss: 0.9289927763097429  val f1:0.72932  seed: 0
epochs: 15 train loss: 0.02361200816595733  train f1: 0.98440  seed: 0 
epochs: 15 val loss: 0.8843531889073991  val f1:0.74313  seed: 0
epochs: 16 train loss: 0.029103831568760664  train f1: 0.96374  seed: 0 
epochs: 16 val loss: 1.103368422564338  val f1:0.69532  seed: 0
epochs: 17 train loss: 0.03266676860069161  train f1: 0.96182  seed: 0 
epochs: 17 val loss: 0.9805746639476103  val f1:0.72264  seed: 0
epochs: 18 train loss: 0.019662373101533345  train f1: 0.97927  seed: 0 
epochs: 18 val loss: 0.9037834616268379  val f1:0.73678  seed: 0
epochs: 19 train loss: 0.019052054455031213  train f1: 0.98808  seed: 0 
epochs: 19 val loss: 0.9629067813648902  val f1:0.75570  seed: 0
epochs: 20 train loss: 0.030125251456872733  train f1: 0.97261  seed: 0 
epochs: 20 val loss: 1.1494427849264708  val f1:0.71698  seed: 0
epochs: 21 train loss: 0.03304036517641436  train f1: 0.97427  seed: 0 
epochs: 21 val loss: 0.9659387925091909  val f1:0.72344  seed: 0
epochs: 22 train loss: 0.009503774678529198  train f1: 0.99329  seed: 0 
epochs: 22 val loss: 1.042627671185662  val f1:0.75232  seed: 0
epochs: 23 train loss: 0.013463228051342185  train f1: 0.98974  seed: 0 
epochs: 23 val loss: 1.1391278435202206  val f1:0.71082  seed: 0
epochs: 24 train loss: 0.051350731458236896  train f1: 0.95615  seed: 0 
epochs: 24 val loss: 1.196335736443014  val f1:0.70255  seed: 0
epochs: 25 train loss: 0.032022104334475394  train f1: 0.97112  seed: 0 
epochs: 25 val loss: 0.9935841279871322  val f1:0.72777  seed: 0
epochs: 26 train loss: 0.035168198062412774  train f1: 0.96705  seed: 0 
epochs: 26 val loss: 1.1273534438189337  val f1:0.70336  seed: 0
epochs: 27 train loss: 0.027395772400187004  train f1: 0.98148  seed: 0 
epochs: 27 val loss: 1.0158498988432039  val f1:0.74069  seed: 0
epochs: 28 train loss: 0.014506972547787338  train f1: 0.98848  seed: 0 
epochs: 28 val loss: 1.0267253202550553  val f1:0.73379  seed: 0
epochs: 29 train loss: 0.01441534063709316  train f1: 0.98946  seed: 0 
epochs: 29 val loss: 0.9821920955882352  val f1:0.75303  seed: 0
epochs: 0 train loss: 0.9389083634561564  train f1: 0.22375  seed: 1 
epochs: 0 val loss: 1.7838852826286768  val f1:0.27631  seed: 1
epochs: 1 train loss: 0.4669207672574626  train f1: 0.42207  seed: 1 
epochs: 1 val loss: 1.5040139590992647  val f1:0.40034  seed: 1
epochs: 0 train loss: 0.9489381704757464  train f1: 0.22327  seed: 0 
epochs: 0 val loss: 1.8232996323529411  val f1:0.23689  seed: 0
epochs: 1 train loss: 0.45888485125641326  train f1: 0.43544  seed: 0 
epochs: 1 val loss: 1.4659244312959563  val f1:0.38394  seed: 0
epochs: 2 train loss: 0.30681735366138063  train f1: 0.57800  seed: 0 
epochs: 2 val loss: 1.1806856043198528  val f1:0.56742  seed: 0
epochs: 3 train loss: 0.1757539208255598  train f1: 0.77567  seed: 0 
epochs: 3 val loss: 1.2318240894990806  val f1:0.56313  seed: 0
epochs: 4 train loss: 0.12753613315411463  train f1: 0.80834  seed: 0 
epochs: 4 val loss: 1.016899557674633  val f1:0.63960  seed: 0
epochs: 5 train loss: 0.09589778843210706  train f1: 0.88199  seed: 0 
epochs: 5 val loss: 1.0065244786879597  val f1:0.66615  seed: 0
epochs: 6 train loss: 0.06765846707927647  train f1: 0.91697  seed: 0 
epochs: 6 val loss: 1.0319541482364427  val f1:0.63974  seed: 0
epochs: 7 train loss: 0.055299595220765094  train f1: 0.91837  seed: 0 
epochs: 7 val loss: 1.0884516098920036  val f1:0.65467  seed: 0
epochs: 8 train loss: 0.061519957300442366  train f1: 0.93424  seed: 0 
epochs: 8 val loss: 1.4092299517463232  val f1:0.63287  seed: 0
epochs: 9 train loss: 0.04511043206969307  train f1: 0.95479  seed: 0 
epochs: 9 val loss: 1.1415153952205885  val f1:0.69161  seed: 0
epochs: 10 train loss: 0.019611494754677387  train f1: 0.98530  seed: 0 
epochs: 10 val loss: 1.1817178165211397  val f1:0.69884  seed: 0
epochs: 11 train loss: 0.04510359977608297  train f1: 0.94258  seed: 0 
epochs: 11 val loss: 1.4841452205882353  val f1:0.64377  seed: 0
epochs: 12 train loss: 0.016945378104252604  train f1: 0.98546  seed: 0 
epochs: 12 val loss: 1.3842181037454044  val f1:0.66352  seed: 0
epochs: 13 train loss: 0.02715724350801155  train f1: 0.97786  seed: 0 
epochs: 13 val loss: 0.9773460836971509  val f1:0.71304  seed: 0
epochs: 14 train loss: 0.031068179144788148  train f1: 0.96045  seed: 0 
epochs: 14 val loss: 1.1468434053308822  val f1:0.67954  seed: 0
epochs: 15 train loss: 0.026164732762237103  train f1: 0.97133  seed: 0 
epochs: 15 val loss: 1.1754437614889706  val f1:0.68853  seed: 0
epochs: 16 train loss: 0.03146084475873121  train f1: 0.97161  seed: 0 
epochs: 16 val loss: 1.2768123851102942  val f1:0.68541  seed: 0
epochs: 17 train loss: 0.03765961305419012  train f1: 0.96258  seed: 0 
epochs: 17 val loss: 1.1283246208639703  val f1:0.70800  seed: 0
epochs: 18 train loss: 0.024244418784753596  train f1: 0.97765  seed: 0 
epochs: 18 val loss: 1.5821497300091916  val f1:0.68814  seed: 0
epochs: 19 train loss: 0.019650576719597204  train f1: 0.98037  seed: 0 
epochs: 19 val loss: 1.1725912655101103  val f1:0.71604  seed: 0
epochs: 20 train loss: 0.033756492742851606  train f1: 0.97356  seed: 0 
epochs: 20 val loss: 1.1930398380055145  val f1:0.71483  seed: 0
epochs: 21 train loss: 0.03028058738850837  train f1: 0.96379  seed: 0 
epochs: 21 val loss: 1.2151273839613974  val f1:0.70943  seed: 0
epochs: 22 train loss: 0.01759429298230071  train f1: 0.97422  seed: 0 
epochs: 22 val loss: 1.1698716107536766  val f1:0.71241  seed: 0
epochs: 23 train loss: 0.02587211043087404  train f1: 0.97678  seed: 0 
epochs: 23 val loss: 0.9449373133042284  val f1:0.75646  seed: 0
epochs: 24 train loss: 0.02030856662721777  train f1: 0.98135  seed: 0 
epochs: 24 val loss: 1.6281924528234133  val f1:0.70243  seed: 0
epochs: 25 train loss: 0.053824008400760445  train f1: 0.95183  seed: 0 
epochs: 25 val loss: 1.153910328360165  val f1:0.70365  seed: 0
epochs: 26 train loss: 0.0433845947037882  train f1: 0.95744  seed: 0 
epochs: 26 val loss: 1.1263643152573537  val f1:0.72311  seed: 0
epochs: 27 train loss: 0.01504977336570398  train f1: 0.98108  seed: 0 
epochs: 27 val loss: 1.045691995059743  val f1:0.72171  seed: 0
epochs: 28 train loss: 0.025467015024441392  train f1: 0.98401  seed: 0 
epochs: 28 val loss: 1.0446633731617647  val f1:0.72306  seed: 0
epochs: 29 train loss: 0.013987266305667245  train f1: 0.98384  seed: 0 
epochs: 29 val loss: 0.9832135368795956  val f1:0.75389  seed: 0
epochs: 0 train loss: 0.9388773903917902  train f1: 0.20303  seed: 0 
epochs: 0 val loss: 2.0087603400735294  val f1:0.26325  seed: 0
epochs: 1 train loss: 0.453935310022155  train f1: 0.44147  seed: 0 
epochs: 1 val loss: 1.526044060202206  val f1:0.43416  seed: 0
epochs: 2 train loss: 0.3072139683054452  train f1: 0.58126  seed: 0 
epochs: 2 val loss: 1.2055592256433825  val f1:0.50162  seed: 0
epochs: 3 train loss: 0.18426362792057785  train f1: 0.74491  seed: 0 
epochs: 3 val loss: 1.0238898782169115  val f1:0.59270  seed: 0
epochs: 4 train loss: 0.1444344022380772  train f1: 0.80474  seed: 0 
epochs: 4 val loss: 0.9215123793658089  val f1:0.64747  seed: 0
epochs: 5 train loss: 0.10102922524978866  train f1: 0.85961  seed: 0 
epochs: 5 val loss: 0.8774270450367646  val f1:0.67214  seed: 0
epochs: 6 train loss: 0.07105490698743225  train f1: 0.90123  seed: 0 
epochs: 6 val loss: 0.8783300063189339  val f1:0.70238  seed: 0
epochs: 7 train loss: 0.05325826958044252  train f1: 0.93086  seed: 0 
epochs: 7 val loss: 0.8304802389705882  val f1:0.70403  seed: 0
epochs: 8 train loss: 0.05614951119494083  train f1: 0.92843  seed: 0 
epochs: 8 val loss: 0.7867000804227945  val f1:0.74217  seed: 0
epochs: 9 train loss: 0.033601301819530874  train f1: 0.96577  seed: 0 
epochs: 9 val loss: 0.9083350686465993  val f1:0.72801  seed: 0
epochs: 10 train loss: 0.03584451817754489  train f1: 0.95143  seed: 0 
epochs: 10 val loss: 0.8259708180147061  val f1:0.74238  seed: 0
epochs: 11 train loss: 0.016309213282457036  train f1: 0.98408  seed: 0 
epochs: 11 val loss: 0.8936013614430146  val f1:0.73034  seed: 0
epochs: 12 train loss: 0.02559481449981234  train f1: 0.97744  seed: 0 
epochs: 12 val loss: 1.098859001608456  val f1:0.70662  seed: 0
epochs: 13 train loss: 0.02721726360605723  train f1: 0.97594  seed: 0 
epochs: 13 val loss: 0.933401668772978  val f1:0.73589  seed: 0
epochs: 14 train loss: 0.04185248132961898  train f1: 0.94556  seed: 0 
epochs: 14 val loss: 1.0924287683823528  val f1:0.68081  seed: 0
epochs: 15 train loss: 0.039983792091483485  train f1: 0.95624  seed: 0 
epochs: 15 val loss: 0.9478391759535846  val f1:0.69642  seed: 0
epochs: 16 train loss: 0.03380824202921854  train f1: 0.96894  seed: 0 
epochs: 16 val loss: 0.9714822208180147  val f1:0.72353  seed: 0
epochs: 17 train loss: 0.05066917191690472  train f1: 0.94973  seed: 0 
epochs: 17 val loss: 1.066131591796875  val f1:0.68675  seed: 0
epochs: 18 train loss: 0.035866182241866836  train f1: 0.96582  seed: 0 
epochs: 18 val loss: 0.9559900620404411  val f1:0.70034  seed: 0
epochs: 19 train loss: 0.013159428959462182  train f1: 0.98619  seed: 0 
epochs: 19 val loss: 0.881975959329044  val f1:0.73732  seed: 0
epochs: 20 train loss: 0.023969125391832043  train f1: 0.97539  seed: 0 
epochs: 20 val loss: 0.8954503676470585  val f1:0.72175  seed: 0
epochs: 21 train loss: 0.02012851700853946  train f1: 0.98016  seed: 0 
epochs: 21 val loss: 0.9824793198529411  val f1:0.71580  seed: 0
epochs: 22 train loss: 0.022553473266203015  train f1: 0.97689  seed: 0 
epochs: 22 val loss: 1.0227122587316175  val f1:0.71934  seed: 0
epochs: 23 train loss: 0.024399982459509563  train f1: 0.97288  seed: 0 
epochs: 23 val loss: 1.105712890625  val f1:0.69236  seed: 0
epochs: 24 train loss: 0.011107252604925816  train f1: 0.98765  seed: 0 
epochs: 24 val loss: 0.8855608771829047  val f1:0.75539  seed: 0
epochs: 25 train loss: 0.014363450345708361  train f1: 0.98688  seed: 0 
epochs: 25 val loss: 0.9314682904411765  val f1:0.75255  seed: 0
epochs: 26 train loss: 0.023674263882992878  train f1: 0.97729  seed: 0 
epochs: 26 val loss: 1.2414586684283087  val f1:0.71482  seed: 0
epochs: 27 train loss: 0.00859058659468124  train f1: 0.99301  seed: 0 
epochs: 27 val loss: 1.1822078929227937  val f1:0.72999  seed: 0
epochs: 28 train loss: 0.012652034634974463  train f1: 0.98868  seed: 0 
epochs: 28 val loss: 0.8813440659466913  val f1:0.75443  seed: 0
epochs: 29 train loss: 0.04080320650072241  train f1: 0.94728  seed: 0 
epochs: 29 val loss: 0.9281221277573529  val f1:0.72309  seed: 0
epochs: 0 train loss: 0.9513886864505593  train f1: 0.21717  seed: 1 
epochs: 0 val loss: 1.9837574678308825  val f1:0.26614  seed: 1
epochs: 1 train loss: 0.460811330311334  train f1: 0.40503  seed: 1 
epochs: 1 val loss: 1.3381419462316173  val f1:0.41764  seed: 1
epochs: 2 train loss: 0.28363242078183315  train f1: 0.61003  seed: 1 
epochs: 2 val loss: 1.1999942555147058  val f1:0.53719  seed: 1
epochs: 3 train loss: 0.2063596355381296  train f1: 0.68909  seed: 1 
epochs: 3 val loss: 0.8787626378676469  val f1:0.64363  seed: 1
epochs: 4 train loss: 0.1228776618615905  train f1: 0.83569  seed: 1 
epochs: 4 val loss: 0.8842091279871326  val f1:0.64099  seed: 1
epochs: 5 train loss: 0.08627379118506591  train f1: 0.85879  seed: 1 
epochs: 5 val loss: 0.9077363855698533  val f1:0.66540  seed: 1
epochs: 6 train loss: 0.09214324381814075  train f1: 0.88379  seed: 1 
epochs: 6 val loss: 1.1119384765624996  val f1:0.63146  seed: 1
epochs: 7 train loss: 0.05417546229575997  train f1: 0.91207  seed: 1 
epochs: 7 val loss: 0.8367094152113969  val f1:0.69907  seed: 1
epochs: 8 train loss: 0.050758867121454485  train f1: 0.93457  seed: 1 
epochs: 8 val loss: 0.8512887393727021  val f1:0.70018  seed: 1
epochs: 9 train loss: 0.04083710997851925  train f1: 0.94314  seed: 1 
epochs: 9 val loss: 0.9056199017693015  val f1:0.72911  seed: 1
epochs: 10 train loss: 0.022555290763057873  train f1: 0.96924  seed: 1 
epochs: 10 val loss: 1.0164615406709558  val f1:0.68992  seed: 1
epochs: 11 train loss: 0.024903115941517392  train f1: 0.97463  seed: 1 
epochs: 11 val loss: 0.9626321231617643  val f1:0.71737  seed: 1
epochs: 12 train loss: 0.017484647124560906  train f1: 0.97904  seed: 1 
epochs: 12 val loss: 0.8817336138556986  val f1:0.73226  seed: 1
epochs: 13 train loss: 0.042695568568670926  train f1: 0.94990  seed: 1 
epochs: 13 val loss: 1.0958718692555147  val f1:0.70295  seed: 1
epochs: 14 train loss: 0.04258936554638308  train f1: 0.96427  seed: 1 
epochs: 14 val loss: 1.0058333453010109  val f1:0.70791  seed: 1
epochs: 15 train loss: 0.04838411131901528  train f1: 0.94854  seed: 1 
epochs: 15 val loss: 1.064804974724265  val f1:0.70904  seed: 1
epochs: 16 train loss: 0.020812191180328826  train f1: 0.98079  seed: 1 
epochs: 16 val loss: 1.0962811638327201  val f1:0.71818  seed: 1
epochs: 17 train loss: 0.021659966725022045  train f1: 0.96537  seed: 1 
epochs: 17 val loss: 1.0472537769990806  val f1:0.72918  seed: 1
epochs: 18 train loss: 0.021271755446248982  train f1: 0.96936  seed: 1 
epochs: 18 val loss: 1.0999661613913136  val f1:0.72270  seed: 1
epochs: 19 train loss: 0.028694028285012316  train f1: 0.97047  seed: 1 
epochs: 19 val loss: 0.8873237161075366  val f1:0.72349  seed: 1
epochs: 20 train loss: 0.019629447317835117  train f1: 0.97362  seed: 1 
epochs: 20 val loss: 1.147940242991728  val f1:0.69848  seed: 1
epochs: 21 train loss: 0.021650514495906544  train f1: 0.97509  seed: 1 
epochs: 21 val loss: 1.054795209099265  val f1:0.73397  seed: 1
epochs: 22 train loss: 0.019677333867371968  train f1: 0.98534  seed: 1 
epochs: 22 val loss: 0.9781188964843751  val f1:0.74134  seed: 1
epochs: 23 train loss: 0.028472128199107605  train f1: 0.97931  seed: 1 
epochs: 23 val loss: 1.0830114028033087  val f1:0.71620  seed: 1
epochs: 24 train loss: 0.027995689591365086  train f1: 0.97662  seed: 1 
epochs: 24 val loss: 1.0307294060202203  val f1:0.73816  seed: 1
epochs: 25 train loss: 0.016998953783690034  train f1: 0.98459  seed: 1 
epochs: 25 val loss: 1.107646493350758  val f1:0.74851  seed: 1
epochs: 26 train loss: 0.022307417285976135  train f1: 0.98581  seed: 1 
epochs: 26 val loss: 1.0137629789464617  val f1:0.73880  seed: 1
epochs: 27 train loss: 0.014417654987591417  train f1: 0.98944  seed: 1 
epochs: 27 val loss: 1.1075977998621325  val f1:0.74969  seed: 1
epochs: 28 train loss: 0.0073822963593611094  train f1: 0.99194  seed: 1 
epochs: 28 val loss: 1.2373298196231617  val f1:0.73027  seed: 1
epochs: 29 train loss: 0.01331587335956631  train f1: 0.98829  seed: 1 
epochs: 29 val loss: 1.1522755342371325  val f1:0.72775  seed: 1
epochs: 0 train loss: 0.9429931640624999  train f1: 0.22010  seed: 2 
epochs: 0 val loss: 1.8782743566176465  val f1:0.30419  seed: 2
epochs: 1 train loss: 0.4350768131996267  train f1: 0.46752  seed: 2 
epochs: 1 val loss: 1.398918600643382  val f1:0.41972  seed: 2
epochs: 2 train loss: 0.28423981168376855  train f1: 0.58814  seed: 2 
epochs: 2 val loss: 0.9348826688878675  val f1:0.55674  seed: 2
epochs: 3 train loss: 0.18457748640829053  train f1: 0.74163  seed: 2 
epochs: 3 val loss: 0.7557714125689339  val f1:0.64951  seed: 2
epochs: 4 train loss: 0.13575383086702716  train f1: 0.80789  seed: 2 
epochs: 4 val loss: 0.7421372357536763  val f1:0.67454  seed: 2
epochs: 5 train loss: 0.094986275060853  train f1: 0.86389  seed: 2 
epochs: 5 val loss: 0.8013987821691174  val f1:0.70262  seed: 2
epochs: 6 train loss: 0.06814842081781644  train f1: 0.92470  seed: 2 
epochs: 6 val loss: 0.9148059171788833  val f1:0.69538  seed: 2
epochs: 7 train loss: 0.04788229358730032  train f1: 0.93886  seed: 2 
epochs: 7 val loss: 0.9415157542509192  val f1:0.68431  seed: 2
epochs: 8 train loss: 0.057936931723978964  train f1: 0.92863  seed: 2 
epochs: 8 val loss: 0.8782245411592372  val f1:0.71605  seed: 2
epochs: 9 train loss: 0.04799816501674367  train f1: 0.95444  seed: 2 
epochs: 9 val loss: 0.8446134679457722  val f1:0.73017  seed: 2
epochs: 10 train loss: 0.04459984622784518  train f1: 0.95057  seed: 2 
epochs: 10 val loss: 1.003369499655331  val f1:0.70067  seed: 2
epochs: 11 train loss: 0.023950334805161212  train f1: 0.97298  seed: 2 
epochs: 11 val loss: 0.8980317957261029  val f1:0.73498  seed: 2
epochs: 12 train loss: 0.04046540829672742  train f1: 0.96257  seed: 2 
epochs: 12 val loss: 0.9783002068014708  val f1:0.70687  seed: 2
epochs: 13 train loss: 0.037491446110739644  train f1: 0.96455  seed: 2 
epochs: 13 val loss: 0.9377202426686007  val f1:0.71971  seed: 2
epochs: 14 train loss: 0.021911815031250923  train f1: 0.97648  seed: 2 
epochs: 14 val loss: 0.8487378288717831  val f1:0.74468  seed: 2
epochs: 15 train loss: 0.007647978725718034  train f1: 0.99047  seed: 2 
epochs: 15 val loss: 0.9327288234935088  val f1:0.73950  seed: 2
epochs: 16 train loss: 0.021624225289074348  train f1: 0.98413  seed: 2 
epochs: 16 val loss: 1.2632948931525734  val f1:0.68052  seed: 2
epochs: 17 train loss: 0.03814760606680344  train f1: 0.96388  seed: 2 
epochs: 17 val loss: 1.0269741731531479  val f1:0.72390  seed: 2
epochs: 18 train loss: 0.05124948095919479  train f1: 0.94710  seed: 2 
epochs: 18 val loss: 0.9935863719266999  val f1:0.70530  seed: 2
epochs: 19 train loss: 0.018028406509712564  train f1: 0.98770  seed: 2 
epochs: 19 val loss: 0.833142224480124  val f1:0.74018  seed: 2
epochs: 20 train loss: 0.00651468803633505  train f1: 0.99313  seed: 2 
epochs: 20 val loss: 0.7834982591516831  val f1:0.77021  seed: 2
epochs: 21 train loss: 0.013555003191108132  train f1: 0.99034  seed: 2 
epochs: 21 val loss: 0.9547379437614889  val f1:0.74583  seed: 2
epochs: 22 train loss: 0.013226238649282886  train f1: 0.98311  seed: 2 
epochs: 22 val loss: 1.1800133200252756  val f1:0.72559  seed: 2
epochs: 23 train loss: 0.011151347587357707  train f1: 0.97688  seed: 2 
epochs: 23 val loss: 0.9949251062729779  val f1:0.74603  seed: 2
epochs: 24 train loss: 0.010296425267831606  train f1: 0.99472  seed: 2 
epochs: 24 val loss: 1.0231290705063765  val f1:0.74275  seed: 2
epochs: 25 train loss: 0.017552019944831507  train f1: 0.97410  seed: 2 
epochs: 25 val loss: 1.0479682473575371  val f1:0.71913  seed: 2
epochs: 26 train loss: 0.02651102952103118  train f1: 0.97684  seed: 2 
epochs: 26 val loss: 1.2789701573988967  val f1:0.73347  seed: 2
epochs: 27 train loss: 0.06874290153161805  train f1: 0.93675  seed: 2 
epochs: 27 val loss: 1.205702837775735  val f1:0.68381  seed: 2
epochs: 28 train loss: 0.045288477370988095  train f1: 0.94724  seed: 2 
epochs: 28 val loss: 1.4686036951401653  val f1:0.68559  seed: 2
epochs: 29 train loss: 0.023943117305414003  train f1: 0.97345  seed: 2 
epochs: 29 val loss: 1.74856387867647  val f1:0.68441  seed: 2
epochs: 0 train loss: 0.9476846723414178  train f1: 0.21463  seed: 3 
epochs: 0 val loss: 1.7832749310661762  val f1:0.27556  seed: 3
epochs: 1 train loss: 0.4224065524428639  train f1: 0.47014  seed: 3 
epochs: 1 val loss: 1.2983111213235294  val f1:0.45047  seed: 3
epochs: 2 train loss: 0.26958568060576016  train f1: 0.63419  seed: 3 
epochs: 2 val loss: 1.015768612132353  val f1:0.56348  seed: 3
epochs: 3 train loss: 0.17825317382812506  train f1: 0.74374  seed: 3 
epochs: 3 val loss: 0.7677414838005516  val f1:0.66305  seed: 3
epochs: 4 train loss: 0.11370991948825208  train f1: 0.84357  seed: 3 
epochs: 4 val loss: 0.8116347369025737  val f1:0.64954  seed: 3
epochs: 5 train loss: 0.07972370688594992  train f1: 0.90106  seed: 3 
epochs: 5 val loss: 0.7959666532628676  val f1:0.72621  seed: 3
epochs: 6 train loss: 0.053474226994300995  train f1: 0.92973  seed: 3 
epochs: 6 val loss: 0.7181549072265627  val f1:0.74718  seed: 3
epochs: 7 train loss: 0.03721080609221955  train f1: 0.95537  seed: 3 
epochs: 7 val loss: 0.7628137925091911  val f1:0.72790  seed: 3
epochs: 8 train loss: 0.05324320294963778  train f1: 0.93107  seed: 3 
epochs: 8 val loss: 1.0123578239889708  val f1:0.67424  seed: 3
epochs: 9 train loss: 0.04582963772674104  train f1: 0.94644  seed: 3 
epochs: 9 val loss: 0.8498535156250002  val f1:0.72291  seed: 3
epochs: 0 train loss: 0.9230030682070037  train f1: 0.24152  seed: 0 
epochs: 0 val loss: 1.7441119025735294  val f1:0.28119  seed: 0
epochs: 1 train loss: 0.41701188324191035  train f1: 0.46475  seed: 0 
epochs: 1 val loss: 1.2209400850183822  val f1:0.45415  seed: 0
epochs: 2 train loss: 0.25796270708665775  train f1: 0.64732  seed: 0 
epochs: 2 val loss: 1.0938397575827208  val f1:0.55908  seed: 0
epochs: 3 train loss: 0.16630067216589103  train f1: 0.75935  seed: 0 
epochs: 3 val loss: 0.9336763269761025  val f1:0.66458  seed: 0
epochs: 4 train loss: 0.11119815474706336  train f1: 0.84593  seed: 0 
epochs: 4 val loss: 1.0430477366727942  val f1:0.65766  seed: 0
epochs: 5 train loss: 0.07643476445624171  train f1: 0.89850  seed: 0 
epochs: 5 val loss: 1.0330702837775732  val f1:0.66943  seed: 0
epochs: 6 train loss: 0.05511984588406612  train f1: 0.93717  seed: 0 
epochs: 6 val loss: 0.8930664062500001  val f1:0.68770  seed: 0
epochs: 7 train loss: 0.05331163879827405  train f1: 0.94054  seed: 0 
epochs: 7 val loss: 0.8710829790900736  val f1:0.71001  seed: 0
epochs: 8 train loss: 0.06838615566280715  train f1: 0.92673  seed: 0 
epochs: 8 val loss: 1.0531652113970593  val f1:0.69984  seed: 0
epochs: 9 train loss: 0.049308411618496494  train f1: 0.94531  seed: 0 
epochs: 9 val loss: 0.9023922190946689  val f1:0.70810  seed: 0
epochs: 10 train loss: 0.036470656699322646  train f1: 0.96260  seed: 0 
epochs: 10 val loss: 1.0474745806525734  val f1:0.69504  seed: 0
epochs: 11 train loss: 0.04629490223336727  train f1: 0.95830  seed: 0 
epochs: 11 val loss: 1.0762867647058825  val f1:0.69863  seed: 0
epochs: 12 train loss: 0.030221036139954922  train f1: 0.96899  seed: 0 
epochs: 12 val loss: 0.8494639677159925  val f1:0.72921  seed: 0
epochs: 13 train loss: 0.02815963359589273  train f1: 0.97610  seed: 0 
epochs: 13 val loss: 0.8354321648092831  val f1:0.73455  seed: 0
epochs: 14 train loss: 0.029788588801174295  train f1: 0.97171  seed: 0 
epochs: 14 val loss: 0.9067113539751839  val f1:0.73293  seed: 0
epochs: 15 train loss: 0.010796166480855745  train f1: 0.98941  seed: 0 
epochs: 15 val loss: 0.9214764763327203  val f1:0.75266  seed: 0
epochs: 16 train loss: 0.01704687852386042  train f1: 0.98049  seed: 0 
epochs: 16 val loss: 0.9661506204044119  val f1:0.74053  seed: 0
epochs: 17 train loss: 0.03453174973210546  train f1: 0.97034  seed: 0 
epochs: 17 val loss: 0.9773523667279411  val f1:0.73396  seed: 0
epochs: 18 train loss: 0.03441850006157624  train f1: 0.96841  seed: 0 
epochs: 18 val loss: 1.1731962316176467  val f1:0.70807  seed: 0
epochs: 19 train loss: 0.024094855531733083  train f1: 0.97699  seed: 0 
epochs: 19 val loss: 0.935085521024816  val f1:0.72912  seed: 0
epochs: 20 train loss: 0.02119604154681484  train f1: 0.98145  seed: 0 
epochs: 20 val loss: 1.0551389806410845  val f1:0.72863  seed: 0
#################################################################################
2022.04.10 ( batchsize, lr 최적점 알아내깅)
#################################################################################epochs: 0 train loss: 1.2753839314207154  train f1: 0.17268  lr: 0.001 batch: 4 
epochs: 0 val loss: 3.6002786438186445  val f1:0.12860  lr: 0.001 batch: 4
epochs: 1 train loss: 0.7900191299924242  train f1: 0.22776  lr: 0.001 batch: 4 
epochs: 1 val loss: 2.975511455358956  val f1:0.16912  lr: 0.001 batch: 4
epochs: 2 train loss: 0.6370017448168127  train f1: 0.27057  lr: 0.001 batch: 4 
epochs: 2 val loss: 3.1055238932536966  val f1:0.19143  lr: 0.001 batch: 4
epochs: 3 train loss: 0.5941163538100578  train f1: 0.31251  lr: 0.001 batch: 4 
epochs: 3 val loss: 3.198993909336864  val f1:0.20831  lr: 0.001 batch: 4
epochs: 4 train loss: 0.5655832897857779  train f1: 0.33679  lr: 0.001 batch: 4 
epochs: 4 val loss: 2.9669289951642956  val f1:0.21372  lr: 0.001 batch: 4
epochs: 5 train loss: 0.5036334848582514  train f1: 0.38492  lr: 0.001 batch: 4 
epochs: 5 val loss: 3.2922414238245015  val f1:0.25776  lr: 0.001 batch: 4
epochs: 6 train loss: 0.4893907286254653  train f1: 0.41636  lr: 0.001 batch: 4 
epochs: 6 val loss: 2.996524832023096  val f1:0.23667  lr: 0.001 batch: 4
epochs: 7 train loss: 0.44196600949719617  train f1: 0.48877  lr: 0.001 batch: 4 
epochs: 7 val loss: 2.898429771522425  val f1:0.26762  lr: 0.001 batch: 4
epochs: 8 train loss: 0.4198735456788135  train f1: 0.48734  lr: 0.001 batch: 4 
epochs: 8 val loss: 3.3466601256758053  val f1:0.21928  lr: 0.001 batch: 4
epochs: 9 train loss: 0.38099798682923647  train f1: 0.52648  lr: 0.001 batch: 4 
epochs: 9 val loss: 3.5477059599641114  val f1:0.25150  lr: 0.001 batch: 4
epochs: 10 train loss: 0.4033744402146065  train f1: 0.50348  lr: 0.001 batch: 4 
epochs: 10 val loss: 3.1671262610157713  val f1:0.30688  lr: 0.001 batch: 4
epochs: 11 train loss: 0.3515113250593121  train f1: 0.57100  lr: 0.001 batch: 4 
epochs: 11 val loss: 3.732479921740816  val f1:0.30112  lr: 0.001 batch: 4
epochs: 12 train loss: 0.3310982189821392  train f1: 0.60142  lr: 0.001 batch: 4 
epochs: 12 val loss: 3.9311760387526826  val f1:0.29735  lr: 0.001 batch: 4
epochs: 13 train loss: 0.3245849397298551  train f1: 0.60367  lr: 0.001 batch: 4 
epochs: 13 val loss: 4.045230766395469  val f1:0.31143  lr: 0.001 batch: 4
epochs: 14 train loss: 0.31406738516989746  train f1: 0.61712  lr: 0.001 batch: 4 
epochs: 14 val loss: 3.5169527942041743  val f1:0.31429  lr: 0.001 batch: 4
epochs: 15 train loss: 0.2901662804660727  train f1: 0.63067  lr: 0.001 batch: 4 
epochs: 15 val loss: 3.5551290352844354  val f1:0.36125  lr: 0.001 batch: 4
epochs: 16 train loss: 0.2802798051512643  train f1: 0.66167  lr: 0.001 batch: 4 
epochs: 16 val loss: 5.999109979463199  val f1:0.29282  lr: 0.001 batch: 4
epochs: 17 train loss: 0.26992801936824656  train f1: 0.65379  lr: 0.001 batch: 4 
epochs: 17 val loss: 4.933155806475984  val f1:0.33366  lr: 0.001 batch: 4
epochs: 18 train loss: 0.2546404620234885  train f1: 0.68266  lr: 0.001 batch: 4 
epochs: 18 val loss: 4.328745005082113  val f1:0.30425  lr: 0.001 batch: 4
epochs: 19 train loss: 0.23634855175732675  train f1: 0.72249  lr: 0.001 batch: 4 
epochs: 19 val loss: 10.827500946667723  val f1:0.29237  lr: 0.001 batch: 4
epochs: 20 train loss: 0.2200930310545787  train f1: 0.72638  lr: 0.001 batch: 4 
epochs: 20 val loss: 3.5887095569900747  val f1:0.40349  lr: 0.001 batch: 4
epochs: 21 train loss: 0.2123825305633331  train f1: 0.74756  lr: 0.001 batch: 4 
epochs: 21 val loss: 4.717943616169946  val f1:0.34132  lr: 0.001 batch: 4
epochs: 0 train loss: 1.0604185611567698  train f1: 0.20387  lr: 0.0003 batch: 4 
epochs: 0 val loss: 2.7635902588796513  val f1:0.20194  lr: 0.0003 batch: 4
epochs: 1 train loss: 0.5649541486961561  train f1: 0.34662  lr: 0.0003 batch: 4 
epochs: 1 val loss: 1.971888837655089  val f1:0.33590  lr: 0.0003 batch: 4
epochs: 2 train loss: 0.4297915371169759  train f1: 0.48657  lr: 0.0003 batch: 4 
epochs: 2 val loss: 2.1904208868023183  val f1:0.37025  lr: 0.0003 batch: 4
epochs: 3 train loss: 0.35405434651321194  train f1: 0.55900  lr: 0.0003 batch: 4 
epochs: 3 val loss: 2.387780522150098  val f1:0.43646  lr: 0.0003 batch: 4
epochs: 4 train loss: 0.2662331367030123  train f1: 0.64249  lr: 0.0003 batch: 4 
epochs: 4 val loss: 2.5243067201745313  val f1:0.46195  lr: 0.0003 batch: 4
epochs: 5 train loss: 0.23392173748337797  train f1: 0.68777  lr: 0.0003 batch: 4 
epochs: 5 val loss: 2.836071442584601  val f1:0.41967  lr: 0.0003 batch: 4
epochs: 6 train loss: 0.18933991775307346  train f1: 0.75963  lr: 0.0003 batch: 4 
epochs: 6 val loss: 2.8686183317251657  val f1:0.41990  lr: 0.0003 batch: 4
epochs: 7 train loss: 0.1712859353322659  train f1: 0.77314  lr: 0.0003 batch: 4 
epochs: 7 val loss: 2.6414962538098163  val f1:0.49381  lr: 0.0003 batch: 4
epochs: 8 train loss: 0.14811890714623965  train f1: 0.81907  lr: 0.0003 batch: 4 
epochs: 8 val loss: 3.419831700139231  val f1:0.52945  lr: 0.0003 batch: 4
epochs: 9 train loss: 0.12427187373352393  train f1: 0.83125  lr: 0.0003 batch: 4 
epochs: 9 val loss: 2.8514214221090888  val f1:0.54122  lr: 0.0003 batch: 4
epochs: 10 train loss: 0.14949092570315578  train f1: 0.82694  lr: 0.0003 batch: 4 
epochs: 10 val loss: 3.0334480414806353  val f1:0.50365  lr: 0.0003 batch: 4
epochs: 11 train loss: 0.10744319967786033  train f1: 0.86521  lr: 0.0003 batch: 4 
epochs: 11 val loss: 3.322945438864497  val f1:0.51757  lr: 0.0003 batch: 4
epochs: 12 train loss: 0.10369503051600648  train f1: 0.88414  lr: 0.0003 batch: 4 
epochs: 12 val loss: 2.9013303041679284  val f1:0.51845  lr: 0.0003 batch: 4
epochs: 13 train loss: 0.08527778608075694  train f1: 0.89521  lr: 0.0003 batch: 4 
epochs: 13 val loss: 3.804989811883124  val f1:0.52595  lr: 0.0003 batch: 4
epochs: 14 train loss: 0.07698205537563856  train f1: 0.90624  lr: 0.0003 batch: 4 
epochs: 14 val loss: 3.670355073817368  val f1:0.52521  lr: 0.0003 batch: 4
epochs: 15 train loss: 0.08758256497901026  train f1: 0.88948  lr: 0.0003 batch: 4 
epochs: 15 val loss: 3.5479490803433675  val f1:0.55317  lr: 0.0003 batch: 4
epochs: 16 train loss: 0.09044173516137757  train f1: 0.89482  lr: 0.0003 batch: 4 
epochs: 16 val loss: 2.8366224829916176  val f1:0.55059  lr: 0.0003 batch: 4
epochs: 17 train loss: 0.07255033551530449  train f1: 0.90976  lr: 0.0003 batch: 4 
epochs: 17 val loss: 3.592286284646653  val f1:0.50730  lr: 0.0003 batch: 4
epochs: 18 train loss: 0.06581031656667088  train f1: 0.93589  lr: 0.0003 batch: 4 
epochs: 18 val loss: 4.586370898863379  val f1:0.50224  lr: 0.0003 batch: 4
epochs: 19 train loss: 0.07238712220379478  train f1: 0.92839  lr: 0.0003 batch: 4 
epochs: 19 val loss: 4.397010919667349  val f1:0.48810  lr: 0.0003 batch: 4
epochs: 20 train loss: 0.059261569090550296  train f1: 0.93024  lr: 0.0003 batch: 4 
epochs: 20 val loss: 3.8402219385959193  val f1:0.56528  lr: 0.0003 batch: 4
epochs: 21 train loss: 0.051732559105876645  train f1: 0.93525  lr: 0.0003 batch: 4 
epochs: 21 val loss: 4.178322191251674  val f1:0.51718  lr: 0.0003 batch: 4
epochs: 0 train loss: 1.1629135617602648  train f1: 0.17295  lr: 0.0001 batch: 4 
epochs: 0 val loss: 2.7264759368047207  val f1:0.16364  lr: 0.0001 batch: 4
epochs: 1 train loss: 0.6106559524821866  train f1: 0.28831  lr: 0.0001 batch: 4 
epochs: 1 val loss: 2.0243643511204183  val f1:0.27002  lr: 0.0001 batch: 4
epochs: 2 train loss: 0.45536293787009663  train f1: 0.43324  lr: 0.0001 batch: 4 
epochs: 2 val loss: 2.037633694169251  val f1:0.35546  lr: 0.0001 batch: 4
epochs: 3 train loss: 0.34327248598305954  train f1: 0.54203  lr: 0.0001 batch: 4 
epochs: 3 val loss: 1.951457977294922  val f1:0.47185  lr: 0.0001 batch: 4
epochs: 4 train loss: 0.2555772347396681  train f1: 0.66263  lr: 0.0001 batch: 4 
epochs: 4 val loss: 1.7804154235047183  val f1:0.49213  lr: 0.0001 batch: 4
epochs: 5 train loss: 0.19823476102914714  train f1: 0.74466  lr: 0.0001 batch: 4 
epochs: 5 val loss: 2.1354417075473866  val f1:0.52857  lr: 0.0001 batch: 4
epochs: 6 train loss: 0.1557831103435618  train f1: 0.79870  lr: 0.0001 batch: 4 
epochs: 6 val loss: 2.214020766221083  val f1:0.52999  lr: 0.0001 batch: 4
epochs: 7 train loss: 0.12662412410371765  train f1: 0.83921  lr: 0.0001 batch: 4 
epochs: 7 val loss: 2.184120041098798  val f1:0.54158  lr: 0.0001 batch: 4
epochs: 8 train loss: 0.10091672854477095  train f1: 0.87690  lr: 0.0001 batch: 4 
epochs: 8 val loss: 2.549471418136566  val f1:0.54253  lr: 0.0001 batch: 4
epochs: 9 train loss: 0.08367789238133233  train f1: 0.88570  lr: 0.0001 batch: 4 
epochs: 9 val loss: 2.6674215501668477  val f1:0.59192  lr: 0.0001 batch: 4
epochs: 10 train loss: 0.07001009142577423  train f1: 0.91151  lr: 0.0001 batch: 4 
epochs: 10 val loss: 2.356236959211459  val f1:0.59023  lr: 0.0001 batch: 4
epochs: 11 train loss: 0.055216956004667854  train f1: 0.92371  lr: 0.0001 batch: 4 
epochs: 11 val loss: 2.704494651925365  val f1:0.56741  lr: 0.0001 batch: 4
epochs: 12 train loss: 0.06306182874945673  train f1: 0.93277  lr: 0.0001 batch: 4 
epochs: 12 val loss: 2.487034541556475  val f1:0.57826  lr: 0.0001 batch: 4
epochs: 13 train loss: 0.0378040719902917  train f1: 0.96144  lr: 0.0001 batch: 4 
epochs: 13 val loss: 2.997634186483711  val f1:0.60744  lr: 0.0001 batch: 4
epochs: 14 train loss: 0.039235688215784395  train f1: 0.95864  lr: 0.0001 batch: 4 
epochs: 14 val loss: 2.8047199054640153  val f1:0.57843  lr: 0.0001 batch: 4
epochs: 15 train loss: 0.045931503120879506  train f1: 0.95299  lr: 0.0001 batch: 4 
epochs: 15 val loss: 2.9400546569549952  val f1:0.60619  lr: 0.0001 batch: 4
epochs: 16 train loss: 0.03980251231443568  train f1: 0.94706  lr: 0.0001 batch: 4 
epochs: 16 val loss: 3.023058445865019  val f1:0.61766  lr: 0.0001 batch: 4
epochs: 17 train loss: 0.02865813739514082  train f1: 0.98216  lr: 0.0001 batch: 4 
epochs: 17 val loss: 3.0841730961330733  val f1:0.61506  lr: 0.0001 batch: 4
epochs: 18 train loss: 0.03860503401649135  train f1: 0.96702  lr: 0.0001 batch: 4 
epochs: 18 val loss: 3.101684563456307  val f1:0.56569  lr: 0.0001 batch: 4
epochs: 19 train loss: 0.033782089805781595  train f1: 0.97231  lr: 0.0001 batch: 4 
epochs: 19 val loss: 3.301567330873521  val f1:0.60784  lr: 0.0001 batch: 4
epochs: 20 train loss: 0.03473599394608974  train f1: 0.96172  lr: 0.0001 batch: 4 
epochs: 20 val loss: 3.5575264390412884  val f1:0.52526  lr: 0.0001 batch: 4
epochs: 21 train loss: 0.02464604070793824  train f1: 0.97651  lr: 0.0001 batch: 4 
epochs: 21 val loss: 3.1408541077585532  val f1:0.58570  lr: 0.0001 batch: 4
epochs: 0 train loss: 1.1347237633408667  train f1: 0.19995  lr: 0.001 batch: 8 
epochs: 0 val loss: 2.7125890661168968  val f1:0.16099  lr: 0.001 batch: 8
epochs: 1 train loss: 0.68184464701106  train f1: 0.27925  lr: 0.001 batch: 8 
epochs: 1 val loss: 2.9988713299786625  val f1:0.20679  lr: 0.001 batch: 8
epochs: 2 train loss: 0.5310458779781498  train f1: 0.37376  lr: 0.001 batch: 8 
epochs: 2 val loss: 2.4829512984664364  val f1:0.26707  lr: 0.001 batch: 8
epochs: 3 train loss: 0.49973171391290694  train f1: 0.40034  lr: 0.001 batch: 8 
epochs: 3 val loss: 2.613202808521413  val f1:0.29189  lr: 0.001 batch: 8
epochs: 4 train loss: 0.42871420928154996  train f1: 0.49838  lr: 0.001 batch: 8 
epochs: 4 val loss: 2.4090928819444453  val f1:0.29809  lr: 0.001 batch: 8
epochs: 5 train loss: 0.3994037971067965  train f1: 0.51395  lr: 0.001 batch: 8 
epochs: 5 val loss: 2.503883644386573  val f1:0.30922  lr: 0.001 batch: 8
epochs: 6 train loss: 0.39410759000742523  train f1: 0.51050  lr: 0.001 batch: 8 
epochs: 6 val loss: 2.928658944589122  val f1:0.32165  lr: 0.001 batch: 8
epochs: 7 train loss: 0.33093112059746793  train f1: 0.60227  lr: 0.001 batch: 8 
epochs: 7 val loss: 4.200553385416668  val f1:0.27200  lr: 0.001 batch: 8
epochs: 8 train loss: 0.3387208681428035  train f1: 0.58578  lr: 0.001 batch: 8 
epochs: 8 val loss: 4.854121907552085  val f1:0.34237  lr: 0.001 batch: 8
epochs: 9 train loss: 0.2942337114712716  train f1: 0.63602  lr: 0.001 batch: 8 
epochs: 9 val loss: 2.5544230143229165  val f1:0.41953  lr: 0.001 batch: 8
epochs: 10 train loss: 0.28899102443166425  train f1: 0.63433  lr: 0.001 batch: 8 
epochs: 10 val loss: 2.467627179181135  val f1:0.37196  lr: 0.001 batch: 8
epochs: 11 train loss: 0.2605308772026374  train f1: 0.66847  lr: 0.001 batch: 8 
epochs: 11 val loss: 2.9957691333912067  val f1:0.40535  lr: 0.001 batch: 8
epochs: 12 train loss: 0.23885657992702292  train f1: 0.70124  lr: 0.001 batch: 8 
epochs: 12 val loss: 3.020594391999422  val f1:0.36549  lr: 0.001 batch: 8
epochs: 13 train loss: 0.21539945280953757  train f1: 0.74105  lr: 0.001 batch: 8 
epochs: 13 val loss: 3.586649802879052  val f1:0.42293  lr: 0.001 batch: 8
epochs: 14 train loss: 0.20858831977129855  train f1: 0.74510  lr: 0.001 batch: 8 
epochs: 14 val loss: 3.95385470920139  val f1:0.42253  lr: 0.001 batch: 8
epochs: 15 train loss: 0.20752050456929277  train f1: 0.73786  lr: 0.001 batch: 8 
epochs: 15 val loss: 3.449048473216867  val f1:0.42227  lr: 0.001 batch: 8
epochs: 16 train loss: 0.18630365307411448  train f1: 0.76753  lr: 0.001 batch: 8 
epochs: 16 val loss: 3.4203823513454834  val f1:0.48032  lr: 0.001 batch: 8
epochs: 17 train loss: 0.17776861351527526  train f1: 0.77827  lr: 0.001 batch: 8 
epochs: 17 val loss: 5.108517908166955  val f1:0.40229  lr: 0.001 batch: 8
epochs: 18 train loss: 0.18785853064462046  train f1: 0.78101  lr: 0.001 batch: 8 
epochs: 18 val loss: 3.61552259657118  val f1:0.49172  lr: 0.001 batch: 8
epochs: 19 train loss: 0.14441065216778806  train f1: 0.82498  lr: 0.001 batch: 8 
epochs: 19 val loss: 4.378082049334485  val f1:0.43903  lr: 0.001 batch: 8
epochs: 20 train loss: 0.17810040288203666  train f1: 0.79220  lr: 0.001 batch: 8 
epochs: 20 val loss: 3.402727254231771  val f1:0.49015  lr: 0.001 batch: 8
epochs: 21 train loss: 0.15173334575324457  train f1: 0.80620  lr: 0.001 batch: 8 
epochs: 21 val loss: 3.831318155924478  val f1:0.45333  lr: 0.001 batch: 8
epochs: 0 train loss: 0.972379520144802  train f1: 0.22754  lr: 0.0003 batch: 8 
epochs: 0 val loss: 2.415322084780093  val f1:0.23423  lr: 0.0003 batch: 8
epochs: 1 train loss: 0.47658392373988634  train f1: 0.45131  lr: 0.0003 batch: 8 
epochs: 1 val loss: 1.9027162905092587  val f1:0.41175  lr: 0.0003 batch: 8
epochs: 2 train loss: 0.3099741310662545  train f1: 0.56269  lr: 0.0003 batch: 8 
epochs: 2 val loss: 1.924581344039353  val f1:0.47701  lr: 0.0003 batch: 8
epochs: 3 train loss: 0.232838482445992  train f1: 0.69433  lr: 0.0003 batch: 8 
epochs: 3 val loss: 2.1152151884856036  val f1:0.51285  lr: 0.0003 batch: 8
epochs: 4 train loss: 0.18641852707452086  train f1: 0.74535  lr: 0.0003 batch: 8 
epochs: 4 val loss: 2.1826653939706304  val f1:0.54783  lr: 0.0003 batch: 8
epochs: 5 train loss: 0.1513607448406436  train f1: 0.80813  lr: 0.0003 batch: 8 
epochs: 5 val loss: 2.255731727458813  val f1:0.56237  lr: 0.0003 batch: 8
epochs: 6 train loss: 0.1289311982272716  train f1: 0.84011  lr: 0.0003 batch: 8 
epochs: 6 val loss: 2.2483641730414496  val f1:0.57980  lr: 0.0003 batch: 8
epochs: 7 train loss: 0.13085982839712942  train f1: 0.83049  lr: 0.0003 batch: 8 
epochs: 7 val loss: 2.5188867074471926  val f1:0.58049  lr: 0.0003 batch: 8
epochs: 8 train loss: 0.10632560583536106  train f1: 0.85712  lr: 0.0003 batch: 8 
epochs: 8 val loss: 2.4977788571958177  val f1:0.53505  lr: 0.0003 batch: 8
epochs: 9 train loss: 0.07779637994837668  train f1: 0.90512  lr: 0.0003 batch: 8 
epochs: 9 val loss: 2.5899523134584768  val f1:0.60035  lr: 0.0003 batch: 8
epochs: 10 train loss: 0.0620013399517045  train f1: 0.91827  lr: 0.0003 batch: 8 
epochs: 10 val loss: 2.4251515706380222  val f1:0.58389  lr: 0.0003 batch: 8
epochs: 11 train loss: 0.08868740448790985  train f1: 0.91179  lr: 0.0003 batch: 8 
epochs: 11 val loss: 2.8755425029330772  val f1:0.54733  lr: 0.0003 batch: 8
epochs: 12 train loss: 0.06408557932028607  train f1: 0.92157  lr: 0.0003 batch: 8 
epochs: 12 val loss: 2.9249798916004313  val f1:0.55873  lr: 0.0003 batch: 8
epochs: 13 train loss: 0.07875923572408129  train f1: 0.90310  lr: 0.0003 batch: 8 
epochs: 13 val loss: 3.303738890753853  val f1:0.56190  lr: 0.0003 batch: 8
epochs: 14 train loss: 0.0667999933721421  train f1: 0.93445  lr: 0.0003 batch: 8 
epochs: 14 val loss: 3.1276061305293323  val f1:0.57952  lr: 0.0003 batch: 8
epochs: 15 train loss: 0.042851104271992325  train f1: 0.95373  lr: 0.0003 batch: 8 
epochs: 15 val loss: 3.19008481061017  val f1:0.56745  lr: 0.0003 batch: 8
epochs: 16 train loss: 0.07286604267827569  train f1: 0.92029  lr: 0.0003 batch: 8 
epochs: 16 val loss: 2.8495793377911607  val f1:0.58915  lr: 0.0003 batch: 8
epochs: 17 train loss: 0.050153889459617164  train f1: 0.94860  lr: 0.0003 batch: 8 
epochs: 17 val loss: 2.876345948819762  val f1:0.58985  lr: 0.0003 batch: 8
epochs: 18 train loss: 0.02689776259861637  train f1: 0.96737  lr: 0.0003 batch: 8 
epochs: 18 val loss: 3.166059266196354  val f1:0.60109  lr: 0.0003 batch: 8
epochs: 19 train loss: 0.033194536015335535  train f1: 0.96963  lr: 0.0003 batch: 8 
epochs: 19 val loss: 3.160867473814225  val f1:0.59888  lr: 0.0003 batch: 8
epochs: 20 train loss: 0.06877543294474421  train f1: 0.94173  lr: 0.0003 batch: 8 
epochs: 20 val loss: 2.8014236547328815  val f1:0.61048  lr: 0.0003 batch: 8
epochs: 21 train loss: 0.05610440208224318  train f1: 0.93913  lr: 0.0003 batch: 8 
epochs: 21 val loss: 3.229848225028428  val f1:0.58279  lr: 0.0003 batch: 8
epochs: 0 train loss: 1.1028441239832054  train f1: 0.16728  lr: 0.0001 batch: 8 
epochs: 0 val loss: 2.2647316261574066  val f1:0.14930  lr: 0.0001 batch: 8
epochs: 1 train loss: 0.5925306113025219  train f1: 0.29401  lr: 0.0001 batch: 8 
epochs: 1 val loss: 1.9188340928819454  val f1:0.28593  lr: 0.0001 batch: 8
epochs: 2 train loss: 0.41970675179127914  train f1: 0.44871  lr: 0.0001 batch: 8 
epochs: 2 val loss: 1.709383138020833  val f1:0.39240  lr: 0.0001 batch: 8
epochs: 3 train loss: 0.29562317208850863  train f1: 0.58791  lr: 0.0001 batch: 8 
epochs: 3 val loss: 1.8561654550057858  val f1:0.48580  lr: 0.0001 batch: 8
epochs: 4 train loss: 0.21588553739397703  train f1: 0.71882  lr: 0.0001 batch: 8 
epochs: 4 val loss: 1.8669738769531252  val f1:0.51517  lr: 0.0001 batch: 8
epochs: 5 train loss: 0.16698115773861777  train f1: 0.77153  lr: 0.0001 batch: 8 
epochs: 5 val loss: 1.7526987711588535  val f1:0.55264  lr: 0.0001 batch: 8
epochs: 6 train loss: 0.12433404422431404  train f1: 0.83770  lr: 0.0001 batch: 8 
epochs: 6 val loss: 1.944590194137009  val f1:0.56830  lr: 0.0001 batch: 8
epochs: 7 train loss: 0.08842142735527693  train f1: 0.88010  lr: 0.0001 batch: 8 
epochs: 7 val loss: 1.9495296407628941  val f1:0.59732  lr: 0.0001 batch: 8
epochs: 8 train loss: 0.07427596778012392  train f1: 0.90128  lr: 0.0001 batch: 8 
epochs: 8 val loss: 2.1740720113118512  val f1:0.62015  lr: 0.0001 batch: 8
epochs: 9 train loss: 0.05563946341753901  train f1: 0.93955  lr: 0.0001 batch: 8 
epochs: 9 val loss: 2.200395887869376  val f1:0.59896  lr: 0.0001 batch: 8
epochs: 10 train loss: 0.053174412875586205  train f1: 0.93844  lr: 0.0001 batch: 8 
epochs: 10 val loss: 2.241827841158267  val f1:0.61933  lr: 0.0001 batch: 8
epochs: 11 train loss: 0.05472963869794923  train f1: 0.93530  lr: 0.0001 batch: 8 
epochs: 11 val loss: 2.345444032880996  val f1:0.60778  lr: 0.0001 batch: 8
epochs: 12 train loss: 0.05378610130106466  train f1: 0.93752  lr: 0.0001 batch: 8 
epochs: 12 val loss: 2.3288410151446315  val f1:0.61720  lr: 0.0001 batch: 8
epochs: 13 train loss: 0.023905556300159718  train f1: 0.97084  lr: 0.0001 batch: 8 
epochs: 13 val loss: 2.5353258433165387  val f1:0.61672  lr: 0.0001 batch: 8
epochs: 14 train loss: 0.029956007383289417  train f1: 0.97095  lr: 0.0001 batch: 8 
epochs: 14 val loss: 2.439559196542811  val f1:0.61809  lr: 0.0001 batch: 8
epochs: 15 train loss: 0.03076140666275882  train f1: 0.96873  lr: 0.0001 batch: 8 
epochs: 15 val loss: 2.5737942448368774  val f1:0.63386  lr: 0.0001 batch: 8
epochs: 16 train loss: 0.02953316600581679  train f1: 0.96932  lr: 0.0001 batch: 8 
epochs: 16 val loss: 2.5155662518960473  val f1:0.61647  lr: 0.0001 batch: 8
epochs: 17 train loss: 0.028737906771206228  train f1: 0.97755  lr: 0.0001 batch: 8 
epochs: 17 val loss: 2.8258362134297714  val f1:0.63170  lr: 0.0001 batch: 8
epochs: 18 train loss: 0.019400433319784725  train f1: 0.97380  lr: 0.0001 batch: 8 
epochs: 18 val loss: 2.829469199754574  val f1:0.60743  lr: 0.0001 batch: 8
epochs: 19 train loss: 0.028148941891023706  train f1: 0.97417  lr: 0.0001 batch: 8 
epochs: 19 val loss: 2.851326190100775  val f1:0.64060  lr: 0.0001 batch: 8
epochs: 20 train loss: 0.018738376960325775  train f1: 0.97953  lr: 0.0001 batch: 8 
epochs: 20 val loss: 2.8871818816220323  val f1:0.63916  lr: 0.0001 batch: 8
epochs: 21 train loss: 0.020484447032771302  train f1: 0.98407  lr: 0.0001 batch: 8 
epochs: 21 val loss: 2.9441469322752054  val f1:0.62931  lr: 0.0001 batch: 8
epochs: 0 train loss: 1.0514327488588482  train f1: 0.21056  lr: 0.001 batch: 16 
epochs: 0 val loss: 2.4003399884259258  val f1:0.20647  lr: 0.001 batch: 16
epochs: 1 train loss: 0.6226900365022238  train f1: 0.31996  lr: 0.001 batch: 16 
epochs: 1 val loss: 2.417100694444445  val f1:0.26986  lr: 0.001 batch: 16
epochs: 2 train loss: 0.480860335103581  train f1: 0.43436  lr: 0.001 batch: 16 
epochs: 2 val loss: 2.3615523726851855  val f1:0.33164  lr: 0.001 batch: 16
epochs: 3 train loss: 0.36560727237315654  train f1: 0.52873  lr: 0.001 batch: 16 
epochs: 3 val loss: 2.207295283564815  val f1:0.40530  lr: 0.001 batch: 16
epochs: 4 train loss: 0.3060174434819026  train f1: 0.59504  lr: 0.001 batch: 16 
epochs: 4 val loss: 2.1322735821759267  val f1:0.41353  lr: 0.001 batch: 16
epochs: 5 train loss: 0.2972557410765231  train f1: 0.60700  lr: 0.001 batch: 16 
epochs: 5 val loss: 2.0579463252314816  val f1:0.45136  lr: 0.001 batch: 16
epochs: 6 train loss: 0.251212716549077  train f1: 0.66429  lr: 0.001 batch: 16 
epochs: 6 val loss: 1.9586697048611106  val f1:0.45347  lr: 0.001 batch: 16
epochs: 7 train loss: 0.2095382204662993  train f1: 0.73146  lr: 0.001 batch: 16 
epochs: 7 val loss: 2.202528211805556  val f1:0.47636  lr: 0.001 batch: 16
epochs: 8 train loss: 0.20197844058833317  train f1: 0.74249  lr: 0.001 batch: 16 
epochs: 8 val loss: 2.3754267939814815  val f1:0.48902  lr: 0.001 batch: 16
epochs: 9 train loss: 0.17645432261491995  train f1: 0.78600  lr: 0.001 batch: 16 
epochs: 9 val loss: 2.3702293113425927  val f1:0.48020  lr: 0.001 batch: 16
epochs: 10 train loss: 0.22050036026743913  train f1: 0.74360  lr: 0.001 batch: 16 
epochs: 10 val loss: 2.714245153356481  val f1:0.46037  lr: 0.001 batch: 16
epochs: 11 train loss: 0.19348047377911398  train f1: 0.75826  lr: 0.001 batch: 16 
epochs: 11 val loss: 2.673753978587964  val f1:0.53523  lr: 0.001 batch: 16
epochs: 12 train loss: 0.1445397830634528  train f1: 0.83021  lr: 0.001 batch: 16 
epochs: 12 val loss: 2.610767505787038  val f1:0.50393  lr: 0.001 batch: 16
epochs: 13 train loss: 0.10980591434664487  train f1: 0.85711  lr: 0.001 batch: 16 
epochs: 13 val loss: 2.219303385416666  val f1:0.53190  lr: 0.001 batch: 16
epochs: 14 train loss: 0.11036027058233484  train f1: 0.85745  lr: 0.001 batch: 16 
epochs: 14 val loss: 2.573864293981481  val f1:0.47181  lr: 0.001 batch: 16
epochs: 15 train loss: 0.13583525468347682  train f1: 0.80872  lr: 0.001 batch: 16 
epochs: 15 val loss: 2.892838541666666  val f1:0.47595  lr: 0.001 batch: 16
epochs: 16 train loss: 0.12524069561047504  train f1: 0.84519  lr: 0.001 batch: 16 
epochs: 16 val loss: 2.432738353587963  val f1:0.48829  lr: 0.001 batch: 16
epochs: 17 train loss: 0.13316786155272067  train f1: 0.84854  lr: 0.001 batch: 16 
epochs: 17 val loss: 2.7754123263888886  val f1:0.51379  lr: 0.001 batch: 16
epochs: 18 train loss: 0.11157360684112659  train f1: 0.85333  lr: 0.001 batch: 16 
epochs: 18 val loss: 3.193945312499999  val f1:0.46643  lr: 0.001 batch: 16
epochs: 19 train loss: 0.11540927601217774  train f1: 0.87342  lr: 0.001 batch: 16 
epochs: 19 val loss: 2.641574435763889  val f1:0.54594  lr: 0.001 batch: 16
epochs: 20 train loss: 0.07585234588451595  train f1: 0.90429  lr: 0.001 batch: 16 
epochs: 20 val loss: 2.806083622685187  val f1:0.49969  lr: 0.001 batch: 16
epochs: 21 train loss: 0.10002064615599678  train f1: 0.87993  lr: 0.001 batch: 16 
epochs: 21 val loss: 2.8550998263888903  val f1:0.53112  lr: 0.001 batch: 16
epochs: 0 train loss: 0.9309924407844679  train f1: 0.22695  lr: 0.0003 batch: 16 
epochs: 0 val loss: 2.286715133101852  val f1:0.27320  lr: 0.0003 batch: 16
epochs: 1 train loss: 0.42224969756737196  train f1: 0.48373  lr: 0.0003 batch: 16 
epochs: 1 val loss: 1.933604600694444  val f1:0.38287  lr: 0.0003 batch: 16
epochs: 2 train loss: 0.2917385315627195  train f1: 0.60368  lr: 0.0003 batch: 16 
epochs: 2 val loss: 1.9933322482638893  val f1:0.45528  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.19497081313686856  train f1: 0.74037  lr: 0.0003 batch: 16 
epochs: 3 val loss: 1.7894314236111113  val f1:0.51679  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.13600672318247806  train f1: 0.83284  lr: 0.0003 batch: 16 
epochs: 4 val loss: 1.9974862557870374  val f1:0.52087  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.09062894542565507  train f1: 0.87221  lr: 0.0003 batch: 16 
epochs: 5 val loss: 1.9405888310185189  val f1:0.59756  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.08458210912983068  train f1: 0.88434  lr: 0.0003 batch: 16 
epochs: 6 val loss: 2.2257197627314813  val f1:0.59144  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.07855891109852313  train f1: 0.90923  lr: 0.0003 batch: 16 
epochs: 7 val loss: 2.3271484375  val f1:0.56195  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.06077207072397293  train f1: 0.92662  lr: 0.0003 batch: 16 
epochs: 8 val loss: 2.1575068721064814  val f1:0.59698  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.04588675766848446  train f1: 0.94867  lr: 0.0003 batch: 16 
epochs: 9 val loss: 2.240838396990741  val f1:0.60231  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.05477092551827878  train f1: 0.95018  lr: 0.0003 batch: 16 
epochs: 10 val loss: 2.6017686631944428  val f1:0.56969  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0507685968491915  train f1: 0.94234  lr: 0.0003 batch: 16 
epochs: 11 val loss: 2.3740143952546306  val f1:0.56530  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.05492455771799838  train f1: 0.94264  lr: 0.0003 batch: 16 
epochs: 12 val loss: 2.5145417390046294  val f1:0.59796  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.03441905841398773  train f1: 0.96749  lr: 0.0003 batch: 16 
epochs: 13 val loss: 2.6205765335648143  val f1:0.59158  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.03475171171324083  train f1: 0.95549  lr: 0.0003 batch: 16 
epochs: 14 val loss: 2.7536458333333345  val f1:0.61489  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.029081755809569634  train f1: 0.96375  lr: 0.0003 batch: 16 
epochs: 15 val loss: 2.7245121708622704  val f1:0.60014  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.050531572170471904  train f1: 0.96037  lr: 0.0003 batch: 16 
epochs: 16 val loss: 2.7906901041666674  val f1:0.60235  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.05478252810931838  train f1: 0.94757  lr: 0.0003 batch: 16 
epochs: 17 val loss: 2.6789523654513894  val f1:0.59600  lr: 0.0003 batch: 16
epochs: 18 train loss: 0.018717968062068643  train f1: 0.97876  lr: 0.0003 batch: 16 
epochs: 18 val loss: 2.7315637659143515  val f1:0.61734  lr: 0.0003 batch: 16
epochs: 19 train loss: 0.02232134409165115  train f1: 0.97287  lr: 0.0003 batch: 16 
epochs: 19 val loss: 2.9094708478009275  val f1:0.61499  lr: 0.0003 batch: 16
epochs: 20 train loss: 0.02381486571236942  train f1: 0.98416  lr: 0.0003 batch: 16 
epochs: 20 val loss: 2.6912624782986114  val f1:0.62436  lr: 0.0003 batch: 16
epochs: 21 train loss: 0.03468255090356318  train f1: 0.98101  lr: 0.0003 batch: 16 
epochs: 21 val loss: 3.0366048177083327  val f1:0.60875  lr: 0.0003 batch: 16
epochs: 0 train loss: 1.0865064756700606  train f1: 0.16335  lr: 0.0001 batch: 16 
epochs: 0 val loss: 2.3814236111111113  val f1:0.15015  lr: 0.0001 batch: 16
epochs: 1 train loss: 0.5693547966774932  train f1: 0.30971  lr: 0.0001 batch: 16 
epochs: 1 val loss: 2.0430627893518514  val f1:0.24604  lr: 0.0001 batch: 16
epochs: 2 train loss: 0.4090134695674596  train f1: 0.43214  lr: 0.0001 batch: 16 
epochs: 2 val loss: 1.7740776909722227  val f1:0.34575  lr: 0.0001 batch: 16
epochs: 3 train loss: 0.3079836270335908  train f1: 0.59095  lr: 0.0001 batch: 16 
epochs: 3 val loss: 1.6561993634259267  val f1:0.46067  lr: 0.0001 batch: 16
epochs: 4 train loss: 0.22124222601844132  train f1: 0.69658  lr: 0.0001 batch: 16 
epochs: 4 val loss: 1.5903284143518523  val f1:0.50099  lr: 0.0001 batch: 16
epochs: 5 train loss: 0.15892433137929404  train f1: 0.79447  lr: 0.0001 batch: 16 
epochs: 5 val loss: 1.800526258680555  val f1:0.52226  lr: 0.0001 batch: 16
epochs: 6 train loss: 0.11396005180444611  train f1: 0.84392  lr: 0.0001 batch: 16 
epochs: 6 val loss: 1.6147822627314818  val f1:0.56430  lr: 0.0001 batch: 16
epochs: 7 train loss: 0.08770086167010474  train f1: 0.90353  lr: 0.0001 batch: 16 
epochs: 7 val loss: 1.9552915219907412  val f1:0.59656  lr: 0.0001 batch: 16
epochs: 8 train loss: 0.06628758362616495  train f1: 0.91889  lr: 0.0001 batch: 16 
epochs: 8 val loss: 1.8163963035300932  val f1:0.57521  lr: 0.0001 batch: 16
epochs: 9 train loss: 0.04080326994706628  train f1: 0.95633  lr: 0.0001 batch: 16 
epochs: 9 val loss: 1.9386483651620372  val f1:0.58408  lr: 0.0001 batch: 16
epochs: 10 train loss: 0.041705560148432005  train f1: 0.95569  lr: 0.0001 batch: 16 
epochs: 10 val loss: 1.708201316550925  val f1:0.60204  lr: 0.0001 batch: 16
epochs: 11 train loss: 0.02795230315419172  train f1: 0.96882  lr: 0.0001 batch: 16 
epochs: 11 val loss: 1.961277488425926  val f1:0.61933  lr: 0.0001 batch: 16
epochs: 12 train loss: 0.034974797388141056  train f1: 0.95990  lr: 0.0001 batch: 16 
epochs: 12 val loss: 1.9175509982638885  val f1:0.61021  lr: 0.0001 batch: 16
epochs: 13 train loss: 0.029297484887226697  train f1: 0.96833  lr: 0.0001 batch: 16 
epochs: 13 val loss: 1.8339454933449075  val f1:0.60282  lr: 0.0001 batch: 16
epochs: 14 train loss: 0.02571043896764406  train f1: 0.98428  lr: 0.0001 batch: 16 
epochs: 14 val loss: 2.031794343171296  val f1:0.60563  lr: 0.0001 batch: 16
epochs: 15 train loss: 0.0254276254203882  train f1: 0.97582  lr: 0.0001 batch: 16 
epochs: 15 val loss: 1.9826397931134259  val f1:0.62034  lr: 0.0001 batch: 16
epochs: 16 train loss: 0.009341454684511107  train f1: 0.99496  lr: 0.0001 batch: 16 
epochs: 16 val loss: 1.9917629665798606  val f1:0.63806  lr: 0.0001 batch: 16
epochs: 17 train loss: 0.019045754541618554  train f1: 0.98727  lr: 0.0001 batch: 16 
epochs: 17 val loss: 2.195753761574073  val f1:0.61272  lr: 0.0001 batch: 16
epochs: 18 train loss: 0.018431996138354806  train f1: 0.98437  lr: 0.0001 batch: 16 
epochs: 18 val loss: 2.1870352285879635  val f1:0.62724  lr: 0.0001 batch: 16
epochs: 19 train loss: 0.015569738680950261  train f1: 0.98323  lr: 0.0001 batch: 16 
epochs: 19 val loss: 2.0181455258969914  val f1:0.63174  lr: 0.0001 batch: 16
epochs: 20 train loss: 0.017705945709671427  train f1: 0.97919  lr: 0.0001 batch: 16 
epochs: 20 val loss: 2.182411928530094  val f1:0.62631  lr: 0.0001 batch: 16
epochs: 21 train loss: 0.02162024568529166  train f1: 0.97719  lr: 0.0001 batch: 16 
epochs: 21 val loss: 2.189422381365741  val f1:0.63009  lr: 0.0001 batch: 16
epochs: 0 train loss: 0.9957539572644589  train f1: 0.22981  lr: 0.001 batch: 32 
epochs: 0 val loss: 2.496596392463236  val f1:0.18972  lr: 0.001 batch: 32
epochs: 1 train loss: 0.5763158086520522  train f1: 0.35671  lr: 0.001 batch: 32 
epochs: 1 val loss: 2.059699563419118  val f1:0.30892  lr: 0.001 batch: 32
epochs: 2 train loss: 0.39679649694642  train f1: 0.50196  lr: 0.001 batch: 32 
epochs: 2 val loss: 2.1043485753676467  val f1:0.37404  lr: 0.001 batch: 32
epochs: 3 train loss: 0.3148216133687033  train f1: 0.59113  lr: 0.001 batch: 32 
epochs: 3 val loss: 2.488913143382353  val f1:0.40484  lr: 0.001 batch: 32
epochs: 4 train loss: 0.25270319696682614  train f1: 0.65391  lr: 0.001 batch: 32 
epochs: 4 val loss: 2.0324994255514697  val f1:0.47474  lr: 0.001 batch: 32
epochs: 5 train loss: 0.20614248247288952  train f1: 0.70951  lr: 0.001 batch: 32 
epochs: 5 val loss: 2.0023408777573533  val f1:0.43204  lr: 0.001 batch: 32
epochs: 6 train loss: 0.17566635359579058  train f1: 0.76355  lr: 0.001 batch: 32 
epochs: 6 val loss: 2.0773638556985294  val f1:0.48625  lr: 0.001 batch: 32
epochs: 7 train loss: 0.13969034223414184  train f1: 0.80566  lr: 0.001 batch: 32 
epochs: 7 val loss: 2.1155000574448537  val f1:0.50461  lr: 0.001 batch: 32
epochs: 8 train loss: 0.13718528178200795  train f1: 0.80115  lr: 0.001 batch: 32 
epochs: 8 val loss: 2.135964786305147  val f1:0.52119  lr: 0.001 batch: 32
epochs: 9 train loss: 0.13488439303725513  train f1: 0.83662  lr: 0.001 batch: 32 
epochs: 9 val loss: 2.2453038832720584  val f1:0.45397  lr: 0.001 batch: 32
epochs: 10 train loss: 0.11896512045789119  train f1: 0.83151  lr: 0.001 batch: 32 
epochs: 10 val loss: 2.4560834099264697  val f1:0.49028  lr: 0.001 batch: 32
epochs: 11 train loss: 0.10947862311975279  train f1: 0.86781  lr: 0.001 batch: 32 
epochs: 11 val loss: 2.403191061580882  val f1:0.52412  lr: 0.001 batch: 32
epochs: 12 train loss: 0.08813001148736302  train f1: 0.88256  lr: 0.001 batch: 32 
epochs: 12 val loss: 2.5326573988970575  val f1:0.55390  lr: 0.001 batch: 32
epochs: 13 train loss: 0.09759508673824477  train f1: 0.90246  lr: 0.001 batch: 32 
epochs: 13 val loss: 3.2054515165441178  val f1:0.50930  lr: 0.001 batch: 32
epochs: 14 train loss: 0.14400171877732923  train f1: 0.83654  lr: 0.001 batch: 32 
epochs: 14 val loss: 2.6626335592830883  val f1:0.53369  lr: 0.001 batch: 32
epochs: 15 train loss: 0.10190236390526614  train f1: 0.87759  lr: 0.001 batch: 32 
epochs: 15 val loss: 2.705451516544118  val f1:0.56763  lr: 0.001 batch: 32
epochs: 16 train loss: 0.05684742998720995  train f1: 0.93496  lr: 0.001 batch: 32 
epochs: 16 val loss: 2.904217888327207  val f1:0.55353  lr: 0.001 batch: 32
epochs: 17 train loss: 0.04396802809701037  train f1: 0.95095  lr: 0.001 batch: 32 
epochs: 17 val loss: 2.6223790785845584  val f1:0.59256  lr: 0.001 batch: 32
epochs: 18 train loss: 0.0576952286620638  train f1: 0.93704  lr: 0.001 batch: 32 
epochs: 18 val loss: 2.3985595703125004  val f1:0.58579  lr: 0.001 batch: 32
epochs: 19 train loss: 0.060770337261370745  train f1: 0.93033  lr: 0.001 batch: 32 
epochs: 19 val loss: 2.831356272977942  val f1:0.54687  lr: 0.001 batch: 32
epochs: 20 train loss: 0.0531465864893216  train f1: 0.93416  lr: 0.001 batch: 32 
epochs: 20 val loss: 2.9057617187499996  val f1:0.55626  lr: 0.001 batch: 32
epochs: 21 train loss: 0.04849900950246783  train f1: 0.94306  lr: 0.001 batch: 32 
epochs: 21 val loss: 2.608972886029411  val f1:0.55548  lr: 0.001 batch: 32
epochs: 0 train loss: 0.9284631529850748  train f1: 0.22385  lr: 0.0003 batch: 32 
epochs: 0 val loss: 2.438519646139707  val f1:0.19230  lr: 0.0003 batch: 32
epochs: 1 train loss: 0.43542298274253743  train f1: 0.44268  lr: 0.0003 batch: 32 
epochs: 1 val loss: 2.1117733226102935  val f1:0.35315  lr: 0.0003 batch: 32
epochs: 2 train loss: 0.287110058229361  train f1: 0.62343  lr: 0.0003 batch: 32 
epochs: 2 val loss: 1.8443747127757355  val f1:0.44913  lr: 0.0003 batch: 32
epochs: 3 train loss: 0.17881387739039178  train f1: 0.73958  lr: 0.0003 batch: 32 
epochs: 3 val loss: 1.7302461511948524  val f1:0.50728  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.12071077147526524  train f1: 0.81698  lr: 0.0003 batch: 32 
epochs: 4 val loss: 1.7198845358455888  val f1:0.52409  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.08287639048562116  train f1: 0.88842  lr: 0.0003 batch: 32 
epochs: 5 val loss: 1.6939122817095587  val f1:0.56459  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.05930613048041047  train f1: 0.91494  lr: 0.0003 batch: 32 
epochs: 6 val loss: 1.810281192555146  val f1:0.57252  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.05489972812026295  train f1: 0.92187  lr: 0.0003 batch: 32 
epochs: 7 val loss: 1.8552389705882353  val f1:0.58609  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.04236428773225243  train f1: 0.94401  lr: 0.0003 batch: 32 
epochs: 8 val loss: 1.928251378676471  val f1:0.59652  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.0363005880099624  train f1: 0.95382  lr: 0.0003 batch: 32 
epochs: 9 val loss: 1.986888212316176  val f1:0.60128  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.0383241852717613  train f1: 0.95800  lr: 0.0003 batch: 32 
epochs: 10 val loss: 1.987534466911764  val f1:0.61708  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.013067794379903309  train f1: 0.98755  lr: 0.0003 batch: 32 
epochs: 11 val loss: 1.9725198184742652  val f1:0.62780  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.019010746656958743  train f1: 0.97345  lr: 0.0003 batch: 32 
epochs: 12 val loss: 2.078196806066177  val f1:0.63023  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.02814288103758399  train f1: 0.97129  lr: 0.0003 batch: 32 
epochs: 13 val loss: 1.9039881089154416  val f1:0.61471  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.026265726160647266  train f1: 0.97693  lr: 0.0003 batch: 32 
epochs: 14 val loss: 2.258121266084559  val f1:0.61440  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.03006679620315781  train f1: 0.96798  lr: 0.0003 batch: 32 
epochs: 15 val loss: 2.073881261488971  val f1:0.60604  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0458120499084245  train f1: 0.95672  lr: 0.0003 batch: 32 
epochs: 16 val loss: 2.2372328814338234  val f1:0.59024  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.055481373374141905  train f1: 0.93989  lr: 0.0003 batch: 32 
epochs: 17 val loss: 2.0778664981617645  val f1:0.61435  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.02004702767329429  train f1: 0.97973  lr: 0.0003 batch: 32 
epochs: 18 val loss: 1.980066636029412  val f1:0.61153  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.013461242860822531  train f1: 0.98141  lr: 0.0003 batch: 32 
epochs: 19 val loss: 2.174582088694852  val f1:0.61035  lr: 0.0003 batch: 32
epochs: 20 train loss: 0.00685663854897912  train f1: 0.99166  lr: 0.0003 batch: 32 
epochs: 20 val loss: 2.109813017003676  val f1:0.64796  lr: 0.0003 batch: 32
epochs: 21 train loss: 0.019762735758254782  train f1: 0.98203  lr: 0.0003 batch: 32 
epochs: 21 val loss: 2.387494255514706  val f1:0.60284  lr: 0.0003 batch: 32
epochs: 0 train loss: 1.164750284223414  train f1: 0.16840  lr: 0.0001 batch: 32 
epochs: 0 val loss: 2.444637522977942  val f1:0.13236  lr: 0.0001 batch: 32
epochs: 1 train loss: 0.565508486619636  train f1: 0.25801  lr: 0.0001 batch: 32 
epochs: 1 val loss: 2.0835535386029416  val f1:0.22843  lr: 0.0001 batch: 32
epochs: 2 train loss: 0.40713091038945903  train f1: 0.41700  lr: 0.0001 batch: 32 
epochs: 2 val loss: 1.8056784237132355  val f1:0.29762  lr: 0.0001 batch: 32
epochs: 3 train loss: 0.30368497478428186  train f1: 0.53621  lr: 0.0001 batch: 32 
epochs: 3 val loss: 1.9561408547794121  val f1:0.34620  lr: 0.0001 batch: 32
epochs: 4 train loss: 0.2423134419455457  train f1: 0.65721  lr: 0.0001 batch: 32 
epochs: 4 val loss: 1.8862017463235292  val f1:0.41824  lr: 0.0001 batch: 32
epochs: 5 train loss: 0.16805107913800135  train f1: 0.79466  lr: 0.0001 batch: 32 
epochs: 5 val loss: 1.697150735294117  val f1:0.45970  lr: 0.0001 batch: 32
epochs: 6 train loss: 0.12328327235890857  train f1: 0.85123  lr: 0.0001 batch: 32 
epochs: 6 val loss: 1.9110969094669126  val f1:0.49014  lr: 0.0001 batch: 32
epochs: 7 train loss: 0.10615348815917965  train f1: 0.88574  lr: 0.0001 batch: 32 
epochs: 7 val loss: 1.8943804572610288  val f1:0.52346  lr: 0.0001 batch: 32
epochs: 8 train loss: 0.07281548229616083  train f1: 0.90553  lr: 0.0001 batch: 32 
epochs: 8 val loss: 1.8716179342830888  val f1:0.53441  lr: 0.0001 batch: 32
epochs: 9 train loss: 0.05669704835806319  train f1: 0.93966  lr: 0.0001 batch: 32 
epochs: 9 val loss: 1.7822481043198533  val f1:0.55664  lr: 0.0001 batch: 32
epochs: 10 train loss: 0.04130762014816057  train f1: 0.95573  lr: 0.0001 batch: 32 
epochs: 10 val loss: 1.9335219439338236  val f1:0.55174  lr: 0.0001 batch: 32
epochs: 11 train loss: 0.024686870290272247  train f1: 0.97871  lr: 0.0001 batch: 32 
epochs: 11 val loss: 1.9816032858455883  val f1:0.56468  lr: 0.0001 batch: 32
epochs: 12 train loss: 0.03406284104532271  train f1: 0.96564  lr: 0.0001 batch: 32 
epochs: 12 val loss: 1.89431583180147  val f1:0.57372  lr: 0.0001 batch: 32
epochs: 13 train loss: 0.0234518762844712  train f1: 0.98636  lr: 0.0001 batch: 32 
epochs: 13 val loss: 1.9466983570772065  val f1:0.57135  lr: 0.0001 batch: 32
epochs: 14 train loss: 0.02683384382902686  train f1: 0.97572  lr: 0.0001 batch: 32 
epochs: 14 val loss: 1.9139691521139715  val f1:0.58295  lr: 0.0001 batch: 32
epochs: 15 train loss: 0.01719119655552195  train f1: 0.98851  lr: 0.0001 batch: 32 
epochs: 15 val loss: 1.8903162339154416  val f1:0.59272  lr: 0.0001 batch: 32
epochs: 16 train loss: 0.013521190899521566  train f1: 0.98636  lr: 0.0001 batch: 32 
epochs: 16 val loss: 1.8492934283088236  val f1:0.59040  lr: 0.0001 batch: 32
epochs: 17 train loss: 0.011343612599728712  train f1: 0.98907  lr: 0.0001 batch: 32 
epochs: 17 val loss: 1.9535127527573528  val f1:0.59281  lr: 0.0001 batch: 32
epochs: 18 train loss: 0.015223090328387359  train f1: 0.98374  lr: 0.0001 batch: 32 
epochs: 18 val loss: 1.9744154986213236  val f1:0.58662  lr: 0.0001 batch: 32
epochs: 19 train loss: 0.015461153058863392  train f1: 0.99129  lr: 0.0001 batch: 32 
epochs: 19 val loss: 1.8639490464154407  val f1:0.60619  lr: 0.0001 batch: 32
epochs: 20 train loss: 0.015633851734559927  train f1: 0.98504  lr: 0.0001 batch: 32 
epochs: 20 val loss: 1.936286477481617  val f1:0.59171  lr: 0.0001 batch: 32
epochs: 21 train loss: 0.007456181654289589  train f1: 0.99583  lr: 0.0001 batch: 32 
epochs: 21 val loss: 1.9631993910845593  val f1:0.60426  lr: 0.0001 batch: 32
epochs: 0 train loss: 1.0497873802756554  train f1: 0.19474  lr: 0.0003 batch: 4 
epochs: 0 val loss: 2.602376254900931  val f1:0.19669  lr: 0.0003 batch: 4
epochs: 1 train loss: 0.5936339517657666  train f1: 0.32009  lr: 0.0003 batch: 4 
epochs: 1 val loss: 2.294867917204167  val f1:0.27973  lr: 0.0003 batch: 4
epochs: 2 train loss: 0.4480009480808557  train f1: 0.47353  lr: 0.0003 batch: 4 
epochs: 2 val loss: 2.2183679357751624  val f1:0.36825  lr: 0.0003 batch: 4
epochs: 3 train loss: 0.3627807718984189  train f1: 0.55090  lr: 0.0003 batch: 4 
epochs: 3 val loss: 2.3614226431483902  val f1:0.38611  lr: 0.0003 batch: 4
epochs: 4 train loss: 0.2983920578653001  train f1: 0.63137  lr: 0.0003 batch: 4 
epochs: 4 val loss: 2.439486340821785  val f1:0.47288  lr: 0.0003 batch: 4
epochs: 5 train loss: 0.24428810408052887  train f1: 0.68152  lr: 0.0003 batch: 4 
epochs: 5 val loss: 2.091665593502914  val f1:0.47963  lr: 0.0003 batch: 4
epochs: 6 train loss: 0.21846459041373983  train f1: 0.72394  lr: 0.0003 batch: 4 
epochs: 6 val loss: 3.1101489412098955  val f1:0.43082  lr: 0.0003 batch: 4
epochs: 7 train loss: 0.1924920173620016  train f1: 0.75948  lr: 0.0003 batch: 4 
epochs: 7 val loss: 2.5614496896350984  val f1:0.50201  lr: 0.0003 batch: 4
epochs: 8 train loss: 0.15447590553135465  train f1: 0.78837  lr: 0.0003 batch: 4 
epochs: 8 val loss: 2.9097675684431743  val f1:0.53056  lr: 0.0003 batch: 4
epochs: 9 train loss: 0.1410708495516903  train f1: 0.84270  lr: 0.0003 batch: 4 
epochs: 9 val loss: 2.9544495919197513  val f1:0.47753  lr: 0.0003 batch: 4
epochs: 10 train loss: 0.12841370199503518  train f1: 0.85436  lr: 0.0003 batch: 4 
epochs: 10 val loss: 3.442008476531571  val f1:0.52146  lr: 0.0003 batch: 4
epochs: 11 train loss: 0.11711031711949847  train f1: 0.84761  lr: 0.0003 batch: 4 
epochs: 11 val loss: 3.7506112156639726  val f1:0.52457  lr: 0.0003 batch: 4
epochs: 12 train loss: 0.10097636410806048  train f1: 0.85004  lr: 0.0003 batch: 4 
epochs: 12 val loss: 3.5949482336115115  val f1:0.49159  lr: 0.0003 batch: 4
epochs: 13 train loss: 0.11164092319958215  train f1: 0.87048  lr: 0.0003 batch: 4 
epochs: 13 val loss: 3.7114208115054  val f1:0.49098  lr: 0.0003 batch: 4
epochs: 14 train loss: 0.08977830700213539  train f1: 0.88133  lr: 0.0003 batch: 4 
epochs: 14 val loss: 3.788680364116889  val f1:0.52320  lr: 0.0003 batch: 4
epochs: 15 train loss: 0.07086154913411169  train f1: 0.90787  lr: 0.0003 batch: 4 
epochs: 15 val loss: 4.048988336092466  val f1:0.51921  lr: 0.0003 batch: 4
epochs: 16 train loss: 0.07660523821575364  train f1: 0.89627  lr: 0.0003 batch: 4 
epochs: 16 val loss: 3.81562503790811  val f1:0.55180  lr: 0.0003 batch: 4
epochs: 17 train loss: 0.06749247974447536  train f1: 0.92007  lr: 0.0003 batch: 4 
epochs: 17 val loss: 3.9689858952789465  val f1:0.53589  lr: 0.0003 batch: 4
epochs: 18 train loss: 0.07078208297156224  train f1: 0.92570  lr: 0.0003 batch: 4 
epochs: 18 val loss: 4.741200777064448  val f1:0.53657  lr: 0.0003 batch: 4
epochs: 19 train loss: 0.06290206999591226  train f1: 0.92877  lr: 0.0003 batch: 4 
epochs: 19 val loss: 3.9385106824545772  val f1:0.54487  lr: 0.0003 batch: 4
epochs: 20 train loss: 0.06856498317548847  train f1: 0.93235  lr: 0.0003 batch: 4 
epochs: 20 val loss: 4.656897594844697  val f1:0.54794  lr: 0.0003 batch: 4
epochs: 21 train loss: 0.06916752463199674  train f1: 0.92783  lr: 0.0003 batch: 4 
epochs: 21 val loss: 4.129898244352642  val f1:0.53050  lr: 0.0003 batch: 4
epochs: 0 train loss: 1.1508761345223992  train f1: 0.16275  lr: 0.0001 batch: 4 
epochs: 0 val loss: 2.679467321548038  val f1:0.16584  lr: 0.0001 batch: 4
epochs: 1 train loss: 0.6378054243794979  train f1: 0.27009  lr: 0.0001 batch: 4 
epochs: 1 val loss: 2.16816201855831  val f1:0.25996  lr: 0.0001 batch: 4
epochs: 2 train loss: 0.4651463255007162  train f1: 0.40888  lr: 0.0001 batch: 4 
epochs: 2 val loss: 1.731726948980498  val f1:0.36584  lr: 0.0001 batch: 4
epochs: 3 train loss: 0.3579399433921789  train f1: 0.51166  lr: 0.0001 batch: 4 
epochs: 3 val loss: 1.7234858723429884  val f1:0.44250  lr: 0.0001 batch: 4
epochs: 4 train loss: 0.2635851736818807  train f1: 0.64132  lr: 0.0001 batch: 4 
epochs: 4 val loss: 1.8999227123932836  val f1:0.48590  lr: 0.0001 batch: 4
epochs: 5 train loss: 0.22003425551710926  train f1: 0.70854  lr: 0.0001 batch: 4 
epochs: 5 val loss: 2.0040845464023445  val f1:0.52186  lr: 0.0001 batch: 4
epochs: 6 train loss: 0.15844955716686734  train f1: 0.79108  lr: 0.0001 batch: 4 
epochs: 6 val loss: 2.2314487874839646  val f1:0.52012  lr: 0.0001 batch: 4
epochs: 7 train loss: 0.13346779279494544  train f1: 0.83055  lr: 0.0001 batch: 4 
epochs: 7 val loss: 2.118015248611819  val f1:0.56383  lr: 0.0001 batch: 4
epochs: 8 train loss: 0.10440934362929433  train f1: 0.87003  lr: 0.0001 batch: 4 
epochs: 8 val loss: 2.4061263248960243  val f1:0.55893  lr: 0.0001 batch: 4
epochs: 9 train loss: 0.08374130312869615  train f1: 0.90794  lr: 0.0001 batch: 4 
epochs: 9 val loss: 2.3279508005046656  val f1:0.53396  lr: 0.0001 batch: 4
epochs: 10 train loss: 0.09330895799822564  train f1: 0.89546  lr: 0.0001 batch: 4 
epochs: 10 val loss: 2.508694447480241  val f1:0.58971  lr: 0.0001 batch: 4
epochs: 11 train loss: 0.06809695757060455  train f1: 0.91446  lr: 0.0001 batch: 4 
epochs: 11 val loss: 2.5834147217985874  val f1:0.57009  lr: 0.0001 batch: 4
epochs: 12 train loss: 0.05585191379325662  train f1: 0.93824  lr: 0.0001 batch: 4 
epochs: 12 val loss: 2.59697712883215  val f1:0.62130  lr: 0.0001 batch: 4
epochs: 13 train loss: 0.04537100180258016  train f1: 0.95325  lr: 0.0001 batch: 4 
epochs: 13 val loss: 2.9501760125381358  val f1:0.59761  lr: 0.0001 batch: 4
epochs: 14 train loss: 0.051264359430873804  train f1: 0.93909  lr: 0.0001 batch: 4 
epochs: 14 val loss: 2.8420925781766657  val f1:0.59531  lr: 0.0001 batch: 4
epochs: 15 train loss: 0.03952773573916502  train f1: 0.96076  lr: 0.0001 batch: 4 
epochs: 15 val loss: 2.856720099312032  val f1:0.59721  lr: 0.0001 batch: 4
epochs: 16 train loss: 0.03882734762148908  train f1: 0.95612  lr: 0.0001 batch: 4 
epochs: 16 val loss: 2.9116348315700735  val f1:0.58832  lr: 0.0001 batch: 4
epochs: 17 train loss: 0.031597131981831825  train f1: 0.95841  lr: 0.0001 batch: 4 
epochs: 17 val loss: 3.240382300900614  val f1:0.59335  lr: 0.0001 batch: 4
epochs: 18 train loss: 0.029708931117915022  train f1: 0.96761  lr: 0.0001 batch: 4 
epochs: 18 val loss: 3.5955222163881606  val f1:0.56678  lr: 0.0001 batch: 4
epochs: 19 train loss: 0.023736791385247043  train f1: 0.97017  lr: 0.0001 batch: 4 
epochs: 19 val loss: 3.1556691583764342  val f1:0.59814  lr: 0.0001 batch: 4
epochs: 20 train loss: 0.044927513945415234  train f1: 0.95581  lr: 0.0001 batch: 4 
epochs: 20 val loss: 3.2029838281128957  val f1:0.59155  lr: 0.0001 batch: 4
epochs: 0 train loss: 0.9370809526585823  train f1: 0.23915  lr: 0.0003 batch: 32 
epochs: 0 val loss: 2.3006232766544117  val f1:0.24175  lr: 0.0003 batch: 32
epochs: 1 train loss: 0.4267947068854946  train f1: 0.43515  lr: 0.0003 batch: 32 
epochs: 1 val loss: 2.10671817555147  val f1:0.35923  lr: 0.0003 batch: 32
epochs: 2 train loss: 0.26888024629052004  train f1: 0.61223  lr: 0.0003 batch: 32 
epochs: 2 val loss: 1.7737103630514706  val f1:0.45778  lr: 0.0003 batch: 32
epochs: 3 train loss: 0.17074858252681896  train f1: 0.75654  lr: 0.0003 batch: 32 
epochs: 3 val loss: 1.6049373851102937  val f1:0.56547  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.12134719962504377  train f1: 0.82459  lr: 0.0003 batch: 32 
epochs: 4 val loss: 1.7640165441176465  val f1:0.55444  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.1066550069780492  train f1: 0.87050  lr: 0.0003 batch: 32 
epochs: 5 val loss: 1.7554644416360297  val f1:0.54355  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.06432762430674993  train f1: 0.91369  lr: 0.0003 batch: 32 
epochs: 6 val loss: 1.7483197380514706  val f1:0.60448  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.0582980611431065  train f1: 0.93547  lr: 0.0003 batch: 32 
epochs: 7 val loss: 1.9175666360294124  val f1:0.60897  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.05125587377975238  train f1: 0.93021  lr: 0.0003 batch: 32 
epochs: 8 val loss: 2.077722886029412  val f1:0.59539  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.023501937069110013  train f1: 0.96827  lr: 0.0003 batch: 32 
epochs: 9 val loss: 2.0409007352941178  val f1:0.59506  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.028695590460478388  train f1: 0.96692  lr: 0.0003 batch: 32 
epochs: 10 val loss: 2.2898092830882355  val f1:0.60061  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.03664601738773178  train f1: 0.96901  lr: 0.0003 batch: 32 
epochs: 11 val loss: 1.9593936695772065  val f1:0.63802  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.03212591783324285  train f1: 0.95874  lr: 0.0003 batch: 32 
epochs: 12 val loss: 2.1458237591911757  val f1:0.58125  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.03226869141877587  train f1: 0.95766  lr: 0.0003 batch: 32 
epochs: 13 val loss: 2.0868494370404416  val f1:0.62615  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.027764692235348835  train f1: 0.97350  lr: 0.0003 batch: 32 
epochs: 14 val loss: 2.0645249310661766  val f1:0.61481  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.01533317743842282  train f1: 0.98105  lr: 0.0003 batch: 32 
epochs: 15 val loss: 2.2384894875919112  val f1:0.60821  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.02046476015404089  train f1: 0.97592  lr: 0.0003 batch: 32 
epochs: 16 val loss: 2.1796731387867645  val f1:0.63077  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.046349187395465924  train f1: 0.96174  lr: 0.0003 batch: 32 
epochs: 17 val loss: 2.2286017922794126  val f1:0.60256  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.038456135721349004  train f1: 0.95578  lr: 0.0003 batch: 32 
epochs: 18 val loss: 2.3467514935661757  val f1:0.60162  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0489051733443986  train f1: 0.95113  lr: 0.0003 batch: 32 
epochs: 19 val loss: 2.540225758272059  val f1:0.58566  lr: 0.0003 batch: 32
epochs: 20 train loss: 0.04177032299895785  train f1: 0.94829  lr: 0.0003 batch: 32 
epochs: 20 val loss: 2.428294462316177  val f1:0.58628  lr: 0.0003 batch: 32
epochs: 21 train loss: 0.04020381151740231  train f1: 0.95472  lr: 0.0003 batch: 32 
epochs: 21 val loss: 2.4530101102941173  val f1:0.61298  lr: 0.0003 batch: 32
epochs: 0 train loss: 0.9386787983908585  train f1: 0.22010  lr: 0.0003 batch: 32 
epochs: 0 val loss: 1.892506318933824  val f1:0.25977  lr: 0.0003 batch: 32
epochs: 0 train loss: 6.546875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 6.3515625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 5.80859375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 6.3515625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 7.05859375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 6.3515625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 5.96484375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 6.3515625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 4 train loss: 5.87890625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 13.9375  val f1:0.06667  lr: 0.0003 batch: 32
epochs: 5 train loss: 2.3046875  train f1: 0.22222  lr: 0.0003 batch: 32 
epochs: 5 val loss: 16.453125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 6 train loss: 6.8828125  train f1: 0.50000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 10.34375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 7 train loss: 3.5703125  train f1: 0.16667  lr: 0.0003 batch: 32 
epochs: 7 val loss: 10.5546875  val f1:0.06667  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.83984375  train f1: 0.60000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 10.125  val f1:0.08333  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.00083160400390625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 9.46875  val f1:0.08333  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.0004069805145263672  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 9.03125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.0003848075866699219  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 9.046875  val f1:0.16667  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.00041937828063964844  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 9.9921875  val f1:0.16667  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.0008440017700195312  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 10.9296875  val f1:0.16667  lr: 0.0003 batch: 32
epochs: 14 train loss: 1.263671875  train f1: 0.77778  lr: 0.0003 batch: 32 
epochs: 14 val loss: 13.4765625  val f1:0.06667  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.5703125  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.77734375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.66796875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.8125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.072265625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.76953125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.126953125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.80859375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.322021484375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.8125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.10198974609375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.796875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.0229034423828125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.86328125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.0158538818359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 4.734375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.00637054443359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 4.60546875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.006900787353515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 4.5625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.0037746429443359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 4.546875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.002445220947265625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 4.51171875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.0015010833740234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 4.34765625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.0011987686157226562  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 4.29296875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0013036727905273438  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 4.3203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.0009393692016601562  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 15 val loss: 4.3515625  val f1:0.09524  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.0007634162902832031  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 16 val loss: 4.53125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.0005555152893066406  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 17 val loss: 4.48046875  val f1:0.08333  lr: 0.0003 batch: 16
epochs: 18 train loss: 0.00043582916259765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 18 val loss: 4.23828125  val f1:0.08333  lr: 0.0003 batch: 16
epochs: 19 train loss: 0.0005102157592773438  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 19 val loss: 3.943359375  val f1:0.08333  lr: 0.0003 batch: 16
epochs: 20 train loss: 0.0004031658172607422  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 20 val loss: 3.876953125  val f1:0.08333  lr: 0.0003 batch: 16
epochs: 21 train loss: 0.0003218650817871094  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 21 val loss: 3.787109375  val f1:0.08333  lr: 0.0003 batch: 16
epochs: 22 train loss: 0.00030159950256347656  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 22 val loss: 3.705078125  val f1:0.08333  lr: 0.0003 batch: 16
epochs: 0 train loss: 1.5599036813896394  train f1: 0.12328  lr: 0.0003 batch: 4 
epochs: 0 val loss: 2.7962611946856173  val f1:0.09519  lr: 0.0003 batch: 4
epochs: 1 train loss: 0.9855993431305223  train f1: 0.15837  lr: 0.0003 batch: 4 
epochs: 1 val loss: 3.3320108105831125  val f1:0.07592  lr: 0.0003 batch: 4
epochs: 2 train loss: 0.88354734616859  train f1: 0.16786  lr: 0.0003 batch: 4 
epochs: 2 val loss: 3.3095123913823348  val f1:0.10439  lr: 0.0003 batch: 4
epochs: 0 train loss: 4.02734375  train f1: 0.00000  lr: 0.0003 batch: 4 
epochs: 0 val loss: 4.5703125  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 1 train loss: 4.16015625  train f1: 0.00000  lr: 0.0003 batch: 4 
epochs: 1 val loss: 4.7734375  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 2 train loss: 2.234375  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 2 val loss: 4.92578125  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 3 train loss: 1.189453125  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 3 val loss: 5.00390625  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 4 train loss: 0.435546875  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 4 val loss: 5.052734375  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 5 train loss: 0.11181640625  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 5 val loss: 5.1171875  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 6 train loss: 0.060791015625  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 6 val loss: 5.203125  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 7 train loss: 0.027923583984375  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 7 val loss: 5.283203125  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 8 train loss: 0.0192718505859375  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 8 val loss: 5.373046875  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 9 train loss: 0.0165252685546875  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 9 val loss: 5.36328125  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 10 train loss: 0.013427734375  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 10 val loss: 5.341796875  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 11 train loss: 0.00617218017578125  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 11 val loss: 5.294921875  val f1:0.14286  lr: 0.0003 batch: 4
epochs: 12 train loss: 0.007659912109375  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 12 val loss: 5.28125  val f1:0.14286  lr: 0.0003 batch: 4
epochs: 13 train loss: 0.005405426025390625  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 13 val loss: 5.234375  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 14 train loss: 0.003253936767578125  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 14 val loss: 5.16015625  val f1:0.07143  lr: 0.0003 batch: 4
epochs: 15 train loss: 0.0022869110107421875  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 15 val loss: 5.1640625  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 16 train loss: 0.0015268325805664062  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 16 val loss: 5.287109375  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 17 train loss: 0.001033782958984375  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 17 val loss: 5.275390625  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 18 train loss: 0.0006265640258789062  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 18 val loss: 5.21875  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 19 train loss: 0.0005726814270019531  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 19 val loss: 5.15234375  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 20 train loss: 0.0005993843078613281  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 20 val loss: 5.14453125  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 21 train loss: 0.0004298686981201172  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 21 val loss: 5.107421875  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 22 train loss: 0.00031828880310058594  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 22 val loss: 5.064453125  val f1:0.00000  lr: 0.0003 batch: 4
epochs: 23 train loss: 0.00022339820861816406  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 23 val loss: 5.01953125  val f1:0.09524  lr: 0.0003 batch: 4
epochs: 24 train loss: 0.0002288818359375  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 24 val loss: 4.7392578125  val f1:0.09524  lr: 0.0003 batch: 4
epochs: 25 train loss: 0.0002434253692626953  train f1: 1.00000  lr: 0.0003 batch: 4 
epochs: 25 val loss: 4.6025390625  val f1:0.09524  lr: 0.0003 batch: 4

########### augmentation train_with_labelwithOut_metalnut_pill_toothbrush_aug #################
epochs: 0 train loss: 0.7426189672167054  train f1: 0.31667  lr: 0.0003 batch: 16 
epochs: 0 val loss: 1.146787290219907  val f1:0.46860  lr: 0.0003 batch: 16
epochs: 1 train loss: 0.2758141704808884  train f1: 0.63318  lr: 0.0003 batch: 16 
epochs: 1 val loss: 0.8122422960069443  val f1:0.59841  lr: 0.0003 batch: 16
epochs: 2 train loss: 0.1687566775027835  train f1: 0.77006  lr: 0.0003 batch: 16 
epochs: 2 val loss: 0.7794652868200238  val f1:0.69173  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.1084519680415358  train f1: 0.85574  lr: 0.0003 batch: 16 
epochs: 3 val loss: 0.8887739393446172  val f1:0.68060  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.08597733863046235  train f1: 0.89514  lr: 0.0003 batch: 16 
epochs: 4 val loss: 0.7094391999421298  val f1:0.76174  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.06534824371337897  train f1: 0.91603  lr: 0.0003 batch: 16 
epochs: 5 val loss: 0.684400544343171  val f1:0.78422  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.07330755429847213  train f1: 0.92319  lr: 0.0003 batch: 16 
epochs: 6 val loss: 0.7639503973501697  val f1:0.76220  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.04473781763950247  train f1: 0.94963  lr: 0.0003 batch: 16 
epochs: 7 val loss: 0.7152439117431635  val f1:0.80172  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.04592859187972877  train f1: 0.95082  lr: 0.0003 batch: 16 
epochs: 8 val loss: 0.8235767929642288  val f1:0.76096  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.04693539499122399  train f1: 0.94260  lr: 0.0003 batch: 16 
epochs: 9 val loss: 1.025586841724537  val f1:0.71547  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.049258921525188716  train f1: 0.94734  lr: 0.0003 batch: 16 
epochs: 10 val loss: 0.920575685854311  val f1:0.75435  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.051799240067740455  train f1: 0.93962  lr: 0.0003 batch: 16 
epochs: 11 val loss: 0.9693947120949077  val f1:0.74495  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.03590923157807825  train f1: 0.95729  lr: 0.0003 batch: 16 
epochs: 12 val loss: 0.75542879457827  val f1:0.79581  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.024902431652924724  train f1: 0.98101  lr: 0.0003 batch: 16 
epochs: 13 val loss: 0.9582926291006579  val f1:0.77209  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.034730818895536  train f1: 0.96676  lr: 0.0003 batch: 16 
epochs: 14 val loss: 0.9035884751213923  val f1:0.78182  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.03376554752064644  train f1: 0.96757  lr: 0.0003 batch: 16 
epochs: 15 val loss: 0.9497984585938629  val f1:0.76933  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.03213288338384892  train f1: 0.96817  lr: 0.0003 batch: 16 
epochs: 16 val loss: 0.9135829501681854  val f1:0.78824  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.026759671273632563  train f1: 0.97158  lr: 0.0003 batch: 16 
epochs: 17 val loss: 1.0374767374109342  val f1:0.76691  lr: 0.0003 batch: 16
epochs: 18 train loss: 0.02829478299506357  train f1: 0.96292  lr: 0.0003 batch: 16 
epochs: 18 val loss: 0.8371459678367331  val f1:0.77909  lr: 0.0003 batch: 16
epochs: 19 train loss: 0.03768770371642064  train f1: 0.96702  lr: 0.0003 batch: 16 
epochs: 19 val loss: 0.8427574440285011  val f1:0.78404  lr: 0.0003 batch: 16
epochs: 20 train loss: 0.016024260097574974  train f1: 0.98262  lr: 0.0003 batch: 16 
epochs: 20 val loss: 1.0155143596507887  val f1:0.78732  lr: 0.0003 batch: 16
epochs: 0 train loss: 0.741341889794193  train f1: 0.32585  lr: 0.0003 batch: 32 
epochs: 0 val loss: 1.273236443014706  val f1:0.46227  lr: 0.0003 batch: 32
epochs: 1 train loss: 0.27596197555314256  train f1: 0.64203  lr: 0.0003 batch: 32 
epochs: 1 val loss: 0.8366986443014706  val f1:0.62037  lr: 0.0003 batch: 32
epochs: 2 train loss: 0.14450420550446025  train f1: 0.79684  lr: 0.0003 batch: 32 
epochs: 2 val loss: 0.6646943933823531  val f1:0.70607  lr: 0.0003 batch: 32
epochs: 3 train loss: 0.09595416908833516  train f1: 0.87546  lr: 0.0003 batch: 32 
epochs: 3 val loss: 0.8733251235064341  val f1:0.69335  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.0707050223848713  train f1: 0.91283  lr: 0.0003 batch: 32 
epochs: 4 val loss: 0.7264743131749771  val f1:0.74991  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.050882962212633706  train f1: 0.93365  lr: 0.0003 batch: 32 
epochs: 5 val loss: 0.7481020759133729  val f1:0.76068  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.03107498652899443  train f1: 0.95296  lr: 0.0003 batch: 32 
epochs: 6 val loss: 0.6897145439596738  val f1:0.78651  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.03216657175946592  train f1: 0.96404  lr: 0.0003 batch: 32 
epochs: 7 val loss: 0.8030987907858455  val f1:0.74634  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.04125507198162932  train f1: 0.95373  lr: 0.0003 batch: 32 
epochs: 8 val loss: 0.6506872738108916  val f1:0.78174  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.029336970243880992  train f1: 0.97005  lr: 0.0003 batch: 32 
epochs: 9 val loss: 0.7829953361960021  val f1:0.77450  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.03012492585538037  train f1: 0.97012  lr: 0.0003 batch: 32 
epochs: 10 val loss: 0.6656541263355928  val f1:0.80003  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.03147942717395612  train f1: 0.97340  lr: 0.0003 batch: 32 
epochs: 11 val loss: 0.6749662511488971  val f1:0.79335  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.03608590542380493  train f1: 0.96146  lr: 0.0003 batch: 32 
epochs: 12 val loss: 0.7439305922564341  val f1:0.78543  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.03741591412629654  train f1: 0.96034  lr: 0.0003 batch: 32 
epochs: 13 val loss: 0.7952303044936235  val f1:0.74828  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.028718447507317387  train f1: 0.96569  lr: 0.0003 batch: 32 
epochs: 14 val loss: 0.8392902823055495  val f1:0.77756  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.019148608197027177  train f1: 0.98172  lr: 0.0003 batch: 32 
epochs: 15 val loss: 0.8211617434726037  val f1:0.80156  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.012776784932435456  train f1: 0.99197  lr: 0.0003 batch: 32 
epochs: 16 val loss: 0.849616092794082  val f1:0.79114  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.024738330449630967  train f1: 0.97925  lr: 0.0003 batch: 32 
epochs: 17 val loss: 1.0231628417968746  val f1:0.74646  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.028629007624156436  train f1: 0.97467  lr: 0.0003 batch: 32 
epochs: 18 val loss: 0.8684647504021137  val f1:0.77960  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.03443318761106747  train f1: 0.96315  lr: 0.0003 batch: 32 
epochs: 19 val loss: 0.8431728587431063  val f1:0.78238  lr: 0.0003 batch: 32
epochs: 20 train loss: 0.011669656011595652  train f1: 0.98800  lr: 0.0003 batch: 32 
epochs: 20 val loss: 0.8651302562040443  val f1:0.77550  lr: 0.0003 batch: 32
epochs: 0 train loss: 0.7629532002957063  train f1: 0.31091  lr: 0.0003 batch: 16 
epochs: 0 val loss: 1.2748300057870368  val f1:0.42775  lr: 0.0003 batch: 16
epochs: 1 train loss: 0.29008661430572813  train f1: 0.60754  lr: 0.0003 batch: 16 
epochs: 0 train loss: 4.96875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.3671875  val f1:0.06667  lr: 0.0003 batch: 32
epochs: 1 train loss: 5.0078125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.0703125  val f1:0.07143  lr: 0.0003 batch: 32
epochs: 2 train loss: 2.705078125  train f1: 0.66667  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.0234375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.2119140625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.078125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.387939453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.13671875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.200927734375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.171875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.046630859375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.26953125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.019683837890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 4.31640625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.01824951171875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 4.44921875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.0059051513671875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 4.59765625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.006683349609375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 4.70703125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 0 train loss: 0.7421614234127206  train f1: 0.34633  lr: 0.0003 batch: 32 
epochs: 0 val loss: 1.0861241957720587  val f1:0.48971  lr: 0.0003 batch: 32
epochs: 1 train loss: 0.2852889103675957  train f1: 0.61995  lr: 0.0003 batch: 32 
epochs: 1 val loss: 0.8846291934742646  val f1:0.63299  lr: 0.0003 batch: 32
epochs: 2 train loss: 0.158851424259926  train f1: 0.79629  lr: 0.0003 batch: 32 
epochs: 2 val loss: 0.7444458007812501  val f1:0.68246  lr: 0.0003 batch: 32
epochs: 3 train loss: 0.09739141321893947  train f1: 0.86734  lr: 0.0003 batch: 32 
epochs: 3 val loss: 0.6136743882123157  val f1:0.76779  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.05996074249495319  train f1: 0.91657  lr: 0.0003 batch: 32 
epochs: 4 val loss: 0.7726781508501841  val f1:0.73038  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.055432177301663055  train f1: 0.92531  lr: 0.0003 batch: 32 
epochs: 5 val loss: 0.791622386259191  val f1:0.72972  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.043760849468743625  train f1: 0.94912  lr: 0.0003 batch: 32 
epochs: 6 val loss: 0.6803122127757354  val f1:0.78268  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.037980768217969314  train f1: 0.95907  lr: 0.0003 batch: 32 
epochs: 7 val loss: 0.8004204245174631  val f1:0.77220  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.047660222694055336  train f1: 0.94421  lr: 0.0003 batch: 32 
epochs: 8 val loss: 0.8503579532398895  val f1:0.75906  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.03931666754964574  train f1: 0.95659  lr: 0.0003 batch: 32 
epochs: 9 val loss: 0.680071662454044  val f1:0.80207  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.026279930748156658  train f1: 0.97526  lr: 0.0003 batch: 32 
epochs: 10 val loss: 0.8555881275850182  val f1:0.77316  lr: 0.0003 batch: 32
epochs: 0 train loss: 0.5935665710905842  train f1: 0.43225  lr: 0.0003 batch: 16 
epochs: 0 val loss: 0.9109879105179404  val f1:0.58286  lr: 0.0003 batch: 16
epochs: 1 train loss: 0.1831508538966759  train f1: 0.76267  lr: 0.0003 batch: 16 
epochs: 1 val loss: 0.7932938187210653  val f1:0.67964  lr: 0.0003 batch: 16
epochs: 2 train loss: 0.10919328163984118  train f1: 0.85258  lr: 0.0003 batch: 16 
epochs: 2 val loss: 0.866852767379196  val f1:0.72315  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.07943437343226409  train f1: 0.89761  lr: 0.0003 batch: 16 
epochs: 3 val loss: 0.730817441587095  val f1:0.76813  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.05541016692829834  train f1: 0.93275  lr: 0.0003 batch: 16 
epochs: 4 val loss: 0.8031697873716004  val f1:0.75932  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.05832175587180848  train f1: 0.93165  lr: 0.0003 batch: 16 
epochs: 5 val loss: 0.827067396375868  val f1:0.75027  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.04795238145271739  train f1: 0.94136  lr: 0.0003 batch: 16 
epochs: 6 val loss: 0.8617149776882593  val f1:0.76082  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.039771255635263895  train f1: 0.96331  lr: 0.0003 batch: 16 
epochs: 7 val loss: 0.960614098442925  val f1:0.76634  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2734375  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.53125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.61328125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.06640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.5  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.85888671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.4921875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.28271484375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.49609375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.0504150390625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.5625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.059417724609375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.6015625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.01983642578125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 4.6015625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.007678985595703125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 4.63671875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.005474090576171875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 4.67578125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.0025005340576171875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 4.671875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.00214385986328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 4.66015625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.0018396377563476562  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 4.578125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.0011272430419921875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 4.61328125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0008902549743652344  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 4.265625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.0005669593811035156  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 15 val loss: 4.0546875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2734375  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.53125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.61328125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.06640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.5  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.85888671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.4921875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.28271484375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.49609375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2734375  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.53125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.61328125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.06640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.5  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.85888671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.4921875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.28271484375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.49609375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2734375  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.53125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.61328125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.06640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.5  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.85888671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.4921875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.28271484375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.49609375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2734375  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.53125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.61328125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.06640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.5  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.85888671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.4921875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.28271484375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.49609375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2734375  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.53125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.61328125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.06640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.5  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.85888671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.4921875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 0.6077506476804204  train f1: 0.42073  lr: 0.0003 batch: 16 
epochs: 0 val loss: 0.9189552589699072  val f1:0.56419  lr: 0.0003 batch: 16
epochs: 1 train loss: 0.18867265791667082  train f1: 0.74041  lr: 0.0003 batch: 16 
epochs: 1 val loss: 0.8559425636574075  val f1:0.67752  lr: 0.0003 batch: 16
epochs: 2 train loss: 0.1068231351952302  train f1: 0.87426  lr: 0.0003 batch: 16 
epochs: 2 val loss: 0.9627536349826391  val f1:0.71637  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.08648594002473982  train f1: 0.90013  lr: 0.0003 batch: 16 
epochs: 3 val loss: 0.7318610297309027  val f1:0.77347  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.056507652537186474  train f1: 0.92462  lr: 0.0003 batch: 16 
epochs: 4 val loss: 0.7570922427707247  val f1:0.78459  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.04720457102592449  train f1: 0.94432  lr: 0.0003 batch: 16 
epochs: 5 val loss: 0.795888378002025  val f1:0.76970  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.042780755166698284  train f1: 0.95143  lr: 0.0003 batch: 16 
epochs: 6 val loss: 0.8986799452039926  val f1:0.75460  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.04558106952177321  train f1: 0.95575  lr: 0.0003 batch: 16 
epochs: 7 val loss: 0.855011607982494  val f1:0.77590  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.03452207515959133  train f1: 0.96447  lr: 0.0003 batch: 16 
epochs: 8 val loss: 0.976939731174045  val f1:0.76550  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.171875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.51171875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.2578125  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.59375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.48046875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.83154296875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.3984375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.36767578125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.41015625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 0.5925660739813069  train f1: 0.43497  lr: 0.0003 batch: 16 
epochs: 0 val loss: 1.0249439380787035  val f1:0.56280  lr: 0.0003 batch: 16
epochs: 1 train loss: 0.18950446407099322  train f1: 0.74845  lr: 0.0003 batch: 16 
epochs: 1 val loss: 0.6961042616102427  val f1:0.72565  lr: 0.0003 batch: 16
epochs: 2 train loss: 0.1074034008301999  train f1: 0.85882  lr: 0.0003 batch: 16 
epochs: 2 val loss: 0.8630642361111109  val f1:0.69179  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.07596058084483152  train f1: 0.90875  lr: 0.0003 batch: 16 
epochs: 3 val loss: 0.6985352410210505  val f1:0.76587  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.06185402284536579  train f1: 0.92878  lr: 0.0003 batch: 16 
epochs: 4 val loss: 0.7763913472493488  val f1:0.76666  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.05289173423500726  train f1: 0.94114  lr: 0.0003 batch: 16 
epochs: 5 val loss: 0.8530366685655377  val f1:0.76799  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.04497406815650159  train f1: 0.95033  lr: 0.0003 batch: 16 
epochs: 6 val loss: 0.939899154945656  val f1:0.73993  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.37109375  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.58984375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3984375  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.546875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 3.69921875  train f1: 0.50000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.52734375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 3 train loss: 2.83984375  train f1: 0.77778  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.50390625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 4 train loss: 1.97265625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.4765625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.77197265625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.4609375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.421142578125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.421875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.2099609375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 4.36328125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0311737060546875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 4.2890625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.016143798828125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 4.21484375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.0038547515869140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 4.140625  val f1:0.14286  lr: 0.0003 batch: 16
epochs: 0 train loss: 0.5229104974323371  train f1: 0.49571  lr: 0.0003 batch: 8 
epochs: 0 val loss: 0.8274096594916449  val f1:0.63622  lr: 0.0003 batch: 8
epochs: 1 train loss: 0.14428013934756173  train f1: 0.80773  lr: 0.0003 batch: 8 
epochs: 1 val loss: 0.6924269499602147  val f1:0.73598  lr: 0.0003 batch: 8
epochs: 2 train loss: 0.08950027600488167  train f1: 0.88931  lr: 0.0003 batch: 8 
epochs: 2 val loss: 0.7084198792775472  val f1:0.76666  lr: 0.0003 batch: 8
epochs: 3 train loss: 0.055237184661879456  train f1: 0.93509  lr: 0.0003 batch: 8 
epochs: 3 val loss: 0.7334385024176704  val f1:0.77845  lr: 0.0003 batch: 8
epochs: 4 train loss: 0.051866286301850736  train f1: 0.94117  lr: 0.0003 batch: 8 
epochs: 4 val loss: 0.939376217347604  val f1:0.76498  lr: 0.0003 batch: 8
epochs: 5 train loss: 0.03325721242481333  train f1: 0.96528  lr: 0.0003 batch: 8 
epochs: 5 val loss: 0.8029389142990111  val f1:0.80035  lr: 0.0003 batch: 8
epochs: 6 train loss: 0.031578920725872366  train f1: 0.97044  lr: 0.0003 batch: 8 
epochs: 6 val loss: 0.9715855059800321  val f1:0.77385  lr: 0.0003 batch: 8
epochs: 0 train loss: 0.6001118115356151  train f1: 0.42592  lr: 0.0003 batch: 16 
epochs: 0 val loss: 1.0125144675925921  val f1:0.56025  lr: 0.0003 batch: 16
epochs: 1 train loss: 0.1940827167539526  train f1: 0.74151  lr: 0.0003 batch: 16 
epochs: 1 val loss: 0.7339251482928238  val f1:0.69116  lr: 0.0003 batch: 16
epochs: 2 train loss: 0.11832599449633374  train f1: 0.84655  lr: 0.0003 batch: 16 
epochs: 2 val loss: 0.7760041413483794  val f1:0.73861  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.07618955186477627  train f1: 0.89980  lr: 0.0003 batch: 16 
epochs: 3 val loss: 0.742197757297092  val f1:0.75000  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.06542371127968111  train f1: 0.92713  lr: 0.0003 batch: 16 
epochs: 4 val loss: 0.8031689396610968  val f1:0.77385  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.22265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.5390625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.22265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.6328125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 4.30859375  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.5390625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 3 train loss: 2.0234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.50390625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.43115234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.4921875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.325439453125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.54296875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.1552734375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.65625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.22265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.5390625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.22265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.6328125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 4.30859375  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.5390625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 3 train loss: 2.0234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.50390625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.43115234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.4921875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.22265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.5390625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.22265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.6328125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 4.30859375  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.5390625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 3 train loss: 2.0234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.50390625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.43115234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.4921875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.325439453125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.54296875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.30859375  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.4453125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.26171875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.53515625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.4375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.263671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.40625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.349365234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.37109375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.144287109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.3359375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.0491943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.34765625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.019378662109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 4.3984375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.30859375  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.4453125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.26171875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.53515625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.4375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.263671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.40625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.3203125  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8671875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.8671875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.681640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.8046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.291015625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.64453125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.355224609375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.5  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.3203125  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8671875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.8671875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.681640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.8046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.291015625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.64453125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2734375  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.82421875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2421875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83984375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.79296875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.81640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.703125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.84375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.79296875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.7578125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69921875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83984375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.79296875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.27734375  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8359375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.7890625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.23828125  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83984375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.79296875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.34765625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.83984375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.25390625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.7890625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.19140625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8359375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.7890625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.69921875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.66015625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.19140625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8359375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.7890625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.26171875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.86328125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.828125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.26171875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.828125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.30078125  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.8203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.763671875  train f1: 0.66667  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.71484375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.296875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.828125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.36328125  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.80859375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.1796875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8359375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.30078125  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.82421875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.21875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.36328125  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.80859375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.66796875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.73046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.888671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.55078125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.371826171875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3515625  val f1:0.14286  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.1322021484375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.17578125  val f1:0.14286  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.034149169921875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0078125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.0171051025390625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.8515625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.01139068603515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.783203125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.004077911376953125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.708984375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.0035953521728515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.673828125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0024013519287109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.6640625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.001827239990234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 3.6328125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.00086212158203125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 3.61328125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0009508132934570312  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 3.615234375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.21875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.36328125  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.80859375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 0.6182759349185617  train f1: 0.41643  lr: 0.0003 batch: 16 
epochs: 0 val loss: 0.9806866681134263  val f1:0.57457  lr: 0.0003 batch: 16
epochs: 1 train loss: 0.18437136557334086  train f1: 0.74949  lr: 0.0003 batch: 16 
epochs: 1 val loss: 0.7362223307291667  val f1:0.71075  lr: 0.0003 batch: 16
epochs: 2 train loss: 0.1236606167438917  train f1: 0.83845  lr: 0.0003 batch: 16 
epochs: 2 val loss: 0.8069954766167531  val f1:0.75755  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.08057997589396712  train f1: 0.90459  lr: 0.0003 batch: 16 
epochs: 3 val loss: 0.9337938661928529  val f1:0.73761  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.0658773252197038  train f1: 0.92527  lr: 0.0003 batch: 16 
epochs: 4 val loss: 0.8313436437536172  val f1:0.73844  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.06213724732101702  train f1: 0.92897  lr: 0.0003 batch: 16 
epochs: 5 val loss: 0.8744946515118638  val f1:0.76465  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.04740709809591058  train f1: 0.94099  lr: 0.0003 batch: 16 
epochs: 6 val loss: 0.8998951099537037  val f1:0.74870  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.04287276571230995  train f1: 0.95556  lr: 0.0003 batch: 16 
epochs: 7 val loss: 0.9848613032588253  val f1:0.78445  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.04121258743386019  train f1: 0.95552  lr: 0.0003 batch: 16 
epochs: 8 val loss: 0.9741448296440977  val f1:0.74903  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.03927432368521087  train f1: 0.95993  lr: 0.0003 batch: 16 
epochs: 9 val loss: 0.8965286431489164  val f1:0.77972  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.025115221590175315  train f1: 0.97511  lr: 0.0003 batch: 16 
epochs: 10 val loss: 0.9699497505470557  val f1:0.77955  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.04417648621628109  train f1: 0.96040  lr: 0.0003 batch: 16 
epochs: 11 val loss: 0.8728532861780238  val f1:0.76810  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.02986518291761154  train f1: 0.96626  lr: 0.0003 batch: 16 
epochs: 12 val loss: 0.9958671428539138  val f1:0.78922  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.026208546021929995  train f1: 0.97288  lr: 0.0003 batch: 16 
epochs: 13 val loss: 0.8269449657864041  val f1:0.82123  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.020088393714957114  train f1: 0.97955  lr: 0.0003 batch: 16 
epochs: 14 val loss: 0.9321589434588399  val f1:0.77923  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.031050319534882066  train f1: 0.97050  lr: 0.0003 batch: 16 
epochs: 15 val loss: 0.9411134887624665  val f1:0.79112  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.032217619499363505  train f1: 0.96268  lr: 0.0003 batch: 16 
epochs: 16 val loss: 0.843244093435782  val f1:0.79341  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.03278754997134504  train f1: 0.96726  lr: 0.0003 batch: 16 
epochs: 17 val loss: 0.9610105020028573  val f1:0.77977  lr: 0.0003 batch: 16
epochs: 18 train loss: 0.020468827940876663  train f1: 0.97987  lr: 0.0003 batch: 16 
epochs: 18 val loss: 1.1488327308937356  val f1:0.77815  lr: 0.0003 batch: 16
epochs: 19 train loss: 0.0325631432402461  train f1: 0.96948  lr: 0.0003 batch: 16 
epochs: 19 val loss: 0.8723292050538239  val f1:0.76882  lr: 0.0003 batch: 16
epochs: 20 train loss: 0.019012179309293217  train f1: 0.98340  lr: 0.0003 batch: 16 
epochs: 20 val loss: 1.003086464493363  val f1:0.78488  lr: 0.0003 batch: 16
epochs: 0 train loss: 0.6182759349185617  train f1: 0.41643  lr: 0.0003 batch: 16 
epochs: 0 val loss: 0.9806866681134263  val f1:0.57457  lr: 0.0003 batch: 16
epochs: 1 train loss: 0.18437136557334086  train f1: 0.74949  lr: 0.0003 batch: 16 
epochs: 1 val loss: 0.7362223307291667  val f1:0.71075  lr: 0.0003 batch: 16
epochs: 2 train loss: 0.1236606167438917  train f1: 0.83845  lr: 0.0003 batch: 16 
epochs: 2 val loss: 0.8069954766167531  val f1:0.75755  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.08057997589396712  train f1: 0.90459  lr: 0.0003 batch: 16 
epochs: 3 val loss: 0.9337938661928529  val f1:0.73761  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.0658773252197038  train f1: 0.92527  lr: 0.0003 batch: 16 
epochs: 4 val loss: 0.8313436437536172  val f1:0.73844  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.06213724732101702  train f1: 0.92897  lr: 0.0003 batch: 16 
epochs: 5 val loss: 0.8744946515118638  val f1:0.76465  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.04740709809591058  train f1: 0.94099  lr: 0.0003 batch: 16 
epochs: 6 val loss: 0.8998951099537037  val f1:0.74870  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.04287276571230995  train f1: 0.95556  lr: 0.0003 batch: 16 
epochs: 7 val loss: 0.9848613032588253  val f1:0.78445  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.04121258743386019  train f1: 0.95552  lr: 0.0003 batch: 16 
epochs: 8 val loss: 0.9741448296440977  val f1:0.74903  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.03927432368521087  train f1: 0.95993  lr: 0.0003 batch: 16 
epochs: 9 val loss: 0.8965286431489164  val f1:0.77972  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.025115221590175315  train f1: 0.97511  lr: 0.0003 batch: 16 
epochs: 10 val loss: 0.9699497505470557  val f1:0.77955  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.04417648621628109  train f1: 0.96040  lr: 0.0003 batch: 16 
epochs: 11 val loss: 0.8728532861780238  val f1:0.76810  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.02986518291761154  train f1: 0.96626  lr: 0.0003 batch: 16 
epochs: 12 val loss: 0.9958671428539138  val f1:0.78922  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.026208546021929995  train f1: 0.97288  lr: 0.0003 batch: 16 
epochs: 13 val loss: 0.8269449657864041  val f1:0.82123  lr: 0.0003 batch: 16
epochs: 0 train loss: 0.6086905757685253  train f1: 0.42895  lr: 0.0003 batch: 16 
epochs: 0 val loss: 0.9423032407407405  val f1:0.56418  lr: 0.0003 batch: 16
epochs: 0 train loss: 0.6086905757685253  train f1: 0.42895  lr: 0.0003 batch: 16 
epochs: 0 val loss: 0.9423032407407405  val f1:0.56418  lr: 0.0003 batch: 16
epochs: 1 train loss: 0.20657824994322668  train f1: 0.73546  lr: 0.0003 batch: 16 
epochs: 1 val loss: 0.8643516257957174  val f1:0.67831  lr: 0.0003 batch: 16
epochs: 2 train loss: 0.1232745308531193  train f1: 0.84048  lr: 0.0003 batch: 16 
epochs: 2 val loss: 0.8054167570891202  val f1:0.71093  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.09372267164197064  train f1: 0.89064  lr: 0.0003 batch: 16 
epochs: 3 val loss: 0.6995326289424192  val f1:0.77036  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.0650376453066704  train f1: 0.92153  lr: 0.0003 batch: 16 
epochs: 4 val loss: 0.8334325861047817  val f1:0.76405  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.06124413072914252  train f1: 0.93127  lr: 0.0003 batch: 16 
epochs: 5 val loss: 0.904157398365162  val f1:0.73337  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.05163063989613124  train f1: 0.94369  lr: 0.0003 batch: 16 
epochs: 6 val loss: 1.0364265724464699  val f1:0.74266  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.04861802382956717  train f1: 0.94962  lr: 0.0003 batch: 16 
epochs: 7 val loss: 0.7745009810836226  val f1:0.77904  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.04960482658590756  train f1: 0.95004  lr: 0.0003 batch: 16 
epochs: 8 val loss: 0.852079928362811  val f1:0.78269  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.03242585055548651  train f1: 0.96706  lr: 0.0003 batch: 16 
epochs: 9 val loss: 0.8194676575837311  val f1:0.80626  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.04129629658344683  train f1: 0.96095  lr: 0.0003 batch: 16 
epochs: 10 val loss: 0.9959488939355917  val f1:0.77017  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.03725898615142653  train f1: 0.96505  lr: 0.0003 batch: 16 
epochs: 11 val loss: 0.9860257749204285  val f1:0.78454  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.037947523772270605  train f1: 0.95748  lr: 0.0003 batch: 16 
epochs: 12 val loss: 0.990027251066985  val f1:0.80506  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.04155118068554754  train f1: 0.96095  lr: 0.0003 batch: 16 
epochs: 13 val loss: 1.212867341218171  val f1:0.73852  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.025241727840870705  train f1: 0.98067  lr: 0.0003 batch: 16 
epochs: 14 val loss: 0.844493809452764  val f1:0.82720  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.02785081823270518  train f1: 0.97808  lr: 0.0003 batch: 16 
epochs: 15 val loss: 0.8718018209492716  val f1:0.78516  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.025379911919781648  train f1: 0.97317  lr: 0.0003 batch: 16 
epochs: 16 val loss: 0.8074565710844813  val f1:0.80990  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.032830129463476465  train f1: 0.96701  lr: 0.0003 batch: 16 
epochs: 17 val loss: 0.9964098506503638  val f1:0.79880  lr: 0.0003 batch: 16
epochs: 18 train loss: 0.027393297735889683  train f1: 0.97173  lr: 0.0003 batch: 16 
epochs: 18 val loss: 1.0292289733886717  val f1:0.78303  lr: 0.0003 batch: 16
epochs: 19 train loss: 0.01646114748315027  train f1: 0.97787  lr: 0.0003 batch: 16 
epochs: 19 val loss: 1.157881192807798  val f1:0.75369  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.17578125  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8359375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.17578125  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8359375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.17578125  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8359375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.17578125  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8359375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 0.6142047349354272  train f1: 0.41836  lr: 0.0003 batch: 16 
epochs: 0 val loss: 0.9094514069733797  val f1:0.55735  lr: 0.0003 batch: 16
epochs: 1 train loss: 0.1958640852473918  train f1: 0.74914  lr: 0.0003 batch: 16 
epochs: 1 val loss: 0.7981924551504629  val f1:0.68019  lr: 0.0003 batch: 16
epochs: 2 train loss: 0.10568350746744577  train f1: 0.85827  lr: 0.0003 batch: 16 
epochs: 2 val loss: 0.9128813566984955  val f1:0.69774  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.09465667018272046  train f1: 0.88885  lr: 0.0003 batch: 16 
epochs: 3 val loss: 0.7531645598234956  val f1:0.77451  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.06317815310937211  train f1: 0.92980  lr: 0.0003 batch: 16 
epochs: 4 val loss: 0.7792228981300636  val f1:0.76249  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.05582668299686872  train f1: 0.93456  lr: 0.0003 batch: 16 
epochs: 5 val loss: 0.8963126005949799  val f1:0.76540  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.04853602158755732  train f1: 0.95017  lr: 0.0003 batch: 16 
epochs: 6 val loss: 0.8212576972113717  val f1:0.77280  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.052049795736993074  train f1: 0.94184  lr: 0.0003 batch: 16 
epochs: 7 val loss: 0.7118586222330728  val f1:0.80650  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.029029735603237385  train f1: 0.96834  lr: 0.0003 batch: 16 
epochs: 8 val loss: 0.8434825332076463  val f1:0.78037  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.036491288508560274  train f1: 0.96264  lr: 0.0003 batch: 16 
epochs: 9 val loss: 0.850811089409722  val f1:0.76815  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.0381447079770285  train f1: 0.95836  lr: 0.0003 batch: 16 
epochs: 10 val loss: 0.8111493145978008  val f1:0.79113  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.046058194669999324  train f1: 0.95837  lr: 0.0003 batch: 16 
epochs: 11 val loss: 0.9113114251030816  val f1:0.77925  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.02910746890410519  train f1: 0.97259  lr: 0.0003 batch: 16 
epochs: 12 val loss: 0.96848166430438  val f1:0.78649  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.12109375  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8671875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.12109375  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8671875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8359375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.12109375  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8671875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.12109375  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8671875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.82421875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 3.009765625  train f1: 0.50000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.77734375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.0234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.640625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.44921875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.1868896484375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.22265625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.04241943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0546875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.020965576171875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.94140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.10546875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.87109375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.82421875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 3.1484375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.71484375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.43359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.55078125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.37890625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.22607421875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.1328125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.0758056640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 3.947265625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.032562255859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.818359375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.01406097412109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.77734375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.0054931640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.724609375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.003711700439453125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.66015625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.00484466552734375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.615234375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.00240325927734375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 3.580078125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.001125335693359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 3.568359375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.1640625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.859375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.990234375  train f1: 0.66667  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.70703125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.02734375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.53515625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.401123046875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.30859375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.1419677734375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.1015625  val f1:0.14286  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.051483154296875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 3.935546875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.02117919921875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.81640625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.01837158203125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.814453125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.01296234130859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.763671875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006481170654296875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.728515625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.79296875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.52734375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.671875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.916015625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.4453125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.4521484375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.21484375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.1083984375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.0234375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.03839111328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 3.908203125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.01763916015625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.84765625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0099945068359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.787109375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.004657745361328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.740234375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006366729736328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.7890625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0019159317016601562  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.751953125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.0019121170043945312  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 3.771484375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.002117156982421875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 3.810546875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0008401870727539062  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 3.83984375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.0008301734924316406  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 15 val loss: 3.849609375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.0007462501525878906  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 16 val loss: 3.8828125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.0005459785461425781  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 17 val loss: 3.89453125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 18 train loss: 0.0008697509765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 18 val loss: 3.892578125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 19 train loss: 0.0003464221954345703  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 19 val loss: 3.8984375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.79296875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.41796875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.65234375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.513671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.51953125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.33642578125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.32421875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.12384033203125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.1171875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047607421875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 3.943359375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.03167724609375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.84375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.01541900634765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.775390625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00934600830078125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.68359375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 0.6138644373030434  train f1: 0.41996  lr: 0.0003 batch: 16 
epochs: 0 val loss: 0.9660590277777776  val f1:0.56326  lr: 0.0003 batch: 16
epochs: 1 train loss: 0.18740519858952479  train f1: 0.74861  lr: 0.0003 batch: 16 
epochs: 1 val loss: 0.7294180410879634  val f1:0.69477  lr: 0.0003 batch: 16
epochs: 2 train loss: 0.12032130412627316  train f1: 0.84220  lr: 0.0003 batch: 16 
epochs: 2 val loss: 0.8129588939525468  val f1:0.73255  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.07791080379723905  train f1: 0.90557  lr: 0.0003 batch: 16 
epochs: 3 val loss: 0.8391934995298032  val f1:0.74634  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.05462736887230239  train f1: 0.94005  lr: 0.0003 batch: 16 
epochs: 4 val loss: 0.9963519626193579  val f1:0.74217  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.055211774577523756  train f1: 0.93887  lr: 0.0003 batch: 16 
epochs: 5 val loss: 0.8845613126401553  val f1:0.76764  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.04409919504512875  train f1: 0.94711  lr: 0.0003 batch: 16 
epochs: 6 val loss: 0.8654644012451167  val f1:0.78120  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.05214655845242549  train f1: 0.94106  lr: 0.0003 batch: 16 
epochs: 7 val loss: 0.8579502812138312  val f1:0.76837  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.046309613676142475  train f1: 0.95257  lr: 0.0003 batch: 16 
epochs: 8 val loss: 1.2264634308991602  val f1:0.76462  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.03811615787242115  train f1: 0.96264  lr: 0.0003 batch: 16 
epochs: 9 val loss: 0.8979156917995879  val f1:0.79264  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.030422819225568123  train f1: 0.97165  lr: 0.0003 batch: 16 
epochs: 10 val loss: 0.828340823562057  val f1:0.77770  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0027866363525390625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.7421875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.0019893646240234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 3.744140625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.000949859619140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 3.73046875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0009784698486328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 3.7265625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.0009250640869140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 15 val loss: 3.740234375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.00038743019104003906  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 16 val loss: 3.720703125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.0002689361572265625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 17 val loss: 3.689453125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 18 train loss: 0.0002396106719970703  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 18 val loss: 3.69921875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 19 train loss: 0.00030040740966796875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 19 val loss: 3.724609375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0027866363525390625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.7421875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.0019893646240234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 3.744140625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.000949859619140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 3.73046875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0009784698486328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 3.7265625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0027866363525390625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.7421875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.0019893646240234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 3.744140625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.000949859619140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 3.73046875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0009784698486328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 3.7265625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.0009250640869140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 15 val loss: 3.740234375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.00038743019104003906  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 16 val loss: 3.720703125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.0002689361572265625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 17 val loss: 3.689453125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 18 train loss: 0.0002396106719970703  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 18 val loss: 3.69921875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 19 train loss: 0.00030040740966796875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 19 val loss: 3.724609375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0027866363525390625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.7421875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.0019893646240234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 3.744140625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.000949859619140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 3.73046875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0009784698486328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 3.7265625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0027866363525390625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.7421875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.0019893646240234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 3.744140625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.000949859619140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 3.73046875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0009784698486328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 3.7265625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.0009250640869140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 15 val loss: 3.740234375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.00038743019104003906  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 16 val loss: 3.720703125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.0002689361572265625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 17 val loss: 3.689453125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 18 train loss: 0.0002396106719970703  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 18 val loss: 3.69921875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 19 train loss: 0.00030040740966796875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 19 val loss: 3.724609375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.3046875  train f1: 0.00000  lr: 0.0003 batch: 2 
epochs: 0 val loss: 4.890625  val f1:0.00000  lr: 0.0003 batch: 2
epochs: 1 train loss: 3.8330078125  train f1: 0.13333  lr: 0.0003 batch: 2 
epochs: 1 val loss: 4.651041666666667  val f1:0.00000  lr: 0.0003 batch: 2
epochs: 2 train loss: 2.7802734375  train f1: 0.41667  lr: 0.0003 batch: 2 
epochs: 2 val loss: 4.345703125  val f1:0.12500  lr: 0.0003 batch: 2
epochs: 3 train loss: 1.82177734375  train f1: 0.77778  lr: 0.0003 batch: 2 
epochs: 3 val loss: 4.165364583333333  val f1:0.11111  lr: 0.0003 batch: 2
epochs: 4 train loss: 1.02880859375  train f1: 1.00000  lr: 0.0003 batch: 2 
epochs: 4 val loss: 4.052083333333334  val f1:0.11111  lr: 0.0003 batch: 2
epochs: 5 train loss: 0.3541259765625  train f1: 1.00000  lr: 0.0003 batch: 2 
epochs: 5 val loss: 4.04296875  val f1:0.11111  lr: 0.0003 batch: 2
epochs: 6 train loss: 0.10272216796875  train f1: 1.00000  lr: 0.0003 batch: 2 
epochs: 6 val loss: 4.070963541666666  val f1:0.11111  lr: 0.0003 batch: 2
epochs: 7 train loss: 0.0645751953125  train f1: 1.00000  lr: 0.0003 batch: 2 
epochs: 7 val loss: 4.076171875  val f1:0.11111  lr: 0.0003 batch: 2
epochs: 8 train loss: 0.50067138671875  train f1: 1.00000  lr: 0.0003 batch: 2 
epochs: 8 val loss: 4.017578125  val f1:0.11111  lr: 0.0003 batch: 2
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0027866363525390625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.7421875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.0019893646240234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 3.744140625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.000949859619140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 3.73046875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0009784698486328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 3.7265625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.0009250640869140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 15 val loss: 3.740234375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.00038743019104003906  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 16 val loss: 3.720703125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.0002689361572265625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 17 val loss: 3.689453125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 18 train loss: 0.0002396106719970703  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 18 val loss: 3.69921875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 19 train loss: 0.00030040740966796875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 19 val loss: 3.724609375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0027866363525390625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.7421875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.0019893646240234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 3.744140625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.000949859619140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 3.73046875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0009784698486328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 3.7265625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.0009250640869140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 15 val loss: 3.740234375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.00038743019104003906  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 16 val loss: 3.720703125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.0002689361572265625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 17 val loss: 3.689453125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 18 train loss: 0.0002396106719970703  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 18 val loss: 3.69921875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 19 train loss: 0.00030040740966796875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 19 val loss: 3.724609375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0027866363525390625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.7421875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.0019893646240234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 3.744140625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0027866363525390625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.7421875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.0019893646240234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 3.744140625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.000949859619140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 3.73046875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0009784698486328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 3.7265625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0027866363525390625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.7421875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.0019893646240234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 3.744140625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.000949859619140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 3.73046875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0009784698486328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 3.7265625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.0009250640869140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 15 val loss: 3.740234375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.00038743019104003906  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 16 val loss: 3.720703125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.0002689361572265625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 17 val loss: 3.689453125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0027866363525390625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.7421875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.0019893646240234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 3.744140625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.000949859619140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 3.73046875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0009784698486328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 3.7265625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.0009250640869140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 15 val loss: 3.740234375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.00038743019104003906  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 16 val loss: 3.720703125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.0002689361572265625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 17 val loss: 3.689453125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 18 train loss: 0.0002396106719970703  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 18 val loss: 3.69921875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 19 train loss: 0.00030040740966796875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 19 val loss: 3.724609375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0027866363525390625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.7421875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.0019893646240234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 3.744140625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.000949859619140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 3.73046875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0009784698486328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 3.7265625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.0009250640869140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 15 val loss: 3.740234375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.00038743019104003906  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 16 val loss: 3.720703125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.0002689361572265625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 17 val loss: 3.689453125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 18 train loss: 0.0002396106719970703  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 18 val loss: 3.69921875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 19 train loss: 0.00030040740966796875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 19 val loss: 3.724609375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0027866363525390625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.7421875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.0019893646240234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 3.744140625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.000949859619140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 3.73046875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0009784698486328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 3.7265625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.0009250640869140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 15 val loss: 3.740234375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.00038743019104003906  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 16 val loss: 3.720703125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.0002689361572265625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 17 val loss: 3.689453125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 18 train loss: 0.0002396106719970703  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 18 val loss: 3.69921875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 19 train loss: 0.00030040740966796875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 19 val loss: 3.724609375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0027866363525390625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.7421875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0027866363525390625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.7421875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.0019893646240234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 3.744140625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.000949859619140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 3.73046875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0009784698486328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 3.7265625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.0009250640869140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 15 val loss: 3.740234375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.00038743019104003906  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 16 val loss: 3.720703125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.0002689361572265625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 17 val loss: 3.689453125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 18 train loss: 0.0002396106719970703  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 18 val loss: 3.69921875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 19 train loss: 0.00030040740966796875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 19 val loss: 3.724609375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0027866363525390625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.7421875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.0019893646240234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 3.744140625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.000949859619140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 3.73046875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0009784698486328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 3.7265625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.0009250640869140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 15 val loss: 3.740234375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.00038743019104003906  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 16 val loss: 3.720703125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.0002689361572265625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 17 val loss: 3.689453125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 18 train loss: 0.0002396106719970703  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 18 val loss: 3.69921875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 19 train loss: 0.00030040740966796875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 19 val loss: 3.724609375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.385009765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.116943359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.047332763671875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.0  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.018890380859375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 3.908203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.0084228515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 3.833984375  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.00820159912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 3.7578125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.006679534912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.0027866363525390625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 3.7421875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.0019893646240234375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 3.744140625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.000949859619140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 3.73046875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0009784698486328125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 3.7265625  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.0009250640869140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 15 val loss: 3.740234375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.00038743019104003906  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 16 val loss: 3.720703125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.0002689361572265625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 17 val loss: 3.689453125  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 18 train loss: 0.0002396106719970703  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 18 val loss: 3.69921875  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 19 train loss: 0.00030040740966796875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 19 val loss: 3.724609375  val f1:0.11111  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.359375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.69140625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 0.6182759349185617  train f1: 0.41643  lr: 0.0003 batch: 16 
epochs: 0 val loss: 0.9806866681134263  val f1:0.57457  lr: 0.0003 batch: 16
epochs: 1 train loss: 0.19499481586446787  train f1: 0.74043  lr: 0.0003 batch: 16 
epochs: 1 val loss: 0.6918303313078707  val f1:0.72345  lr: 0.0003 batch: 16
epochs: 2 train loss: 0.11705371388176151  train f1: 0.84674  lr: 0.0003 batch: 16 
epochs: 2 val loss: 0.7371333369502312  val f1:0.74116  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.08605314192926507  train f1: 0.88751  lr: 0.0003 batch: 16 
epochs: 3 val loss: 0.9308325167055483  val f1:0.72972  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.06414947872447255  train f1: 0.92337  lr: 0.0003 batch: 16 
epochs: 4 val loss: 0.807210710313585  val f1:0.78644  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.0514236102229045  train f1: 0.94333  lr: 0.0003 batch: 16 
epochs: 5 val loss: 0.9471306694878469  val f1:0.75595  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.048475552378152736  train f1: 0.94821  lr: 0.0003 batch: 16 
epochs: 6 val loss: 0.9443966335720486  val f1:0.76569  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.04937441806840785  train f1: 0.94698  lr: 0.0003 batch: 16 
epochs: 7 val loss: 0.81913491708261  val f1:0.77834  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.034365307140231394  train f1: 0.95921  lr: 0.0003 batch: 16 
epochs: 8 val loss: 0.7489488919576004  val f1:0.81027  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.03157425907781888  train f1: 0.96227  lr: 0.0003 batch: 16 
epochs: 9 val loss: 0.8862346861097544  val f1:0.76780  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.032457665686595485  train f1: 0.96812  lr: 0.0003 batch: 16 
epochs: 10 val loss: 1.270830472310384  val f1:0.73968  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.04432054462278273  train f1: 0.95190  lr: 0.0003 batch: 16 
epochs: 11 val loss: 1.0681382497151692  val f1:0.75348  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.037528138802830416  train f1: 0.96584  lr: 0.0003 batch: 16 
epochs: 12 val loss: 0.8463199650799795  val f1:0.81614  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.02626649310761262  train f1: 0.97512  lr: 0.0003 batch: 16 
epochs: 13 val loss: 1.1337641115541808  val f1:0.77858  lr: 0.0003 batch: 16
epochs: 0 train loss: 0.6171068110668158  train f1: 0.41985  lr: 0.0003 batch: 16 
epochs: 0 val loss: 1.1027117693865742  val f1:0.55512  lr: 0.0003 batch: 16
epochs: 1 train loss: 0.20030105619359184  train f1: 0.73196  lr: 0.0003 batch: 16 
epochs: 1 val loss: 0.7963130244502314  val f1:0.66386  lr: 0.0003 batch: 16
epochs: 2 train loss: 0.10630266446425136  train f1: 0.85821  lr: 0.0003 batch: 16 
epochs: 2 val loss: 0.8716464572482636  val f1:0.71050  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.0953962160762112  train f1: 0.88552  lr: 0.0003 batch: 16 
epochs: 3 val loss: 0.9570615415219909  val f1:0.74816  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.05651880588912018  train f1: 0.92791  lr: 0.0003 batch: 16 
epochs: 4 val loss: 0.8240616268581813  val f1:0.77171  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.055828098941622294  train f1: 0.94818  lr: 0.0003 batch: 16 
epochs: 5 val loss: 1.0061530925609452  val f1:0.73172  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.05390110946355621  train f1: 0.94131  lr: 0.0003 batch: 16 
epochs: 6 val loss: 0.9487760543823239  val f1:0.76059  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.04241820300309138  train f1: 0.95525  lr: 0.0003 batch: 16 
epochs: 7 val loss: 0.9200299510249381  val f1:0.76236  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.04930793666780145  train f1: 0.95316  lr: 0.0003 batch: 16 
epochs: 8 val loss: 0.9563728615089698  val f1:0.76704  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.03771726508390283  train f1: 0.96372  lr: 0.0003 batch: 16 
epochs: 9 val loss: 1.018552405745895  val f1:0.76267  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.03213155774998844  train f1: 0.96318  lr: 0.0003 batch: 16 
epochs: 10 val loss: 0.8990374105947982  val f1:0.76310  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.050717278980554795  train f1: 0.94630  lr: 0.0003 batch: 16 
epochs: 11 val loss: 0.7662780196578414  val f1:0.78529  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.024006605817195468  train f1: 0.97822  lr: 0.0003 batch: 16 
epochs: 12 val loss: 0.873808119032118  val f1:0.78742  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.02817103987620062  train f1: 0.97489  lr: 0.0003 batch: 16 
epochs: 13 val loss: 1.0436854962949396  val f1:0.78843  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.03842993745780054  train f1: 0.96328  lr: 0.0003 batch: 16 
epochs: 14 val loss: 1.0831374556929978  val f1:0.75504  lr: 0.0003 batch: 16
epochs: 0 train loss: 0.6090206612375313  train f1: 0.40814  lr: 0.0003 batch: 32 
epochs: 0 val loss: 1.0505012063419117  val f1:0.54206  lr: 0.0003 batch: 32
epochs: 1 train loss: 0.17699986027363218  train f1: 0.76117  lr: 0.0003 batch: 32 
epochs: 1 val loss: 0.7107876048368567  val f1:0.71178  lr: 0.0003 batch: 32
epochs: 2 train loss: 0.0858088467186526  train f1: 0.89317  lr: 0.0003 batch: 32 
epochs: 2 val loss: 0.7038035673253676  val f1:0.75119  lr: 0.0003 batch: 32
epochs: 3 train loss: 0.06236409189695132  train f1: 0.92501  lr: 0.0003 batch: 32 
epochs: 3 val loss: 0.5995555204503676  val f1:0.78114  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.044444264913734946  train f1: 0.95295  lr: 0.0003 batch: 32 
epochs: 4 val loss: 0.8006807215073529  val f1:0.75926  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.0410457159812908  train f1: 0.95104  lr: 0.0003 batch: 32 
epochs: 5 val loss: 0.830644495346967  val f1:0.75608  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.04198378874476712  train f1: 0.95824  lr: 0.0003 batch: 32 
epochs: 6 val loss: 0.7214876062729781  val f1:0.78475  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.029936284198428035  train f1: 0.96874  lr: 0.0003 batch: 32 
epochs: 7 val loss: 0.7465892118566176  val f1:0.76587  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.036584449825144146  train f1: 0.96891  lr: 0.0003 batch: 32 
epochs: 8 val loss: 0.9048093907973347  val f1:0.76803  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.032062491276615  train f1: 0.96040  lr: 0.0003 batch: 32 
epochs: 9 val loss: 0.9559308220358456  val f1:0.76549  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.023679763301649594  train f1: 0.97914  lr: 0.0003 batch: 32 
epochs: 10 val loss: 0.8529606987448299  val f1:0.76234  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.031139555863311467  train f1: 0.97206  lr: 0.0003 batch: 32 
epochs: 11 val loss: 0.8050366569967831  val f1:0.77457  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.02157931642936649  train f1: 0.97522  lr: 0.0003 batch: 32 
epochs: 12 val loss: 0.8102596507352942  val f1:0.79277  lr: 0.0003 batch: 32
epochs: 0 train loss: 0.6042257484949738  train f1: 0.41192  lr: 0.0003 batch: 32 
epochs: 0 val loss: 0.999856387867647  val f1:0.56005  lr: 0.0003 batch: 32
epochs: 1 train loss: 0.17227673708946603  train f1: 0.76876  lr: 0.0003 batch: 32 
epochs: 1 val loss: 0.7830379710477942  val f1:0.69918  lr: 0.0003 batch: 32
epochs: 2 train loss: 0.08109732934661637  train f1: 0.88601  lr: 0.0003 batch: 32 
epochs: 2 val loss: 0.6326563218060661  val f1:0.75811  lr: 0.0003 batch: 32
epochs: 3 train loss: 0.06637495235909252  train f1: 0.92007  lr: 0.0003 batch: 32 
epochs: 3 val loss: 0.8510006175321692  val f1:0.74285  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.038794370066198035  train f1: 0.95602  lr: 0.0003 batch: 32 
epochs: 4 val loss: 0.7327189725988049  val f1:0.78186  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.04554240305227531  train f1: 0.94799  lr: 0.0003 batch: 32 
epochs: 5 val loss: 0.7917794620289523  val f1:0.76684  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.02851048372035608  train f1: 0.96619  lr: 0.0003 batch: 32 
epochs: 6 val loss: 0.7177025290096507  val f1:0.79233  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.039108469599203007  train f1: 0.95830  lr: 0.0003 batch: 32 
epochs: 7 val loss: 0.8275308048023897  val f1:0.79492  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.03010156237870977  train f1: 0.97369  lr: 0.0003 batch: 32 
epochs: 8 val loss: 0.7892904842601102  val f1:0.81064  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.021244670982075435  train f1: 0.97769  lr: 0.0003 batch: 32 
epochs: 9 val loss: 0.9002003389246325  val f1:0.75666  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.03379261047762826  train f1: 0.96837  lr: 0.0003 batch: 32 
epochs: 10 val loss: 0.7404803107766542  val f1:0.77706  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.030788055530510037  train f1: 0.97107  lr: 0.0003 batch: 32 
epochs: 11 val loss: 0.758959601907169  val f1:0.76970  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.02252430853403715  train f1: 0.96994  lr: 0.0003 batch: 32 
epochs: 12 val loss: 0.8316973517922793  val f1:0.77611  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.020262509064186845  train f1: 0.97607  lr: 0.0003 batch: 32 
epochs: 13 val loss: 0.8586030847886029  val f1:0.77445  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.12890625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 train loss: 4.125  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8515625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 0.6260465588652877  train f1: 0.39884  lr: 0.0003 batch: 16 
epochs: 0 val loss: 0.9496202256944447  val f1:0.55674  lr: 0.0003 batch: 16
epochs: 1 train loss: 0.2266583430796784  train f1: 0.70535  lr: 0.0003 batch: 16 
epochs: 1 val loss: 0.7242088035300928  val f1:0.69909  lr: 0.0003 batch: 16
epochs: 2 train loss: 0.13312848369379576  train f1: 0.83772  lr: 0.0003 batch: 16 
epochs: 2 val loss: 0.6320712619357637  val f1:0.75589  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.09175600732056566  train f1: 0.89144  lr: 0.0003 batch: 16 
epochs: 3 val loss: 0.7450953730830436  val f1:0.71982  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.08091873094030741  train f1: 0.90423  lr: 0.0003 batch: 16 
epochs: 4 val loss: 0.9858127170138895  val f1:0.71338  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.06701054269833459  train f1: 0.92721  lr: 0.0003 batch: 16 
epochs: 5 val loss: 0.8500148066767947  val f1:0.78295  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.0471584053705458  train f1: 0.94820  lr: 0.0003 batch: 16 
epochs: 6 val loss: 0.8418162027994791  val f1:0.77663  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.0662050737704422  train f1: 0.93520  lr: 0.0003 batch: 16 
epochs: 7 val loss: 0.8088290179217302  val f1:0.77875  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.04994983216770863  train f1: 0.95512  lr: 0.0003 batch: 16 
epochs: 8 val loss: 0.9213384628295898  val f1:0.75980  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.045029311406047545  train f1: 0.95473  lr: 0.0003 batch: 16 
epochs: 9 val loss: 0.8560893729881003  val f1:0.79215  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.04720770123593522  train f1: 0.94647  lr: 0.0003 batch: 16 
epochs: 10 val loss: 0.7770801685474538  val f1:0.79170  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.044666541336183245  train f1: 0.95841  lr: 0.0003 batch: 16 
epochs: 11 val loss: 0.9717792369701247  val f1:0.75456  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.040934777765202685  train f1: 0.95816  lr: 0.0003 batch: 16 
epochs: 12 val loss: 1.0542018042670358  val f1:0.77901  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.0417379157204283  train f1: 0.95969  lr: 0.0003 batch: 16 
epochs: 13 val loss: 0.877323517975984  val f1:0.78989  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.03573901650316993  train f1: 0.96416  lr: 0.0003 batch: 16 
epochs: 14 val loss: 0.7756833888866284  val f1:0.81194  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.03890690096001373  train f1: 0.96585  lr: 0.0003 batch: 16 
epochs: 15 val loss: 0.88095028841937  val f1:0.79270  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.02742202033723086  train f1: 0.97854  lr: 0.0003 batch: 16 
epochs: 16 val loss: 0.8848547829522025  val f1:0.79726  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.027338291715802685  train f1: 0.97362  lr: 0.0003 batch: 16 
epochs: 17 val loss: 0.8824003590477841  val f1:0.79794  lr: 0.0003 batch: 16
epochs: 18 train loss: 0.03869094582567193  train f1: 0.96641  lr: 0.0003 batch: 16 
epochs: 18 val loss: 0.8009570369014035  val f1:0.80477  lr: 0.0003 batch: 16
epochs: 19 train loss: 0.03453905951055207  train f1: 0.97138  lr: 0.0003 batch: 16 
epochs: 19 val loss: 0.8968246601246018  val f1:0.79294  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8359375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.16015625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.515625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.26171875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.62109375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 3.0  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.53125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.4853515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.4609375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.7080078125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.421875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.1728515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.4765625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.0650634765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.52734375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.0241241455078125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 4.62890625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.01273345947265625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 4.65625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.004688262939453125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 4.62890625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.003635406494140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 4.66015625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.00453948974609375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 4.72265625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.002044677734375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.0006990432739257812  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 4.85546875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.16015625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.515625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.26171875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.62109375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 3.0  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.53125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 3 train loss: 1.4853515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.4609375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.7080078125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.421875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.1728515625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.4765625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.0650634765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 6 val loss: 4.52734375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.0241241455078125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 7 val loss: 4.62890625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.01273345947265625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 8 val loss: 4.65625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.004688262939453125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 9 val loss: 4.62890625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.003635406494140625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 10 val loss: 4.66015625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.00453948974609375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 11 val loss: 4.72265625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.002044677734375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 12 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.0006990432739257812  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 13 val loss: 4.85546875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.0010023117065429688  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 14 val loss: 4.85546875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.001834869384765625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 15 val loss: 4.83984375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.00045299530029296875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 16 val loss: 4.8671875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.00036644935607910156  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 17 val loss: 4.87890625  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 18 train loss: 0.00098419189453125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 18 val loss: 4.83984375  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.1640625  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.453125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.26171875  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.5546875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 3.2890625  train f1: 0.66667  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.54296875  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.203125  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.7578125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 0 train loss: 0.6402335702035186  train f1: 0.39426  lr: 0.0003 batch: 16 
epochs: 0 val loss: 1.0129774305555552  val f1:0.54486  lr: 0.0003 batch: 16
epochs: 1 train loss: 0.23595311933027552  train f1: 0.70387  lr: 0.0003 batch: 16 
epochs: 1 val loss: 0.8638057002314816  val f1:0.66659  lr: 0.0003 batch: 16
epochs: 2 train loss: 0.1457082719874204  train f1: 0.81540  lr: 0.0003 batch: 16 
epochs: 2 val loss: 0.7465530960648147  val f1:0.70270  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.11460017385030927  train f1: 0.86468  lr: 0.0003 batch: 16 
epochs: 3 val loss: 0.7899420844184029  val f1:0.74031  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.08761924044449719  train f1: 0.89741  lr: 0.0003 batch: 16 
epochs: 4 val loss: 0.8002264517324942  val f1:0.72524  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.0766598117024524  train f1: 0.91124  lr: 0.0003 batch: 16 
epochs: 5 val loss: 0.8692496970847806  val f1:0.75178  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.0736288346554572  train f1: 0.91923  lr: 0.0003 batch: 16 
epochs: 6 val loss: 0.7480523533291287  val f1:0.77351  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.06430009832405989  train f1: 0.92725  lr: 0.0003 batch: 16 
epochs: 7 val loss: 0.8977732905635122  val f1:0.74627  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.051376068755575606  train f1: 0.95059  lr: 0.0003 batch: 16 
epochs: 8 val loss: 1.0503250969780815  val f1:0.75568  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.053814203513233426  train f1: 0.94002  lr: 0.0003 batch: 16 
epochs: 9 val loss: 0.8183792114257814  val f1:0.78403  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.04834758016533985  train f1: 0.95309  lr: 0.0003 batch: 16 
epochs: 10 val loss: 0.8744154612223304  val f1:0.77277  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.056511979447933125  train f1: 0.94347  lr: 0.0003 batch: 16 
epochs: 11 val loss: 0.8431184698034214  val f1:0.78260  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.04501825303508151  train f1: 0.95547  lr: 0.0003 batch: 16 
epochs: 12 val loss: 1.0986626801667387  val f1:0.76452  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.29296875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.82421875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 0 train loss: 0.6046977435561484  train f1: 0.40227  lr: 0.0003 batch: 32 
epochs: 0 val loss: 0.9912145278033088  val f1:0.53551  lr: 0.0003 batch: 32
epochs: 1 train loss: 0.175573353755504  train f1: 0.76233  lr: 0.0003 batch: 32 
epochs: 1 val loss: 0.7151884191176473  val f1:0.70211  lr: 0.0003 batch: 32
epochs: 2 train loss: 0.09013783842548166  train f1: 0.87284  lr: 0.0003 batch: 32 
epochs: 2 val loss: 0.7318007525275733  val f1:0.71909  lr: 0.0003 batch: 32
epochs: 3 train loss: 0.06030184015668837  train f1: 0.92608  lr: 0.0003 batch: 32 
epochs: 3 val loss: 0.7660019818474264  val f1:0.75145  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.04439693555570299  train f1: 0.94755  lr: 0.0003 batch: 32 
epochs: 4 val loss: 0.7956174962660847  val f1:0.79132  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.043115374453347205  train f1: 0.95799  lr: 0.0003 batch: 32 
epochs: 5 val loss: 0.7780878403607535  val f1:0.79259  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.04031662572351776  train f1: 0.95129  lr: 0.0003 batch: 32 
epochs: 6 val loss: 0.7037066291360293  val f1:0.79975  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.0373230468007989  train f1: 0.96238  lr: 0.0003 batch: 32 
epochs: 7 val loss: 0.759587287902832  val f1:0.79405  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.025760470185791168  train f1: 0.97003  lr: 0.0003 batch: 32 
epochs: 8 val loss: 0.8038092220530793  val f1:0.79644  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.0278143410076227  train f1: 0.97060  lr: 0.0003 batch: 32 
epochs: 9 val loss: 0.77698875876034  val f1:0.78839  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.02883056200056006  train f1: 0.96549  lr: 0.0003 batch: 32 
epochs: 10 val loss: 0.8981412999770222  val f1:0.76417  lr: 0.0003 batch: 32
epochs: 0 train loss: 0.6050109102244392  train f1: 0.41299  lr: 0.0003 batch: 32 
epochs: 0 val loss: 1.0416439280790437  val f1:0.54316  lr: 0.0003 batch: 32
epochs: 1 train loss: 0.17366948686633024  train f1: 0.75887  lr: 0.0003 batch: 32 
epochs: 1 val loss: 0.6679974724264703  val f1:0.71408  lr: 0.0003 batch: 32
epochs: 2 train loss: 0.09680156517504458  train f1: 0.87102  lr: 0.0003 batch: 32 
epochs: 2 val loss: 0.6378425149356618  val f1:0.77326  lr: 0.0003 batch: 32
epochs: 3 train loss: 0.058489816147193036  train f1: 0.92323  lr: 0.0003 batch: 32 
epochs: 3 val loss: 0.8382590798770683  val f1:0.74350  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.047177267193496956  train f1: 0.94178  lr: 0.0003 batch: 32 
epochs: 4 val loss: 0.7348780912511489  val f1:0.76634  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.0504685019019833  train f1: 0.94352  lr: 0.0003 batch: 32 
epochs: 5 val loss: 0.801276711856618  val f1:0.75819  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.03734217023017102  train f1: 0.96870  lr: 0.0003 batch: 32 
epochs: 6 val loss: 0.9060327866498162  val f1:0.74288  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.03230300181524412  train f1: 0.96064  lr: 0.0003 batch: 32 
epochs: 7 val loss: 0.6574738446403952  val f1:0.80417  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.02038014886385189  train f1: 0.98181  lr: 0.0003 batch: 32 
epochs: 8 val loss: 0.7958409365485695  val f1:0.78357  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.04629261089382028  train f1: 0.95031  lr: 0.0003 batch: 32 
epochs: 9 val loss: 0.7370569565716913  val f1:0.78049  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.034731927952564266  train f1: 0.95710  lr: 0.0003 batch: 32 
epochs: 10 val loss: 0.8480628518497243  val f1:0.76813  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.019280538891913612  train f1: 0.97912  lr: 0.0003 batch: 32 
epochs: 11 val loss: 0.8243141174316405  val f1:0.79330  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.02983197532687104  train f1: 0.97305  lr: 0.0003 batch: 32 
epochs: 12 val loss: 0.8736159380744485  val f1:0.78040  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.026745400821181587  train f1: 0.97700  lr: 0.0003 batch: 32 
epochs: 13 val loss: 0.794314188115737  val f1:0.81104  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.025376946105624076  train f1: 0.97860  lr: 0.0003 batch: 32 
epochs: 14 val loss: 0.7855583639705879  val f1:0.78075  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.021574473291858468  train f1: 0.97879  lr: 0.0003 batch: 32 
epochs: 15 val loss: 0.7204993752872241  val f1:0.80482  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0206958583168258  train f1: 0.98126  lr: 0.0003 batch: 32 
epochs: 16 val loss: 0.9848345588235294  val f1:0.75568  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.023169405145240855  train f1: 0.97592  lr: 0.0003 batch: 32 
epochs: 17 val loss: 0.7685834099264706  val f1:0.81031  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.017497294412884046  train f1: 0.98754  lr: 0.0003 batch: 32 
epochs: 18 val loss: 0.770832286161535  val f1:0.80755  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.015138226702920827  train f1: 0.98654  lr: 0.0003 batch: 32 
epochs: 19 val loss: 0.8272471708409932  val f1:0.80292  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.671875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.68359375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.671875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.68359375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.5625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.71875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 2.8515625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.71484375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 2.7734375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.703125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 4 train loss: 1.6376953125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.65625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.896484375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.55859375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.5390625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.54296875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.1986083984375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 4.62890625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.133056640625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 4.671875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.04754638671875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 4.68359375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.031524658203125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 4.6875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.021759033203125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 4.61328125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.0135498046875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 4.60546875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.009918212890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 4.5390625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.008544921875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 4.4296875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.00684356689453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 4.296875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.005584716796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 4.21484375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.00531005859375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 4.23828125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0034160614013671875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 4.28125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.002819061279296875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 4.28125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.46484375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.47265625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.40625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.5078125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.232421875  train f1: 0.33333  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.5859375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 3.16796875  train f1: 0.55556  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.62890625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 4 train loss: 2.962890625  train f1: 0.33333  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.67578125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 5 train loss: 2.28515625  train f1: 0.55556  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.84375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 6 train loss: 3.650390625  train f1: 0.37500  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.91796875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 7 train loss: 1.53125  train f1: 0.55556  lr: 0.0003 batch: 32 
epochs: 7 val loss: 5.19140625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 8 train loss: 2.095703125  train f1: 0.60000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 5.65625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 9 train loss: 2.447265625  train f1: 0.26667  lr: 0.0003 batch: 32 
epochs: 9 val loss: 6.26953125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.521484375  train f1: 0.55556  lr: 0.0003 batch: 32 
epochs: 10 val loss: 6.9296875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.79296875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 7.76171875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.65380859375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 8.71875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.056121826171875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 9.546875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.0350341796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 10.3359375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.017486572265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 11.171875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0106964111328125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 11.984375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.009185791015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 12.796875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.1370849609375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 14.359375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.003475189208984375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 15.546875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.5078125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 5.015625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.9375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 2.66796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.859375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.7060546875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.7734375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.5712890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.181640625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.4453125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.053802490234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.3046875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.027984619140625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 4.171875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.01160430908203125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 4.1015625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.0084381103515625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 4.046875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.00556182861328125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 4.0078125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.0025577545166015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.98046875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.0048828125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.9453125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.00243377685546875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.91796875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.00125885009765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.896484375  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.001796722412109375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.884765625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0009021759033203125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.876953125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0006151199340820312  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.880859375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0007066726684570312  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.873046875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0007157325744628906  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.853515625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.48828125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.4453125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.515625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.3125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.080078125  train f1: 0.66667  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.1328125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 2.26953125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.0078125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 4 train loss: 1.1708984375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 3.912109375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 3.8046875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.24267578125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 3.7421875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.057647705078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 3.703125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.039764404296875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.6484375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.01209259033203125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.642578125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.00591278076171875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.66796875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.0067596435546875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.66015625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.0037403106689453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.671875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.00336456298828125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.728515625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.0031185150146484375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.73828125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.0018901824951171875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.794921875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.00177764892578125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.81640625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0016078948974609375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.828125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0013141632080078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.853515625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0011930465698242188  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.837890625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.62109375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.88671875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.5859375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.796875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.16796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.7421875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.794921875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.66015625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.8994140625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.51171875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.35009765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.29296875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.119384765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.044219970703125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 4.00390625  val f1:0.08333  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.0243682861328125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.88671875  val f1:0.09524  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.0100555419921875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.8125  val f1:0.09524  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.00742340087890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.7578125  val f1:0.08333  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.005664825439453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.724609375  val f1:0.09524  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.003765106201171875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.701171875  val f1:0.27778  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.00394439697265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.669921875  val f1:0.27778  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.002410888671875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.64453125  val f1:0.27778  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.0018558502197265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.62890625  val f1:0.27778  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0013875961303710938  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.623046875  val f1:0.27778  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0010900497436523438  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.630859375  val f1:0.27778  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0025348663330078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.6328125  val f1:0.27778  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0008945465087890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.6328125  val f1:0.27778  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.5078125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.82421875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.45703125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.640625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 2.810546875  train f1: 0.66667  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.4921875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.7509765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.34375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 4 train loss: 1.416015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.25390625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.458740234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.21875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.154541015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.34375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.068115234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 4.40234375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.04730224609375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 4.46484375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.0286712646484375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 4.45703125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.01214599609375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 4.44921875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.005634307861328125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 4.44140625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.006076812744140625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 4.43359375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.01180267333984375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 4.40625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.0028820037841796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 4.3828125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.004047393798828125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 4.359375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0026149749755859375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 4.296875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.00131988525390625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 4.33984375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0013093948364257812  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 4.375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0021533966064453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 4.3671875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.62109375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.88671875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.5859375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.796875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.16796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.7421875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.794921875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.66015625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.8994140625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.51171875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.35009765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.29296875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.119384765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.044219970703125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 4.00390625  val f1:0.08333  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.0243682861328125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.88671875  val f1:0.09524  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.0100555419921875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.8125  val f1:0.09524  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.00742340087890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.7578125  val f1:0.08333  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.005664825439453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.724609375  val f1:0.09524  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.003765106201171875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.701171875  val f1:0.27778  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.00394439697265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.669921875  val f1:0.27778  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.002410888671875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.64453125  val f1:0.27778  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.0018558502197265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.62890625  val f1:0.27778  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0013875961303710938  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.623046875  val f1:0.27778  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0010900497436523438  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.630859375  val f1:0.27778  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0025348663330078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.6328125  val f1:0.27778  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0008945465087890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.6328125  val f1:0.27778  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.65625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.7578125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.59375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.25390625  train f1: 0.40000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.41796875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.693359375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.2578125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.72265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.12109375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.30224609375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.046875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.18408203125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.0390625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.0364990234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 4.02734375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.034210205078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 4.0625  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.021392822265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 4.0703125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.018096923828125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 4.09375  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.00678253173828125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 4.12109375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.00528717041015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 4.1328125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.0069732666015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 4.140625  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.003627777099609375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 4.18359375  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.003047943115234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 4.2734375  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0020084381103515625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 4.25  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.001529693603515625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 4.3359375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0015239715576171875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 4.3828125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0019426345825195312  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 4.34765625  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.33984375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.5  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.3828125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.3828125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.009765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.23828125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.7216796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.10546875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 4 train loss: 1.10546875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 3.9609375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.278564453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 3.935546875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.177001953125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 3.951171875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.10723876953125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 3.935546875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.044036865234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.931640625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.0152130126953125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.92578125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.0152130126953125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.939453125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.00795745849609375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.9609375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.007518768310546875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.890625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.004913330078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.87109375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.0025272369384765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.90625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.0017004013061523438  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.916015625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.002216339111328125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.87890625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0014162063598632812  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.892578125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.003414154052734375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.98046875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.00146484375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.978515625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.2890625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.8671875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.21875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.640625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.107421875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.46875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.705078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.296875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.6484375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.1796875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.3251953125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.140625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.1343994140625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.05145263671875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 4.12890625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.02813720703125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 4.09765625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.0271453857421875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 4.04296875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.01593017578125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.98046875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.0110626220703125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.935546875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.006961822509765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.919921875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.00882720947265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.951171875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.00760650634765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.9140625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.00408935546875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.904296875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0021038055419921875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.896484375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.00186920166015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.939453125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0014371871948242188  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 4.015625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.001552581787109375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 4.0078125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.62109375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.703125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.59375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.47265625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.291015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.28515625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 2.119140625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.1328125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.78271484375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.015625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.218994140625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 3.865234375  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.28173828125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 3.763671875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.055145263671875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 3.6328125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.0265045166015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.55078125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.0186920166015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.494140625  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.01126861572265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.451171875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.006992340087890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.478515625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.00405120849609375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.484375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.00255584716796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.525390625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.0025043487548828125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.55078125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.0017709732055664062  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.55078125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0017690658569335938  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.548828125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0013599395751953125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.537109375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0011434555053710938  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.517578125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0009412765502929688  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.5234375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.86328125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.5234375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.92578125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.44921875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.2890625  train f1: 0.66667  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.359375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.9130859375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.25  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.755859375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.16796875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.54296875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.01953125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.08099365234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 3.88671875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.09332275390625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 3.80078125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.04803466796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.76171875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.01393890380859375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.76953125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.0227813720703125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.75  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.015716552734375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.73828125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.004039764404296875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.771484375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.0076446533203125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.73828125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.003253936767578125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.779296875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.004817962646484375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.75  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0013551712036132812  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.755859375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0008935928344726562  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.8046875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0009360313415527344  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.853515625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0006246566772460938  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.810546875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.78125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 5.01171875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.8671875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.8046875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.6015625  train f1: 0.40000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.62109375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.66015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.42578125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 4 train loss: 1.322265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.28515625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.41943359375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.16796875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.11572265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.13671875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.06854248046875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 4.19921875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.048126220703125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 4.1796875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.0201263427734375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 4.09375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.027008056640625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 4.03515625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.012664794921875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 4.0  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.005565643310546875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.990234375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.00394439697265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.98046875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.00264739990234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.986328125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.001468658447265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.982421875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.001522064208984375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.939453125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0010356903076171875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.908203125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0009608268737792969  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.88671875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0011196136474609375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.86328125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.265625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 5.015625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.2109375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.85546875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 2.6328125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.68359375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.4921875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.5703125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.5068359375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.44140625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.202392578125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.29296875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.08197021484375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.15625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.026580810546875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 3.990234375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.033477783203125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.89453125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.0136871337890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.81640625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.00716400146484375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.736328125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.00583648681640625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.70703125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.004550933837890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.669921875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.0015840530395507812  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.609375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.0014371871948242188  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.576171875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.0015010833740234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.587890625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.00193023681640625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.51953125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0007328987121582031  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.45703125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0009975433349609375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.435546875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0005984306335449219  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.390625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.6640625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 5.12890625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.75  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 5.0  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 2.85546875  train f1: 0.66667  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.85546875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.7265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.68359375  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.82421875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.45703125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.30517578125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.27734375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.11480712890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.17578125  val f1:0.09524  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.083740234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 4.1484375  val f1:0.09524  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.02423095703125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 4.1328125  val f1:0.09524  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.01641845703125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 4.12109375  val f1:0.08333  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.03094482421875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 4.10546875  val f1:0.08333  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.01024627685546875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 4.171875  val f1:0.08333  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.008026123046875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 4.16015625  val f1:0.08333  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.00550079345703125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 4.15234375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.006183624267578125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 4.14453125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.005397796630859375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 4.140625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.00229644775390625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 4.12890625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0026226043701171875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 4.1171875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0014219284057617188  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 4.08203125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0014429092407226562  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 4.04296875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.48828125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.4453125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.515625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.3125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.080078125  train f1: 0.66667  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.1328125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 2.26953125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.0078125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 4 train loss: 1.1708984375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 3.912109375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 3.8046875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.24267578125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 3.7421875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.057647705078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 3.703125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.039764404296875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.6484375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.01209259033203125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.642578125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.00591278076171875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.66796875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.0067596435546875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.66015625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.0037403106689453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.671875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.00336456298828125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.728515625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.0031185150146484375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.73828125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.0018901824951171875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.794921875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.00177764892578125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.81640625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0016078948974609375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.828125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0013141632080078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.853515625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0011930465698242188  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.837890625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.29296875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.8984375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.44140625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 2.830078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.69921875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 2.078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.6171875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.943359375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.5390625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.328857421875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.46875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.18017578125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.34375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.068603515625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 4.26171875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.035736083984375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 4.26171875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.0218353271484375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 4.26953125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.01416778564453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 4.26953125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.01053619384765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 4.296875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.00978851318359375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 4.27734375  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.0053558349609375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 4.265625  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.003559112548828125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 4.234375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.002513885498046875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 4.203125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0037975311279296875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 4.19921875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0020351409912109375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 4.24609375  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0017786026000976562  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 4.24609375  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.001094818115234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 4.31640625  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 0 train loss: 5.0078125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 5.3046875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 5.015625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 5.05078125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.3671875  train f1: 0.66667  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.8515625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 2.140625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.6875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 4 train loss: 1.4453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.54296875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.62451171875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.3984375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.177978515625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.19140625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.1290283203125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 4.01953125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.02874755859375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.859375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.042022705078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.75  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.016937255859375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.685546875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.0186920166015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.591796875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.0041046142578125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.55078125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.002300262451171875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.556640625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.00199127197265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.5625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.0018701553344726562  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.556640625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0018167495727539062  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.556640625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.00186920166015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.5625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0018587112426757812  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.611328125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0013866424560546875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.697265625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.828125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.62890625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.8828125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.515625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.365234375  train f1: 0.20000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.44140625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 2.3828125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.37109375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.88427734375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.2734375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.35791015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.1953125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.176025390625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.1328125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.0992431640625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 4.0546875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.04058837890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.97265625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.0242156982421875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.89453125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.011138916015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.822265625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.0073089599609375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.74609375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.004756927490234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.728515625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.00749969482421875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.69921875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.002933502197265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.68359375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.0024318695068359375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.6875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0009965896606445312  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.6953125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0011034011840820312  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.71875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0012111663818359375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.728515625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.00069427490234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.73828125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.3984375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.6015625  val f1:0.08333  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.43359375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.484375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 2.861328125  train f1: 0.50000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.31640625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 2.41796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.2109375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 4 train loss: 1.0  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 3.986328125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.456298828125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 3.8515625  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.12335205078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 3.826171875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.1434326171875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 3.875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.025848388671875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 4.01953125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.02630615234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 4.0234375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.01557159423828125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 4.01171875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.00991058349609375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 4.03125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.00640869140625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 4.01953125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.005970001220703125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 4.03515625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.00771331787109375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 4.04296875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.00417327880859375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.994140625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.004791259765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.943359375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.00252532958984375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.9765625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.002044677734375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.92578125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0022716522216796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.87890625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.5625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 5.1015625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.4921875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.90234375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 2.94921875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.71484375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.4814453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.5  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.7412109375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.24609375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.337158203125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 3.955078125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.19580078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 3.775390625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.06561279296875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 3.6640625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.03704833984375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.57421875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.0152130126953125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.5234375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.00946807861328125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.5390625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.0038585662841796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.544921875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.001956939697265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.5546875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.00142669677734375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.58203125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.001575469970703125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.599609375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.0009331703186035156  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.587890625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0017461776733398438  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.615234375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0011014938354492188  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.623046875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0004496574401855469  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.6328125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0007719993591308594  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.6171875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.390625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 3.970703125  val f1:0.08333  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 3.849609375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.044921875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 3.80078125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.4677734375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 3.763671875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.6748046875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 3.767578125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.192626953125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 3.744140625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.07940673828125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 3.73046875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.09564208984375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 3.693359375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.0240631103515625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.630859375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.030059814453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.5703125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.0101165771484375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.55078125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.0034923553466796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.517578125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.003047943115234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.505859375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.029937744140625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.490234375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.0105438232421875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.478515625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.004840850830078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.462890625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.004150390625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.45703125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.00223541259765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.451171875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.001995086669921875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.451171875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.001430511474609375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.46484375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.609375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.54296875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.66796875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.45703125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 2.419921875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.35546875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 3 train loss: 2.01171875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.29296875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.78857421875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.18359375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.1585693359375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.0390625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.271728515625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 3.98828125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.0888671875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 3.927734375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.040313720703125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.90625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.018218994140625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.8828125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.008209228515625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.86328125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.006137847900390625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.83203125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.007724761962890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.81640625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.003818511962890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.796875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.002361297607421875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.80078125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.0030670166015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.779296875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.002460479736328125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.775390625  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.002368927001953125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.7421875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0012350082397460938  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.72265625  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0010175704956054688  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.72265625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.8046875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.74609375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.9296875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.68359375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.529296875  train f1: 0.16667  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.62890625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 3 train loss: 2.109375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.5859375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.85546875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.51953125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.23388671875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.49609375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.2017822265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.51171875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.08404541015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 4.53515625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.049591064453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 4.49609375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.01322174072265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 4.47265625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.0229949951171875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 4.37890625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.0053863525390625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 4.30078125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.006664276123046875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 4.2421875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.00405120849609375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 4.171875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.0034122467041015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 4.109375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.0013561248779296875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 4.07421875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.001171112060546875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 4.04296875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0010814666748046875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 4.02734375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0014209747314453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 4.02734375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.000949859619140625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 4.0546875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.5703125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 5.15625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.4609375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.9921875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.05859375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.85546875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.6396484375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.671875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.79736328125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.36328125  val f1:0.23810  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.27294921875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.11328125  val f1:0.23810  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.12060546875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.03125  val f1:0.23810  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.0428466796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 3.970703125  val f1:0.23810  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.0230865478515625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.98828125  val f1:0.23810  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.027740478515625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.96875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.0084686279296875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.95703125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.00612640380859375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.97265625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.005462646484375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 4.00390625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.0037899017333984375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 4.015625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.002288818359375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 4.01171875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.002536773681640625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 4.015625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0021610260009765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 4.0234375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0015239715576171875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 4.05859375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.001293182373046875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 4.01953125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.001644134521484375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.998046875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.0546875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.37890625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.140625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.2265625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 2.41796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.04296875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.09375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 3.869140625  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.40771484375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 3.71875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.318115234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 3.7265625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.08026123046875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 3.763671875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.03912353515625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 3.791015625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.0270843505859375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.74609375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.0144500732421875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.732421875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.047882080078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.693359375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.020599365234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.705078125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.0029773712158203125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.767578125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.007965087890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.77734375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.001667022705078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.8203125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.0006375312805175781  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.908203125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0008778572082519531  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.919921875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0017833709716796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.92578125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.00102996826171875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.904296875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0005049705505371094  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.921875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.60546875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 5.23828125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.6328125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.9765625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 2.787109375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.80859375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.005859375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.59765625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.83544921875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.31640625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.439453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.171875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.11102294921875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.10546875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.0989990234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 4.0625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.026885986328125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 4.02734375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.0205535888671875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.9765625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.0152130126953125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.931640625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.00943756103515625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.923828125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.0086212158203125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.94140625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.0037136077880859375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.986328125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.004001617431640625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.98828125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.002422332763671875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.990234375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.00136566162109375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.982421875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.001110076904296875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.96875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0008707046508789062  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 4.015625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0010957717895507812  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 4.03515625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.203125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.73046875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.55078125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 2.66015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.3828125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.55078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.2578125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.6015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.15625  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.5185546875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.09375  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.1827392578125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.05078125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.06787109375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 4.02734375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.03985595703125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.982421875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.03887939453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.93359375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.0135955810546875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.904296875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.00649261474609375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.86328125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.00689697265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.8671875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.0038928985595703125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.87109375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.0031528472900390625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.87890625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.00147247314453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.87890625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0022792816162109375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.890625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0008983612060546875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.8828125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0013036727905273438  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.908203125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0008106231689453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.927734375  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 0 train loss: 3.859375  train f1: 0.11111  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.5703125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 1 train loss: 3.875  train f1: 0.11111  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.46484375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 2.6640625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.3515625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.287109375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.234375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.79296875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.15234375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.44189453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.078125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.1640625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.09375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.047607421875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 4.12109375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.03302001953125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 4.06640625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.03240966796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.984375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.0275115966796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.931640625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.01336669921875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.927734375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.012664794921875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.916015625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.00817108154296875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.955078125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.0037555694580078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.97265625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.0022029876708984375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 4.08984375  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0027484893798828125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 4.1171875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0028705596923828125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 4.265625  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.00174713134765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 4.40234375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0009775161743164062  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 4.53515625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.62109375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.3046875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.5234375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.2421875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 2.103515625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.203125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.1962890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.0625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.437744140625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 3.912109375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.19091796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 3.78515625  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.06732177734375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 3.70703125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.036102294921875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 3.693359375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.01629638671875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.68359375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.00917816162109375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.658203125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.00609588623046875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.64453125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.0045013427734375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.619140625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.005115509033203125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.6171875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.004131317138671875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.60546875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.0023632049560546875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.578125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.0016260147094726562  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.560546875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0016260147094726562  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.55078125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0008292198181152344  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.58203125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0012941360473632812  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.564453125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0007185935974121094  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.583984375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.421875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.71484375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.55859375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.54296875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 2.802734375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.7265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.25  val f1:0.25000  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.7802734375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.16796875  val f1:0.23810  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.2529296875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.09375  val f1:0.23810  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.099609375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.0234375  val f1:0.23810  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.04583740234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 4.03125  val f1:0.23810  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.0302581787109375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.986328125  val f1:0.25000  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.017791748046875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.97265625  val f1:0.25000  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.0092315673828125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.939453125  val f1:0.25000  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.0046539306640625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.923828125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.00505828857421875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.935546875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.0056304931640625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.9375  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.004802703857421875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.923828125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.00319671630859375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.94140625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0021457672119140625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.9921875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0011653900146484375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 4.015625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0014123916625976562  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 4.03125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.0011949539184570312  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 4.0859375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 0 train loss: 0.5920842472751845  train f1: 0.44341  lr: 0.0003 batch: 8 
epochs: 0 val loss: 1.0730538544831447  val f1:0.54995  lr: 0.0003 batch: 8
epochs: 1 train loss: 0.2184416055679318  train f1: 0.73064  lr: 0.0003 batch: 8 
epochs: 1 val loss: 0.8110257961131908  val f1:0.68297  lr: 0.0003 batch: 8
epochs: 2 train loss: 0.1416850953625325  train f1: 0.81801  lr: 0.0003 batch: 8 
epochs: 2 val loss: 0.7878433810340036  val f1:0.72854  lr: 0.0003 batch: 8
epochs: 3 train loss: 0.10536915784762094  train f1: 0.86528  lr: 0.0003 batch: 8 
epochs: 3 val loss: 0.8052694002787268  val f1:0.71468  lr: 0.0003 batch: 8
epochs: 4 train loss: 0.08249606730932  train f1: 0.90319  lr: 0.0003 batch: 8 
epochs: 4 val loss: 0.8886121003716081  val f1:0.74275  lr: 0.0003 batch: 8
epochs: 5 train loss: 0.07326794740862376  train f1: 0.91275  lr: 0.0003 batch: 8 
epochs: 5 val loss: 0.9879308082439278  val f1:0.71916  lr: 0.0003 batch: 8
epochs: 6 train loss: 0.061928020897054306  train f1: 0.93522  lr: 0.0003 batch: 8 
epochs: 6 val loss: 0.9703274885813398  val f1:0.76620  lr: 0.0003 batch: 8
epochs: 7 train loss: 0.059433901659271114  train f1: 0.93440  lr: 0.0003 batch: 8 
epochs: 7 val loss: 0.9612365236988775  val f1:0.73685  lr: 0.0003 batch: 8
epochs: 8 train loss: 0.039656026627952  train f1: 0.96175  lr: 0.0003 batch: 8 
epochs: 8 val loss: 0.9615356930979975  val f1:0.79475  lr: 0.0003 batch: 8
epochs: 9 train loss: 0.046818649233725244  train f1: 0.96018  lr: 0.0003 batch: 8 
epochs: 9 val loss: 1.0418511924920257  val f1:0.79208  lr: 0.0003 batch: 8
epochs: 10 train loss: 0.03807651881416541  train f1: 0.95419  lr: 0.0003 batch: 8 
epochs: 10 val loss: 1.142962004741032  val f1:0.75456  lr: 0.0003 batch: 8
epochs: 11 train loss: 0.030165154403284586  train f1: 0.96927  lr: 0.0003 batch: 8 
epochs: 11 val loss: 1.3189186365516101  val f1:0.76090  lr: 0.0003 batch: 8
epochs: 12 train loss: 0.045266132105021145  train f1: 0.95653  lr: 0.0003 batch: 8 
epochs: 12 val loss: 1.3344476827868699  val f1:0.74877  lr: 0.0003 batch: 8
epochs: 13 train loss: 0.039144953252965985  train f1: 0.95851  lr: 0.0003 batch: 8 
epochs: 13 val loss: 1.0653310303334835  val f1:0.76845  lr: 0.0003 batch: 8
epochs: 14 train loss: 0.036816055526459904  train f1: 0.96106  lr: 0.0003 batch: 8 
epochs: 14 val loss: 1.0571158060321104  val f1:0.76221  lr: 0.0003 batch: 8
epochs: 15 train loss: 0.023161774450109498  train f1: 0.97634  lr: 0.0003 batch: 8 
epochs: 15 val loss: 1.2765011573279352  val f1:0.76173  lr: 0.0003 batch: 8
epochs: 16 train loss: 0.035159325510486436  train f1: 0.95971  lr: 0.0003 batch: 8 
epochs: 16 val loss: 0.9169708859037475  val f1:0.80637  lr: 0.0003 batch: 8
epochs: 17 train loss: 0.027882456296399943  train f1: 0.97378  lr: 0.0003 batch: 8 
epochs: 17 val loss: 1.1550539509013853  val f1:0.77809  lr: 0.0003 batch: 8
epochs: 18 train loss: 0.02734810779070912  train f1: 0.97813  lr: 0.0003 batch: 8 
epochs: 18 val loss: 1.464297082026799  val f1:0.75558  lr: 0.0003 batch: 8
epochs: 19 train loss: 0.028539043077804218  train f1: 0.97426  lr: 0.0003 batch: 8 
epochs: 19 val loss: 1.1313402001504549  val f1:0.77891  lr: 0.0003 batch: 8
epochs: 0 train loss: 4.55859375  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 0 val loss: 4.8828125  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 0 train loss: 4.55859375  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 0 val loss: 4.8828125  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 1 train loss: 4.55859375  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 1 val loss: 4.80859375  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 0 train loss: 4.390625  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 1 train loss: 4.30078125  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 1 val loss: 4.7890625  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 2 train loss: 3.515625  train f1: 0.33333  lr: 0.0003 batch: 8 
epochs: 2 val loss: 4.78125  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 0 train loss: 4.37109375  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 0 val loss: 4.8046875  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 1 val loss: 4.76171875  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 2 train loss: 2.619140625  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 2 val loss: 4.609375  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 3 train loss: 0.9208984375  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 3 val loss: 4.41015625  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 4 train loss: 0.397705078125  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 4 val loss: 4.15625  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 5 train loss: 0.09356689453125  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 5 val loss: 3.94921875  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 6 train loss: 0.034393310546875  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 6 val loss: 3.833984375  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 7 train loss: 0.017730712890625  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 7 val loss: 3.73828125  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 8 train loss: 0.016571044921875  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 8 val loss: 3.677734375  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 9 train loss: 0.01079559326171875  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 9 val loss: 3.671875  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 10 train loss: 0.0042266845703125  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 10 val loss: 3.666015625  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 11 train loss: 0.001979827880859375  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 11 val loss: 3.646484375  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 12 train loss: 0.002506256103515625  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 12 val loss: 3.62890625  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 0 train loss: 4.3984375  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 0 val loss: 4.81640625  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 1 val loss: 4.7734375  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 2 train loss: 2.705078125  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 2 val loss: 4.64453125  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 3 train loss: 1.05859375  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 3 val loss: 4.453125  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 4 train loss: 0.31494140625  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 4 val loss: 4.19921875  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 5 train loss: 0.12225341796875  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 5 val loss: 4.02734375  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 6 train loss: 0.042877197265625  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 6 val loss: 3.92578125  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 7 train loss: 0.018463134765625  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 7 val loss: 3.8671875  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 8 train loss: 0.0125885009765625  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 8 val loss: 3.826171875  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 9 train loss: 0.00479888916015625  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 9 val loss: 3.818359375  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 10 train loss: 0.0031585693359375  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 10 val loss: 3.81640625  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 11 train loss: 0.00560760498046875  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 11 val loss: 3.798828125  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 12 train loss: 0.0018148422241210938  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 12 val loss: 3.771484375  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 13 train loss: 0.0009350776672363281  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 13 val loss: 3.76171875  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 14 train loss: 0.0012750625610351562  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 14 val loss: 3.783203125  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 15 train loss: 0.0005784034729003906  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 15 val loss: 3.822265625  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 16 train loss: 0.0004248619079589844  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 16 val loss: 3.84375  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 17 train loss: 0.0005850791931152344  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 17 val loss: 3.869140625  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 18 train loss: 0.0003561973571777344  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 18 val loss: 3.9140625  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 19 train loss: 0.0002472400665283203  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 19 val loss: 3.95703125  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 0 train loss: 4.359375  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 0 val loss: 4.80859375  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 1 train loss: 4.30078125  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 1 val loss: 4.796875  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 2 train loss: 2.5390625  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 2 val loss: 4.7109375  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 3 train loss: 0.822265625  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 3 val loss: 4.4765625  val f1:0.14286  lr: 0.0003 batch: 8
epochs: 4 train loss: 0.379150390625  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 4 val loss: 4.22265625  val f1:0.14286  lr: 0.0003 batch: 8
epochs: 5 train loss: 0.09344482421875  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 5 val loss: 4.03515625  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 6 train loss: 0.0255126953125  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 6 val loss: 3.90625  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 7 train loss: 0.015655517578125  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 7 val loss: 3.8203125  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 0 train loss: 4.3671875  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 0 val loss: 4.8203125  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 1 val loss: 4.77734375  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 2 train loss: 2.630859375  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 2 val loss: 4.640625  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 3 train loss: 0.99658203125  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 3 val loss: 4.46484375  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 4 train loss: 0.321044921875  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 4 val loss: 4.2421875  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 5 train loss: 0.11395263671875  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 5 val loss: 4.08203125  val f1:0.14286  lr: 0.0003 batch: 8
epochs: 6 train loss: 0.035614013671875  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 6 val loss: 3.998046875  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 7 train loss: 0.0159454345703125  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 7 val loss: 3.931640625  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 8 train loss: 0.00936126708984375  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 8 val loss: 3.8828125  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 9 train loss: 0.004688262939453125  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 9 val loss: 3.86328125  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 10 train loss: 0.007389068603515625  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 10 val loss: 3.86328125  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 11 train loss: 0.0025768280029296875  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 11 val loss: 3.83203125  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 12 train loss: 0.0021572113037109375  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 12 val loss: 3.783203125  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 13 train loss: 0.00217437744140625  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 13 val loss: 3.755859375  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 14 train loss: 0.00257110595703125  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 14 val loss: 3.759765625  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 15 train loss: 0.00154876708984375  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 15 val loss: 3.796875  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 16 train loss: 0.0005078315734863281  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 16 val loss: 3.80078125  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 17 train loss: 0.0004591941833496094  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 17 val loss: 3.818359375  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 18 train loss: 0.0007581710815429688  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 18 val loss: 3.837890625  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 19 train loss: 0.0003120899200439453  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 19 val loss: 3.853515625  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 0 train loss: 4.3203125  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 0 val loss: 4.8125  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 1 val loss: 4.796875  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 2 train loss: 2.51953125  train f1: 0.66667  lr: 0.0003 batch: 8 
epochs: 2 val loss: 4.75  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 3 train loss: 0.92138671875  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 3 val loss: 4.55078125  val f1:0.14286  lr: 0.0003 batch: 8
epochs: 4 train loss: 0.544921875  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 4 val loss: 4.359375  val f1:0.14286  lr: 0.0003 batch: 8
epochs: 5 train loss: 0.0970458984375  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 5 val loss: 4.15234375  val f1:0.14286  lr: 0.0003 batch: 8
epochs: 6 train loss: 0.024810791015625  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 6 val loss: 3.998046875  val f1:0.14286  lr: 0.0003 batch: 8
epochs: 7 train loss: 0.01873779296875  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 7 val loss: 3.875  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 8 train loss: 0.0157012939453125  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 8 val loss: 3.80078125  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 9 train loss: 0.006587982177734375  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 9 val loss: 3.763671875  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 10 train loss: 0.0043182373046875  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 10 val loss: 3.767578125  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 11 train loss: 0.00296783447265625  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 11 val loss: 3.755859375  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 12 train loss: 0.002475738525390625  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 12 val loss: 3.783203125  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 13 train loss: 0.0014028549194335938  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 13 val loss: 3.7890625  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 14 train loss: 0.0011796951293945312  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 14 val loss: 3.802734375  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 15 train loss: 0.0007977485656738281  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 15 val loss: 3.8125  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 16 train loss: 0.0005750656127929688  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 16 val loss: 3.822265625  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 17 train loss: 0.0004801750183105469  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 17 val loss: 3.78125  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 18 train loss: 0.0004911422729492188  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 18 val loss: 3.787109375  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 19 train loss: 0.00025844573974609375  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 19 val loss: 3.755859375  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 0 train loss: 4.2734375  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 0 val loss: 4.8203125  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 1 val loss: 4.78125  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 1 val loss: 4.75390625  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 2 train loss: 2.548828125  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 2 val loss: 4.66015625  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 3 train loss: 0.87255859375  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 3 val loss: 4.453125  val f1:0.14286  lr: 0.0003 batch: 8
epochs: 4 train loss: 0.396240234375  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 4 val loss: 4.2265625  val f1:0.14286  lr: 0.0003 batch: 8
epochs: 5 train loss: 0.0960693359375  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 5 val loss: 4.0078125  val f1:0.14286  lr: 0.0003 batch: 8
epochs: 6 train loss: 0.033966064453125  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 6 val loss: 3.830078125  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 7 train loss: 0.0136566162109375  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 7 val loss: 3.7265625  val f1:0.11111  lr: 0.0003 batch: 8
epochs: 8 train loss: 0.00677490234375  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 8 val loss: 3.66796875  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 9 train loss: 0.003452301025390625  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 9 val loss: 3.62890625  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 10 train loss: 0.0025768280029296875  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 10 val loss: 3.623046875  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 11 train loss: 0.002773284912109375  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 11 val loss: 3.625  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 12 train loss: 0.0015630722045898438  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 12 val loss: 3.640625  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 13 train loss: 0.0006480216979980469  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 13 val loss: 3.658203125  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 14 train loss: 0.0009508132934570312  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 14 val loss: 3.6875  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 15 train loss: 0.0006375312805175781  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 15 val loss: 3.740234375  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 16 train loss: 0.0005788803100585938  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 16 val loss: 3.79296875  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 17 train loss: 0.00025916099548339844  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 17 val loss: 3.79296875  val f1:0.14286  lr: 0.0003 batch: 8
epochs: 18 train loss: 0.0005283355712890625  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 18 val loss: 3.826171875  val f1:0.14286  lr: 0.0003 batch: 8
epochs: 19 train loss: 0.00022470951080322266  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 19 val loss: 3.814453125  val f1:0.14286  lr: 0.0003 batch: 8
epochs: 0 train loss: 4.21875  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 0 val loss: 4.14453125  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 1 train loss: 4.26171875  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 1 val loss: 4.0859375  val f1:0.12500  lr: 0.0003 batch: 8
epochs: 0 train loss: 4.4375  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 0 val loss: 4.27734375  val f1:0.00000  lr: 0.0003 batch: 8
epochs: 1 train loss: 4.4140625  train f1: 0.00000  lr: 0.0003 batch: 8 
epochs: 1 val loss: 4.17578125  val f1:0.14286  lr: 0.0003 batch: 8
epochs: 2 train loss: 2.728515625  train f1: 1.00000  lr: 0.0003 batch: 8 
epochs: 2 val loss: 4.0859375  val f1:0.14286  lr: 0.0003 batch: 8
epochs: 0 train loss: 0.6428531637215549  train f1: 0.38117  lr: 0.0003 batch: 32 
epochs: 0 val loss: 1.2435877182904411  val f1:0.49808  lr: 0.0003 batch: 32
epochs: 1 train loss: 0.21258543019282855  train f1: 0.72917  lr: 0.0003 batch: 32 
epochs: 1 val loss: 1.0797334558823528  val f1:0.64567  lr: 0.0003 batch: 32
epochs: 2 train loss: 0.10558480812129822  train f1: 0.86899  lr: 0.0003 batch: 32 
epochs: 2 val loss: 0.8736464556525735  val f1:0.70113  lr: 0.0003 batch: 32
epochs: 3 train loss: 0.07541153258516306  train f1: 0.91672  lr: 0.0003 batch: 32 
epochs: 3 val loss: 0.7341515036190258  val f1:0.77681  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.05453536873149152  train f1: 0.93847  lr: 0.0003 batch: 32 
epochs: 4 val loss: 0.8500886804917278  val f1:0.72606  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.03834504795787935  train f1: 0.96146  lr: 0.0003 batch: 32 
epochs: 5 val loss: 0.9591010598575367  val f1:0.73155  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.04071352666155658  train f1: 0.95881  lr: 0.0003 batch: 32 
epochs: 6 val loss: 0.951132381663603  val f1:0.75568  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.03417167996527849  train f1: 0.96750  lr: 0.0003 batch: 32 
epochs: 7 val loss: 0.888759837431066  val f1:0.76008  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.04100387441249859  train f1: 0.95498  lr: 0.0003 batch: 32 
epochs: 8 val loss: 0.8293743133544923  val f1:0.76977  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.032581972659674614  train f1: 0.96580  lr: 0.0003 batch: 32 
epochs: 9 val loss: 1.0757778392118567  val f1:0.73278  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.026638118406186385  train f1: 0.97514  lr: 0.0003 batch: 32 
epochs: 10 val loss: 1.183075848747702  val f1:0.74315  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.037618420665103625  train f1: 0.95383  lr: 0.0003 batch: 32 
epochs: 11 val loss: 1.1264504825367647  val f1:0.74958  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.02840205380446892  train f1: 0.97494  lr: 0.0003 batch: 32 
epochs: 12 val loss: 0.9331772748161767  val f1:0.76747  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.021524137689585693  train f1: 0.98072  lr: 0.0003 batch: 32 
epochs: 13 val loss: 1.182977115406709  val f1:0.75489  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.028487790552457957  train f1: 0.96937  lr: 0.0003 batch: 32 
epochs: 14 val loss: 0.9722370820886949  val f1:0.76235  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.0248073684307108  train f1: 0.98149  lr: 0.0003 batch: 32 
epochs: 15 val loss: 1.0352316463694855  val f1:0.75536  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.022988600623875186  train f1: 0.97836  lr: 0.0003 batch: 32 
epochs: 16 val loss: 0.9422670252182904  val f1:0.76633  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.022990167735520765  train f1: 0.97404  lr: 0.0003 batch: 32 
epochs: 17 val loss: 1.251319436465992  val f1:0.73403  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.023764278526020786  train f1: 0.97765  lr: 0.0003 batch: 32 
epochs: 18 val loss: 1.0752222397748168  val f1:0.76200  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.018568042359149967  train f1: 0.98636  lr: 0.0003 batch: 32 
epochs: 19 val loss: 1.0454783720128678  val f1:0.76731  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.75390625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 2.548828125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.66015625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 3 train loss: 0.87255859375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.453125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.396240234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.2265625  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.0960693359375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.0078125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.033966064453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 3.830078125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.0136566162109375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 3.7265625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.00677490234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.66796875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.003452301025390625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.62890625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.0025768280029296875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.623046875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.002773284912109375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.0015630722045898438  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.640625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.75390625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 2.548828125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.66015625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.75390625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 2.548828125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.66015625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 3 train loss: 0.87255859375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.453125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.396240234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.2265625  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.0960693359375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.0078125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.033966064453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 3.830078125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.0136566162109375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 3.7265625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.00677490234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.66796875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.003452301025390625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.62890625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.0025768280029296875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.623046875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.002773284912109375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.0015630722045898438  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.640625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.0006480216979980469  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.658203125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.0009508132934570312  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.6875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.0006375312805175781  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.740234375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0005788803100585938  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.79296875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.00025916099548339844  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.79296875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0005283355712890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.826171875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.00022470951080322266  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 3.814453125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 0 train loss: 6.54296875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 6.6328125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 6.53515625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 6.5546875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 6.09375  train f1: 0.16667  lr: 0.0003 batch: 32 
epochs: 2 val loss: 6.484375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 3 train loss: 5.40625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 6.375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 4 train loss: 5.11328125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 6.28125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 5 train loss: 4.453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 6.16015625  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 6 train loss: 4.1015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 6.03125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 7 train loss: 3.45703125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 5.8984375  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 8 train loss: 3.083984375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 5.76953125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 9 train loss: 2.482421875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 5.61328125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 10 train loss: 2.12890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 5.46875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 11 train loss: 1.6181640625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 5.328125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 12 train loss: 1.1689453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 5.19921875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.77978515625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 5.12890625  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.634765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 5.12109375  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.347900390625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 5.12109375  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.2076416015625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 5.12890625  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.1177978515625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 5.14453125  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.0855712890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 5.16015625  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.051177978515625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 19 val loss: 5.171875  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 0 train loss: 0.863122041088684  train f1: 0.14367  lr: 0.0003 batch: 32 
epochs: 0 val loss: 1.3545280905330885  val f1:0.35611  lr: 0.0003 batch: 32
epochs: 1 train loss: 0.27319716455930476  train f1: 0.60471  lr: 0.0003 batch: 32 
epochs: 1 val loss: 0.9206148035386027  val f1:0.57566  lr: 0.0003 batch: 32
epochs: 2 train loss: 0.13969243494352496  train f1: 0.78726  lr: 0.0003 batch: 32 
epochs: 2 val loss: 0.6897223977481617  val f1:0.71981  lr: 0.0003 batch: 32
epochs: 3 train loss: 0.07946920751633489  train f1: 0.88770  lr: 0.0003 batch: 32 
epochs: 3 val loss: 0.6220653758329504  val f1:0.75452  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.06449116851920793  train f1: 0.91683  lr: 0.0003 batch: 32 
epochs: 4 val loss: 0.6309240004595588  val f1:0.77314  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.0485956092130514  train f1: 0.94922  lr: 0.0003 batch: 32 
epochs: 5 val loss: 0.6635167738970588  val f1:0.78516  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.04295882560368492  train f1: 0.95074  lr: 0.0003 batch: 32 
epochs: 6 val loss: 0.6970766852883731  val f1:0.79482  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.032663258531147134  train f1: 0.96163  lr: 0.0003 batch: 32 
epochs: 7 val loss: 0.9531106387867648  val f1:0.78232  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.035121780975798406  train f1: 0.96219  lr: 0.0003 batch: 32 
epochs: 8 val loss: 0.8429179191589359  val f1:0.78505  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.02918722772241527  train f1: 0.96370  lr: 0.0003 batch: 32 
epochs: 9 val loss: 0.8277264763327205  val f1:0.76281  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.024915855424362504  train f1: 0.97352  lr: 0.0003 batch: 32 
epochs: 10 val loss: 0.7902356316061581  val f1:0.80453  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.02678782832890077  train f1: 0.97337  lr: 0.0003 batch: 32 
epochs: 11 val loss: 0.748381670783548  val f1:0.80702  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.027703344970569928  train f1: 0.96794  lr: 0.0003 batch: 32 
epochs: 12 val loss: 0.8788057776058421  val f1:0.79199  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.02320655370293707  train f1: 0.97888  lr: 0.0003 batch: 32 
epochs: 13 val loss: 0.825386874815997  val f1:0.79817  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.03482268694927568  train f1: 0.95982  lr: 0.0003 batch: 32 
epochs: 14 val loss: 0.7895198148839615  val f1:0.78814  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.45703125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.7890625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.45703125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.7890625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.75  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.32421875  train f1: 0.33333  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.64453125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.447265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.51953125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.7373046875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.3203125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.1728515625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.14453125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.1036376953125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.0234375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.028350830078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 3.908203125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.0158843994140625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.83203125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.00582122802734375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.767578125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.005084991455078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.75  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.0087127685546875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.73828125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.002567291259765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.7421875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.00110626220703125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.7109375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.005496978759765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.69921875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.0031757354736328125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.751953125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.0015878677368164062  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.767578125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0008707046508789062  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.767578125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.00041222572326660156  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 18 val loss: 3.798828125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.390625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.82421875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.2890625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.78125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.13671875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.63671875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.796875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.546875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.564453125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.38671875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.62646484375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.24609375  val f1:0.14286  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.1708984375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.05078125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.4609375  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.7734375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.2890625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.734375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.24609375  train f1: 0.66667  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.6484375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 3 train loss: 2.220703125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.5390625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.66845703125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.40234375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.5703125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.76953125  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.2890625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.72265625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.48828125  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.82421875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.2890625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.7734375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.62109375  train f1: 0.11111  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.609375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.8740234375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.44140625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.58642578125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.28125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.259765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.1328125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.13232421875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.01171875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.059051513671875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 3.892578125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.06939697265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.8359375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.83984375  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.2890625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.78515625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.521484375  train f1: 0.33333  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.6640625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.705078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.5078125  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.7275390625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.390625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.274658203125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.21875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.1158447265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.0390625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.265625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 0 val loss: 4.78515625  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 1 train loss: 4.2890625  train f1: 0.00000  lr: 0.0003 batch: 32 
epochs: 1 val loss: 4.73046875  val f1:0.00000  lr: 0.0003 batch: 32
epochs: 2 train loss: 3.552734375  train f1: 0.33333  lr: 0.0003 batch: 32 
epochs: 2 val loss: 4.6171875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 3 train loss: 1.705078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 3 val loss: 4.53515625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.71142578125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 4 val loss: 4.4140625  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.45458984375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 5 val loss: 4.26171875  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.1181640625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 6 val loss: 4.1484375  val f1:0.12500  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.0621337890625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 7 val loss: 4.05859375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.0594482421875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 8 val loss: 3.966796875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.0267486572265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 9 val loss: 3.8671875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.034210205078125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 10 val loss: 3.865234375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.005046844482421875  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 11 val loss: 3.8515625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.006092071533203125  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 12 val loss: 3.849609375  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.002285003662109375  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 13 val loss: 3.8671875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.001468658447265625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 14 val loss: 3.884765625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.0017499923706054688  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 15 val loss: 3.8828125  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.002323150634765625  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 16 val loss: 3.91015625  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.0006375312805175781  train f1: 1.00000  lr: 0.0003 batch: 32 
epochs: 17 val loss: 3.904296875  val f1:0.11111  lr: 0.0003 batch: 32
epochs: 0 train loss: 1.0251209771455232  train f1: 0.21363  lr: 0.0003 batch: 32 
epochs: 0 val loss: 1.814438763786764  val f1:0.27725  lr: 0.0003 batch: 32
epochs: 1 train loss: 0.48951743965718286  train f1: 0.40177  lr: 0.0003 batch: 32 
epochs: 1 val loss: 1.2148581112132353  val f1:0.41737  lr: 0.0003 batch: 32
epochs: 2 train loss: 0.32950011296058757  train f1: 0.56463  lr: 0.0003 batch: 32 
epochs: 2 val loss: 1.0078627642463232  val f1:0.52343  lr: 0.0003 batch: 32
epochs: 3 train loss: 0.22381011051918154  train f1: 0.70704  lr: 0.0003 batch: 32 
epochs: 3 val loss: 0.9112010282628679  val f1:0.60782  lr: 0.0003 batch: 32
epochs: 4 train loss: 0.18879659851985187  train f1: 0.74040  lr: 0.0003 batch: 32 
epochs: 4 val loss: 0.7335653866038605  val f1:0.66934  lr: 0.0003 batch: 32
epochs: 5 train loss: 0.13913197303885846  train f1: 0.80392  lr: 0.0003 batch: 32 
epochs: 5 val loss: 0.7231499167049631  val f1:0.71544  lr: 0.0003 batch: 32
epochs: 6 train loss: 0.11509741598100805  train f1: 0.85512  lr: 0.0003 batch: 32 
epochs: 6 val loss: 0.724199182846967  val f1:0.73428  lr: 0.0003 batch: 32
epochs: 7 train loss: 0.10163265911500845  train f1: 0.87206  lr: 0.0003 batch: 32 
epochs: 7 val loss: 0.8020593979779411  val f1:0.70235  lr: 0.0003 batch: 32
epochs: 8 train loss: 0.06754379841818738  train f1: 0.91190  lr: 0.0003 batch: 32 
epochs: 8 val loss: 0.653347239774816  val f1:0.74554  lr: 0.0003 batch: 32
epochs: 9 train loss: 0.0802915487716447  train f1: 0.90673  lr: 0.0003 batch: 32 
epochs: 9 val loss: 0.7022830738740807  val f1:0.75300  lr: 0.0003 batch: 32
epochs: 10 train loss: 0.061203928136113854  train f1: 0.93506  lr: 0.0003 batch: 32 
epochs: 10 val loss: 0.744994219611673  val f1:0.76153  lr: 0.0003 batch: 32
epochs: 11 train loss: 0.06456624216108182  train f1: 0.91668  lr: 0.0003 batch: 32 
epochs: 11 val loss: 0.7186961454503679  val f1:0.74243  lr: 0.0003 batch: 32
epochs: 12 train loss: 0.05928503933237557  train f1: 0.91764  lr: 0.0003 batch: 32 
epochs: 12 val loss: 0.7152081657858456  val f1:0.75031  lr: 0.0003 batch: 32
epochs: 13 train loss: 0.05910121860788831  train f1: 0.94105  lr: 0.0003 batch: 32 
epochs: 13 val loss: 0.7357518813189341  val f1:0.74873  lr: 0.0003 batch: 32
epochs: 14 train loss: 0.06089621871265012  train f1: 0.92502  lr: 0.0003 batch: 32 
epochs: 14 val loss: 0.9172291475183821  val f1:0.72469  lr: 0.0003 batch: 32
epochs: 15 train loss: 0.049947542930716925  train f1: 0.94902  lr: 0.0003 batch: 32 
epochs: 15 val loss: 0.683048023897059  val f1:0.80189  lr: 0.0003 batch: 32
epochs: 16 train loss: 0.04465455439553333  train f1: 0.95127  lr: 0.0003 batch: 32 
epochs: 16 val loss: 0.7660648121553311  val f1:0.78860  lr: 0.0003 batch: 32
epochs: 17 train loss: 0.05244905913054054  train f1: 0.95022  lr: 0.0003 batch: 32 
epochs: 17 val loss: 0.6858179428998161  val f1:0.78835  lr: 0.0003 batch: 32
epochs: 18 train loss: 0.04472790191422649  train f1: 0.94863  lr: 0.0003 batch: 32 
epochs: 18 val loss: 0.7013406192555146  val f1:0.77584  lr: 0.0003 batch: 32
epochs: 19 train loss: 0.03983047115268993  train f1: 0.95309  lr: 0.0003 batch: 32 
epochs: 19 val loss: 0.9324771656709561  val f1:0.75063  lr: 0.0003 batch: 32
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.035719286524462164 batch: 10 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.035719286524462164 batch: 10
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.035719286524462164 batch: 10 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.035719286524462164 batch: 10
epochs: 2 train loss: 96.625  train f1: 0.00000  lr: 0.035719286524462164 batch: 10 
epochs: 2 val loss: nan  val f1:0.00000  lr: 0.035719286524462164 batch: 10
epochs: 3 train loss: 61.34375  train f1: 0.12500  lr: 0.035719286524462164 batch: 10 
epochs: 3 val loss: nan  val f1:0.00000  lr: 0.035719286524462164 batch: 10
epochs: 4 train loss: 91.25  train f1: 0.00000  lr: 0.035719286524462164 batch: 10 
epochs: 4 val loss: nan  val f1:0.00000  lr: 0.035719286524462164 batch: 10
epochs: 5 train loss: 23.6875  train f1: 0.12500  lr: 0.035719286524462164 batch: 10 
epochs: 5 val loss: nan  val f1:0.00000  lr: 0.035719286524462164 batch: 10
epochs: 6 train loss: 60.90625  train f1: 0.20000  lr: 0.035719286524462164 batch: 10 
epochs: 6 val loss: nan  val f1:0.00000  lr: 0.035719286524462164 batch: 10
epochs: 7 train loss: 24.625  train f1: 0.12500  lr: 0.035719286524462164 batch: 10 
epochs: 7 val loss: nan  val f1:0.00000  lr: 0.035719286524462164 batch: 10
epochs: 8 train loss: 97.4375  train f1: 0.00000  lr: 0.035719286524462164 batch: 10 
epochs: 8 val loss: nan  val f1:0.00000  lr: 0.035719286524462164 batch: 10
epochs: 9 train loss: 23.625  train f1: 0.12500  lr: 0.035719286524462164 batch: 10 
epochs: 9 val loss: nan  val f1:0.00000  lr: 0.035719286524462164 batch: 10
epochs: 0 train loss: 5.01171875  train f1: 0.00000  lr: 0.0006532588947222302 batch: 18 
epochs: 0 val loss: 4.79296875  val f1:0.00000  lr: 0.0006532588947222302 batch: 18
epochs: 1 train loss: 4.96875  train f1: 0.00000  lr: 0.0006532588947222302 batch: 18 
epochs: 1 val loss: 4.7578125  val f1:0.00000  lr: 0.0006532588947222302 batch: 18
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 2.2617499414497587e-05 batch: 6 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 2.2617499414497587e-05 batch: 6
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.008163818767877853 batch: 20 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.008163818767877853 batch: 20
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.05387952855485316 batch: 9 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.05387952855485316 batch: 9
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.05387952855485316 batch: 9 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.05387952855485316 batch: 9
epochs: 2 train loss: 97.5  train f1: 0.22222  lr: 0.05387952855485316 batch: 9 
epochs: 2 val loss: nan  val f1:0.00000  lr: 0.05387952855485316 batch: 9
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.0016197610162452419 batch: 13 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.0016197610162452419 batch: 13
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0016197610162452419 batch: 13 
epochs: 1 val loss: 4.8203125  val f1:0.00000  lr: 0.0016197610162452419 batch: 13
epochs: 2 train loss: 4.05078125  train f1: 0.00000  lr: 0.0016197610162452419 batch: 13 
epochs: 2 val loss: 4.8046875  val f1:0.00000  lr: 0.0016197610162452419 batch: 13
epochs: 3 train loss: 3.98046875  train f1: 0.00000  lr: 0.0016197610162452419 batch: 13 
epochs: 3 val loss: 4.77734375  val f1:0.00000  lr: 0.0016197610162452419 batch: 13
epochs: 4 train loss: 3.958984375  train f1: 0.00000  lr: 0.0016197610162452419 batch: 13 
epochs: 4 val loss: 4.7265625  val f1:0.00000  lr: 0.0016197610162452419 batch: 13
epochs: 5 train loss: 3.80078125  train f1: 0.00000  lr: 0.0016197610162452419 batch: 13 
epochs: 5 val loss: 4.6875  val f1:0.00000  lr: 0.0016197610162452419 batch: 13
epochs: 6 train loss: 3.7734375  train f1: 0.00000  lr: 0.0016197610162452419 batch: 13 
epochs: 6 val loss: 4.625  val f1:0.00000  lr: 0.0016197610162452419 batch: 13
epochs: 7 train loss: 3.55859375  train f1: 0.00000  lr: 0.0016197610162452419 batch: 13 
epochs: 7 val loss: 4.5703125  val f1:0.00000  lr: 0.0016197610162452419 batch: 13
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.00018662459409642872 batch: 17 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.00018662459409642872 batch: 17
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.00018662459409642872 batch: 17 
epochs: 1 val loss: 4.21875  val f1:0.12500  lr: 0.00018662459409642872 batch: 17
epochs: 2 train loss: 0.258056640625  train f1: 1.00000  lr: 0.00018662459409642872 batch: 17 
epochs: 2 val loss: 3.9609375  val f1:0.12500  lr: 0.00018662459409642872 batch: 17
epochs: 3 train loss: 0.0543212890625  train f1: 1.00000  lr: 0.00018662459409642872 batch: 17 
epochs: 3 val loss: 3.927734375  val f1:0.12500  lr: 0.00018662459409642872 batch: 17
epochs: 4 train loss: 0.0023326873779296875  train f1: 1.00000  lr: 0.00018662459409642872 batch: 17 
epochs: 4 val loss: 3.984375  val f1:0.11111  lr: 0.00018662459409642872 batch: 17
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.08464477502483783 batch: 11 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.08464477502483783 batch: 11
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.08464477502483783 batch: 11 
epochs: 1 val loss: 4.51171875  val f1:0.12500  lr: 0.08464477502483783 batch: 11
epochs: 2 train loss: 1.0107421875  train f1: 1.00000  lr: 0.08464477502483783 batch: 11 
epochs: 2 val loss: 4.47265625  val f1:0.12500  lr: 0.08464477502483783 batch: 11
epochs: 3 train loss: 0.07568359375  train f1: 1.00000  lr: 0.08464477502483783 batch: 11 
epochs: 3 val loss: 4.33984375  val f1:0.14286  lr: 0.08464477502483783 batch: 11
epochs: 4 train loss: 0.0452880859375  train f1: 1.00000  lr: 0.08464477502483783 batch: 11 
epochs: 4 val loss: 4.2109375  val f1:0.14286  lr: 0.08464477502483783 batch: 11
epochs: 5 train loss: 0.025726318359375  train f1: 1.00000  lr: 0.08464477502483783 batch: 11 
epochs: 5 val loss: 4.12109375  val f1:0.12500  lr: 0.08464477502483783 batch: 11
epochs: 6 train loss: 0.0174102783203125  train f1: 1.00000  lr: 0.08464477502483783 batch: 11 
epochs: 6 val loss: 3.96484375  val f1:0.14286  lr: 0.08464477502483783 batch: 11
epochs: 7 train loss: 0.0150299072265625  train f1: 1.00000  lr: 0.08464477502483783 batch: 11 
epochs: 7 val loss: 3.8203125  val f1:0.14286  lr: 0.08464477502483783 batch: 11
epochs: 8 train loss: 0.0141143798828125  train f1: 1.00000  lr: 0.08464477502483783 batch: 11 
epochs: 8 val loss: 3.751953125  val f1:0.12500  lr: 0.08464477502483783 batch: 11
epochs: 9 train loss: 0.01110076904296875  train f1: 1.00000  lr: 0.08464477502483783 batch: 11 
epochs: 9 val loss: 3.689453125  val f1:0.12500  lr: 0.08464477502483783 batch: 11
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.002678228274316318 batch: 25 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.002678228274316318 batch: 25
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.002678228274316318 batch: 25 
epochs: 1 val loss: nan  val f1:0.16667  lr: 0.002678228274316318 batch: 25
epochs: 2 train loss: 4.85546875  train f1: 0.26667  lr: 0.002678228274316318 batch: 25 
epochs: 2 val loss: 10688.0  val f1:0.06667  lr: 0.002678228274316318 batch: 25
epochs: 3 train loss: 4.34765625  train f1: 0.26667  lr: 0.002678228274316318 batch: 25 
epochs: 3 val loss: 717.5  val f1:0.06667  lr: 0.002678228274316318 batch: 25
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 2.117182825177276e-05 batch: 23 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 2.117182825177276e-05 batch: 23
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 2.117182825177276e-05 batch: 23 
epochs: 1 val loss: 4.828125  val f1:0.00000  lr: 2.117182825177276e-05 batch: 23
epochs: 2 train loss: 4.15234375  train f1: 0.00000  lr: 2.117182825177276e-05 batch: 23 
epochs: 2 val loss: 4.82421875  val f1:0.00000  lr: 2.117182825177276e-05 batch: 23
epochs: 3 train loss: 4.21484375  train f1: 0.00000  lr: 2.117182825177276e-05 batch: 23 
epochs: 3 val loss: 4.8203125  val f1:0.00000  lr: 2.117182825177276e-05 batch: 23
epochs: 4 train loss: 4.30078125  train f1: 0.00000  lr: 2.117182825177276e-05 batch: 23 
epochs: 4 val loss: 4.7890625  val f1:0.00000  lr: 2.117182825177276e-05 batch: 23
epochs: 5 train loss: 4.2734375  train f1: 0.00000  lr: 2.117182825177276e-05 batch: 23 
epochs: 5 val loss: 4.77734375  val f1:0.00000  lr: 2.117182825177276e-05 batch: 23
epochs: 6 train loss: 4.375  train f1: 0.00000  lr: 2.117182825177276e-05 batch: 23 
epochs: 6 val loss: 4.73828125  val f1:0.00000  lr: 2.117182825177276e-05 batch: 23
epochs: 7 train loss: 4.3125  train f1: 0.00000  lr: 2.117182825177276e-05 batch: 23 
epochs: 7 val loss: 4.703125  val f1:0.00000  lr: 2.117182825177276e-05 batch: 23
epochs: 8 train loss: 4.25  train f1: 0.00000  lr: 2.117182825177276e-05 batch: 23 
epochs: 8 val loss: 4.6796875  val f1:0.00000  lr: 2.117182825177276e-05 batch: 23
epochs: 9 train loss: 4.26171875  train f1: 0.00000  lr: 2.117182825177276e-05 batch: 23 
epochs: 9 val loss: 4.68359375  val f1:0.00000  lr: 2.117182825177276e-05 batch: 23
epochs: 10 train loss: 4.19921875  train f1: 0.00000  lr: 2.117182825177276e-05 batch: 23 
epochs: 10 val loss: 4.66015625  val f1:0.00000  lr: 2.117182825177276e-05 batch: 23
epochs: 11 train loss: 4.3125  train f1: 0.00000  lr: 2.117182825177276e-05 batch: 23 
epochs: 11 val loss: 4.64453125  val f1:0.00000  lr: 2.117182825177276e-05 batch: 23
epochs: 12 train loss: 4.2265625  train f1: 0.00000  lr: 2.117182825177276e-05 batch: 23 
epochs: 12 val loss: 4.625  val f1:0.00000  lr: 2.117182825177276e-05 batch: 23
epochs: 13 train loss: 4.25  train f1: 0.00000  lr: 2.117182825177276e-05 batch: 23 
epochs: 13 val loss: 4.6015625  val f1:0.00000  lr: 2.117182825177276e-05 batch: 23
epochs: 14 train loss: 4.1953125  train f1: 0.00000  lr: 2.117182825177276e-05 batch: 23 
epochs: 14 val loss: 4.59375  val f1:0.00000  lr: 2.117182825177276e-05 batch: 23
epochs: 15 train loss: 4.328125  train f1: 0.00000  lr: 2.117182825177276e-05 batch: 23 
epochs: 15 val loss: 4.62109375  val f1:0.00000  lr: 2.117182825177276e-05 batch: 23
epochs: 16 train loss: 4.30078125  train f1: 0.00000  lr: 2.117182825177276e-05 batch: 23 
epochs: 16 val loss: 4.6328125  val f1:0.00000  lr: 2.117182825177276e-05 batch: 23
epochs: 17 train loss: 4.2421875  train f1: 0.00000  lr: 2.117182825177276e-05 batch: 23 
epochs: 17 val loss: 4.6171875  val f1:0.00000  lr: 2.117182825177276e-05 batch: 23
epochs: 0 train loss: 4.953125  train f1: 0.00000  lr: 0.006146035321308269 batch: 26 
epochs: 0 val loss: 5.49609375  val f1:0.00000  lr: 0.006146035321308269 batch: 26
epochs: 1 train loss: 5.015625  train f1: 0.00000  lr: 0.006146035321308269 batch: 26 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.006146035321308269 batch: 26
epochs: 2 train loss: 2.056640625  train f1: 0.13333  lr: 0.006146035321308269 batch: 26 
epochs: 2 val loss: nan  val f1:0.00000  lr: 0.006146035321308269 batch: 26
epochs: 3 train loss: 3.1875  train f1: 0.16667  lr: 0.006146035321308269 batch: 26 
epochs: 3 val loss: nan  val f1:0.00000  lr: 0.006146035321308269 batch: 26
epochs: 4 train loss: 2.865234375  train f1: 0.16667  lr: 0.006146035321308269 batch: 26 
epochs: 4 val loss: nan  val f1:0.00000  lr: 0.006146035321308269 batch: 26
epochs: 5 train loss: 3.46875  train f1: 0.13333  lr: 0.006146035321308269 batch: 26 
epochs: 5 val loss: nan  val f1:0.00000  lr: 0.006146035321308269 batch: 26
epochs: 6 train loss: 38.90625  train f1: 0.25000  lr: 0.006146035321308269 batch: 26 
epochs: 6 val loss: nan  val f1:0.00000  lr: 0.006146035321308269 batch: 26
epochs: 7 train loss: 38.90625  train f1: 0.25000  lr: 0.006146035321308269 batch: 26 
epochs: 7 val loss: nan  val f1:0.00000  lr: 0.006146035321308269 batch: 26
epochs: 8 train loss: 1.3154296875  train f1: 0.55556  lr: 0.006146035321308269 batch: 26 
epochs: 8 val loss: nan  val f1:0.00000  lr: 0.006146035321308269 batch: 26
epochs: 9 train loss: 3.705078125  train f1: 0.55556  lr: 0.006146035321308269 batch: 26 
epochs: 9 val loss: nan  val f1:0.00000  lr: 0.006146035321308269 batch: 26
epochs: 10 train loss: 12.015625  train f1: 0.16667  lr: 0.006146035321308269 batch: 26 
epochs: 10 val loss: nan  val f1:0.00000  lr: 0.006146035321308269 batch: 26
epochs: 11 train loss: 12.0  train f1: 0.00000  lr: 0.006146035321308269 batch: 26 
epochs: 11 val loss: nan  val f1:0.00000  lr: 0.006146035321308269 batch: 26
epochs: 12 train loss: 5.7890625  train f1: 0.25000  lr: 0.006146035321308269 batch: 26 
epochs: 12 val loss: nan  val f1:0.00000  lr: 0.006146035321308269 batch: 26
epochs: 0 train loss: 4.7109375  train f1: 0.00000  lr: 1.94158924843284e-05 batch: 20 
epochs: 0 val loss: 4.89453125  val f1:0.00000  lr: 1.94158924843284e-05 batch: 20
epochs: 1 train loss: 4.75  train f1: 0.00000  lr: 1.94158924843284e-05 batch: 20 
epochs: 1 val loss: 4.96875  val f1:0.00000  lr: 1.94158924843284e-05 batch: 20
epochs: 2 train loss: 4.54296875  train f1: 0.00000  lr: 1.94158924843284e-05 batch: 20 
epochs: 2 val loss: 5.03515625  val f1:0.00000  lr: 1.94158924843284e-05 batch: 20
epochs: 3 train loss: 4.7109375  train f1: 0.00000  lr: 1.94158924843284e-05 batch: 20 
epochs: 3 val loss: 5.08984375  val f1:0.00000  lr: 1.94158924843284e-05 batch: 20
epochs: 4 train loss: 4.64453125  train f1: 0.00000  lr: 1.94158924843284e-05 batch: 20 
epochs: 4 val loss: 5.09765625  val f1:0.00000  lr: 1.94158924843284e-05 batch: 20
epochs: 5 train loss: 4.67578125  train f1: 0.00000  lr: 1.94158924843284e-05 batch: 20 
epochs: 5 val loss: 5.0859375  val f1:0.00000  lr: 1.94158924843284e-05 batch: 20
epochs: 6 train loss: 4.75  train f1: 0.00000  lr: 1.94158924843284e-05 batch: 20 
epochs: 6 val loss: 5.07421875  val f1:0.00000  lr: 1.94158924843284e-05 batch: 20
epochs: 7 train loss: 4.6640625  train f1: 0.00000  lr: 1.94158924843284e-05 batch: 20 
epochs: 7 val loss: 5.00390625  val f1:0.00000  lr: 1.94158924843284e-05 batch: 20
epochs: 8 train loss: 4.7265625  train f1: 0.00000  lr: 1.94158924843284e-05 batch: 20 
epochs: 8 val loss: 4.9453125  val f1:0.00000  lr: 1.94158924843284e-05 batch: 20
epochs: 9 train loss: 4.66796875  train f1: 0.00000  lr: 1.94158924843284e-05 batch: 20 
epochs: 9 val loss: 4.9140625  val f1:0.00000  lr: 1.94158924843284e-05 batch: 20
epochs: 10 train loss: 4.734375  train f1: 0.00000  lr: 1.94158924843284e-05 batch: 20 
epochs: 10 val loss: 4.89453125  val f1:0.00000  lr: 1.94158924843284e-05 batch: 20
epochs: 11 train loss: 4.6640625  train f1: 0.00000  lr: 1.94158924843284e-05 batch: 20 
epochs: 11 val loss: 4.8984375  val f1:0.00000  lr: 1.94158924843284e-05 batch: 20
epochs: 12 train loss: 4.65234375  train f1: 0.00000  lr: 1.94158924843284e-05 batch: 20 
epochs: 12 val loss: 4.8828125  val f1:0.00000  lr: 1.94158924843284e-05 batch: 20
epochs: 13 train loss: 4.51171875  train f1: 0.00000  lr: 1.94158924843284e-05 batch: 20 
epochs: 13 val loss: 4.86328125  val f1:0.00000  lr: 1.94158924843284e-05 batch: 20
epochs: 14 train loss: 4.7578125  train f1: 0.00000  lr: 1.94158924843284e-05 batch: 20 
epochs: 14 val loss: 4.84765625  val f1:0.00000  lr: 1.94158924843284e-05 batch: 20
epochs: 15 train loss: 4.72265625  train f1: 0.00000  lr: 1.94158924843284e-05 batch: 20 
epochs: 15 val loss: 4.8515625  val f1:0.00000  lr: 1.94158924843284e-05 batch: 20
epochs: 16 train loss: 4.74609375  train f1: 0.00000  lr: 1.94158924843284e-05 batch: 20 
epochs: 16 val loss: 4.828125  val f1:0.00000  lr: 1.94158924843284e-05 batch: 20
epochs: 17 train loss: 4.70703125  train f1: 0.00000  lr: 1.94158924843284e-05 batch: 20 
epochs: 17 val loss: 4.7890625  val f1:0.00000  lr: 1.94158924843284e-05 batch: 20
epochs: 18 train loss: 4.7578125  train f1: 0.00000  lr: 1.94158924843284e-05 batch: 20 
epochs: 18 val loss: 4.75390625  val f1:0.00000  lr: 1.94158924843284e-05 batch: 20
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.06938806928215069 batch: 23 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.06938806928215069 batch: 23
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.06938806928215069 batch: 23 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.06938806928215069 batch: 23
epochs: 2 train loss: 9.53125  train f1: 0.12500  lr: 0.06938806928215069 batch: 23 
epochs: 2 val loss: nan  val f1:0.00000  lr: 0.06938806928215069 batch: 23
epochs: 3 train loss: 5.203125  train f1: 0.25000  lr: 0.06938806928215069 batch: 23 
epochs: 3 val loss: nan  val f1:0.00000  lr: 0.06938806928215069 batch: 23
epochs: 4 train loss: 4.97265625  train f1: 0.25000  lr: 0.06938806928215069 batch: 23 
epochs: 4 val loss: nan  val f1:0.00000  lr: 0.06938806928215069 batch: 23
epochs: 5 train loss: 7.42578125  train f1: 0.16667  lr: 0.06938806928215069 batch: 23 
epochs: 5 val loss: nan  val f1:0.00000  lr: 0.06938806928215069 batch: 23
epochs: 6 train loss: 6.3671875  train f1: 0.25000  lr: 0.06938806928215069 batch: 23 
epochs: 6 val loss: nan  val f1:0.00000  lr: 0.06938806928215069 batch: 23
epochs: 0 train loss: 4.86328125  train f1: 0.00000  lr: 0.0024423216828863377 batch: 23 
epochs: 0 val loss: 5.2421875  val f1:0.00000  lr: 0.0024423216828863377 batch: 23
epochs: 1 train loss: 4.9453125  train f1: 0.00000  lr: 0.0024423216828863377 batch: 23 
epochs: 1 val loss: 5.12109375  val f1:0.00000  lr: 0.0024423216828863377 batch: 23
epochs: 2 train loss: 4.73828125  train f1: 0.00000  lr: 0.0024423216828863377 batch: 23 
epochs: 2 val loss: 5.015625  val f1:0.00000  lr: 0.0024423216828863377 batch: 23
epochs: 3 train loss: 4.54296875  train f1: 0.00000  lr: 0.0024423216828863377 batch: 23 
epochs: 3 val loss: 4.89453125  val f1:0.00000  lr: 0.0024423216828863377 batch: 23
epochs: 4 train loss: 4.33984375  train f1: 0.00000  lr: 0.0024423216828863377 batch: 23 
epochs: 4 val loss: 4.78125  val f1:0.00000  lr: 0.0024423216828863377 batch: 23
epochs: 5 train loss: 4.2265625  train f1: 0.00000  lr: 0.0024423216828863377 batch: 23 
epochs: 5 val loss: 4.66796875  val f1:0.00000  lr: 0.0024423216828863377 batch: 23
epochs: 6 train loss: 3.919921875  train f1: 0.00000  lr: 0.0024423216828863377 batch: 23 
epochs: 6 val loss: 4.59375  val f1:0.00000  lr: 0.0024423216828863377 batch: 23
epochs: 7 train loss: 3.81640625  train f1: 0.16667  lr: 0.0024423216828863377 batch: 23 
epochs: 7 val loss: 4.51953125  val f1:0.00000  lr: 0.0024423216828863377 batch: 23
epochs: 8 train loss: 3.759765625  train f1: 0.16667  lr: 0.0024423216828863377 batch: 23 
epochs: 8 val loss: 4.44140625  val f1:0.00000  lr: 0.0024423216828863377 batch: 23
epochs: 9 train loss: 3.45703125  train f1: 0.40000  lr: 0.0024423216828863377 batch: 23 
epochs: 9 val loss: 4.3828125  val f1:0.00000  lr: 0.0024423216828863377 batch: 23
epochs: 10 train loss: 3.109375  train f1: 0.66667  lr: 0.0024423216828863377 batch: 23 
epochs: 10 val loss: 4.32421875  val f1:0.00000  lr: 0.0024423216828863377 batch: 23
epochs: 11 train loss: 3.326171875  train f1: 0.33333  lr: 0.0024423216828863377 batch: 23 
epochs: 11 val loss: 4.30078125  val f1:0.00000  lr: 0.0024423216828863377 batch: 23
epochs: 12 train loss: 3.099609375  train f1: 1.00000  lr: 0.0024423216828863377 batch: 23 
epochs: 12 val loss: 4.29296875  val f1:0.00000  lr: 0.0024423216828863377 batch: 23
epochs: 13 train loss: 2.966796875  train f1: 1.00000  lr: 0.0024423216828863377 batch: 23 
epochs: 13 val loss: 4.28125  val f1:0.00000  lr: 0.0024423216828863377 batch: 23
epochs: 0 train loss: 4.54296875  train f1: 0.00000  lr: 3.80680092815544e-05 batch: 19 
epochs: 0 val loss: 4.73046875  val f1:0.00000  lr: 3.80680092815544e-05 batch: 19
epochs: 1 train loss: 4.421875  train f1: 0.00000  lr: 3.80680092815544e-05 batch: 19 
epochs: 1 val loss: 4.38671875  val f1:0.00000  lr: 3.80680092815544e-05 batch: 19
epochs: 2 train loss: 1.91796875  train f1: 1.00000  lr: 3.80680092815544e-05 batch: 19 
epochs: 2 val loss: 4.203125  val f1:0.00000  lr: 3.80680092815544e-05 batch: 19
epochs: 3 train loss: 1.2998046875  train f1: 1.00000  lr: 3.80680092815544e-05 batch: 19 
epochs: 3 val loss: 4.1171875  val f1:0.12500  lr: 3.80680092815544e-05 batch: 19
epochs: 4 train loss: 0.4296875  train f1: 1.00000  lr: 3.80680092815544e-05 batch: 19 
epochs: 4 val loss: 3.94921875  val f1:0.12500  lr: 3.80680092815544e-05 batch: 19
epochs: 5 train loss: 0.2177734375  train f1: 1.00000  lr: 3.80680092815544e-05 batch: 19 
epochs: 5 val loss: 3.8671875  val f1:0.11111  lr: 3.80680092815544e-05 batch: 19
epochs: 6 train loss: 0.1661376953125  train f1: 1.00000  lr: 3.80680092815544e-05 batch: 19 
epochs: 6 val loss: 3.78515625  val f1:0.11111  lr: 3.80680092815544e-05 batch: 19
epochs: 7 train loss: 0.257080078125  train f1: 1.00000  lr: 3.80680092815544e-05 batch: 19 
epochs: 7 val loss: 3.6875  val f1:0.11111  lr: 3.80680092815544e-05 batch: 19
epochs: 0 train loss: 4.6015625  train f1: 0.00000  lr: 0.01930078656240832 batch: 16 
epochs: 0 val loss: 5.48828125  val f1:0.00000  lr: 0.01930078656240832 batch: 16
epochs: 1 train loss: 4.703125  train f1: 0.00000  lr: 0.01930078656240832 batch: 16 
epochs: 1 val loss: 5.40625  val f1:0.00000  lr: 0.01930078656240832 batch: 16
epochs: 2 train loss: 3.1171875  train f1: 0.50000  lr: 0.01930078656240832 batch: 16 
epochs: 2 val loss: 5.19921875  val f1:0.00000  lr: 0.01930078656240832 batch: 16
epochs: 3 train loss: 2.27734375  train f1: 1.00000  lr: 0.01930078656240832 batch: 16 
epochs: 3 val loss: 4.71875  val f1:0.12500  lr: 0.01930078656240832 batch: 16
epochs: 4 train loss: 1.3134765625  train f1: 1.00000  lr: 0.01930078656240832 batch: 16 
epochs: 4 val loss: 4.73046875  val f1:0.12500  lr: 0.01930078656240832 batch: 16
epochs: 5 train loss: 0.89208984375  train f1: 1.00000  lr: 0.01930078656240832 batch: 16 
epochs: 5 val loss: 4.56640625  val f1:0.12500  lr: 0.01930078656240832 batch: 16
epochs: 6 train loss: 0.6083984375  train f1: 1.00000  lr: 0.01930078656240832 batch: 16 
epochs: 6 val loss: 4.4921875  val f1:0.12500  lr: 0.01930078656240832 batch: 16
epochs: 7 train loss: 0.3720703125  train f1: 1.00000  lr: 0.01930078656240832 batch: 16 
epochs: 7 val loss: 4.4921875  val f1:0.11111  lr: 0.01930078656240832 batch: 16
epochs: 8 train loss: 0.2071533203125  train f1: 1.00000  lr: 0.01930078656240832 batch: 16 
epochs: 8 val loss: 4.390625  val f1:0.11111  lr: 0.01930078656240832 batch: 16
epochs: 9 train loss: 0.1685791015625  train f1: 1.00000  lr: 0.01930078656240832 batch: 16 
epochs: 9 val loss: 4.296875  val f1:0.11111  lr: 0.01930078656240832 batch: 16
epochs: 10 train loss: 0.1641845703125  train f1: 1.00000  lr: 0.01930078656240832 batch: 16 
epochs: 10 val loss: 4.19140625  val f1:0.11111  lr: 0.01930078656240832 batch: 16
epochs: 0 train loss: 4.4140625  train f1: 0.00000  lr: 0.009897838477004492 batch: 18 
epochs: 0 val loss: 4.8203125  val f1:0.00000  lr: 0.009897838477004492 batch: 18
epochs: 1 train loss: 4.4375  train f1: 0.00000  lr: 0.009897838477004492 batch: 18 
epochs: 1 val loss: 4.9453125  val f1:0.00000  lr: 0.009897838477004492 batch: 18
epochs: 2 train loss: 1.119140625  train f1: 0.50000  lr: 0.009897838477004492 batch: 18 
epochs: 2 val loss: 1112.0  val f1:0.16667  lr: 0.009897838477004492 batch: 18
epochs: 3 train loss: 1.796875  train f1: 0.26667  lr: 0.009897838477004492 batch: 18 
epochs: 3 val loss: 262.75  val f1:0.16667  lr: 0.009897838477004492 batch: 18
epochs: 4 train loss: 1.4462890625  train f1: 0.26667  lr: 0.009897838477004492 batch: 18 
epochs: 4 val loss: 65.4375  val f1:0.16667  lr: 0.009897838477004492 batch: 18
epochs: 5 train loss: 1.482421875  train f1: 0.26667  lr: 0.009897838477004492 batch: 18 
epochs: 5 val loss: 36.21875  val f1:0.16667  lr: 0.009897838477004492 batch: 18
epochs: 6 train loss: 2.49609375  train f1: 0.26667  lr: 0.009897838477004492 batch: 18 
epochs: 6 val loss: 194.5  val f1:0.00000  lr: 0.009897838477004492 batch: 18
epochs: 7 train loss: 0.826171875  train f1: 1.00000  lr: 0.009897838477004492 batch: 18 
epochs: 7 val loss: 2732.0  val f1:0.00000  lr: 0.009897838477004492 batch: 18
epochs: 8 train loss: 2.060546875  train f1: 0.77778  lr: 0.009897838477004492 batch: 18 
epochs: 8 val loss: 923.5  val f1:0.00000  lr: 0.009897838477004492 batch: 18
epochs: 9 train loss: 0.85400390625  train f1: 0.77778  lr: 0.009897838477004492 batch: 18 
epochs: 9 val loss: 427.5  val f1:0.00000  lr: 0.009897838477004492 batch: 18
epochs: 10 train loss: 0.471923828125  train f1: 0.77778  lr: 0.009897838477004492 batch: 18 
epochs: 10 val loss: 22384.0  val f1:0.00000  lr: 0.009897838477004492 batch: 18
epochs: 11 train loss: 1.0654296875  train f1: 0.66667  lr: 0.009897838477004492 batch: 18 
epochs: 11 val loss: nan  val f1:0.00000  lr: 0.009897838477004492 batch: 18
epochs: 0 train loss: 4.203125  train f1: 0.00000  lr: 2.9743875107771688e-05 batch: 30 
epochs: 0 val loss: 4.859375  val f1:0.12500  lr: 2.9743875107771688e-05 batch: 30
epochs: 1 train loss: 4.2890625  train f1: 0.00000  lr: 2.9743875107771688e-05 batch: 30 
epochs: 1 val loss: 4.7265625  val f1:0.12500  lr: 2.9743875107771688e-05 batch: 30
epochs: 2 train loss: 4.109375  train f1: 0.16667  lr: 2.9743875107771688e-05 batch: 30 
epochs: 2 val loss: 4.5859375  val f1:0.12500  lr: 2.9743875107771688e-05 batch: 30
epochs: 3 train loss: 3.86328125  train f1: 0.00000  lr: 2.9743875107771688e-05 batch: 30 
epochs: 3 val loss: 4.44140625  val f1:0.11111  lr: 2.9743875107771688e-05 batch: 30
epochs: 4 train loss: 3.62109375  train f1: 0.33333  lr: 2.9743875107771688e-05 batch: 30 
epochs: 4 val loss: 4.3203125  val f1:0.11111  lr: 2.9743875107771688e-05 batch: 30
epochs: 5 train loss: 3.345703125  train f1: 0.33333  lr: 2.9743875107771688e-05 batch: 30 
epochs: 5 val loss: 4.23046875  val f1:0.12500  lr: 2.9743875107771688e-05 batch: 30
epochs: 6 train loss: 3.287109375  train f1: 0.33333  lr: 2.9743875107771688e-05 batch: 30 
epochs: 6 val loss: 4.15234375  val f1:0.12500  lr: 2.9743875107771688e-05 batch: 30
epochs: 7 train loss: 2.845703125  train f1: 0.66667  lr: 2.9743875107771688e-05 batch: 30 
epochs: 7 val loss: 4.0625  val f1:0.12500  lr: 2.9743875107771688e-05 batch: 30
epochs: 8 train loss: 2.73046875  train f1: 1.00000  lr: 2.9743875107771688e-05 batch: 30 
epochs: 8 val loss: 3.982421875  val f1:0.12500  lr: 2.9743875107771688e-05 batch: 30
epochs: 9 train loss: 2.658203125  train f1: 0.66667  lr: 2.9743875107771688e-05 batch: 30 
epochs: 9 val loss: 3.927734375  val f1:0.12500  lr: 2.9743875107771688e-05 batch: 30
epochs: 10 train loss: 2.62890625  train f1: 1.00000  lr: 2.9743875107771688e-05 batch: 30 
epochs: 10 val loss: 3.880859375  val f1:0.12500  lr: 2.9743875107771688e-05 batch: 30
epochs: 11 train loss: 2.328125  train f1: 1.00000  lr: 2.9743875107771688e-05 batch: 30 
epochs: 11 val loss: 3.900390625  val f1:0.12500  lr: 2.9743875107771688e-05 batch: 30
epochs: 12 train loss: 1.927734375  train f1: 1.00000  lr: 2.9743875107771688e-05 batch: 30 
epochs: 12 val loss: 3.91015625  val f1:0.12500  lr: 2.9743875107771688e-05 batch: 30
epochs: 0 train loss: 4.78125  train f1: 0.00000  lr: 1.9586363118949208e-05 batch: 19 
epochs: 0 val loss: 5.1484375  val f1:0.00000  lr: 1.9586363118949208e-05 batch: 19
epochs: 1 train loss: 4.79296875  train f1: 0.00000  lr: 1.9586363118949208e-05 batch: 19 
epochs: 1 val loss: 5.1171875  val f1:0.00000  lr: 1.9586363118949208e-05 batch: 19
epochs: 2 train loss: 4.875  train f1: 0.00000  lr: 1.9586363118949208e-05 batch: 19 
epochs: 2 val loss: 5.09375  val f1:0.00000  lr: 1.9586363118949208e-05 batch: 19
epochs: 3 train loss: 4.765625  train f1: 0.00000  lr: 1.9586363118949208e-05 batch: 19 
epochs: 3 val loss: 5.046875  val f1:0.00000  lr: 1.9586363118949208e-05 batch: 19
epochs: 4 train loss: 4.7109375  train f1: 0.00000  lr: 1.9586363118949208e-05 batch: 19 
epochs: 4 val loss: 5.0  val f1:0.00000  lr: 1.9586363118949208e-05 batch: 19
epochs: 0 train loss: 4.484375  train f1: 0.00000  lr: 0.037831422686202924 batch: 22 
epochs: 0 val loss: 4.765625  val f1:0.00000  lr: 0.037831422686202924 batch: 22
epochs: 1 train loss: 4.671875  train f1: 0.00000  lr: 0.037831422686202924 batch: 22 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.037831422686202924 batch: 22
epochs: 2 train loss: 8.8359375  train f1: 0.10000  lr: 0.037831422686202924 batch: 22 
epochs: 2 val loss: nan  val f1:0.00000  lr: 0.037831422686202924 batch: 22
epochs: 3 train loss: 6.4609375  train f1: 0.10000  lr: 0.037831422686202924 batch: 22 
epochs: 3 val loss: inf  val f1:0.06667  lr: 0.037831422686202924 batch: 22
epochs: 4 train loss: 6.578125  train f1: 0.20000  lr: 0.037831422686202924 batch: 22 
epochs: 4 val loss: 8776.0  val f1:0.06667  lr: 0.037831422686202924 batch: 22
epochs: 5 train loss: 10.0546875  train f1: 0.00000  lr: 0.037831422686202924 batch: 22 
epochs: 5 val loss: 3008.0  val f1:0.06667  lr: 0.037831422686202924 batch: 22
epochs: 6 train loss: 6.453125  train f1: 0.10000  lr: 0.037831422686202924 batch: 22 
epochs: 6 val loss: 1398.0  val f1:0.06667  lr: 0.037831422686202924 batch: 22
epochs: 7 train loss: 7.4375  train f1: 0.10000  lr: 0.037831422686202924 batch: 22 
epochs: 7 val loss: nan  val f1:0.00000  lr: 0.037831422686202924 batch: 22
epochs: 8 train loss: 11.3515625  train f1: 0.25000  lr: 0.037831422686202924 batch: 22 
epochs: 8 val loss: nan  val f1:0.00000  lr: 0.037831422686202924 batch: 22
epochs: 9 train loss: 1.1142578125  train f1: 0.26667  lr: 0.037831422686202924 batch: 22 
epochs: 9 val loss: nan  val f1:0.00000  lr: 0.037831422686202924 batch: 22
epochs: 10 train loss: 11.078125  train f1: 0.00000  lr: 0.037831422686202924 batch: 22 
epochs: 10 val loss: nan  val f1:0.00000  lr: 0.037831422686202924 batch: 22
epochs: 11 train loss: 2.267578125  train f1: 0.55556  lr: 0.037831422686202924 batch: 22 
epochs: 11 val loss: nan  val f1:0.00000  lr: 0.037831422686202924 batch: 22
epochs: 12 train loss: 5.4609375  train f1: 0.20000  lr: 0.037831422686202924 batch: 22 
epochs: 12 val loss: nan  val f1:0.00000  lr: 0.037831422686202924 batch: 22
epochs: 13 train loss: 0.1488037109375  train f1: 1.00000  lr: 0.037831422686202924 batch: 22 
epochs: 13 val loss: nan  val f1:0.00000  lr: 0.037831422686202924 batch: 22
epochs: 14 train loss: 0.84326171875  train f1: 0.55556  lr: 0.037831422686202924 batch: 22 
epochs: 14 val loss: nan  val f1:0.00000  lr: 0.037831422686202924 batch: 22
epochs: 15 train loss: 0.09814453125  train f1: 1.00000  lr: 0.037831422686202924 batch: 22 
epochs: 15 val loss: nan  val f1:0.00000  lr: 0.037831422686202924 batch: 22
epochs: 16 train loss: 0.00012636184692382812  train f1: 1.00000  lr: 0.037831422686202924 batch: 22 
epochs: 16 val loss: nan  val f1:0.00000  lr: 0.037831422686202924 batch: 22
epochs: 17 train loss: 1.138671875  train f1: 0.77778  lr: 0.037831422686202924 batch: 22 
epochs: 17 val loss: nan  val f1:0.00000  lr: 0.037831422686202924 batch: 22
epochs: 0 train loss: 5.0703125  train f1: 0.00000  lr: 0.00013728832291769324 batch: 14 
epochs: 0 val loss: 4.69921875  val f1:0.00000  lr: 0.00013728832291769324 batch: 14
epochs: 1 train loss: 5.1484375  train f1: 0.00000  lr: 0.00013728832291769324 batch: 14 
epochs: 1 val loss: 4.640625  val f1:0.00000  lr: 0.00013728832291769324 batch: 14
epochs: 2 train loss: 4.95703125  train f1: 0.00000  lr: 0.00013728832291769324 batch: 14 
epochs: 2 val loss: 4.625  val f1:0.00000  lr: 0.00013728832291769324 batch: 14
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 1.9223508374523378e-05 batch: 15 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 1.9223508374523378e-05 batch: 15
epochs: 0 train loss: 4.78125  train f1: 0.00000  lr: 3.375465143633981e-05 batch: 13 
epochs: 0 val loss: 5.59375  val f1:0.00000  lr: 3.375465143633981e-05 batch: 13
epochs: 0 train loss: 5.0078125  train f1: 0.00000  lr: 1.4970900003781417e-05 batch: 20 
epochs: 0 val loss: 5.30859375  val f1:0.00000  lr: 1.4970900003781417e-05 batch: 20
epochs: 0 train loss: 4.47265625  train f1: 0.00000  lr: 0.03928946693034651 batch: 18 
epochs: 0 val loss: 4.16015625  val f1:0.11111  lr: 0.03928946693034651 batch: 18
epochs: 0 train loss: 5.2578125  train f1: 0.00000  lr: 1.4185624234324002e-05 batch: 21 
epochs: 0 val loss: 5.171875  val f1:0.00000  lr: 1.4185624234324002e-05 batch: 21
epochs: 0 train loss: 5.0  train f1: 0.00000  lr: 0.027868422953792008 batch: 29 
epochs: 0 val loss: 4.56640625  val f1:0.00000  lr: 0.027868422953792008 batch: 29
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.008058108903545342 batch: 21 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.008058108903545342 batch: 21
epochs: 0 train loss: 4.78125  train f1: 0.00000  lr: 0.01460286701346049 batch: 17 
epochs: 0 val loss: 5.59375  val f1:0.00000  lr: 0.01460286701346049 batch: 17
epochs: 0 train loss: 5.0078125  train f1: 0.00000  lr: 0.00012126055637907843 batch: 18 
epochs: 0 val loss: 5.30859375  val f1:0.00000  lr: 0.00012126055637907843 batch: 18
epochs: 0 train loss: 4.47265625  train f1: 0.00000  lr: 0.00026811091660750594 batch: 13 
epochs: 0 val loss: 4.16015625  val f1:0.11111  lr: 0.00026811091660750594 batch: 13
epochs: 0 train loss: 5.2578125  train f1: 0.00000  lr: 0.00014276097051537485 batch: 26 
epochs: 0 val loss: 5.171875  val f1:0.00000  lr: 0.00014276097051537485 batch: 26
epochs: 0 train loss: 5.0  train f1: 0.00000  lr: 0.0001119160410935569 batch: 32 
epochs: 0 val loss: 4.56640625  val f1:0.00000  lr: 0.0001119160410935569 batch: 32
epochs: 0 train loss: 4.8203125  train f1: 0.00000  lr: 0.00014966130609985067 batch: 28 
epochs: 0 val loss: 4.74609375  val f1:0.00000  lr: 0.00014966130609985067 batch: 28
epochs: 0 train loss: 4.48828125  train f1: 0.00000  lr: 0.0004286213699740803 batch: 13 
epochs: 0 val loss: 5.765625  val f1:0.00000  lr: 0.0004286213699740803 batch: 13
epochs: 0 train loss: 4.375  train f1: 0.00000  lr: 0.06162910688555971 batch: 30 
epochs: 0 val loss: 4.22265625  val f1:0.00000  lr: 0.06162910688555971 batch: 30
epochs: 0 train loss: 4.5859375  train f1: 0.00000  lr: 0.09817954207505156 batch: 31 
epochs: 0 val loss: 5.14453125  val f1:0.00000  lr: 0.09817954207505156 batch: 31
epochs: 0 train loss: 4.65234375  train f1: 0.00000  lr: 2.189544971660596e-05 batch: 10 
epochs: 0 val loss: 5.5390625  val f1:0.00000  lr: 2.189544971660596e-05 batch: 10
epochs: 0 train loss: 4.9609375  train f1: 0.00000  lr: 0.003107441216212963 batch: 22 
epochs: 0 val loss: 5.37109375  val f1:0.00000  lr: 0.003107441216212963 batch: 22
epochs: 0 train loss: 4.6484375  train f1: 0.00000  lr: 0.00223247932127077 batch: 23 
epochs: 0 val loss: 5.44921875  val f1:0.00000  lr: 0.00223247932127077 batch: 23
epochs: 0 train loss: 4.21484375  train f1: 0.00000  lr: 0.011060367127703122 batch: 14 
epochs: 0 val loss: 4.890625  val f1:0.00000  lr: 0.011060367127703122 batch: 14
epochs: 0 train loss: 4.125  train f1: 0.00000  lr: 0.0009734527354599777 batch: 10 
epochs: 0 val loss: 4.5625  val f1:0.00000  lr: 0.0009734527354599777 batch: 10
epochs: 0 train loss: 5.2890625  train f1: 0.00000  lr: 1.1863084721952298e-05 batch: 19 
epochs: 0 val loss: 4.91796875  val f1:0.00000  lr: 1.1863084721952298e-05 batch: 19
epochs: 0 train loss: 3.921875  train f1: 0.00000  lr: 0.013963380931533815 batch: 15 
epochs: 0 val loss: 5.796875  val f1:0.00000  lr: 0.013963380931533815 batch: 15
epochs: 0 train loss: 4.75390625  train f1: 0.00000  lr: 0.003969311935684592 batch: 8 
epochs: 0 val loss: 5.6640625  val f1:0.00000  lr: 0.003969311935684592 batch: 8
epochs: 0 train loss: 4.94921875  train f1: 0.00000  lr: 0.0006296564666939994 batch: 24 
epochs: 0 val loss: 4.70703125  val f1:0.00000  lr: 0.0006296564666939994 batch: 24
epochs: 0 train loss: 4.8125  train f1: 0.00000  lr: 4.52930241664729e-05 batch: 21 
epochs: 0 val loss: 4.9921875  val f1:0.00000  lr: 4.52930241664729e-05 batch: 21
epochs: 0 train loss: 4.4765625  train f1: 0.00000  lr: 0.028340111005469668 batch: 16 
epochs: 0 val loss: 5.4140625  val f1:0.00000  lr: 0.028340111005469668 batch: 16
epochs: 0 train loss: 4.9609375  train f1: 0.00000  lr: 0.0005526083664890837 batch: 25 
epochs: 0 val loss: 4.30859375  val f1:0.00000  lr: 0.0005526083664890837 batch: 25
epochs: 0 train loss: 4.08203125  train f1: 0.00000  lr: 3.889083835340568e-05 batch: 21 
epochs: 0 val loss: 3.7265625  val f1:0.12500  lr: 3.889083835340568e-05 batch: 21
epochs: 0 train loss: 4.375  train f1: 0.00000  lr: 4.6501646821985486e-05 batch: 16 
epochs: 0 val loss: 4.58203125  val f1:0.00000  lr: 4.6501646821985486e-05 batch: 16
epochs: 0 train loss: 4.703125  train f1: 0.00000  lr: 0.00027831347875332835 batch: 20 
epochs: 0 val loss: 4.66796875  val f1:0.00000  lr: 0.00027831347875332835 batch: 20
epochs: 0 train loss: 4.265625  train f1: 0.00000  lr: 0.0018311093964660829 batch: 12 
epochs: 0 val loss: 4.12890625  val f1:0.00000  lr: 0.0018311093964660829 batch: 12
epochs: 0 train loss: 4.27734375  train f1: 0.00000  lr: 3.4219794190365286e-05 batch: 27 
epochs: 0 val loss: 4.43359375  val f1:0.00000  lr: 3.4219794190365286e-05 batch: 27
epochs: 0 train loss: 4.90625  train f1: 0.00000  lr: 0.006405428178104098 batch: 20 
epochs: 0 val loss: 4.80078125  val f1:0.00000  lr: 0.006405428178104098 batch: 20
epochs: 0 train loss: 4.640625  train f1: 0.00000  lr: 1.067299222389805e-05 batch: 23 
epochs: 0 val loss: 5.79296875  val f1:0.00000  lr: 1.067299222389805e-05 batch: 23
epochs: 0 train loss: 4.68359375  train f1: 0.00000  lr: 7.528966022220601e-05 batch: 18 
epochs: 0 val loss: 4.7265625  val f1:0.00000  lr: 7.528966022220601e-05 batch: 18
epochs: 0 train loss: 4.8125  train f1: 0.00000  lr: 0.0002738679450579267 batch: 17 
epochs: 0 val loss: 5.04296875  val f1:0.00000  lr: 0.0002738679450579267 batch: 17
epochs: 0 train loss: 3.984375  train f1: 0.11111  lr: 1.4807051954294561e-05 batch: 22 
epochs: 0 val loss: 5.28125  val f1:0.00000  lr: 1.4807051954294561e-05 batch: 22
epochs: 0 train loss: 4.359375  train f1: 0.00000  lr: 7.581762957314342e-05 batch: 18 
epochs: 0 val loss: 4.56640625  val f1:0.00000  lr: 7.581762957314342e-05 batch: 18
epochs: 0 train loss: 4.5859375  train f1: 0.00000  lr: 0.0002508760231681438 batch: 17 
epochs: 0 val loss: 4.4140625  val f1:0.00000  lr: 0.0002508760231681438 batch: 17
epochs: 0 train loss: 5.26953125  train f1: 0.00000  lr: 3.4253874186068354e-05 batch: 20 
epochs: 0 val loss: 4.6796875  val f1:0.00000  lr: 3.4253874186068354e-05 batch: 20
epochs: 0 train loss: 4.25  train f1: 0.00000  lr: 0.03346417910505955 batch: 15 
epochs: 0 val loss: 4.43359375  val f1:0.00000  lr: 0.03346417910505955 batch: 15
epochs: 0 train loss: 4.45703125  train f1: 0.00000  lr: 0.020751327385817676 batch: 12 
epochs: 0 val loss: 5.17578125  val f1:0.00000  lr: 0.020751327385817676 batch: 12
epochs: 0 train loss: 4.66015625  train f1: 0.00000  lr: 0.0007650971226084004 batch: 25 
epochs: 0 val loss: 4.84375  val f1:0.00000  lr: 0.0007650971226084004 batch: 25
epochs: 0 train loss: 4.0546875  train f1: 0.00000  lr: 0.00012087409879421949 batch: 29 
epochs: 0 val loss: 4.375  val f1:0.00000  lr: 0.00012087409879421949 batch: 29
epochs: 0 train loss: 5.24609375  train f1: 0.00000  lr: 5.438950536236265e-05 batch: 13 
epochs: 0 val loss: 5.453125  val f1:0.00000  lr: 5.438950536236265e-05 batch: 13
epochs: 0 train loss: 4.3515625  train f1: 0.00000  lr: 0.0014410904924586202 batch: 16 
epochs: 0 val loss: 4.47265625  val f1:0.00000  lr: 0.0014410904924586202 batch: 16
epochs: 0 train loss: 4.671875  train f1: 0.00000  lr: 0.0001919079414539218 batch: 19 
epochs: 0 val loss: 4.03515625  val f1:0.08333  lr: 0.0001919079414539218 batch: 19
epochs: 0 train loss: 4.2890625  train f1: 0.00000  lr: 0.00024074234690804939 batch: 19 
epochs: 0 val loss: 4.859375  val f1:0.00000  lr: 0.00024074234690804939 batch: 19
epochs: 0 train loss: 4.859375  train f1: 0.00000  lr: 0.00039363363760907557 batch: 21 
epochs: 0 val loss: 4.38671875  val f1:0.00000  lr: 0.00039363363760907557 batch: 21
epochs: 0 train loss: 4.72265625  train f1: 0.00000  lr: 0.0014434423751487826 batch: 10 
epochs: 0 val loss: 5.3125  val f1:0.00000  lr: 0.0014434423751487826 batch: 10
epochs: 0 train loss: 5.12109375  train f1: 0.00000  lr: 2.5962428401118836e-05 batch: 27 
epochs: 0 val loss: 4.9453125  val f1:0.00000  lr: 2.5962428401118836e-05 batch: 27
epochs: 0 train loss: 4.890625  train f1: 0.00000  lr: 0.00018397293486151325 batch: 12 
epochs: 0 val loss: 4.8125  val f1:0.00000  lr: 0.00018397293486151325 batch: 12
epochs: 0 train loss: 4.99609375  train f1: 0.00000  lr: 0.0041617552339179185 batch: 12 
epochs: 0 val loss: 5.35546875  val f1:0.00000  lr: 0.0041617552339179185 batch: 12
epochs: 0 train loss: 4.83984375  train f1: 0.00000  lr: 8.913168593425959e-05 batch: 27 
epochs: 0 val loss: 4.87890625  val f1:0.00000  lr: 8.913168593425959e-05 batch: 27
epochs: 0 train loss: 4.640625  train f1: 0.00000  lr: 0.011577575577175045 batch: 22 
epochs: 0 val loss: 4.5625  val f1:0.00000  lr: 0.011577575577175045 batch: 22
epochs: 0 train loss: 4.62109375  train f1: 0.00000  lr: 1.0410448728038326e-05 batch: 23 
epochs: 0 val loss: 5.4375  val f1:0.00000  lr: 1.0410448728038326e-05 batch: 23
epochs: 0 train loss: 5.12109375  train f1: 0.00000  lr: 1.8804398844989535e-05 batch: 18 
epochs: 0 val loss: 4.76171875  val f1:0.00000  lr: 1.8804398844989535e-05 batch: 18
epochs: 0 train loss: 4.6953125  train f1: 0.00000  lr: 0.00017854246781886444 batch: 19 
epochs: 0 val loss: 5.2109375  val f1:0.00000  lr: 0.00017854246781886444 batch: 19
epochs: 0 train loss: 4.625  train f1: 0.00000  lr: 7.430220186488826e-05 batch: 18 
epochs: 0 val loss: 5.09765625  val f1:0.00000  lr: 7.430220186488826e-05 batch: 18
epochs: 0 train loss: 4.7734375  train f1: 0.00000  lr: 1.574741147624744e-05 batch: 22 
epochs: 0 val loss: 5.25  val f1:0.00000  lr: 1.574741147624744e-05 batch: 22
epochs: 0 train loss: 5.1171875  train f1: 0.00000  lr: 0.00040590662769148694 batch: 17 
epochs: 0 val loss: 5.19921875  val f1:0.00000  lr: 0.00040590662769148694 batch: 17
epochs: 0 train loss: 4.90625  train f1: 0.00000  lr: 2.8192248222174793e-05 batch: 21 
epochs: 0 val loss: 4.5546875  val f1:0.00000  lr: 2.8192248222174793e-05 batch: 21
epochs: 0 train loss: 4.46484375  train f1: 0.00000  lr: 0.00012158767563131961 batch: 24 
epochs: 0 val loss: 4.41796875  val f1:0.00000  lr: 0.00012158767563131961 batch: 24
epochs: 0 train loss: 4.546875  train f1: 0.00000  lr: 6.0060637732355644e-05 batch: 15 
epochs: 0 val loss: 5.24609375  val f1:0.00000  lr: 6.0060637732355644e-05 batch: 15
epochs: 0 train loss: 5.25  train f1: 0.00000  lr: 0.00016415753863414562 batch: 14 
epochs: 0 val loss: 4.78125  val f1:0.00000  lr: 0.00016415753863414562 batch: 14
epochs: 0 train loss: 4.296875  train f1: 0.00000  lr: 3.775128321345315e-05 batch: 20 
epochs: 0 val loss: 5.41796875  val f1:0.00000  lr: 3.775128321345315e-05 batch: 20
epochs: 0 train loss: 4.953125  train f1: 0.00000  lr: 0.03834285790593024 batch: 15 
epochs: 0 val loss: 5.11328125  val f1:0.00000  lr: 0.03834285790593024 batch: 15
epochs: 0 train loss: 4.796875  train f1: 0.00000  lr: 0.06554508273767844 batch: 11 
epochs: 0 val loss: 4.94921875  val f1:0.00000  lr: 0.06554508273767844 batch: 11
epochs: 0 train loss: 4.53125  train f1: 0.00000  lr: 0.03003241089516848 batch: 8 
epochs: 0 val loss: 4.7578125  val f1:0.00000  lr: 0.03003241089516848 batch: 8
epochs: 0 train loss: 3.970703125  train f1: 0.20000  lr: 0.01937020726163284 batch: 14 
epochs: 0 val loss: 5.60546875  val f1:0.00000  lr: 0.01937020726163284 batch: 14
epochs: 0 train loss: 4.109375  train f1: 0.16667  lr: 0.007736222616466785 batch: 11 
epochs: 0 val loss: 4.95703125  val f1:0.00000  lr: 0.007736222616466785 batch: 11
epochs: 0 train loss: 4.7421875  train f1: 0.00000  lr: 0.0010608348664287693 batch: 29 
epochs: 0 val loss: 4.9921875  val f1:0.00000  lr: 0.0010608348664287693 batch: 29
epochs: 0 train loss: 4.51171875  train f1: 0.00000  lr: 2.411989235707415e-05 batch: 9 
epochs: 0 val loss: 5.4453125  val f1:0.00000  lr: 2.411989235707415e-05 batch: 9
epochs: 0 train loss: 4.640625  train f1: 0.00000  lr: 0.002664192065561615 batch: 32 
epochs: 0 val loss: 4.1796875  val f1:0.07143  lr: 0.002664192065561615 batch: 32
epochs: 0 train loss: 5.10546875  train f1: 0.00000  lr: 0.0028249949366939515 batch: 32 
epochs: 0 val loss: 4.48828125  val f1:0.00000  lr: 0.0028249949366939515 batch: 32
epochs: 0 train loss: 4.32421875  train f1: 0.00000  lr: 0.005393731873453234 batch: 26 
epochs: 0 val loss: 4.9453125  val f1:0.00000  lr: 0.005393731873453234 batch: 26
epochs: 0 train loss: 4.3828125  train f1: 0.00000  lr: 0.010381685717276403 batch: 31 
epochs: 0 val loss: 5.39453125  val f1:0.00000  lr: 0.010381685717276403 batch: 31
epochs: 0 train loss: 4.98828125  train f1: 0.00000  lr: 0.00010136911167910074 batch: 23 
epochs: 0 val loss: 5.5703125  val f1:0.00000  lr: 0.00010136911167910074 batch: 23
epochs: 0 train loss: 5.0703125  train f1: 0.00000  lr: 1.1163356761890918e-05 batch: 22 
epochs: 0 val loss: 5.38671875  val f1:0.00000  lr: 1.1163356761890918e-05 batch: 22
epochs: 0 train loss: 5.28515625  train f1: 0.00000  lr: 1.728651176482588e-05 batch: 19 
epochs: 0 val loss: 4.65234375  val f1:0.00000  lr: 1.728651176482588e-05 batch: 19
epochs: 0 train loss: 4.91015625  train f1: 0.00000  lr: 1.832429511623612e-05 batch: 19 
epochs: 0 val loss: 4.43359375  val f1:0.00000  lr: 1.832429511623612e-05 batch: 19
epochs: 0 train loss: 4.20703125  train f1: 0.00000  lr: 7.108832051930109e-05 batch: 18 
epochs: 0 val loss: 4.09765625  val f1:0.12500  lr: 7.108832051930109e-05 batch: 18
epochs: 0 train loss: 4.25390625  train f1: 0.00000  lr: 0.00019743600469403387 batch: 18 
epochs: 0 val loss: 4.6484375  val f1:0.00000  lr: 0.00019743600469403387 batch: 18
epochs: 0 train loss: 4.4609375  train f1: 0.00000  lr: 0.00037190451961127853 batch: 17 
epochs: 0 val loss: 5.19140625  val f1:0.00000  lr: 0.00037190451961127853 batch: 17
epochs: 0 train loss: 4.8125  train f1: 0.00000  lr: 0.0017490099136237627 batch: 9 
epochs: 0 val loss: 5.27734375  val f1:0.00000  lr: 0.0017490099136237627 batch: 9
epochs: 0 train loss: 4.84765625  train f1: 0.00000  lr: 0.0001387985041514345 batch: 21 
epochs: 0 val loss: 4.9765625  val f1:0.00000  lr: 0.0001387985041514345 batch: 21
epochs: 0 train loss: 4.05859375  train f1: 0.00000  lr: 2.947143795623248e-05 batch: 24 
epochs: 0 val loss: 5.32421875  val f1:0.00000  lr: 2.947143795623248e-05 batch: 24
epochs: 0 train loss: 4.4609375  train f1: 0.00000  lr: 5.99494489219928e-05 batch: 25 
epochs: 0 val loss: 4.50390625  val f1:0.11111  lr: 5.99494489219928e-05 batch: 25
epochs: 0 train loss: 4.4140625  train f1: 0.00000  lr: 3.9134576324249874e-05 batch: 30 
epochs: 0 val loss: 5.28125  val f1:0.00000  lr: 3.9134576324249874e-05 batch: 30
epochs: 0 train loss: 4.703125  train f1: 0.00000  lr: 0.0039732270485461595 batch: 13 
epochs: 0 val loss: 5.10546875  val f1:0.00000  lr: 0.0039732270485461595 batch: 13
epochs: 0 train loss: 4.87890625  train f1: 0.00000  lr: 6.327044378902618e-05 batch: 20 
epochs: 0 val loss: 5.046875  val f1:0.00000  lr: 6.327044378902618e-05 batch: 20
epochs: 0 train loss: 4.1640625  train f1: 0.00000  lr: 0.043700104438792214 batch: 21 
epochs: 0 val loss: 5.2265625  val f1:0.00000  lr: 0.043700104438792214 batch: 21
epochs: 0 train loss: 5.4765625  train f1: 0.00000  lr: 0.09289954429940468 batch: 11 
epochs: 0 val loss: 4.6484375  val f1:0.00000  lr: 0.09289954429940468 batch: 11
epochs: 0 train loss: 4.66796875  train f1: 0.00000  lr: 0.05884165525030855 batch: 16 
epochs: 0 val loss: 5.16015625  val f1:0.00000  lr: 0.05884165525030855 batch: 16
epochs: 0 train loss: 4.09765625  train f1: 0.00000  lr: 0.03132225320582479 batch: 8 
epochs: 0 val loss: 4.67578125  val f1:0.00000  lr: 0.03132225320582479 batch: 8
epochs: 0 train loss: 4.87890625  train f1: 0.00000  lr: 0.06296750896702927 batch: 14 
epochs: 0 val loss: 5.29296875  val f1:0.00000  lr: 0.06296750896702927 batch: 14
epochs: 0 train loss: 4.38671875  train f1: 0.00000  lr: 0.015970006155284183 batch: 11 
epochs: 0 val loss: 4.9609375  val f1:0.00000  lr: 0.015970006155284183 batch: 11
epochs: 0 train loss: 4.546875  train f1: 0.00000  lr: 0.007516785831989137 batch: 11 
epochs: 0 val loss: 5.14453125  val f1:0.00000  lr: 0.007516785831989137 batch: 11
epochs: 0 train loss: 3.90234375  train f1: 0.20000  lr: 0.021073318807784375 batch: 29 
epochs: 0 val loss: 4.1875  val f1:0.00000  lr: 0.021073318807784375 batch: 29
epochs: 0 train loss: 3.85546875  train f1: 0.20000  lr: 0.0008468164886185026 batch: 28 
epochs: 0 val loss: 4.32421875  val f1:0.12500  lr: 0.0008468164886185026 batch: 28
epochs: 0 train loss: 4.734375  train f1: 0.00000  lr: 2.3633144811693343e-05 batch: 28 
epochs: 0 val loss: 4.96484375  val f1:0.00000  lr: 2.3633144811693343e-05 batch: 28
epochs: 0 train loss: 4.7890625  train f1: 0.00000  lr: 0.0013058697808030074 batch: 30 
epochs: 0 val loss: 5.59375  val f1:0.00000  lr: 0.0013058697808030074 batch: 30
epochs: 0 train loss: 4.01171875  train f1: 0.00000  lr: 0.0008522807334095304 batch: 31 
epochs: 0 val loss: 5.76171875  val f1:0.00000  lr: 0.0008522807334095304 batch: 31
epochs: 0 train loss: 4.859375  train f1: 0.00000  lr: 0.002803564937504347 batch: 31 
epochs: 0 val loss: 5.26171875  val f1:0.00000  lr: 0.002803564937504347 batch: 31
epochs: 0 train loss: 4.3125  train f1: 0.00000  lr: 0.0051659077887170725 batch: 26 
epochs: 0 val loss: 4.62109375  val f1:0.00000  lr: 0.0051659077887170725 batch: 26
epochs: 0 train loss: 1.512911212978077  train f1: 0.15222  lr: 0.009855776595271511 batch: 32 
epochs: 0 val loss: 2.946834788602942  val f1:0.11624  lr: 0.009855776595271511 batch: 32
epochs: 0 train loss: 4.152682000698325  train f1: 0.02124  lr: 0.00025846971787580204 batch: 24 
epochs: 0 val loss: 4.1541015625  val f1:0.03888  lr: 0.00025846971787580204 batch: 24
epochs: 0 train loss: 1.1657991810005248  train f1: 0.16298  lr: 7.820536266607622e-05 batch: 18 
epochs: 0 val loss: 2.1806477864583322  val f1:0.13806  lr: 7.820536266607622e-05 batch: 18
epochs: 0 train loss: 1.042336432057358  train f1: 0.18113  lr: 0.03276574616253206 batch: 11 
epochs: 0 val loss: 2.224006497130103  val f1:0.19930  lr: 0.03276574616253206 batch: 11
epochs: 0 train loss: 1.0093571677136775  train f1: 0.19637  lr: 0.05445654378854562 batch: 16 
epochs: 0 val loss: 2.1019350405092587  val f1:0.21992  lr: 0.05445654378854562 batch: 16
epochs: 0 train loss: 2.8668387276785703  train f1: 0.07893  lr: 0.014002854534820156 batch: 13 
epochs: 0 val loss: 3.563270660768073  val f1:0.07308  lr: 0.014002854534820156 batch: 13
epochs: 0 train loss: 2.1442700366040204  train f1: 0.13739  lr: 1.9855688689627575e-05 batch: 30 
epochs: 0 val loss: 3.1331922743055545  val f1:0.10670  lr: 1.9855688689627575e-05 batch: 30
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.00013961572173084718 batch: 19 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.00013961572173084718 batch: 19
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.00013961572173084718 batch: 19 
epochs: 1 val loss: 4.39453125  val f1:0.12500  lr: 0.00013961572173084718 batch: 19
epochs: 2 train loss: 0.40185546875  train f1: 1.00000  lr: 0.00013961572173084718 batch: 19 
epochs: 2 val loss: 4.08984375  val f1:0.12500  lr: 0.00013961572173084718 batch: 19
epochs: 3 train loss: 0.07025146484375  train f1: 1.00000  lr: 0.00013961572173084718 batch: 19 
epochs: 3 val loss: 3.98046875  val f1:0.12500  lr: 0.00013961572173084718 batch: 19
epochs: 4 train loss: 0.007785797119140625  train f1: 1.00000  lr: 0.00013961572173084718 batch: 19 
epochs: 4 val loss: 4.01953125  val f1:0.12500  lr: 0.00013961572173084718 batch: 19
epochs: 5 train loss: 0.003078460693359375  train f1: 1.00000  lr: 0.00013961572173084718 batch: 19 
epochs: 5 val loss: 4.0078125  val f1:0.12500  lr: 0.00013961572173084718 batch: 19
epochs: 6 train loss: 0.00678253173828125  train f1: 1.00000  lr: 0.00013961572173084718 batch: 19 
epochs: 6 val loss: 3.978515625  val f1:0.11111  lr: 0.00013961572173084718 batch: 19
epochs: 7 train loss: 0.00273895263671875  train f1: 1.00000  lr: 0.00013961572173084718 batch: 19 
epochs: 7 val loss: 3.916015625  val f1:0.11111  lr: 0.00013961572173084718 batch: 19
epochs: 8 train loss: 0.0028705596923828125  train f1: 1.00000  lr: 0.00013961572173084718 batch: 19 
epochs: 8 val loss: 3.87890625  val f1:0.12500  lr: 0.00013961572173084718 batch: 19
epochs: 9 train loss: 0.0019102096557617188  train f1: 1.00000  lr: 0.00013961572173084718 batch: 19 
epochs: 9 val loss: 3.83984375  val f1:0.12500  lr: 0.00013961572173084718 batch: 19
epochs: 10 train loss: 0.0022144317626953125  train f1: 1.00000  lr: 0.00013961572173084718 batch: 19 
epochs: 10 val loss: 3.841796875  val f1:0.12500  lr: 0.00013961572173084718 batch: 19
epochs: 0 train loss: 4.9453125  train f1: 0.00000  lr: 0.0009698902671803047 batch: 13 
epochs: 0 val loss: 5.3203125  val f1:0.00000  lr: 0.0009698902671803047 batch: 13
epochs: 1 train loss: 4.859375  train f1: 0.00000  lr: 0.0009698902671803047 batch: 13 
epochs: 1 val loss: 4.73828125  val f1:0.00000  lr: 0.0009698902671803047 batch: 13
epochs: 2 train loss: 1.2314453125  train f1: 1.00000  lr: 0.0009698902671803047 batch: 13 
epochs: 2 val loss: 4.2265625  val f1:0.12500  lr: 0.0009698902671803047 batch: 13
epochs: 3 train loss: 0.070556640625  train f1: 1.00000  lr: 0.0009698902671803047 batch: 13 
epochs: 3 val loss: 4.0234375  val f1:0.14286  lr: 0.0009698902671803047 batch: 13
epochs: 4 train loss: 0.0077362060546875  train f1: 1.00000  lr: 0.0009698902671803047 batch: 13 
epochs: 4 val loss: 4.0  val f1:0.14286  lr: 0.0009698902671803047 batch: 13
epochs: 5 train loss: 0.0015926361083984375  train f1: 1.00000  lr: 0.0009698902671803047 batch: 13 
epochs: 5 val loss: 4.015625  val f1:0.12500  lr: 0.0009698902671803047 batch: 13
epochs: 6 train loss: 0.00041866302490234375  train f1: 1.00000  lr: 0.0009698902671803047 batch: 13 
epochs: 6 val loss: 4.03515625  val f1:0.12500  lr: 0.0009698902671803047 batch: 13
epochs: 7 train loss: 0.0003509521484375  train f1: 1.00000  lr: 0.0009698902671803047 batch: 13 
epochs: 7 val loss: 4.0234375  val f1:0.12500  lr: 0.0009698902671803047 batch: 13
epochs: 8 train loss: 0.0003314018249511719  train f1: 1.00000  lr: 0.0009698902671803047 batch: 13 
epochs: 8 val loss: 4.03125  val f1:0.11111  lr: 0.0009698902671803047 batch: 13
epochs: 9 train loss: 0.00018298625946044922  train f1: 1.00000  lr: 0.0009698902671803047 batch: 13 
epochs: 9 val loss: 4.0234375  val f1:0.11111  lr: 0.0009698902671803047 batch: 13
epochs: 10 train loss: 9.763240814208984e-05  train f1: 1.00000  lr: 0.0009698902671803047 batch: 13 
epochs: 10 val loss: 4.00390625  val f1:0.11111  lr: 0.0009698902671803047 batch: 13
epochs: 11 train loss: 5.0067901611328125e-05  train f1: 1.00000  lr: 0.0009698902671803047 batch: 13 
epochs: 11 val loss: 3.951171875  val f1:0.11111  lr: 0.0009698902671803047 batch: 13
epochs: 12 train loss: 5.352497100830078e-05  train f1: 1.00000  lr: 0.0009698902671803047 batch: 13 
epochs: 12 val loss: 3.8828125  val f1:0.11111  lr: 0.0009698902671803047 batch: 13
epochs: 13 train loss: 4.0590763092041016e-05  train f1: 1.00000  lr: 0.0009698902671803047 batch: 13 
epochs: 13 val loss: 3.85546875  val f1:0.11111  lr: 0.0009698902671803047 batch: 13
epochs: 14 train loss: 2.8967857360839844e-05  train f1: 1.00000  lr: 0.0009698902671803047 batch: 13 
epochs: 14 val loss: 3.80078125  val f1:0.11111  lr: 0.0009698902671803047 batch: 13
epochs: 15 train loss: 1.8715858459472656e-05  train f1: 1.00000  lr: 0.0009698902671803047 batch: 13 
epochs: 15 val loss: 3.759765625  val f1:0.11111  lr: 0.0009698902671803047 batch: 13
epochs: 0 train loss: 4.703125  train f1: 0.00000  lr: 0.0005510172999350924 batch: 21 
epochs: 0 val loss: 4.83984375  val f1:0.00000  lr: 0.0005510172999350924 batch: 21
epochs: 1 train loss: 4.7421875  train f1: 0.00000  lr: 0.0005510172999350924 batch: 21 
epochs: 1 val loss: 3.380859375  val f1:0.11111  lr: 0.0005510172999350924 batch: 21
epochs: 2 train loss: 0.08935546875  train f1: 1.00000  lr: 0.0005510172999350924 batch: 21 
epochs: 2 val loss: 5.1796875  val f1:0.12500  lr: 0.0005510172999350924 batch: 21
epochs: 3 train loss: 0.499267578125  train f1: 1.00000  lr: 0.0005510172999350924 batch: 21 
epochs: 3 val loss: 4.6640625  val f1:0.14286  lr: 0.0005510172999350924 batch: 21
epochs: 4 train loss: 0.2509765625  train f1: 1.00000  lr: 0.0005510172999350924 batch: 21 
epochs: 4 val loss: 3.783203125  val f1:0.08333  lr: 0.0005510172999350924 batch: 21
epochs: 5 train loss: 1.5712890625  train f1: 0.50000  lr: 0.0005510172999350924 batch: 21 
epochs: 5 val loss: 7.87890625  val f1:0.14286  lr: 0.0005510172999350924 batch: 21
epochs: 6 train loss: 3.4570693969726562e-06  train f1: 1.00000  lr: 0.0005510172999350924 batch: 21 
epochs: 6 val loss: 6.7890625  val f1:0.14286  lr: 0.0005510172999350924 batch: 21
epochs: 7 train loss: 4.76837158203125e-06  train f1: 1.00000  lr: 0.0005510172999350924 batch: 21 
epochs: 7 val loss: 6.296875  val f1:0.14286  lr: 0.0005510172999350924 batch: 21
epochs: 0 train loss: 4.3203125  train f1: 0.00000  lr: 1.2153362220890667e-05 batch: 32 
epochs: 0 val loss: 5.24609375  val f1:0.00000  lr: 1.2153362220890667e-05 batch: 32
epochs: 1 train loss: 4.23828125  train f1: 0.00000  lr: 1.2153362220890667e-05 batch: 32 
epochs: 1 val loss: 5.05078125  val f1:0.00000  lr: 1.2153362220890667e-05 batch: 32
epochs: 2 train loss: 4.20703125  train f1: 0.16667  lr: 1.2153362220890667e-05 batch: 32 
epochs: 2 val loss: 4.91015625  val f1:0.00000  lr: 1.2153362220890667e-05 batch: 32
epochs: 3 train loss: 4.16015625  train f1: 0.00000  lr: 1.2153362220890667e-05 batch: 32 
epochs: 3 val loss: 4.79296875  val f1:0.00000  lr: 1.2153362220890667e-05 batch: 32
epochs: 4 train loss: 4.34375  train f1: 0.00000  lr: 1.2153362220890667e-05 batch: 32 
epochs: 4 val loss: 4.71484375  val f1:0.00000  lr: 1.2153362220890667e-05 batch: 32
epochs: 5 train loss: 4.1328125  train f1: 0.00000  lr: 1.2153362220890667e-05 batch: 32 
epochs: 5 val loss: 4.6953125  val f1:0.00000  lr: 1.2153362220890667e-05 batch: 32
epochs: 6 train loss: 4.24609375  train f1: 0.16667  lr: 1.2153362220890667e-05 batch: 32 
epochs: 6 val loss: 4.6953125  val f1:0.00000  lr: 1.2153362220890667e-05 batch: 32
epochs: 7 train loss: 4.23046875  train f1: 0.00000  lr: 1.2153362220890667e-05 batch: 32 
epochs: 7 val loss: 4.62109375  val f1:0.00000  lr: 1.2153362220890667e-05 batch: 32
epochs: 8 train loss: 4.2578125  train f1: 0.00000  lr: 1.2153362220890667e-05 batch: 32 
epochs: 8 val loss: 4.5  val f1:0.00000  lr: 1.2153362220890667e-05 batch: 32
epochs: 9 train loss: 4.36328125  train f1: 0.00000  lr: 1.2153362220890667e-05 batch: 32 
epochs: 9 val loss: 4.453125  val f1:0.00000  lr: 1.2153362220890667e-05 batch: 32
epochs: 10 train loss: 4.125  train f1: 0.16667  lr: 1.2153362220890667e-05 batch: 32 
epochs: 10 val loss: 4.4140625  val f1:0.00000  lr: 1.2153362220890667e-05 batch: 32
epochs: 11 train loss: 4.26953125  train f1: 0.00000  lr: 1.2153362220890667e-05 batch: 32 
epochs: 11 val loss: 4.37890625  val f1:0.00000  lr: 1.2153362220890667e-05 batch: 32
epochs: 12 train loss: 4.37109375  train f1: 0.00000  lr: 1.2153362220890667e-05 batch: 32 
epochs: 12 val loss: 4.359375  val f1:0.00000  lr: 1.2153362220890667e-05 batch: 32
epochs: 13 train loss: 4.21484375  train f1: 0.00000  lr: 1.2153362220890667e-05 batch: 32 
epochs: 13 val loss: 4.35546875  val f1:0.00000  lr: 1.2153362220890667e-05 batch: 32
epochs: 14 train loss: 4.19921875  train f1: 0.16667  lr: 1.2153362220890667e-05 batch: 32 
epochs: 14 val loss: 4.3515625  val f1:0.00000  lr: 1.2153362220890667e-05 batch: 32
epochs: 15 train loss: 4.10546875  train f1: 0.00000  lr: 1.2153362220890667e-05 batch: 32 
epochs: 15 val loss: 4.3671875  val f1:0.00000  lr: 1.2153362220890667e-05 batch: 32
epochs: 16 train loss: 4.22265625  train f1: 0.00000  lr: 1.2153362220890667e-05 batch: 32 
epochs: 16 val loss: 4.41015625  val f1:0.00000  lr: 1.2153362220890667e-05 batch: 32
epochs: 0 train loss: 4.234375  train f1: 0.00000  lr: 1.395345861261365e-05 batch: 25 
epochs: 0 val loss: 3.716796875  val f1:0.14286  lr: 1.395345861261365e-05 batch: 25
epochs: 1 train loss: 4.28125  train f1: 0.00000  lr: 1.395345861261365e-05 batch: 25 
epochs: 1 val loss: 3.681640625  val f1:0.14286  lr: 1.395345861261365e-05 batch: 25
epochs: 2 train loss: 3.22265625  train f1: 0.20000  lr: 1.395345861261365e-05 batch: 25 
epochs: 2 val loss: 3.65234375  val f1:0.33333  lr: 1.395345861261365e-05 batch: 25
epochs: 3 train loss: 2.595703125  train f1: 0.50000  lr: 1.395345861261365e-05 batch: 25 
epochs: 3 val loss: 3.662109375  val f1:0.33333  lr: 1.395345861261365e-05 batch: 25
epochs: 4 train loss: 2.435546875  train f1: 0.50000  lr: 1.395345861261365e-05 batch: 25 
epochs: 4 val loss: 3.6875  val f1:0.33333  lr: 1.395345861261365e-05 batch: 25
epochs: 5 train loss: 1.8994140625  train f1: 1.00000  lr: 1.395345861261365e-05 batch: 25 
epochs: 5 val loss: 3.720703125  val f1:0.33333  lr: 1.395345861261365e-05 batch: 25
epochs: 6 train loss: 1.5927734375  train f1: 1.00000  lr: 1.395345861261365e-05 batch: 25 
epochs: 6 val loss: 3.736328125  val f1:0.14286  lr: 1.395345861261365e-05 batch: 25
epochs: 0 train loss: 4.2890625  train f1: 0.00000  lr: 0.00014871081594848895 batch: 20 
epochs: 0 val loss: 5.14453125  val f1:0.00000  lr: 0.00014871081594848895 batch: 20
epochs: 1 train loss: 4.26953125  train f1: 0.00000  lr: 0.00014871081594848895 batch: 20 
epochs: 1 val loss: 5.015625  val f1:0.00000  lr: 0.00014871081594848895 batch: 20
epochs: 0 train loss: 4.70703125  train f1: 0.00000  lr: 0.04852761237856969 batch: 26 
epochs: 0 val loss: 4.85546875  val f1:0.00000  lr: 0.04852761237856969 batch: 26
epochs: 1 train loss: 4.70703125  train f1: 0.00000  lr: 0.04852761237856969 batch: 26 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.04852761237856969 batch: 26
epochs: 0 train loss: 4.75390625  train f1: 0.00000  lr: 0.013790349508052873 batch: 29 
epochs: 0 val loss: 4.59765625  val f1:0.00000  lr: 0.013790349508052873 batch: 29
epochs: 1 train loss: 4.734375  train f1: 0.00000  lr: 0.013790349508052873 batch: 29 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.013790349508052873 batch: 29
epochs: 0 train loss: 5.046875  train f1: 0.00000  lr: 0.02924584120021802 batch: 22 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.02924584120021802 batch: 22
epochs: 1 train loss: 5.0625  train f1: 0.00000  lr: 0.02924584120021802 batch: 22 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.02924584120021802 batch: 22
epochs: 0 train loss: 4.79296875  train f1: 0.00000  lr: 0.0015015915951049814 batch: 31 
epochs: 0 val loss: 4.38671875  val f1:0.00000  lr: 0.0015015915951049814 batch: 31
epochs: 1 train loss: 4.90625  train f1: 0.00000  lr: 0.0015015915951049814 batch: 31 
epochs: 1 val loss: 3.8984375  val f1:0.00000  lr: 0.0015015915951049814 batch: 31
epochs: 0 train loss: 5.109375  train f1: 0.00000  lr: 0.002741794706556979 batch: 8 
epochs: 0 val loss: 5.21875  val f1:0.00000  lr: 0.002741794706556979 batch: 8
epochs: 1 train loss: 5.03515625  train f1: 0.00000  lr: 0.002741794706556979 batch: 8 
epochs: 1 val loss: 5.14453125  val f1:0.00000  lr: 0.002741794706556979 batch: 8
epochs: 0 train loss: 4.99609375  train f1: 0.00000  lr: 2.161892602795228e-05 batch: 24 
epochs: 0 val loss: 4.9609375  val f1:0.00000  lr: 2.161892602795228e-05 batch: 24
epochs: 1 train loss: 5.0234375  train f1: 0.00000  lr: 2.161892602795228e-05 batch: 24 
epochs: 1 val loss: 4.83984375  val f1:0.00000  lr: 2.161892602795228e-05 batch: 24
epochs: 0 train loss: 5.0078125  train f1: 0.00000  lr: 9.556298796640392e-05 batch: 17 
epochs: 0 val loss: 5.1171875  val f1:0.00000  lr: 9.556298796640392e-05 batch: 17
epochs: 1 train loss: 4.98828125  train f1: 0.00000  lr: 9.556298796640392e-05 batch: 17 
epochs: 1 val loss: 4.33203125  val f1:0.16667  lr: 9.556298796640392e-05 batch: 17
epochs: 2 train loss: 1.05859375  train f1: 1.00000  lr: 9.556298796640392e-05 batch: 17 
epochs: 2 val loss: 4.44921875  val f1:0.14286  lr: 9.556298796640392e-05 batch: 17
epochs: 3 train loss: 0.292724609375  train f1: 1.00000  lr: 9.556298796640392e-05 batch: 17 
epochs: 3 val loss: 4.19921875  val f1:0.14286  lr: 9.556298796640392e-05 batch: 17
epochs: 4 train loss: 0.06964111328125  train f1: 1.00000  lr: 9.556298796640392e-05 batch: 17 
epochs: 4 val loss: 4.2109375  val f1:0.14286  lr: 9.556298796640392e-05 batch: 17
epochs: 5 train loss: 0.039794921875  train f1: 1.00000  lr: 9.556298796640392e-05 batch: 17 
epochs: 5 val loss: 4.25  val f1:0.12500  lr: 9.556298796640392e-05 batch: 17
epochs: 6 train loss: 0.02203369140625  train f1: 1.00000  lr: 9.556298796640392e-05 batch: 17 
epochs: 6 val loss: 4.23828125  val f1:0.12500  lr: 9.556298796640392e-05 batch: 17
epochs: 7 train loss: 0.0215911865234375  train f1: 1.00000  lr: 9.556298796640392e-05 batch: 17 
epochs: 7 val loss: 4.21875  val f1:0.12500  lr: 9.556298796640392e-05 batch: 17
epochs: 0 train loss: 4.75  train f1: 0.00000  lr: 0.00044778924709763026 batch: 26 
epochs: 0 val loss: 4.7734375  val f1:0.00000  lr: 0.00044778924709763026 batch: 26
epochs: 1 train loss: 4.9375  train f1: 0.00000  lr: 0.00044778924709763026 batch: 26 
epochs: 1 val loss: 4.16015625  val f1:0.12500  lr: 0.00044778924709763026 batch: 26
epochs: 2 train loss: 0.14892578125  train f1: 1.00000  lr: 0.00044778924709763026 batch: 26 
epochs: 2 val loss: 5.921875  val f1:0.14286  lr: 0.00044778924709763026 batch: 26
epochs: 3 train loss: 0.160888671875  train f1: 1.00000  lr: 0.00044778924709763026 batch: 26 
epochs: 3 val loss: 8.8203125  val f1:0.14286  lr: 0.00044778924709763026 batch: 26
epochs: 4 train loss: 0.00342559814453125  train f1: 1.00000  lr: 0.00044778924709763026 batch: 26 
epochs: 4 val loss: 6.29296875  val f1:0.14286  lr: 0.00044778924709763026 batch: 26
epochs: 5 train loss: 0.0006957054138183594  train f1: 1.00000  lr: 0.00044778924709763026 batch: 26 
epochs: 5 val loss: 5.02734375  val f1:0.12500  lr: 0.00044778924709763026 batch: 26
epochs: 6 train loss: 0.00020039081573486328  train f1: 1.00000  lr: 0.00044778924709763026 batch: 26 
epochs: 6 val loss: 4.10546875  val f1:0.14286  lr: 0.00044778924709763026 batch: 26
epochs: 7 train loss: 0.0002574920654296875  train f1: 1.00000  lr: 0.00044778924709763026 batch: 26 
epochs: 7 val loss: 3.623046875  val f1:0.14286  lr: 0.00044778924709763026 batch: 26
epochs: 0 train loss: 4.6796875  train f1: 0.00000  lr: 0.0063490096263043435 batch: 16 
epochs: 0 val loss: 5.109375  val f1:0.00000  lr: 0.0063490096263043435 batch: 16
epochs: 1 train loss: 4.46875  train f1: 0.16667  lr: 0.0063490096263043435 batch: 16 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.0063490096263043435 batch: 16
epochs: 0 train loss: 4.8203125  train f1: 0.00000  lr: 3.5962204036860296e-05 batch: 23 
epochs: 0 val loss: 4.09765625  val f1:0.00000  lr: 3.5962204036860296e-05 batch: 23
epochs: 1 train loss: 4.79296875  train f1: 0.00000  lr: 3.5962204036860296e-05 batch: 23 
epochs: 1 val loss: 4.00390625  val f1:0.00000  lr: 3.5962204036860296e-05 batch: 23
epochs: 0 train loss: 4.7734375  train f1: 0.00000  lr: 0.00039278730132771806 batch: 28 
epochs: 0 val loss: 5.015625  val f1:0.00000  lr: 0.00039278730132771806 batch: 28
epochs: 1 train loss: 4.8046875  train f1: 0.00000  lr: 0.00039278730132771806 batch: 28 
epochs: 1 val loss: 5.0703125  val f1:0.00000  lr: 0.00039278730132771806 batch: 28
epochs: 0 train loss: 4.5625  train f1: 0.00000  lr: 3.789454329475019e-05 batch: 15 
epochs: 0 val loss: 4.87890625  val f1:0.00000  lr: 3.789454329475019e-05 batch: 15
epochs: 1 train loss: 4.39453125  train f1: 0.00000  lr: 3.789454329475019e-05 batch: 15 
epochs: 1 val loss: 4.53515625  val f1:0.00000  lr: 3.789454329475019e-05 batch: 15
epochs: 0 train loss: 4.5390625  train f1: 0.00000  lr: 1.056180444119256e-05 batch: 11 
epochs: 0 val loss: 4.50390625  val f1:0.00000  lr: 1.056180444119256e-05 batch: 11
epochs: 1 train loss: 4.64453125  train f1: 0.00000  lr: 1.056180444119256e-05 batch: 11 
epochs: 1 val loss: 4.4765625  val f1:0.00000  lr: 1.056180444119256e-05 batch: 11
epochs: 0 train loss: 4.30078125  train f1: 0.00000  lr: 0.005706188136414269 batch: 21 
epochs: 0 val loss: 5.20703125  val f1:0.00000  lr: 0.005706188136414269 batch: 21
epochs: 1 train loss: 4.29296875  train f1: 0.00000  lr: 0.005706188136414269 batch: 21 
epochs: 1 val loss: 5.0  val f1:0.00000  lr: 0.005706188136414269 batch: 21
epochs: 0 train loss: 4.3828125  train f1: 0.00000  lr: 0.0003896035077314276 batch: 25 
epochs: 0 val loss: 4.3828125  val f1:0.00000  lr: 0.0003896035077314276 batch: 25
epochs: 1 train loss: 4.44140625  train f1: 0.11111  lr: 0.0003896035077314276 batch: 25 
epochs: 1 val loss: 3.390625  val f1:0.23810  lr: 0.0003896035077314276 batch: 25
epochs: 2 train loss: 1.267578125  train f1: 1.00000  lr: 0.0003896035077314276 batch: 25 
epochs: 2 val loss: 7.54296875  val f1:0.14286  lr: 0.0003896035077314276 batch: 25
epochs: 3 train loss: 1.607421875  train f1: 1.00000  lr: 0.0003896035077314276 batch: 25 
epochs: 3 val loss: 3.919921875  val f1:0.14286  lr: 0.0003896035077314276 batch: 25
epochs: 4 train loss: 0.08184814453125  train f1: 1.00000  lr: 0.0003896035077314276 batch: 25 
epochs: 4 val loss: 3.966796875  val f1:0.14286  lr: 0.0003896035077314276 batch: 25
epochs: 0 train loss: 4.734375  train f1: 0.00000  lr: 0.00047026668058706164 batch: 27 
epochs: 0 val loss: 4.83984375  val f1:0.00000  lr: 0.00047026668058706164 batch: 27
epochs: 1 train loss: 4.68359375  train f1: 0.00000  lr: 0.00047026668058706164 batch: 27 
epochs: 1 val loss: 4.6640625  val f1:0.14286  lr: 0.00047026668058706164 batch: 27
epochs: 2 train loss: 0.2498779296875  train f1: 1.00000  lr: 0.00047026668058706164 batch: 27 
epochs: 2 val loss: 4.20703125  val f1:0.12500  lr: 0.00047026668058706164 batch: 27
epochs: 3 train loss: 1.048828125  train f1: 0.50000  lr: 0.00047026668058706164 batch: 27 
epochs: 3 val loss: 6.2734375  val f1:0.14286  lr: 0.00047026668058706164 batch: 27
epochs: 4 train loss: 0.0031185150146484375  train f1: 1.00000  lr: 0.00047026668058706164 batch: 27 
epochs: 4 val loss: 5.8359375  val f1:0.14286  lr: 0.00047026668058706164 batch: 27
epochs: 0 train loss: 4.484375  train f1: 0.00000  lr: 0.0004334133769481548 batch: 28 
epochs: 0 val loss: 4.5546875  val f1:0.09524  lr: 0.0004334133769481548 batch: 28
epochs: 1 train loss: 4.34375  train f1: 0.00000  lr: 0.0004334133769481548 batch: 28 
epochs: 1 val loss: 4.8203125  val f1:0.16667  lr: 0.0004334133769481548 batch: 28
epochs: 2 train loss: 0.7919921875  train f1: 1.00000  lr: 0.0004334133769481548 batch: 28 
epochs: 2 val loss: 13.296875  val f1:0.00000  lr: 0.0004334133769481548 batch: 28
epochs: 3 train loss: 1.4462890625  train f1: 1.00000  lr: 0.0004334133769481548 batch: 28 
epochs: 3 val loss: 4.5625  val f1:0.16667  lr: 0.0004334133769481548 batch: 28
epochs: 4 train loss: 0.21875  train f1: 1.00000  lr: 0.0004334133769481548 batch: 28 
epochs: 4 val loss: 11.46875  val f1:0.16667  lr: 0.0004334133769481548 batch: 28
epochs: 5 train loss: 0.00754547119140625  train f1: 1.00000  lr: 0.0004334133769481548 batch: 28 
epochs: 5 val loss: 10.3125  val f1:0.16667  lr: 0.0004334133769481548 batch: 28
epochs: 6 train loss: 0.0002225637435913086  train f1: 1.00000  lr: 0.0004334133769481548 batch: 28 
epochs: 6 val loss: 9.109375  val f1:0.16667  lr: 0.0004334133769481548 batch: 28
epochs: 7 train loss: 0.00021457672119140625  train f1: 1.00000  lr: 0.0004334133769481548 batch: 28 
epochs: 7 val loss: 8.1640625  val f1:0.16667  lr: 0.0004334133769481548 batch: 28
epochs: 0 train loss: 4.8671875  train f1: 0.00000  lr: 0.000929566936404147 batch: 30 
epochs: 0 val loss: 5.60546875  val f1:0.00000  lr: 0.000929566936404147 batch: 30
epochs: 1 train loss: 4.7421875  train f1: 0.00000  lr: 0.000929566936404147 batch: 30 
epochs: 1 val loss: 3.775390625  val f1:0.14286  lr: 0.000929566936404147 batch: 30
epochs: 2 train loss: 0.280029296875  train f1: 1.00000  lr: 0.000929566936404147 batch: 30 
epochs: 2 val loss: 8.3125  val f1:0.06667  lr: 0.000929566936404147 batch: 30
epochs: 3 train loss: 2.728515625  train f1: 0.20000  lr: 0.000929566936404147 batch: 30 
epochs: 3 val loss: 48.0625  val f1:0.00000  lr: 0.000929566936404147 batch: 30
epochs: 4 train loss: 0.042022705078125  train f1: 1.00000  lr: 0.000929566936404147 batch: 30 
epochs: 4 val loss: 65.375  val f1:0.00000  lr: 0.000929566936404147 batch: 30
epochs: 5 train loss: 0.26025390625  train f1: 1.00000  lr: 0.000929566936404147 batch: 30 
epochs: 5 val loss: 65.125  val f1:0.00000  lr: 0.000929566936404147 batch: 30
epochs: 6 train loss: 0.01499176025390625  train f1: 1.00000  lr: 0.000929566936404147 batch: 30 
epochs: 6 val loss: 63.09375  val f1:0.00000  lr: 0.000929566936404147 batch: 30
epochs: 0 train loss: 4.8515625  train f1: 0.00000  lr: 0.00025162164326599385 batch: 28 
epochs: 0 val loss: 5.09375  val f1:0.00000  lr: 0.00025162164326599385 batch: 28
epochs: 1 train loss: 4.875  train f1: 0.00000  lr: 0.00025162164326599385 batch: 28 
epochs: 1 val loss: 4.18359375  val f1:0.12500  lr: 0.00025162164326599385 batch: 28
epochs: 0 train loss: 4.98046875  train f1: 0.00000  lr: 6.790641155225252e-05 batch: 27 
epochs: 0 val loss: 4.6796875  val f1:0.00000  lr: 6.790641155225252e-05 batch: 27
epochs: 1 train loss: 4.98046875  train f1: 0.00000  lr: 6.790641155225252e-05 batch: 27 
epochs: 1 val loss: 4.546875  val f1:0.00000  lr: 6.790641155225252e-05 batch: 27
epochs: 0 train loss: 4.2578125  train f1: 0.00000  lr: 0.002085984336916877 batch: 18 
epochs: 0 val loss: 4.76171875  val f1:0.00000  lr: 0.002085984336916877 batch: 18
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.002085984336916877 batch: 18 
epochs: 1 val loss: 199.0  val f1:0.08333  lr: 0.002085984336916877 batch: 18
epochs: 0 train loss: 4.640625  train f1: 0.16667  lr: 0.0006000839050217516 batch: 23 
epochs: 0 val loss: 5.25  val f1:0.00000  lr: 0.0006000839050217516 batch: 23
epochs: 1 train loss: 4.86328125  train f1: 0.00000  lr: 0.0006000839050217516 batch: 23 
epochs: 1 val loss: 4.8515625  val f1:0.00000  lr: 0.0006000839050217516 batch: 23
epochs: 0 train loss: 4.8671875  train f1: 0.00000  lr: 0.004200533751257036 batch: 21 
epochs: 0 val loss: 4.46875  val f1:0.00000  lr: 0.004200533751257036 batch: 21
epochs: 1 train loss: 4.7109375  train f1: 0.00000  lr: 0.004200533751257036 batch: 21 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.004200533751257036 batch: 21
epochs: 0 train loss: 4.9609375  train f1: 0.00000  lr: 0.0001858733203560168 batch: 19 
epochs: 0 val loss: 4.9140625  val f1:0.00000  lr: 0.0001858733203560168 batch: 19
epochs: 1 train loss: 4.94140625  train f1: 0.00000  lr: 0.0001858733203560168 batch: 19 
epochs: 1 val loss: 4.90625  val f1:0.00000  lr: 0.0001858733203560168 batch: 19
epochs: 0 train loss: 4.171875  train f1: 0.00000  lr: 7.56911076432142e-05 batch: 24 
epochs: 0 val loss: 5.046875  val f1:0.00000  lr: 7.56911076432142e-05 batch: 24
epochs: 1 train loss: 4.08203125  train f1: 0.00000  lr: 7.56911076432142e-05 batch: 24 
epochs: 1 val loss: 4.69140625  val f1:0.12500  lr: 7.56911076432142e-05 batch: 24
epochs: 0 train loss: 4.9765625  train f1: 0.00000  lr: 0.0002162499781210514 batch: 26 
epochs: 0 val loss: 4.62890625  val f1:0.00000  lr: 0.0002162499781210514 batch: 26
epochs: 1 train loss: 4.98828125  train f1: 0.00000  lr: 0.0002162499781210514 batch: 26 
epochs: 1 val loss: 3.662109375  val f1:0.11111  lr: 0.0002162499781210514 batch: 26
epochs: 0 train loss: 4.3984375  train f1: 0.00000  lr: 0.00143288870617614 batch: 29 
epochs: 0 val loss: 4.85546875  val f1:0.11111  lr: 0.00143288870617614 batch: 29
epochs: 1 train loss: 4.38671875  train f1: 0.00000  lr: 0.00143288870617614 batch: 29 
epochs: 1 val loss: 14.5390625  val f1:0.06667  lr: 0.00143288870617614 batch: 29
epochs: 0 train loss: 4.47265625  train f1: 0.00000  lr: 0.0007648017726287348 batch: 32 
epochs: 0 val loss: 4.53515625  val f1:0.00000  lr: 0.0007648017726287348 batch: 32
epochs: 1 train loss: 4.48828125  train f1: 0.00000  lr: 0.0007648017726287348 batch: 32 
epochs: 1 val loss: 5.75390625  val f1:0.16667  lr: 0.0007648017726287348 batch: 32
epochs: 2 train loss: 0.399658203125  train f1: 1.00000  lr: 0.0007648017726287348 batch: 32 
epochs: 2 val loss: 11.5078125  val f1:0.14286  lr: 0.0007648017726287348 batch: 32
epochs: 3 train loss: 1.083984375  train f1: 0.50000  lr: 0.0007648017726287348 batch: 32 
epochs: 3 val loss: 13.53125  val f1:0.00000  lr: 0.0007648017726287348 batch: 32
epochs: 4 train loss: 0.70751953125  train f1: 1.00000  lr: 0.0007648017726287348 batch: 32 
epochs: 4 val loss: 6.91796875  val f1:0.16667  lr: 0.0007648017726287348 batch: 32
epochs: 5 train loss: 0.0060882568359375  train f1: 1.00000  lr: 0.0007648017726287348 batch: 32 
epochs: 5 val loss: 7.734375  val f1:0.16667  lr: 0.0007648017726287348 batch: 32
epochs: 6 train loss: 5.447864532470703e-05  train f1: 1.00000  lr: 0.0007648017726287348 batch: 32 
epochs: 6 val loss: 6.953125  val f1:0.16667  lr: 0.0007648017726287348 batch: 32
epochs: 7 train loss: 9.930133819580078e-05  train f1: 1.00000  lr: 0.0007648017726287348 batch: 32 
epochs: 7 val loss: 6.42578125  val f1:0.16667  lr: 0.0007648017726287348 batch: 32
epochs: 8 train loss: 8.445978164672852e-05  train f1: 1.00000  lr: 0.0007648017726287348 batch: 32 
epochs: 8 val loss: 5.90625  val f1:0.16667  lr: 0.0007648017726287348 batch: 32
epochs: 0 train loss: 4.95703125  train f1: 0.00000  lr: 0.000915047624419589 batch: 32 
epochs: 0 val loss: 5.3359375  val f1:0.00000  lr: 0.000915047624419589 batch: 32
epochs: 1 train loss: 5.00390625  train f1: 0.00000  lr: 0.000915047624419589 batch: 32 
epochs: 1 val loss: 4.96484375  val f1:0.00000  lr: 0.000915047624419589 batch: 32
epochs: 0 train loss: 4.546875  train f1: 0.00000  lr: 0.0006804349994759452 batch: 31 
epochs: 0 val loss: 5.08984375  val f1:0.00000  lr: 0.0006804349994759452 batch: 31
epochs: 1 train loss: 4.40625  train f1: 0.00000  lr: 0.0006804349994759452 batch: 31 
epochs: 1 val loss: 7.2109375  val f1:0.00000  lr: 0.0006804349994759452 batch: 31
epochs: 0 train loss: 4.91015625  train f1: 0.00000  lr: 0.00031921124887645245 batch: 30 
epochs: 0 val loss: 4.6328125  val f1:0.00000  lr: 0.00031921124887645245 batch: 30
epochs: 1 train loss: 4.76171875  train f1: 0.00000  lr: 0.00031921124887645245 batch: 30 
epochs: 1 val loss: 4.453125  val f1:0.00000  lr: 0.00031921124887645245 batch: 30
epochs: 0 train loss: 5.23828125  train f1: 0.00000  lr: 0.00010810494169974072 batch: 32 
epochs: 0 val loss: 5.5234375  val f1:0.00000  lr: 0.00010810494169974072 batch: 32
epochs: 1 train loss: 5.07421875  train f1: 0.00000  lr: 0.00010810494169974072 batch: 32 
epochs: 1 val loss: 4.96484375  val f1:0.00000  lr: 0.00010810494169974072 batch: 32
epochs: 0 train loss: 5.171875  train f1: 0.00000  lr: 0.001292773022211469 batch: 25 
epochs: 0 val loss: 5.546875  val f1:0.00000  lr: 0.001292773022211469 batch: 25
epochs: 1 train loss: 5.203125  train f1: 0.00000  lr: 0.001292773022211469 batch: 25 
epochs: 1 val loss: 5.515625  val f1:0.00000  lr: 0.001292773022211469 batch: 25
epochs: 0 train loss: 4.26953125  train f1: 0.00000  lr: 0.00268158054398485 batch: 28 
epochs: 0 val loss: 5.00390625  val f1:0.00000  lr: 0.00268158054398485 batch: 28
epochs: 1 train loss: 4.22265625  train f1: 0.00000  lr: 0.00268158054398485 batch: 28 
epochs: 1 val loss: 14328.0  val f1:0.06667  lr: 0.00268158054398485 batch: 28
epochs: 0 train loss: 4.109375  train f1: 0.00000  lr: 0.019279502246587598 batch: 20 
epochs: 0 val loss: 5.18359375  val f1:0.00000  lr: 0.019279502246587598 batch: 20
epochs: 1 train loss: 4.2109375  train f1: 0.00000  lr: 0.019279502246587598 batch: 20 
epochs: 1 val loss: 198.75  val f1:0.06667  lr: 0.019279502246587598 batch: 20
epochs: 0 train loss: 4.29296875  train f1: 0.00000  lr: 0.00014895610186718366 batch: 25 
epochs: 0 val loss: 5.20703125  val f1:0.00000  lr: 0.00014895610186718366 batch: 25
epochs: 1 train loss: 4.2578125  train f1: 0.00000  lr: 0.00014895610186718366 batch: 25 
epochs: 1 val loss: 4.01953125  val f1:0.11111  lr: 0.00014895610186718366 batch: 25
epochs: 0 train loss: 5.0078125  train f1: 0.00000  lr: 0.06962193247528317 batch: 22 
epochs: 0 val loss: 4.6484375  val f1:0.00000  lr: 0.06962193247528317 batch: 22
epochs: 1 train loss: 4.85546875  train f1: 0.00000  lr: 0.06962193247528317 batch: 22 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.06962193247528317 batch: 22
epochs: 0 train loss: 4.47265625  train f1: 0.00000  lr: 1.9044625311754758e-05 batch: 27 
epochs: 0 val loss: 4.96484375  val f1:0.07143  lr: 1.9044625311754758e-05 batch: 27
epochs: 1 train loss: 4.51953125  train f1: 0.00000  lr: 1.9044625311754758e-05 batch: 27 
epochs: 1 val loss: 4.8125  val f1:0.07143  lr: 1.9044625311754758e-05 batch: 27
epochs: 0 train loss: 4.859375  train f1: 0.00000  lr: 4.2377565500663655e-05 batch: 30 
epochs: 0 val loss: 4.76953125  val f1:0.00000  lr: 4.2377565500663655e-05 batch: 30
epochs: 1 train loss: 4.79296875  train f1: 0.00000  lr: 4.2377565500663655e-05 batch: 30 
epochs: 1 val loss: 4.546875  val f1:0.00000  lr: 4.2377565500663655e-05 batch: 30
epochs: 0 train loss: 4.84765625  train f1: 0.00000  lr: 0.000631390323095841 batch: 27 
epochs: 0 val loss: 4.703125  val f1:0.00000  lr: 0.000631390323095841 batch: 27
epochs: 1 train loss: 4.83203125  train f1: 0.00000  lr: 0.000631390323095841 batch: 27 
epochs: 1 val loss: 4.7734375  val f1:0.12500  lr: 0.000631390323095841 batch: 27
epochs: 0 train loss: 5.0546875  train f1: 0.00000  lr: 0.011180055710251692 batch: 29 
epochs: 0 val loss: 5.30859375  val f1:0.00000  lr: 0.011180055710251692 batch: 29
epochs: 1 train loss: 5.08984375  train f1: 0.00000  lr: 0.011180055710251692 batch: 29 
epochs: 1 val loss: 6.2890625  val f1:0.11111  lr: 0.011180055710251692 batch: 29
epochs: 0 train loss: 4.828125  train f1: 0.00000  lr: 0.0018826267563724407 batch: 31 
epochs: 0 val loss: 4.53515625  val f1:0.00000  lr: 0.0018826267563724407 batch: 31
epochs: 1 train loss: 4.74609375  train f1: 0.00000  lr: 0.0018826267563724407 batch: 31 
epochs: 1 val loss: 80.9375  val f1:0.00000  lr: 0.0018826267563724407 batch: 31
epochs: 0 train loss: 4.25390625  train f1: 0.00000  lr: 0.00029594982641627395 batch: 23 
epochs: 0 val loss: 5.08203125  val f1:0.00000  lr: 0.00029594982641627395 batch: 23
epochs: 1 train loss: 4.4609375  train f1: 0.00000  lr: 0.00029594982641627395 batch: 23 
epochs: 1 val loss: 3.998046875  val f1:0.11111  lr: 0.00029594982641627395 batch: 23
epochs: 0 train loss: 4.40234375  train f1: 0.00000  lr: 0.0005377619740202911 batch: 24 
epochs: 0 val loss: 5.18359375  val f1:0.00000  lr: 0.0005377619740202911 batch: 24
epochs: 1 train loss: 4.34765625  train f1: 0.00000  lr: 0.0005377619740202911 batch: 24 
epochs: 1 val loss: 5.1328125  val f1:0.00000  lr: 0.0005377619740202911 batch: 24
epochs: 0 train loss: 4.44921875  train f1: 0.00000  lr: 1.882171269292773e-05 batch: 14 
epochs: 0 val loss: 4.5078125  val f1:0.00000  lr: 1.882171269292773e-05 batch: 14
epochs: 1 train loss: 4.3359375  train f1: 0.00000  lr: 1.882171269292773e-05 batch: 14 
epochs: 1 val loss: 4.390625  val f1:0.00000  lr: 1.882171269292773e-05 batch: 14
epochs: 0 train loss: 4.640625  train f1: 0.00000  lr: 0.0003565559074261889 batch: 25 
epochs: 0 val loss: 5.0546875  val f1:0.00000  lr: 0.0003565559074261889 batch: 25
epochs: 1 train loss: 4.671875  train f1: 0.00000  lr: 0.0003565559074261889 batch: 25 
epochs: 1 val loss: 4.21875  val f1:0.14286  lr: 0.0003565559074261889 batch: 25
epochs: 2 train loss: 0.72021484375  train f1: 1.00000  lr: 0.0003565559074261889 batch: 25 
epochs: 2 val loss: 5.44140625  val f1:0.00000  lr: 0.0003565559074261889 batch: 25
epochs: 3 train loss: 0.654296875  train f1: 1.00000  lr: 0.0003565559074261889 batch: 25 
epochs: 3 val loss: 3.94140625  val f1:0.12500  lr: 0.0003565559074261889 batch: 25
epochs: 4 train loss: 0.002674102783203125  train f1: 1.00000  lr: 0.0003565559074261889 batch: 25 
epochs: 4 val loss: 3.90625  val f1:0.12500  lr: 0.0003565559074261889 batch: 25
epochs: 0 train loss: 4.8125  train f1: 0.00000  lr: 0.0011538320704632574 batch: 26 
epochs: 0 val loss: 4.9921875  val f1:0.00000  lr: 0.0011538320704632574 batch: 26
epochs: 1 train loss: 4.60546875  train f1: 0.00000  lr: 0.0011538320704632574 batch: 26 
epochs: 1 val loss: 5.3046875  val f1:0.00000  lr: 0.0011538320704632574 batch: 26
epochs: 0 train loss: 5.2890625  train f1: 0.00000  lr: 0.0004124202471183139 batch: 26 
epochs: 0 val loss: 4.94921875  val f1:0.00000  lr: 0.0004124202471183139 batch: 26
epochs: 1 train loss: 5.3203125  train f1: 0.00000  lr: 0.0004124202471183139 batch: 26 
epochs: 1 val loss: 4.640625  val f1:0.14286  lr: 0.0004124202471183139 batch: 26
epochs: 2 train loss: 0.68212890625  train f1: 1.00000  lr: 0.0004124202471183139 batch: 26 
epochs: 2 val loss: 3.55859375  val f1:0.08333  lr: 0.0004124202471183139 batch: 26
epochs: 3 train loss: 0.90771484375  train f1: 1.00000  lr: 0.0004124202471183139 batch: 26 
epochs: 3 val loss: 3.654296875  val f1:0.12500  lr: 0.0004124202471183139 batch: 26
epochs: 4 train loss: 0.00015091896057128906  train f1: 1.00000  lr: 0.0004124202471183139 batch: 26 
epochs: 4 val loss: 3.810546875  val f1:0.12500  lr: 0.0004124202471183139 batch: 26
epochs: 5 train loss: 0.0001323223114013672  train f1: 1.00000  lr: 0.0004124202471183139 batch: 26 
epochs: 5 val loss: 3.947265625  val f1:0.11111  lr: 0.0004124202471183139 batch: 26
epochs: 6 train loss: 0.00012743473052978516  train f1: 1.00000  lr: 0.0004124202471183139 batch: 26 
epochs: 6 val loss: 3.953125  val f1:0.11111  lr: 0.0004124202471183139 batch: 26
epochs: 7 train loss: 0.00017690658569335938  train f1: 1.00000  lr: 0.0004124202471183139 batch: 26 
epochs: 7 val loss: 3.91015625  val f1:0.11111  lr: 0.0004124202471183139 batch: 26
epochs: 0 train loss: 4.609375  train f1: 0.00000  lr: 0.0007233375271532114 batch: 22 
epochs: 0 val loss: 5.3046875  val f1:0.00000  lr: 0.0007233375271532114 batch: 22
epochs: 1 train loss: 4.625  train f1: 0.00000  lr: 0.0007233375271532114 batch: 22 
epochs: 1 val loss: 5.25  val f1:0.00000  lr: 0.0007233375271532114 batch: 22
epochs: 0 train loss: 4.49609375  train f1: 0.00000  lr: 0.00015616010025010964 batch: 28 
epochs: 0 val loss: 5.5234375  val f1:0.00000  lr: 0.00015616010025010964 batch: 28
epochs: 1 train loss: 4.4921875  train f1: 0.00000  lr: 0.00015616010025010964 batch: 28 
epochs: 1 val loss: 4.3359375  val f1:0.00000  lr: 0.00015616010025010964 batch: 28
epochs: 0 train loss: 4.48828125  train f1: 0.00000  lr: 0.00010181569194547894 batch: 27 
epochs: 0 val loss: 4.6640625  val f1:0.00000  lr: 0.00010181569194547894 batch: 27
epochs: 1 train loss: 4.49609375  train f1: 0.00000  lr: 0.00010181569194547894 batch: 27 
epochs: 1 val loss: 4.15625  val f1:0.12500  lr: 0.00010181569194547894 batch: 27
epochs: 0 train loss: 4.4453125  train f1: 0.00000  lr: 0.00045303149778960273 batch: 29 
epochs: 0 val loss: 5.28125  val f1:0.00000  lr: 0.00045303149778960273 batch: 29
epochs: 1 train loss: 4.3828125  train f1: 0.00000  lr: 0.00045303149778960273 batch: 29 
epochs: 1 val loss: 4.2890625  val f1:0.12500  lr: 0.00045303149778960273 batch: 29
epochs: 0 train loss: 4.64453125  train f1: 0.00000  lr: 0.0008774514140877114 batch: 25 
epochs: 0 val loss: 5.26171875  val f1:0.00000  lr: 0.0008774514140877114 batch: 25
epochs: 1 train loss: 4.56640625  train f1: 0.00000  lr: 0.0008774514140877114 batch: 25 
epochs: 1 val loss: 9.2890625  val f1:0.11111  lr: 0.0008774514140877114 batch: 25
epochs: 0 train loss: 5.1484375  train f1: 0.00000  lr: 0.00022416564871920066 batch: 24 
epochs: 0 val loss: 4.39453125  val f1:0.00000  lr: 0.00022416564871920066 batch: 24
epochs: 1 train loss: 5.046875  train f1: 0.00000  lr: 0.00022416564871920066 batch: 24 
epochs: 1 val loss: 4.40625  val f1:0.00000  lr: 0.00022416564871920066 batch: 24
epochs: 0 train loss: 4.328125  train f1: 0.00000  lr: 0.004656714138901761 batch: 19 
epochs: 0 val loss: 4.765625  val f1:0.07143  lr: 0.004656714138901761 batch: 19
epochs: 1 train loss: 4.40625  train f1: 0.00000  lr: 0.004656714138901761 batch: 19 
epochs: 1 val loss: 3.65234375  val f1:0.25000  lr: 0.004656714138901761 batch: 19
epochs: 2 train loss: 0.06256103515625  train f1: 1.00000  lr: 0.004656714138901761 batch: 19 
epochs: 2 val loss: 4.90625  val f1:0.14286  lr: 0.004656714138901761 batch: 19
epochs: 3 train loss: 0.5009765625  train f1: 1.00000  lr: 0.004656714138901761 batch: 19 
epochs: 3 val loss: 12.296875  val f1:0.00000  lr: 0.004656714138901761 batch: 19
epochs: 4 train loss: 0.0009765625  train f1: 1.00000  lr: 0.004656714138901761 batch: 19 
epochs: 4 val loss: 19.6875  val f1:0.00000  lr: 0.004656714138901761 batch: 19
epochs: 5 train loss: 0.013153076171875  train f1: 1.00000  lr: 0.004656714138901761 batch: 19 
epochs: 5 val loss: 19.328125  val f1:0.00000  lr: 0.004656714138901761 batch: 19
epochs: 6 train loss: 0.00011098384857177734  train f1: 1.00000  lr: 0.004656714138901761 batch: 19 
epochs: 6 val loss: 14.296875  val f1:0.00000  lr: 0.004656714138901761 batch: 19
epochs: 0 train loss: 4.33984375  train f1: 0.00000  lr: 0.0004908713358547037 batch: 26 
epochs: 0 val loss: 5.4609375  val f1:0.00000  lr: 0.0004908713358547037 batch: 26
epochs: 1 train loss: 4.40234375  train f1: 0.00000  lr: 0.0004908713358547037 batch: 26 
epochs: 1 val loss: 4.125  val f1:0.14286  lr: 0.0004908713358547037 batch: 26
epochs: 2 train loss: 0.26416015625  train f1: 1.00000  lr: 0.0004908713358547037 batch: 26 
epochs: 2 val loss: 5.921875  val f1:0.00000  lr: 0.0004908713358547037 batch: 26
epochs: 3 train loss: 0.76904296875  train f1: 1.00000  lr: 0.0004908713358547037 batch: 26 
epochs: 3 val loss: 18.234375  val f1:0.00000  lr: 0.0004908713358547037 batch: 26
epochs: 4 train loss: 0.011260986328125  train f1: 1.00000  lr: 0.0004908713358547037 batch: 26 
epochs: 4 val loss: 13.9140625  val f1:0.00000  lr: 0.0004908713358547037 batch: 26
epochs: 5 train loss: 3.933906555175781e-06  train f1: 1.00000  lr: 0.0004908713358547037 batch: 26 
epochs: 5 val loss: 10.21875  val f1:0.16667  lr: 0.0004908713358547037 batch: 26
epochs: 6 train loss: 9.894371032714844e-06  train f1: 1.00000  lr: 0.0004908713358547037 batch: 26 
epochs: 6 val loss: 8.2578125  val f1:0.16667  lr: 0.0004908713358547037 batch: 26
epochs: 7 train loss: 4.172325134277344e-06  train f1: 1.00000  lr: 0.0004908713358547037 batch: 26 
epochs: 7 val loss: 7.09765625  val f1:0.16667  lr: 0.0004908713358547037 batch: 26
epochs: 0 train loss: 5.046875  train f1: 0.00000  lr: 0.0020319647691828735 batch: 21 
epochs: 0 val loss: 4.81640625  val f1:0.00000  lr: 0.0020319647691828735 batch: 21
epochs: 1 train loss: 4.7890625  train f1: 0.00000  lr: 0.0020319647691828735 batch: 21 
epochs: 1 val loss: 167.75  val f1:0.06667  lr: 0.0020319647691828735 batch: 21
epochs: 0 train loss: 4.6796875  train f1: 0.00000  lr: 0.00026824540033023014 batch: 23 
epochs: 0 val loss: 5.3359375  val f1:0.00000  lr: 0.00026824540033023014 batch: 23
epochs: 1 train loss: 4.734375  train f1: 0.00000  lr: 0.00026824540033023014 batch: 23 
epochs: 1 val loss: 4.2265625  val f1:0.14286  lr: 0.00026824540033023014 batch: 23
epochs: 2 train loss: 0.368408203125  train f1: 1.00000  lr: 0.00026824540033023014 batch: 23 
epochs: 2 val loss: 4.96484375  val f1:0.12500  lr: 0.00026824540033023014 batch: 23
epochs: 3 train loss: 0.345458984375  train f1: 1.00000  lr: 0.00026824540033023014 batch: 23 
epochs: 3 val loss: 4.5703125  val f1:0.14286  lr: 0.00026824540033023014 batch: 23
epochs: 4 train loss: 0.0144805908203125  train f1: 1.00000  lr: 0.00026824540033023014 batch: 23 
epochs: 4 val loss: 4.9609375  val f1:0.14286  lr: 0.00026824540033023014 batch: 23
epochs: 0 train loss: 4.2421875  train f1: 0.00000  lr: 0.0002674996801944697 batch: 23 
epochs: 0 val loss: 4.56640625  val f1:0.00000  lr: 0.0002674996801944697 batch: 23
epochs: 1 train loss: 4.27734375  train f1: 0.00000  lr: 0.0002674996801944697 batch: 23 
epochs: 1 val loss: 3.51953125  val f1:0.12500  lr: 0.0002674996801944697 batch: 23
epochs: 0 train loss: 4.5  train f1: 0.00000  lr: 0.0005409935453856141 batch: 21 
epochs: 0 val loss: 4.97265625  val f1:0.00000  lr: 0.0005409935453856141 batch: 21
epochs: 1 train loss: 4.546875  train f1: 0.20000  lr: 0.0005409935453856141 batch: 21 
epochs: 1 val loss: 4.37109375  val f1:0.14286  lr: 0.0005409935453856141 batch: 21
epochs: 2 train loss: 0.26171875  train f1: 1.00000  lr: 0.0005409935453856141 batch: 21 
epochs: 2 val loss: 8.546875  val f1:0.14286  lr: 0.0005409935453856141 batch: 21
epochs: 3 train loss: 0.9755859375  train f1: 0.50000  lr: 0.0005409935453856141 batch: 21 
epochs: 3 val loss: 13.3515625  val f1:0.00000  lr: 0.0005409935453856141 batch: 21
epochs: 4 train loss: 0.036224365234375  train f1: 1.00000  lr: 0.0005409935453856141 batch: 21 
epochs: 4 val loss: 11.2890625  val f1:0.16667  lr: 0.0005409935453856141 batch: 21
epochs: 5 train loss: 0.00010794401168823242  train f1: 1.00000  lr: 0.0005409935453856141 batch: 21 
epochs: 5 val loss: 13.0703125  val f1:0.16667  lr: 0.0005409935453856141 batch: 21
epochs: 6 train loss: 0.0008883476257324219  train f1: 1.00000  lr: 0.0005409935453856141 batch: 21 
epochs: 6 val loss: 14.171875  val f1:0.16667  lr: 0.0005409935453856141 batch: 21
epochs: 7 train loss: 7.963180541992188e-05  train f1: 1.00000  lr: 0.0005409935453856141 batch: 21 
epochs: 7 val loss: 15.0078125  val f1:0.16667  lr: 0.0005409935453856141 batch: 21
epochs: 0 train loss: 4.515625  train f1: 0.00000  lr: 0.000791871935445385 batch: 20 
epochs: 0 val loss: 4.9296875  val f1:0.00000  lr: 0.000791871935445385 batch: 20
epochs: 1 train loss: 4.59375  train f1: 0.00000  lr: 0.000791871935445385 batch: 20 
epochs: 1 val loss: 4.34765625  val f1:0.00000  lr: 0.000791871935445385 batch: 20
epochs: 0 train loss: 4.30078125  train f1: 0.11111  lr: 6.528804653407522e-05 batch: 17 
epochs: 0 val loss: 3.955078125  val f1:0.00000  lr: 6.528804653407522e-05 batch: 17
epochs: 1 train loss: 4.203125  train f1: 0.00000  lr: 6.528804653407522e-05 batch: 17 
epochs: 1 val loss: 3.703125  val f1:0.00000  lr: 6.528804653407522e-05 batch: 17
epochs: 0 train loss: 5.03515625  train f1: 0.00000  lr: 0.0011333012940981122 batch: 22 
epochs: 0 val loss: 5.4609375  val f1:0.00000  lr: 0.0011333012940981122 batch: 22
epochs: 1 train loss: 4.96484375  train f1: 0.00000  lr: 0.0011333012940981122 batch: 22 
epochs: 1 val loss: 4.59375  val f1:0.14286  lr: 0.0011333012940981122 batch: 22
epochs: 2 train loss: 0.354248046875  train f1: 1.00000  lr: 0.0011333012940981122 batch: 22 
epochs: 2 val loss: 45.8125  val f1:0.11111  lr: 0.0011333012940981122 batch: 22
epochs: 3 train loss: 1.564453125  train f1: 0.50000  lr: 0.0011333012940981122 batch: 22 
epochs: 3 val loss: 109.1875  val f1:0.16667  lr: 0.0011333012940981122 batch: 22
epochs: 4 train loss: 0.054443359375  train f1: 1.00000  lr: 0.0011333012940981122 batch: 22 
epochs: 4 val loss: 59.75  val f1:0.16667  lr: 0.0011333012940981122 batch: 22
epochs: 5 train loss: 3.3855438232421875e-05  train f1: 1.00000  lr: 0.0011333012940981122 batch: 22 
epochs: 5 val loss: 47.1875  val f1:0.16667  lr: 0.0011333012940981122 batch: 22
epochs: 6 train loss: 5.08427619934082e-05  train f1: 1.00000  lr: 0.0011333012940981122 batch: 22 
epochs: 6 val loss: 36.46875  val f1:0.16667  lr: 0.0011333012940981122 batch: 22
epochs: 7 train loss: 0.0008645057678222656  train f1: 1.00000  lr: 0.0011333012940981122 batch: 22 
epochs: 7 val loss: 28.78125  val f1:0.16667  lr: 0.0011333012940981122 batch: 22
epochs: 8 train loss: 6.157159805297852e-05  train f1: 1.00000  lr: 0.0011333012940981122 batch: 22 
epochs: 8 val loss: 24.140625  val f1:0.16667  lr: 0.0011333012940981122 batch: 22
epochs: 9 train loss: 3.832578659057617e-05  train f1: 1.00000  lr: 0.0011333012940981122 batch: 22 
epochs: 9 val loss: 20.65625  val f1:0.16667  lr: 0.0011333012940981122 batch: 22
epochs: 0 train loss: 4.984375  train f1: 0.00000  lr: 0.0011250170465281293 batch: 22 
epochs: 0 val loss: 4.65625  val f1:0.00000  lr: 0.0011250170465281293 batch: 22
epochs: 1 train loss: 5.12890625  train f1: 0.00000  lr: 0.0011250170465281293 batch: 22 
epochs: 1 val loss: 8.3984375  val f1:0.06667  lr: 0.0011250170465281293 batch: 22
epochs: 0 train loss: 4.2734375  train f1: 0.00000  lr: 0.0004958420629717988 batch: 21 
epochs: 0 val loss: 4.74609375  val f1:0.00000  lr: 0.0004958420629717988 batch: 21
epochs: 1 train loss: 4.1171875  train f1: 0.00000  lr: 0.0004958420629717988 batch: 21 
epochs: 1 val loss: 4.75390625  val f1:0.14286  lr: 0.0004958420629717988 batch: 21
epochs: 2 train loss: 0.2003173828125  train f1: 1.00000  lr: 0.0004958420629717988 batch: 21 
epochs: 2 val loss: 3.8046875  val f1:0.12500  lr: 0.0004958420629717988 batch: 21
epochs: 3 train loss: 1.28125  train f1: 0.50000  lr: 0.0004958420629717988 batch: 21 
epochs: 3 val loss: 14.515625  val f1:0.14286  lr: 0.0004958420629717988 batch: 21
epochs: 4 train loss: 0.0005631446838378906  train f1: 1.00000  lr: 0.0004958420629717988 batch: 21 
epochs: 4 val loss: 11.3125  val f1:0.14286  lr: 0.0004958420629717988 batch: 21
epochs: 5 train loss: 0.00044608116149902344  train f1: 1.00000  lr: 0.0004958420629717988 batch: 21 
epochs: 5 val loss: 9.28125  val f1:0.14286  lr: 0.0004958420629717988 batch: 21
epochs: 6 train loss: 0.0002281665802001953  train f1: 1.00000  lr: 0.0004958420629717988 batch: 21 
epochs: 6 val loss: 8.15625  val f1:0.14286  lr: 0.0004958420629717988 batch: 21
epochs: 7 train loss: 0.0005397796630859375  train f1: 1.00000  lr: 0.0004958420629717988 batch: 21 
epochs: 7 val loss: 7.41796875  val f1:0.14286  lr: 0.0004958420629717988 batch: 21
epochs: 8 train loss: 0.00020313262939453125  train f1: 1.00000  lr: 0.0004958420629717988 batch: 21 
epochs: 8 val loss: 6.94140625  val f1:0.14286  lr: 0.0004958420629717988 batch: 21
epochs: 9 train loss: 0.00018739700317382812  train f1: 1.00000  lr: 0.0004958420629717988 batch: 21 
epochs: 9 val loss: 6.5625  val f1:0.14286  lr: 0.0004958420629717988 batch: 21
epochs: 0 train loss: 4.53125  train f1: 0.00000  lr: 0.0015810722788915437 batch: 18 
epochs: 0 val loss: 4.9140625  val f1:0.00000  lr: 0.0015810722788915437 batch: 18
epochs: 1 train loss: 4.5390625  train f1: 0.00000  lr: 0.0015810722788915437 batch: 18 
epochs: 1 val loss: 5.62109375  val f1:0.11111  lr: 0.0015810722788915437 batch: 18
epochs: 0 train loss: 4.32421875  train f1: 0.00000  lr: 0.0005671908672460443 batch: 8 
epochs: 0 val loss: 4.53515625  val f1:0.00000  lr: 0.0005671908672460443 batch: 8
epochs: 1 train loss: 4.26171875  train f1: 0.00000  lr: 0.0005671908672460443 batch: 8 
epochs: 1 val loss: 5.28125  val f1:0.14286  lr: 0.0005671908672460443 batch: 8
epochs: 2 train loss: 0.0199127197265625  train f1: 1.00000  lr: 0.0005671908672460443 batch: 8 
epochs: 2 val loss: 6.69140625  val f1:0.12500  lr: 0.0005671908672460443 batch: 8
epochs: 3 train loss: 0.457763671875  train f1: 1.00000  lr: 0.0005671908672460443 batch: 8 
epochs: 3 val loss: 4.73046875  val f1:0.07143  lr: 0.0005671908672460443 batch: 8
epochs: 4 train loss: 0.447998046875  train f1: 1.00000  lr: 0.0005671908672460443 batch: 8 
epochs: 4 val loss: 11.2109375  val f1:0.11111  lr: 0.0005671908672460443 batch: 8
epochs: 5 train loss: 0.034820556640625  train f1: 1.00000  lr: 0.0005671908672460443 batch: 8 
epochs: 5 val loss: 12.875  val f1:0.16667  lr: 0.0005671908672460443 batch: 8
epochs: 6 train loss: 0.00011682510375976562  train f1: 1.00000  lr: 0.0005671908672460443 batch: 8 
epochs: 6 val loss: 11.703125  val f1:0.16667  lr: 0.0005671908672460443 batch: 8
epochs: 7 train loss: 5.3822994232177734e-05  train f1: 1.00000  lr: 0.0005671908672460443 batch: 8 
epochs: 7 val loss: 10.6328125  val f1:0.16667  lr: 0.0005671908672460443 batch: 8
epochs: 8 train loss: 8.994340896606445e-05  train f1: 1.00000  lr: 0.0005671908672460443 batch: 8 
epochs: 8 val loss: 9.625  val f1:0.16667  lr: 0.0005671908672460443 batch: 8
epochs: 0 train loss: 4.734375  train f1: 0.00000  lr: 0.0005435785771056181 batch: 8 
epochs: 0 val loss: 5.1171875  val f1:0.00000  lr: 0.0005435785771056181 batch: 8
epochs: 1 train loss: 4.66015625  train f1: 0.00000  lr: 0.0005435785771056181 batch: 8 
epochs: 1 val loss: 3.5546875  val f1:0.42857  lr: 0.0005435785771056181 batch: 8
epochs: 2 train loss: 0.295654296875  train f1: 1.00000  lr: 0.0005435785771056181 batch: 8 
epochs: 2 val loss: 16.5  val f1:0.00000  lr: 0.0005435785771056181 batch: 8
epochs: 3 train loss: 2.12890625  train f1: 0.40000  lr: 0.0005435785771056181 batch: 8 
epochs: 3 val loss: 6.0859375  val f1:0.09524  lr: 0.0005435785771056181 batch: 8
epochs: 4 train loss: 0.304931640625  train f1: 1.00000  lr: 0.0005435785771056181 batch: 8 
epochs: 4 val loss: 7.83203125  val f1:0.14286  lr: 0.0005435785771056181 batch: 8
epochs: 5 train loss: 0.0576171875  train f1: 1.00000  lr: 0.0005435785771056181 batch: 8 
epochs: 5 val loss: 7.890625  val f1:0.12500  lr: 0.0005435785771056181 batch: 8
epochs: 6 train loss: 0.005931854248046875  train f1: 1.00000  lr: 0.0005435785771056181 batch: 8 
epochs: 6 val loss: 5.91015625  val f1:0.12500  lr: 0.0005435785771056181 batch: 8
epochs: 7 train loss: 0.0005483627319335938  train f1: 1.00000  lr: 0.0005435785771056181 batch: 8 
epochs: 7 val loss: 4.9453125  val f1:0.12500  lr: 0.0005435785771056181 batch: 8
epochs: 8 train loss: 0.0009222030639648438  train f1: 1.00000  lr: 0.0005435785771056181 batch: 8 
epochs: 8 val loss: 4.26953125  val f1:0.12500  lr: 0.0005435785771056181 batch: 8
epochs: 9 train loss: 0.0007925033569335938  train f1: 1.00000  lr: 0.0005435785771056181 batch: 8 
epochs: 9 val loss: 3.96484375  val f1:0.12500  lr: 0.0005435785771056181 batch: 8
epochs: 10 train loss: 0.0005197525024414062  train f1: 1.00000  lr: 0.0005435785771056181 batch: 8 
epochs: 10 val loss: 3.78515625  val f1:0.12500  lr: 0.0005435785771056181 batch: 8
epochs: 0 train loss: 3.779296875  train f1: 0.00000  lr: 0.002789680115554902 batch: 10 
epochs: 0 val loss: 4.6640625  val f1:0.00000  lr: 0.002789680115554902 batch: 10
epochs: 1 train loss: 3.8046875  train f1: 0.00000  lr: 0.002789680115554902 batch: 10 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.002789680115554902 batch: 10
epochs: 0 train loss: 4.49609375  train f1: 0.00000  lr: 0.00018715277289653185 batch: 12 
epochs: 0 val loss: 4.6171875  val f1:0.00000  lr: 0.00018715277289653185 batch: 12
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.00018715277289653185 batch: 12 
epochs: 1 val loss: 4.2890625  val f1:0.12500  lr: 0.00018715277289653185 batch: 12
epochs: 0 train loss: 5.14453125  train f1: 0.00000  lr: 0.0009423620742961165 batch: 9 
epochs: 0 val loss: 4.73046875  val f1:0.00000  lr: 0.0009423620742961165 batch: 9
epochs: 1 train loss: 5.22265625  train f1: 0.00000  lr: 0.0009423620742961165 batch: 9 
epochs: 1 val loss: 4.734375  val f1:0.00000  lr: 0.0009423620742961165 batch: 9
epochs: 0 train loss: 4.5078125  train f1: 0.00000  lr: 0.0003426639799463719 batch: 31 
epochs: 0 val loss: 5.02734375  val f1:0.00000  lr: 0.0003426639799463719 batch: 31
epochs: 1 train loss: 4.41796875  train f1: 0.00000  lr: 0.0003426639799463719 batch: 31 
epochs: 1 val loss: 4.11328125  val f1:0.09524  lr: 0.0003426639799463719 batch: 31
epochs: 0 train loss: 4.8828125  train f1: 0.00000  lr: 0.0005876413670880754 batch: 19 
epochs: 0 val loss: 5.12109375  val f1:0.00000  lr: 0.0005876413670880754 batch: 19
epochs: 1 train loss: 4.9375  train f1: 0.00000  lr: 0.0005876413670880754 batch: 19 
epochs: 1 val loss: 3.623046875  val f1:0.12500  lr: 0.0005876413670880754 batch: 19
epochs: 0 train loss: 4.51171875  train f1: 0.00000  lr: 0.0007718181225836537 batch: 18 
epochs: 0 val loss: 5.55859375  val f1:0.11111  lr: 0.0007718181225836537 batch: 18
epochs: 1 train loss: 4.5390625  train f1: 0.00000  lr: 0.0007718181225836537 batch: 18 
epochs: 1 val loss: 5.05078125  val f1:0.25000  lr: 0.0007718181225836537 batch: 18
epochs: 2 train loss: 1.0419921875  train f1: 1.00000  lr: 0.0007718181225836537 batch: 18 
epochs: 2 val loss: 4.6796875  val f1:0.28571  lr: 0.0007718181225836537 batch: 18
epochs: 3 train loss: 0.1866455078125  train f1: 1.00000  lr: 0.0007718181225836537 batch: 18 
epochs: 3 val loss: 4.4609375  val f1:0.12500  lr: 0.0007718181225836537 batch: 18
epochs: 4 train loss: 0.029571533203125  train f1: 1.00000  lr: 0.0007718181225836537 batch: 18 
epochs: 4 val loss: 4.39453125  val f1:0.12500  lr: 0.0007718181225836537 batch: 18
epochs: 5 train loss: 0.006168365478515625  train f1: 1.00000  lr: 0.0007718181225836537 batch: 18 
epochs: 5 val loss: 4.421875  val f1:0.12500  lr: 0.0007718181225836537 batch: 18
epochs: 6 train loss: 0.0009617805480957031  train f1: 1.00000  lr: 0.0007718181225836537 batch: 18 
epochs: 6 val loss: 4.43359375  val f1:0.12500  lr: 0.0007718181225836537 batch: 18
epochs: 7 train loss: 0.00113677978515625  train f1: 1.00000  lr: 0.0007718181225836537 batch: 18 
epochs: 7 val loss: 4.46484375  val f1:0.12500  lr: 0.0007718181225836537 batch: 18
epochs: 0 train loss: 5.1328125  train f1: 0.00000  lr: 0.0027258042745421747 batch: 21 
epochs: 0 val loss: 5.546875  val f1:0.00000  lr: 0.0027258042745421747 batch: 21
epochs: 1 train loss: 5.0078125  train f1: 0.00000  lr: 0.0027258042745421747 batch: 21 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.0027258042745421747 batch: 21
epochs: 0 train loss: 5.34375  train f1: 0.00000  lr: 0.0014088562390220118 batch: 20 
epochs: 0 val loss: 4.609375  val f1:0.00000  lr: 0.0014088562390220118 batch: 20
epochs: 1 train loss: 5.30078125  train f1: 0.00000  lr: 0.0014088562390220118 batch: 20 
epochs: 1 val loss: 7.0390625  val f1:0.09524  lr: 0.0014088562390220118 batch: 20
epochs: 0 train loss: 4.6953125  train f1: 0.00000  lr: 0.0002736660464975809 batch: 23 
epochs: 0 val loss: 4.0859375  val f1:0.00000  lr: 0.0002736660464975809 batch: 23
epochs: 1 train loss: 4.828125  train f1: 0.00000  lr: 0.0002736660464975809 batch: 23 
epochs: 1 val loss: 3.888671875  val f1:0.12500  lr: 0.0002736660464975809 batch: 23
epochs: 0 train loss: 3.61328125  train f1: 0.20000  lr: 1.2583346889318542e-05 batch: 27 
epochs: 0 val loss: 4.70703125  val f1:0.00000  lr: 1.2583346889318542e-05 batch: 27
epochs: 1 train loss: 3.673828125  train f1: 0.20000  lr: 1.2583346889318542e-05 batch: 27 
epochs: 1 val loss: 4.59375  val f1:0.00000  lr: 1.2583346889318542e-05 batch: 27
epochs: 0 train loss: 4.59375  train f1: 0.00000  lr: 0.000433394431694495 batch: 24 
epochs: 0 val loss: 5.11328125  val f1:0.00000  lr: 0.000433394431694495 batch: 24
epochs: 1 train loss: 4.42578125  train f1: 0.00000  lr: 0.000433394431694495 batch: 24 
epochs: 1 val loss: 4.4609375  val f1:0.12500  lr: 0.000433394431694495 batch: 24
epochs: 0 train loss: 4.5625  train f1: 0.00000  lr: 0.00037531250729451807 batch: 22 
epochs: 0 val loss: 4.12890625  val f1:0.00000  lr: 0.00037531250729451807 batch: 22
epochs: 1 train loss: 4.7578125  train f1: 0.00000  lr: 0.00037531250729451807 batch: 22 
epochs: 1 val loss: 3.89453125  val f1:0.12500  lr: 0.00037531250729451807 batch: 22
epochs: 0 train loss: 4.7265625  train f1: 0.00000  lr: 0.001000041734464247 batch: 28 
epochs: 0 val loss: 4.828125  val f1:0.07143  lr: 0.001000041734464247 batch: 28
epochs: 1 train loss: 4.74609375  train f1: 0.00000  lr: 0.001000041734464247 batch: 28 
epochs: 1 val loss: 8.34375  val f1:0.00000  lr: 0.001000041734464247 batch: 28
epochs: 0 train loss: 4.55078125  train f1: 0.00000  lr: 0.0005626303415300896 batch: 26 
epochs: 0 val loss: 4.6328125  val f1:0.00000  lr: 0.0005626303415300896 batch: 26
epochs: 1 train loss: 4.50390625  train f1: 0.00000  lr: 0.0005626303415300896 batch: 26 
epochs: 1 val loss: 4.21875  val f1:0.14286  lr: 0.0005626303415300896 batch: 26
epochs: 2 train loss: 0.08392333984375  train f1: 1.00000  lr: 0.0005626303415300896 batch: 26 
epochs: 2 val loss: 12.78125  val f1:0.00000  lr: 0.0005626303415300896 batch: 26
epochs: 3 train loss: 2.6796875  train f1: 0.50000  lr: 0.0005626303415300896 batch: 26 
epochs: 3 val loss: 5.13671875  val f1:0.14286  lr: 0.0005626303415300896 batch: 26
epochs: 4 train loss: 0.0016679763793945312  train f1: 1.00000  lr: 0.0005626303415300896 batch: 26 
epochs: 4 val loss: 5.26953125  val f1:0.16667  lr: 0.0005626303415300896 batch: 26
epochs: 5 train loss: 0.0010671615600585938  train f1: 1.00000  lr: 0.0005626303415300896 batch: 26 
epochs: 5 val loss: 5.3125  val f1:0.14286  lr: 0.0005626303415300896 batch: 26
epochs: 6 train loss: 0.0010519027709960938  train f1: 1.00000  lr: 0.0005626303415300896 batch: 26 
epochs: 6 val loss: 5.37890625  val f1:0.16667  lr: 0.0005626303415300896 batch: 26
epochs: 7 train loss: 0.0004763603210449219  train f1: 1.00000  lr: 0.0005626303415300896 batch: 26 
epochs: 7 val loss: 5.62890625  val f1:0.16667  lr: 0.0005626303415300896 batch: 26
epochs: 8 train loss: 0.0005040168762207031  train f1: 1.00000  lr: 0.0005626303415300896 batch: 26 
epochs: 8 val loss: 5.83203125  val f1:0.16667  lr: 0.0005626303415300896 batch: 26
epochs: 0 train loss: 4.71875  train f1: 0.00000  lr: 0.0005468267212590964 batch: 26 
epochs: 0 val loss: 4.890625  val f1:0.00000  lr: 0.0005468267212590964 batch: 26
epochs: 1 train loss: 4.640625  train f1: 0.00000  lr: 0.0005468267212590964 batch: 26 
epochs: 1 val loss: 3.818359375  val f1:0.08333  lr: 0.0005468267212590964 batch: 26
epochs: 0 train loss: 4.28125  train f1: 0.00000  lr: 0.00023101921290966107 batch: 25 
epochs: 0 val loss: 5.01953125  val f1:0.00000  lr: 0.00023101921290966107 batch: 25
epochs: 1 train loss: 4.23828125  train f1: 0.16667  lr: 0.00023101921290966107 batch: 25 
epochs: 1 val loss: 4.08203125  val f1:0.12500  lr: 0.00023101921290966107 batch: 25
epochs: 0 train loss: 4.96875  train f1: 0.00000  lr: 0.00012948164369119773 batch: 30 
epochs: 0 val loss: 5.31640625  val f1:0.00000  lr: 0.00012948164369119773 batch: 30
epochs: 1 train loss: 4.84765625  train f1: 0.00000  lr: 0.00012948164369119773 batch: 30 
epochs: 1 val loss: 4.78125  val f1:0.00000  lr: 0.00012948164369119773 batch: 30
epochs: 0 train loss: 4.96484375  train f1: 0.00000  lr: 0.0006771053547051515 batch: 24 
epochs: 0 val loss: 4.33984375  val f1:0.00000  lr: 0.0006771053547051515 batch: 24
epochs: 1 train loss: 4.84765625  train f1: 0.00000  lr: 0.0006771053547051515 batch: 24 
epochs: 1 val loss: 4.89453125  val f1:0.14286  lr: 0.0006771053547051515 batch: 24
epochs: 2 train loss: 0.378173828125  train f1: 1.00000  lr: 0.0006771053547051515 batch: 24 
epochs: 2 val loss: 5.69921875  val f1:0.07143  lr: 0.0006771053547051515 batch: 24
epochs: 3 train loss: 2.10546875  train f1: 0.50000  lr: 0.0006771053547051515 batch: 24 
epochs: 3 val loss: 12.25  val f1:0.00000  lr: 0.0006771053547051515 batch: 24
epochs: 4 train loss: 0.02178955078125  train f1: 1.00000  lr: 0.0006771053547051515 batch: 24 
epochs: 4 val loss: 11.140625  val f1:0.14286  lr: 0.0006771053547051515 batch: 24
epochs: 5 train loss: 0.00014412403106689453  train f1: 1.00000  lr: 0.0006771053547051515 batch: 24 
epochs: 5 val loss: 11.203125  val f1:0.14286  lr: 0.0006771053547051515 batch: 24
epochs: 0 train loss: 4.5390625  train f1: 0.00000  lr: 0.000665337596299468 batch: 23 
epochs: 0 val loss: 5.63671875  val f1:0.00000  lr: 0.000665337596299468 batch: 23
epochs: 1 train loss: 4.4375  train f1: 0.00000  lr: 0.000665337596299468 batch: 23 
epochs: 1 val loss: 7.3671875  val f1:0.12500  lr: 0.000665337596299468 batch: 23
epochs: 0 train loss: 5.25  train f1: 0.00000  lr: 0.0005147715868316717 batch: 21 
epochs: 0 val loss: 4.30859375  val f1:0.00000  lr: 0.0005147715868316717 batch: 21
epochs: 1 train loss: 5.2890625  train f1: 0.00000  lr: 0.0005147715868316717 batch: 21 
epochs: 1 val loss: 6.51171875  val f1:0.00000  lr: 0.0005147715868316717 batch: 21
epochs: 0 train loss: 5.33203125  train f1: 0.00000  lr: 0.0010531729804397797 batch: 26 
epochs: 0 val loss: 4.68359375  val f1:0.00000  lr: 0.0010531729804397797 batch: 26
epochs: 1 train loss: 5.34765625  train f1: 0.00000  lr: 0.0010531729804397797 batch: 26 
epochs: 1 val loss: 4.6953125  val f1:0.00000  lr: 0.0010531729804397797 batch: 26
epochs: 0 train loss: 4.890625  train f1: 0.00000  lr: 0.00044078276938223183 batch: 24 
epochs: 0 val loss: 5.7421875  val f1:0.00000  lr: 0.00044078276938223183 batch: 24
epochs: 1 train loss: 4.89453125  train f1: 0.00000  lr: 0.00044078276938223183 batch: 24 
epochs: 1 val loss: 4.34375  val f1:0.14286  lr: 0.00044078276938223183 batch: 24
epochs: 2 train loss: 0.0751953125  train f1: 1.00000  lr: 0.00044078276938223183 batch: 24 
epochs: 2 val loss: 8.234375  val f1:0.16667  lr: 0.00044078276938223183 batch: 24
epochs: 3 train loss: 0.044586181640625  train f1: 1.00000  lr: 0.00044078276938223183 batch: 24 
epochs: 3 val loss: 4.01171875  val f1:0.16667  lr: 0.00044078276938223183 batch: 24
epochs: 4 train loss: 0.0001939535140991211  train f1: 1.00000  lr: 0.00044078276938223183 batch: 24 
epochs: 4 val loss: 3.693359375  val f1:0.16667  lr: 0.00044078276938223183 batch: 24
epochs: 5 train loss: 5.644559860229492e-05  train f1: 1.00000  lr: 0.00044078276938223183 batch: 24 
epochs: 5 val loss: 3.4921875  val f1:0.16667  lr: 0.00044078276938223183 batch: 24
epochs: 6 train loss: 5.7816505432128906e-05  train f1: 1.00000  lr: 0.00044078276938223183 batch: 24 
epochs: 6 val loss: 3.33984375  val f1:0.16667  lr: 0.00044078276938223183 batch: 24
epochs: 7 train loss: 0.00015938282012939453  train f1: 1.00000  lr: 0.00044078276938223183 batch: 24 
epochs: 7 val loss: 3.27734375  val f1:0.16667  lr: 0.00044078276938223183 batch: 24
epochs: 8 train loss: 7.87973403930664e-05  train f1: 1.00000  lr: 0.00044078276938223183 batch: 24 
epochs: 8 val loss: 3.23046875  val f1:0.16667  lr: 0.00044078276938223183 batch: 24
epochs: 9 train loss: 4.851818084716797e-05  train f1: 1.00000  lr: 0.00044078276938223183 batch: 24 
epochs: 9 val loss: 3.2109375  val f1:0.14286  lr: 0.00044078276938223183 batch: 24
epochs: 10 train loss: 3.0219554901123047e-05  train f1: 1.00000  lr: 0.00044078276938223183 batch: 24 
epochs: 10 val loss: 3.265625  val f1:0.14286  lr: 0.00044078276938223183 batch: 24
epochs: 0 train loss: 4.328125  train f1: 0.00000  lr: 0.00031387833192059845 batch: 25 
epochs: 0 val loss: 5.1796875  val f1:0.00000  lr: 0.00031387833192059845 batch: 25
epochs: 1 train loss: 4.49609375  train f1: 0.00000  lr: 0.00031387833192059845 batch: 25 
epochs: 1 val loss: 4.14453125  val f1:0.11111  lr: 0.00031387833192059845 batch: 25
epochs: 0 train loss: 4.8828125  train f1: 0.00000  lr: 0.0015585641807035636 batch: 28 
epochs: 0 val loss: 5.2734375  val f1:0.00000  lr: 0.0015585641807035636 batch: 28
epochs: 1 train loss: 4.92578125  train f1: 0.00000  lr: 0.0015585641807035636 batch: 28 
epochs: 1 val loss: 4.34375  val f1:0.11111  lr: 0.0015585641807035636 batch: 28
epochs: 0 train loss: 5.0078125  train f1: 0.00000  lr: 0.00038138476860074204 batch: 27 
epochs: 0 val loss: 4.375  val f1:0.00000  lr: 0.00038138476860074204 batch: 27
epochs: 1 train loss: 5.1015625  train f1: 0.00000  lr: 0.00038138476860074204 batch: 27 
epochs: 1 val loss: 3.841796875  val f1:0.14286  lr: 0.00038138476860074204 batch: 27
epochs: 2 train loss: 0.385986328125  train f1: 1.00000  lr: 0.00038138476860074204 batch: 27 
epochs: 2 val loss: 3.435546875  val f1:0.14286  lr: 0.00038138476860074204 batch: 27
epochs: 3 train loss: 1.099609375  train f1: 1.00000  lr: 0.00038138476860074204 batch: 27 
epochs: 3 val loss: 4.1171875  val f1:0.14286  lr: 0.00038138476860074204 batch: 27
epochs: 4 train loss: 0.0010919570922851562  train f1: 1.00000  lr: 0.00038138476860074204 batch: 27 
epochs: 4 val loss: 3.755859375  val f1:0.14286  lr: 0.00038138476860074204 batch: 27
epochs: 5 train loss: 0.000732421875  train f1: 1.00000  lr: 0.00038138476860074204 batch: 27 
epochs: 5 val loss: 3.59765625  val f1:0.33333  lr: 0.00038138476860074204 batch: 27
epochs: 6 train loss: 0.00049591064453125  train f1: 1.00000  lr: 0.00038138476860074204 batch: 27 
epochs: 6 val loss: 3.5546875  val f1:0.33333  lr: 0.00038138476860074204 batch: 27
epochs: 7 train loss: 0.000629425048828125  train f1: 1.00000  lr: 0.00038138476860074204 batch: 27 
epochs: 7 val loss: 3.5390625  val f1:0.27778  lr: 0.00038138476860074204 batch: 27
epochs: 0 train loss: 5.0625  train f1: 0.00000  lr: 0.00033704993707656355 batch: 29 
epochs: 0 val loss: 4.921875  val f1:0.00000  lr: 0.00033704993707656355 batch: 29
epochs: 1 train loss: 4.9765625  train f1: 0.00000  lr: 0.00033704993707656355 batch: 29 
epochs: 1 val loss: 3.380859375  val f1:0.12500  lr: 0.00033704993707656355 batch: 29
epochs: 0 train loss: 4.515625  train f1: 0.00000  lr: 0.00018506595065742481 batch: 32 
epochs: 0 val loss: 4.74609375  val f1:0.00000  lr: 0.00018506595065742481 batch: 32
epochs: 1 train loss: 4.59375  train f1: 0.00000  lr: 0.00018506595065742481 batch: 32 
epochs: 1 val loss: 4.06640625  val f1:0.14286  lr: 0.00018506595065742481 batch: 32
epochs: 2 train loss: 0.7353515625  train f1: 1.00000  lr: 0.00018506595065742481 batch: 32 
epochs: 2 val loss: 4.33203125  val f1:0.14286  lr: 0.00018506595065742481 batch: 32
epochs: 3 train loss: 0.478759765625  train f1: 1.00000  lr: 0.00018506595065742481 batch: 32 
epochs: 3 val loss: 4.2734375  val f1:0.16667  lr: 0.00018506595065742481 batch: 32
epochs: 4 train loss: 0.011688232421875  train f1: 1.00000  lr: 0.00018506595065742481 batch: 32 
epochs: 4 val loss: 4.2109375  val f1:0.16667  lr: 0.00018506595065742481 batch: 32
epochs: 5 train loss: 0.0098114013671875  train f1: 1.00000  lr: 0.00018506595065742481 batch: 32 
epochs: 5 val loss: 4.21875  val f1:0.14286  lr: 0.00018506595065742481 batch: 32
epochs: 6 train loss: 0.004055023193359375  train f1: 1.00000  lr: 0.00018506595065742481 batch: 32 
epochs: 6 val loss: 4.19921875  val f1:0.12500  lr: 0.00018506595065742481 batch: 32
epochs: 0 train loss: 4.9609375  train f1: 0.00000  lr: 0.000793303241472807 batch: 27 
epochs: 0 val loss: 5.5625  val f1:0.00000  lr: 0.000793303241472807 batch: 27
epochs: 1 train loss: 4.83984375  train f1: 0.00000  lr: 0.000793303241472807 batch: 27 
epochs: 1 val loss: 5.05078125  val f1:0.00000  lr: 0.000793303241472807 batch: 27
epochs: 0 train loss: 4.0234375  train f1: 0.00000  lr: 0.00039991791005706114 batch: 22 
epochs: 0 val loss: 4.94140625  val f1:0.00000  lr: 0.00039991791005706114 batch: 22
epochs: 1 train loss: 3.9765625  train f1: 0.00000  lr: 0.00039991791005706114 batch: 22 
epochs: 1 val loss: 3.984375  val f1:0.14286  lr: 0.00039991791005706114 batch: 22
epochs: 2 train loss: 0.4951171875  train f1: 1.00000  lr: 0.00039991791005706114 batch: 22 
epochs: 2 val loss: 6.78125  val f1:0.14286  lr: 0.00039991791005706114 batch: 22
epochs: 3 train loss: 0.8544921875  train f1: 1.00000  lr: 0.00039991791005706114 batch: 22 
epochs: 3 val loss: 4.19140625  val f1:0.11111  lr: 0.00039991791005706114 batch: 22
epochs: 4 train loss: 0.494873046875  train f1: 1.00000  lr: 0.00039991791005706114 batch: 22 
epochs: 4 val loss: 6.44921875  val f1:0.14286  lr: 0.00039991791005706114 batch: 22
epochs: 5 train loss: 0.00011181831359863281  train f1: 1.00000  lr: 0.00039991791005706114 batch: 22 
epochs: 5 val loss: 6.0625  val f1:0.14286  lr: 0.00039991791005706114 batch: 22
epochs: 6 train loss: 8.189678192138672e-05  train f1: 1.00000  lr: 0.00039991791005706114 batch: 22 
epochs: 6 val loss: 5.546875  val f1:0.12500  lr: 0.00039991791005706114 batch: 22
epochs: 7 train loss: 0.0004010200500488281  train f1: 1.00000  lr: 0.00039991791005706114 batch: 22 
epochs: 7 val loss: 5.421875  val f1:0.12500  lr: 0.00039991791005706114 batch: 22
epochs: 8 train loss: 4.1961669921875e-05  train f1: 1.00000  lr: 0.00039991791005706114 batch: 22 
epochs: 8 val loss: 5.27734375  val f1:0.12500  lr: 0.00039991791005706114 batch: 22
epochs: 0 train loss: 4.515625  train f1: 0.00000  lr: 0.0004806879033758885 batch: 21 
epochs: 0 val loss: 4.515625  val f1:0.00000  lr: 0.0004806879033758885 batch: 21
epochs: 1 train loss: 4.609375  train f1: 0.00000  lr: 0.0004806879033758885 batch: 21 
epochs: 1 val loss: 4.171875  val f1:0.12500  lr: 0.0004806879033758885 batch: 21
epochs: 0 train loss: 4.48046875  train f1: 0.00000  lr: 0.0011989339259569794 batch: 26 
epochs: 0 val loss: 4.6953125  val f1:0.00000  lr: 0.0011989339259569794 batch: 26
epochs: 1 train loss: 4.6015625  train f1: 0.00000  lr: 0.0011989339259569794 batch: 26 
epochs: 1 val loss: 6.703125  val f1:0.00000  lr: 0.0011989339259569794 batch: 26
epochs: 0 train loss: 4.7109375  train f1: 0.00000  lr: 0.00042486662110130703 batch: 28 
epochs: 0 val loss: 5.22265625  val f1:0.00000  lr: 0.00042486662110130703 batch: 28
epochs: 1 train loss: 4.8984375  train f1: 0.00000  lr: 0.00042486662110130703 batch: 28 
epochs: 1 val loss: 4.140625  val f1:0.11111  lr: 0.00042486662110130703 batch: 28
epochs: 0 train loss: 4.390625  train f1: 0.00000  lr: 0.00067355548565388 batch: 24 
epochs: 0 val loss: 5.34375  val f1:0.00000  lr: 0.00067355548565388 batch: 24
epochs: 1 train loss: 4.109375  train f1: 0.00000  lr: 0.00067355548565388 batch: 24 
epochs: 1 val loss: 3.587890625  val f1:0.14286  lr: 0.00067355548565388 batch: 24
epochs: 2 train loss: 1.0673828125  train f1: 1.00000  lr: 0.00067355548565388 batch: 24 
epochs: 2 val loss: 96.1875  val f1:0.00000  lr: 0.00067355548565388 batch: 24
epochs: 3 train loss: 2.615234375  train f1: 0.40000  lr: 0.00067355548565388 batch: 24 
epochs: 3 val loss: 6.88671875  val f1:0.00000  lr: 0.00067355548565388 batch: 24
epochs: 4 train loss: 0.00026679039001464844  train f1: 1.00000  lr: 0.00067355548565388 batch: 24 
epochs: 4 val loss: 8.03125  val f1:0.00000  lr: 0.00067355548565388 batch: 24
epochs: 5 train loss: 0.00024771690368652344  train f1: 1.00000  lr: 0.00067355548565388 batch: 24 
epochs: 5 val loss: 9.0078125  val f1:0.00000  lr: 0.00067355548565388 batch: 24
epochs: 6 train loss: 0.00019752979278564453  train f1: 1.00000  lr: 0.00067355548565388 batch: 24 
epochs: 6 val loss: 10.1796875  val f1:0.00000  lr: 0.00067355548565388 batch: 24
epochs: 7 train loss: 0.00014960765838623047  train f1: 1.00000  lr: 0.00067355548565388 batch: 24 
epochs: 7 val loss: 10.9453125  val f1:0.00000  lr: 0.00067355548565388 batch: 24
epochs: 0 train loss: 4.6015625  train f1: 0.00000  lr: 0.00027037453795883686 batch: 26 
epochs: 0 val loss: 4.1796875  val f1:0.00000  lr: 0.00027037453795883686 batch: 26
epochs: 1 train loss: 4.69140625  train f1: 0.00000  lr: 0.00027037453795883686 batch: 26 
epochs: 1 val loss: 3.525390625  val f1:0.11111  lr: 0.00027037453795883686 batch: 26
epochs: 0 train loss: 4.52734375  train f1: 0.00000  lr: 0.00021062876152224858 batch: 25 
epochs: 0 val loss: 5.0625  val f1:0.00000  lr: 0.00021062876152224858 batch: 25
epochs: 1 train loss: 4.54296875  train f1: 0.00000  lr: 0.00021062876152224858 batch: 25 
epochs: 1 val loss: 3.5703125  val f1:0.11111  lr: 0.00021062876152224858 batch: 25
epochs: 0 train loss: 4.69921875  train f1: 0.00000  lr: 0.000870749483023471 batch: 29 
epochs: 0 val loss: 4.61328125  val f1:0.00000  lr: 0.000870749483023471 batch: 29
epochs: 1 train loss: 4.6328125  train f1: 0.00000  lr: 0.000870749483023471 batch: 29 
epochs: 1 val loss: 5.35546875  val f1:0.09524  lr: 0.000870749483023471 batch: 29
epochs: 0 train loss: 4.46875  train f1: 0.00000  lr: 3.0485933735578715e-05 batch: 27 
epochs: 0 val loss: 5.51953125  val f1:0.00000  lr: 3.0485933735578715e-05 batch: 27
epochs: 1 train loss: 4.33984375  train f1: 0.00000  lr: 3.0485933735578715e-05 batch: 27 
epochs: 1 val loss: 5.50390625  val f1:0.00000  lr: 3.0485933735578715e-05 batch: 27
epochs: 0 train loss: 4.40234375  train f1: 0.00000  lr: 0.0006461190863145893 batch: 24 
epochs: 0 val loss: 5.09375  val f1:0.00000  lr: 0.0006461190863145893 batch: 24
epochs: 1 train loss: 4.3359375  train f1: 0.00000  lr: 0.0006461190863145893 batch: 24 
epochs: 1 val loss: 5.15625  val f1:0.00000  lr: 0.0006461190863145893 batch: 24
epochs: 0 train loss: 4.9296875  train f1: 0.00000  lr: 0.00048607594028345525 batch: 22 
epochs: 0 val loss: 4.55078125  val f1:0.00000  lr: 0.00048607594028345525 batch: 22
epochs: 1 train loss: 5.08203125  train f1: 0.00000  lr: 0.00048607594028345525 batch: 22 
epochs: 1 val loss: 4.44140625  val f1:0.14286  lr: 0.00048607594028345525 batch: 22
epochs: 2 train loss: 0.54833984375  train f1: 1.00000  lr: 0.00048607594028345525 batch: 22 
epochs: 2 val loss: 6.48828125  val f1:0.16667  lr: 0.00048607594028345525 batch: 22
epochs: 3 train loss: 1.041015625  train f1: 0.50000  lr: 0.00048607594028345525 batch: 22 
epochs: 3 val loss: 7.74609375  val f1:0.14286  lr: 0.00048607594028345525 batch: 22
epochs: 4 train loss: 0.00010120868682861328  train f1: 1.00000  lr: 0.00048607594028345525 batch: 22 
epochs: 4 val loss: 6.61328125  val f1:0.14286  lr: 0.00048607594028345525 batch: 22
epochs: 5 train loss: 0.0002307891845703125  train f1: 1.00000  lr: 0.00048607594028345525 batch: 22 
epochs: 5 val loss: 5.83203125  val f1:0.12500  lr: 0.00048607594028345525 batch: 22
epochs: 6 train loss: 0.00013840198516845703  train f1: 1.00000  lr: 0.00048607594028345525 batch: 22 
epochs: 6 val loss: 5.2734375  val f1:0.11111  lr: 0.00048607594028345525 batch: 22
epochs: 7 train loss: 9.870529174804688e-05  train f1: 1.00000  lr: 0.00048607594028345525 batch: 22 
epochs: 7 val loss: 5.203125  val f1:0.12500  lr: 0.00048607594028345525 batch: 22
epochs: 8 train loss: 0.0005450248718261719  train f1: 1.00000  lr: 0.00048607594028345525 batch: 22 
epochs: 8 val loss: 5.19921875  val f1:0.14286  lr: 0.00048607594028345525 batch: 22
epochs: 9 train loss: 6.914138793945312e-05  train f1: 1.00000  lr: 0.00048607594028345525 batch: 22 
epochs: 9 val loss: 5.13671875  val f1:0.14286  lr: 0.00048607594028345525 batch: 22
epochs: 0 train loss: 4.94921875  train f1: 0.00000  lr: 0.0005031866567634249 batch: 20 
epochs: 0 val loss: 4.84375  val f1:0.00000  lr: 0.0005031866567634249 batch: 20
epochs: 1 train loss: 4.99609375  train f1: 0.00000  lr: 0.0005031866567634249 batch: 20 
epochs: 1 val loss: 3.78125  val f1:0.14286  lr: 0.0005031866567634249 batch: 20
epochs: 2 train loss: 0.386474609375  train f1: 1.00000  lr: 0.0005031866567634249 batch: 20 
epochs: 2 val loss: 3.701171875  val f1:0.11111  lr: 0.0005031866567634249 batch: 20
epochs: 3 train loss: 0.479736328125  train f1: 1.00000  lr: 0.0005031866567634249 batch: 20 
epochs: 3 val loss: 20.953125  val f1:0.00000  lr: 0.0005031866567634249 batch: 20
epochs: 4 train loss: 0.0258941650390625  train f1: 1.00000  lr: 0.0005031866567634249 batch: 20 
epochs: 4 val loss: 14.125  val f1:0.00000  lr: 0.0005031866567634249 batch: 20
epochs: 5 train loss: 0.0008640289306640625  train f1: 1.00000  lr: 0.0005031866567634249 batch: 20 
epochs: 5 val loss: 11.40625  val f1:0.00000  lr: 0.0005031866567634249 batch: 20
epochs: 6 train loss: 0.0002636909484863281  train f1: 1.00000  lr: 0.0005031866567634249 batch: 20 
epochs: 6 val loss: 9.75  val f1:0.00000  lr: 0.0005031866567634249 batch: 20
epochs: 7 train loss: 0.00018739700317382812  train f1: 1.00000  lr: 0.0005031866567634249 batch: 20 
epochs: 7 val loss: 8.53125  val f1:0.00000  lr: 0.0005031866567634249 batch: 20
epochs: 8 train loss: 0.000118255615234375  train f1: 1.00000  lr: 0.0005031866567634249 batch: 20 
epochs: 8 val loss: 7.77734375  val f1:0.00000  lr: 0.0005031866567634249 batch: 20
epochs: 9 train loss: 0.00010973215103149414  train f1: 1.00000  lr: 0.0005031866567634249 batch: 20 
epochs: 9 val loss: 7.39453125  val f1:0.00000  lr: 0.0005031866567634249 batch: 20
epochs: 0 train loss: 4.6796875  train f1: 0.00000  lr: 0.00031365853771877296 batch: 22 
epochs: 0 val loss: 4.64453125  val f1:0.00000  lr: 0.00031365853771877296 batch: 22
epochs: 1 train loss: 4.78125  train f1: 0.00000  lr: 0.00031365853771877296 batch: 22 
epochs: 1 val loss: 4.2734375  val f1:0.14286  lr: 0.00031365853771877296 batch: 22
epochs: 2 train loss: 0.1639404296875  train f1: 1.00000  lr: 0.00031365853771877296 batch: 22 
epochs: 2 val loss: 6.6171875  val f1:0.14286  lr: 0.00031365853771877296 batch: 22
epochs: 3 train loss: 0.84033203125  train f1: 1.00000  lr: 0.00031365853771877296 batch: 22 
epochs: 3 val loss: 3.88671875  val f1:0.14286  lr: 0.00031365853771877296 batch: 22
epochs: 4 train loss: 0.28125  train f1: 1.00000  lr: 0.00031365853771877296 batch: 22 
epochs: 4 val loss: 4.17578125  val f1:0.14286  lr: 0.00031365853771877296 batch: 22
epochs: 0 train loss: 4.3125  train f1: 0.00000  lr: 0.0003852337603929153 batch: 27 
epochs: 0 val loss: 4.71875  val f1:0.00000  lr: 0.0003852337603929153 batch: 27
epochs: 1 train loss: 4.29296875  train f1: 0.00000  lr: 0.0003852337603929153 batch: 27 
epochs: 1 val loss: 3.810546875  val f1:0.14286  lr: 0.0003852337603929153 batch: 27
epochs: 2 train loss: 0.349365234375  train f1: 1.00000  lr: 0.0003852337603929153 batch: 27 
epochs: 2 val loss: 5.12890625  val f1:0.12500  lr: 0.0003852337603929153 batch: 27
epochs: 3 train loss: 0.8154296875  train f1: 1.00000  lr: 0.0003852337603929153 batch: 27 
epochs: 3 val loss: 4.34765625  val f1:0.14286  lr: 0.0003852337603929153 batch: 27
epochs: 4 train loss: 0.048919677734375  train f1: 1.00000  lr: 0.0003852337603929153 batch: 27 
epochs: 4 val loss: 5.23046875  val f1:0.14286  lr: 0.0003852337603929153 batch: 27
epochs: 5 train loss: 0.00012481212615966797  train f1: 1.00000  lr: 0.0003852337603929153 batch: 27 
epochs: 5 val loss: 5.0703125  val f1:0.14286  lr: 0.0003852337603929153 batch: 27
epochs: 6 train loss: 0.0001436471939086914  train f1: 1.00000  lr: 0.0003852337603929153 batch: 27 
epochs: 6 val loss: 4.86328125  val f1:0.14286  lr: 0.0003852337603929153 batch: 27
epochs: 7 train loss: 7.516145706176758e-05  train f1: 1.00000  lr: 0.0003852337603929153 batch: 27 
epochs: 7 val loss: 4.71875  val f1:0.14286  lr: 0.0003852337603929153 batch: 27
epochs: 8 train loss: 5.793571472167969e-05  train f1: 1.00000  lr: 0.0003852337603929153 batch: 27 
epochs: 8 val loss: 4.6875  val f1:0.14286  lr: 0.0003852337603929153 batch: 27
epochs: 9 train loss: 6.902217864990234e-05  train f1: 1.00000  lr: 0.0003852337603929153 batch: 27 
epochs: 9 val loss: 4.6484375  val f1:0.12500  lr: 0.0003852337603929153 batch: 27
epochs: 10 train loss: 6.35385513305664e-05  train f1: 1.00000  lr: 0.0003852337603929153 batch: 27 
epochs: 10 val loss: 4.640625  val f1:0.12500  lr: 0.0003852337603929153 batch: 27
epochs: 0 train loss: 4.5  train f1: 0.00000  lr: 0.02348970227466846 batch: 25 
epochs: 0 val loss: 4.62109375  val f1:0.00000  lr: 0.02348970227466846 batch: 25
epochs: 1 train loss: 4.44921875  train f1: 0.00000  lr: 0.02348970227466846 batch: 25 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.02348970227466846 batch: 25
epochs: 0 train loss: 4.06640625  train f1: 0.00000  lr: 0.0017070144764070121 batch: 16 
epochs: 0 val loss: 5.359375  val f1:0.00000  lr: 0.0017070144764070121 batch: 16
epochs: 1 train loss: 4.20703125  train f1: 0.00000  lr: 0.0017070144764070121 batch: 16 
epochs: 1 val loss: 4.41015625  val f1:0.11111  lr: 0.0017070144764070121 batch: 16
epochs: 0 train loss: 4.8984375  train f1: 0.00000  lr: 0.000745917672019202 batch: 23 
epochs: 0 val loss: 4.5859375  val f1:0.00000  lr: 0.000745917672019202 batch: 23
epochs: 1 train loss: 4.984375  train f1: 0.00000  lr: 0.000745917672019202 batch: 23 
epochs: 1 val loss: 5.2421875  val f1:0.14286  lr: 0.000745917672019202 batch: 23
epochs: 2 train loss: 0.69580078125  train f1: 1.00000  lr: 0.000745917672019202 batch: 23 
epochs: 2 val loss: 6.2109375  val f1:0.06667  lr: 0.000745917672019202 batch: 23
epochs: 3 train loss: 1.501953125  train f1: 0.50000  lr: 0.000745917672019202 batch: 23 
epochs: 3 val loss: 13.8828125  val f1:0.06667  lr: 0.000745917672019202 batch: 23
epochs: 4 train loss: 0.19580078125  train f1: 0.60000  lr: 0.000745917672019202 batch: 23 
epochs: 4 val loss: 10.796875  val f1:0.16667  lr: 0.000745917672019202 batch: 23
epochs: 5 train loss: 0.057861328125  train f1: 1.00000  lr: 0.000745917672019202 batch: 23 
epochs: 5 val loss: 32.40625  val f1:0.16667  lr: 0.000745917672019202 batch: 23
epochs: 6 train loss: 0.001323699951171875  train f1: 1.00000  lr: 0.000745917672019202 batch: 23 
epochs: 6 val loss: 21.46875  val f1:0.16667  lr: 0.000745917672019202 batch: 23
epochs: 7 train loss: 0.0001493692398071289  train f1: 1.00000  lr: 0.000745917672019202 batch: 23 
epochs: 7 val loss: 14.1328125  val f1:0.16667  lr: 0.000745917672019202 batch: 23
epochs: 8 train loss: 0.000308990478515625  train f1: 1.00000  lr: 0.000745917672019202 batch: 23 
epochs: 8 val loss: 9.609375  val f1:0.16667  lr: 0.000745917672019202 batch: 23
epochs: 9 train loss: 0.0002498626708984375  train f1: 1.00000  lr: 0.000745917672019202 batch: 23 
epochs: 9 val loss: 6.62109375  val f1:0.16667  lr: 0.000745917672019202 batch: 23
epochs: 10 train loss: 0.0001939535140991211  train f1: 1.00000  lr: 0.000745917672019202 batch: 23 
epochs: 10 val loss: 5.0625  val f1:0.16667  lr: 0.000745917672019202 batch: 23
epochs: 0 train loss: 4.8828125  train f1: 0.00000  lr: 0.000805397335401445 batch: 23 
epochs: 0 val loss: 3.8359375  val f1:0.12500  lr: 0.000805397335401445 batch: 23
epochs: 1 train loss: 4.953125  train f1: 0.00000  lr: 0.000805397335401445 batch: 23 
epochs: 1 val loss: 6.65625  val f1:0.16667  lr: 0.000805397335401445 batch: 23
epochs: 2 train loss: 0.87451171875  train f1: 1.00000  lr: 0.000805397335401445 batch: 23 
epochs: 2 val loss: 3.5546875  val f1:0.25000  lr: 0.000805397335401445 batch: 23
epochs: 3 train loss: 2.357421875  train f1: 0.25000  lr: 0.000805397335401445 batch: 23 
epochs: 3 val loss: 8.2109375  val f1:0.11111  lr: 0.000805397335401445 batch: 23
epochs: 4 train loss: 0.67822265625  train f1: 1.00000  lr: 0.000805397335401445 batch: 23 
epochs: 4 val loss: 23.015625  val f1:0.00000  lr: 0.000805397335401445 batch: 23
epochs: 5 train loss: 0.0287322998046875  train f1: 1.00000  lr: 0.000805397335401445 batch: 23 
epochs: 5 val loss: 35.78125  val f1:0.00000  lr: 0.000805397335401445 batch: 23
epochs: 6 train loss: 0.008514404296875  train f1: 1.00000  lr: 0.000805397335401445 batch: 23 
epochs: 6 val loss: 35.65625  val f1:0.00000  lr: 0.000805397335401445 batch: 23
epochs: 7 train loss: 6.735324859619141e-06  train f1: 1.00000  lr: 0.000805397335401445 batch: 23 
epochs: 7 val loss: 33.625  val f1:0.00000  lr: 0.000805397335401445 batch: 23
epochs: 8 train loss: 9.655952453613281e-06  train f1: 1.00000  lr: 0.000805397335401445 batch: 23 
epochs: 8 val loss: 29.59375  val f1:0.00000  lr: 0.000805397335401445 batch: 23
epochs: 9 train loss: 7.62939453125e-06  train f1: 1.00000  lr: 0.000805397335401445 batch: 23 
epochs: 9 val loss: 24.578125  val f1:0.00000  lr: 0.000805397335401445 batch: 23
epochs: 0 train loss: 4.41796875  train f1: 0.00000  lr: 0.0005839389183088526 batch: 23 
epochs: 0 val loss: 4.5703125  val f1:0.00000  lr: 0.0005839389183088526 batch: 23
epochs: 1 train loss: 4.5078125  train f1: 0.00000  lr: 0.0005839389183088526 batch: 23 
epochs: 1 val loss: 4.45703125  val f1:0.14286  lr: 0.0005839389183088526 batch: 23
epochs: 2 train loss: 0.061309814453125  train f1: 1.00000  lr: 0.0005839389183088526 batch: 23 
epochs: 2 val loss: 6.73046875  val f1:0.14286  lr: 0.0005839389183088526 batch: 23
epochs: 3 train loss: 0.248291015625  train f1: 1.00000  lr: 0.0005839389183088526 batch: 23 
epochs: 3 val loss: 3.892578125  val f1:0.16667  lr: 0.0005839389183088526 batch: 23
epochs: 4 train loss: 0.189208984375  train f1: 1.00000  lr: 0.0005839389183088526 batch: 23 
epochs: 4 val loss: 40.0625  val f1:0.00000  lr: 0.0005839389183088526 batch: 23
epochs: 5 train loss: 0.0148773193359375  train f1: 1.00000  lr: 0.0005839389183088526 batch: 23 
epochs: 5 val loss: 24.140625  val f1:0.16667  lr: 0.0005839389183088526 batch: 23
epochs: 6 train loss: 2.1696090698242188e-05  train f1: 1.00000  lr: 0.0005839389183088526 batch: 23 
epochs: 6 val loss: 21.34375  val f1:0.16667  lr: 0.0005839389183088526 batch: 23
epochs: 7 train loss: 3.4570693969726562e-06  train f1: 1.00000  lr: 0.0005839389183088526 batch: 23 
epochs: 7 val loss: 17.625  val f1:0.16667  lr: 0.0005839389183088526 batch: 23
epochs: 8 train loss: 2.5033950805664062e-06  train f1: 1.00000  lr: 0.0005839389183088526 batch: 23 
epochs: 8 val loss: 15.4140625  val f1:0.16667  lr: 0.0005839389183088526 batch: 23
epochs: 9 train loss: 1.627206802368164e-05  train f1: 1.00000  lr: 0.0005839389183088526 batch: 23 
epochs: 9 val loss: 13.234375  val f1:0.16667  lr: 0.0005839389183088526 batch: 23
epochs: 10 train loss: 0.00032067298889160156  train f1: 1.00000  lr: 0.0005839389183088526 batch: 23 
epochs: 10 val loss: 11.703125  val f1:0.16667  lr: 0.0005839389183088526 batch: 23
epochs: 11 train loss: 1.1920928955078125e-06  train f1: 1.00000  lr: 0.0005839389183088526 batch: 23 
epochs: 11 val loss: 9.7578125  val f1:0.16667  lr: 0.0005839389183088526 batch: 23
epochs: 0 train loss: 4.1875  train f1: 0.00000  lr: 0.0005802404990932141 batch: 23 
epochs: 0 val loss: 4.98046875  val f1:0.00000  lr: 0.0005802404990932141 batch: 23
epochs: 1 train loss: 4.1953125  train f1: 0.00000  lr: 0.0005802404990932141 batch: 23 
epochs: 1 val loss: 3.923828125  val f1:0.16667  lr: 0.0005802404990932141 batch: 23
epochs: 2 train loss: 0.69482421875  train f1: 1.00000  lr: 0.0005802404990932141 batch: 23 
epochs: 2 val loss: 5.26171875  val f1:0.14286  lr: 0.0005802404990932141 batch: 23
epochs: 3 train loss: 0.75830078125  train f1: 1.00000  lr: 0.0005802404990932141 batch: 23 
epochs: 3 val loss: 7.25390625  val f1:0.00000  lr: 0.0005802404990932141 batch: 23
epochs: 4 train loss: 0.4912109375  train f1: 1.00000  lr: 0.0005802404990932141 batch: 23 
epochs: 4 val loss: 5.21875  val f1:0.14286  lr: 0.0005802404990932141 batch: 23
epochs: 5 train loss: 0.00032520294189453125  train f1: 1.00000  lr: 0.0005802404990932141 batch: 23 
epochs: 5 val loss: 4.09375  val f1:0.14286  lr: 0.0005802404990932141 batch: 23
epochs: 6 train loss: 0.00043392181396484375  train f1: 1.00000  lr: 0.0005802404990932141 batch: 23 
epochs: 6 val loss: 3.685546875  val f1:0.14286  lr: 0.0005802404990932141 batch: 23
epochs: 7 train loss: 0.0001926422119140625  train f1: 1.00000  lr: 0.0005802404990932141 batch: 23 
epochs: 7 val loss: 3.48046875  val f1:0.14286  lr: 0.0005802404990932141 batch: 23
epochs: 8 train loss: 0.0002837181091308594  train f1: 1.00000  lr: 0.0005802404990932141 batch: 23 
epochs: 8 val loss: 3.4765625  val f1:0.14286  lr: 0.0005802404990932141 batch: 23
epochs: 9 train loss: 0.0001251697540283203  train f1: 1.00000  lr: 0.0005802404990932141 batch: 23 
epochs: 9 val loss: 3.484375  val f1:0.14286  lr: 0.0005802404990932141 batch: 23
epochs: 10 train loss: 0.0001819133758544922  train f1: 1.00000  lr: 0.0005802404990932141 batch: 23 
epochs: 10 val loss: 3.513671875  val f1:0.14286  lr: 0.0005802404990932141 batch: 23
epochs: 11 train loss: 8.738040924072266e-05  train f1: 1.00000  lr: 0.0005802404990932141 batch: 23 
epochs: 11 val loss: 3.537109375  val f1:0.14286  lr: 0.0005802404990932141 batch: 23
epochs: 12 train loss: 0.00011324882507324219  train f1: 1.00000  lr: 0.0005802404990932141 batch: 23 
epochs: 12 val loss: 3.58203125  val f1:0.14286  lr: 0.0005802404990932141 batch: 23
epochs: 0 train loss: 5.046875  train f1: 0.00000  lr: 0.0010519222049643162 batch: 26 
epochs: 0 val loss: 4.3671875  val f1:0.00000  lr: 0.0010519222049643162 batch: 26
epochs: 1 train loss: 5.04296875  train f1: 0.00000  lr: 0.0010519222049643162 batch: 26 
epochs: 1 val loss: 9.59375  val f1:0.00000  lr: 0.0010519222049643162 batch: 26
epochs: 0 train loss: 4.8046875  train f1: 0.00000  lr: 0.0005926329169000066 batch: 23 
epochs: 0 val loss: 5.14453125  val f1:0.00000  lr: 0.0005926329169000066 batch: 23
epochs: 1 train loss: 4.73828125  train f1: 0.00000  lr: 0.0005926329169000066 batch: 23 
epochs: 1 val loss: 4.4296875  val f1:0.00000  lr: 0.0005926329169000066 batch: 23
epochs: 0 train loss: 4.6484375  train f1: 0.00000  lr: 0.0013048049706683121 batch: 22 
epochs: 0 val loss: 4.8671875  val f1:0.00000  lr: 0.0013048049706683121 batch: 22
epochs: 1 train loss: 4.75390625  train f1: 0.00000  lr: 0.0013048049706683121 batch: 22 
epochs: 1 val loss: 15.9296875  val f1:0.00000  lr: 0.0013048049706683121 batch: 22
epochs: 0 train loss: 3.9375  train f1: 0.00000  lr: 0.0002940023247118429 batch: 23 
epochs: 0 val loss: 4.7265625  val f1:0.00000  lr: 0.0002940023247118429 batch: 23
epochs: 1 train loss: 4.01171875  train f1: 0.00000  lr: 0.0002940023247118429 batch: 23 
epochs: 1 val loss: 4.11328125  val f1:0.11111  lr: 0.0002940023247118429 batch: 23
epochs: 0 train loss: 4.23828125  train f1: 0.00000  lr: 0.000562554153330596 batch: 21 
epochs: 0 val loss: 5.75  val f1:0.00000  lr: 0.000562554153330596 batch: 21
epochs: 1 train loss: 4.05078125  train f1: 0.00000  lr: 0.000562554153330596 batch: 21 
epochs: 1 val loss: 6.6484375  val f1:0.16667  lr: 0.000562554153330596 batch: 21
epochs: 2 train loss: 0.181884765625  train f1: 1.00000  lr: 0.000562554153330596 batch: 21 
epochs: 2 val loss: 3.830078125  val f1:0.12500  lr: 0.000562554153330596 batch: 21
epochs: 3 train loss: 1.3759765625  train f1: 0.50000  lr: 0.000562554153330596 batch: 21 
epochs: 3 val loss: 9.3359375  val f1:0.16667  lr: 0.000562554153330596 batch: 21
epochs: 4 train loss: 3.0994415283203125e-05  train f1: 1.00000  lr: 0.000562554153330596 batch: 21 
epochs: 4 val loss: 8.0625  val f1:0.16667  lr: 0.000562554153330596 batch: 21
epochs: 5 train loss: 3.68952751159668e-05  train f1: 1.00000  lr: 0.000562554153330596 batch: 21 
epochs: 5 val loss: 6.9609375  val f1:0.16667  lr: 0.000562554153330596 batch: 21
epochs: 6 train loss: 0.0001735687255859375  train f1: 1.00000  lr: 0.000562554153330596 batch: 21 
epochs: 6 val loss: 6.26953125  val f1:0.16667  lr: 0.000562554153330596 batch: 21
epochs: 7 train loss: 1.7404556274414062e-05  train f1: 1.00000  lr: 0.000562554153330596 batch: 21 
epochs: 7 val loss: 5.91015625  val f1:0.16667  lr: 0.000562554153330596 batch: 21
epochs: 8 train loss: 1.811981201171875e-05  train f1: 1.00000  lr: 0.000562554153330596 batch: 21 
epochs: 8 val loss: 5.73046875  val f1:0.16667  lr: 0.000562554153330596 batch: 21
epochs: 9 train loss: 0.0001494884490966797  train f1: 1.00000  lr: 0.000562554153330596 batch: 21 
epochs: 9 val loss: 5.63671875  val f1:0.16667  lr: 0.000562554153330596 batch: 21
epochs: 10 train loss: 3.224611282348633e-05  train f1: 1.00000  lr: 0.000562554153330596 batch: 21 
epochs: 10 val loss: 5.67578125  val f1:0.16667  lr: 0.000562554153330596 batch: 21
epochs: 11 train loss: 3.153085708618164e-05  train f1: 1.00000  lr: 0.000562554153330596 batch: 21 
epochs: 11 val loss: 5.6953125  val f1:0.16667  lr: 0.000562554153330596 batch: 21
epochs: 12 train loss: 3.9696693420410156e-05  train f1: 1.00000  lr: 0.000562554153330596 batch: 21 
epochs: 12 val loss: 5.76953125  val f1:0.16667  lr: 0.000562554153330596 batch: 21
epochs: 0 train loss: 4.39453125  train f1: 0.00000  lr: 0.0007620365140176869 batch: 21 
epochs: 0 val loss: 4.36328125  val f1:0.00000  lr: 0.0007620365140176869 batch: 21
epochs: 1 train loss: 4.3515625  train f1: 0.00000  lr: 0.0007620365140176869 batch: 21 
epochs: 1 val loss: 4.5703125  val f1:0.12500  lr: 0.0007620365140176869 batch: 21
epochs: 0 train loss: 5.05859375  train f1: 0.00000  lr: 0.0009266905761544198 batch: 28 
epochs: 0 val loss: 4.89453125  val f1:0.00000  lr: 0.0009266905761544198 batch: 28
epochs: 1 train loss: 4.98828125  train f1: 0.00000  lr: 0.0009266905761544198 batch: 28 
epochs: 1 val loss: 5.33984375  val f1:0.00000  lr: 0.0009266905761544198 batch: 28
epochs: 0 train loss: 4.578125  train f1: 0.00000  lr: 0.00035932594328312735 batch: 30 
epochs: 0 val loss: 5.09375  val f1:0.00000  lr: 0.00035932594328312735 batch: 30
epochs: 1 train loss: 4.578125  train f1: 0.00000  lr: 0.00035932594328312735 batch: 30 
epochs: 1 val loss: 3.982421875  val f1:0.12500  lr: 0.00035932594328312735 batch: 30
epochs: 0 train loss: 4.6015625  train f1: 0.00000  lr: 0.0022849072213570716 batch: 27 
epochs: 0 val loss: 4.39453125  val f1:0.00000  lr: 0.0022849072213570716 batch: 27
epochs: 1 train loss: 4.71875  train f1: 0.00000  lr: 0.0022849072213570716 batch: 27 
epochs: 1 val loss: 4020.0  val f1:0.00000  lr: 0.0022849072213570716 batch: 27
epochs: 0 train loss: 5.17578125  train f1: 0.00000  lr: 0.00024658136409598226 batch: 20 
epochs: 0 val loss: 4.56640625  val f1:0.00000  lr: 0.00024658136409598226 batch: 20
epochs: 1 train loss: 5.34375  train f1: 0.00000  lr: 0.00024658136409598226 batch: 20 
epochs: 1 val loss: 3.943359375  val f1:0.11111  lr: 0.00024658136409598226 batch: 20
epochs: 0 train loss: 4.5078125  train f1: 0.00000  lr: 0.0003108840448926699 batch: 22 
epochs: 0 val loss: 5.0390625  val f1:0.00000  lr: 0.0003108840448926699 batch: 22
epochs: 1 train loss: 4.453125  train f1: 0.00000  lr: 0.0003108840448926699 batch: 22 
epochs: 1 val loss: 4.53515625  val f1:0.12500  lr: 0.0003108840448926699 batch: 22
epochs: 0 train loss: 5.33203125  train f1: 0.00000  lr: 0.0006251660895571786 batch: 25 
epochs: 0 val loss: 5.19921875  val f1:0.00000  lr: 0.0006251660895571786 batch: 25
epochs: 1 train loss: 5.421875  train f1: 0.00000  lr: 0.0006251660895571786 batch: 25 
epochs: 1 val loss: 4.54296875  val f1:0.16667  lr: 0.0006251660895571786 batch: 25
epochs: 2 train loss: 0.415283203125  train f1: 1.00000  lr: 0.0006251660895571786 batch: 25 
epochs: 2 val loss: 6.796875  val f1:0.00000  lr: 0.0006251660895571786 batch: 25
epochs: 3 train loss: 0.98583984375  train f1: 1.00000  lr: 0.0006251660895571786 batch: 25 
epochs: 3 val loss: 4.97265625  val f1:0.14286  lr: 0.0006251660895571786 batch: 25
epochs: 4 train loss: 0.016510009765625  train f1: 1.00000  lr: 0.0006251660895571786 batch: 25 
epochs: 4 val loss: 6.28125  val f1:0.16667  lr: 0.0006251660895571786 batch: 25
epochs: 5 train loss: 3.5762786865234375e-05  train f1: 1.00000  lr: 0.0006251660895571786 batch: 25 
epochs: 5 val loss: 7.3125  val f1:0.16667  lr: 0.0006251660895571786 batch: 25
epochs: 6 train loss: 3.2901763916015625e-05  train f1: 1.00000  lr: 0.0006251660895571786 batch: 25 
epochs: 6 val loss: 8.203125  val f1:0.14286  lr: 0.0006251660895571786 batch: 25
epochs: 7 train loss: 3.635883331298828e-05  train f1: 1.00000  lr: 0.0006251660895571786 batch: 25 
epochs: 7 val loss: 8.703125  val f1:0.14286  lr: 0.0006251660895571786 batch: 25
epochs: 8 train loss: 2.7120113372802734e-05  train f1: 1.00000  lr: 0.0006251660895571786 batch: 25 
epochs: 8 val loss: 8.4609375  val f1:0.14286  lr: 0.0006251660895571786 batch: 25
epochs: 9 train loss: 2.014636993408203e-05  train f1: 1.00000  lr: 0.0006251660895571786 batch: 25 
epochs: 9 val loss: 8.1875  val f1:0.14286  lr: 0.0006251660895571786 batch: 25
epochs: 10 train loss: 3.170967102050781e-05  train f1: 1.00000  lr: 0.0006251660895571786 batch: 25 
epochs: 10 val loss: 7.90234375  val f1:0.14286  lr: 0.0006251660895571786 batch: 25
epochs: 11 train loss: 2.473592758178711e-05  train f1: 1.00000  lr: 0.0006251660895571786 batch: 25 
epochs: 11 val loss: 7.74609375  val f1:0.14286  lr: 0.0006251660895571786 batch: 25
epochs: 12 train loss: 3.314018249511719e-05  train f1: 1.00000  lr: 0.0006251660895571786 batch: 25 
epochs: 12 val loss: 7.609375  val f1:0.14286  lr: 0.0006251660895571786 batch: 25
epochs: 0 train loss: 4.81640625  train f1: 0.00000  lr: 0.00042268854529797366 batch: 26 
epochs: 0 val loss: 4.37109375  val f1:0.00000  lr: 0.00042268854529797366 batch: 26
epochs: 1 train loss: 4.953125  train f1: 0.00000  lr: 0.00042268854529797366 batch: 26 
epochs: 1 val loss: 3.7421875  val f1:0.12500  lr: 0.00042268854529797366 batch: 26
epochs: 0 train loss: 5.05078125  train f1: 0.00000  lr: 0.0004724792465535337 batch: 24 
epochs: 0 val loss: 4.7109375  val f1:0.00000  lr: 0.0004724792465535337 batch: 24
epochs: 1 train loss: 5.0234375  train f1: 0.00000  lr: 0.0004724792465535337 batch: 24 
epochs: 1 val loss: 3.966796875  val f1:0.16667  lr: 0.0004724792465535337 batch: 24
epochs: 2 train loss: 0.822265625  train f1: 1.00000  lr: 0.0004724792465535337 batch: 24 
epochs: 2 val loss: 11.28125  val f1:0.14286  lr: 0.0004724792465535337 batch: 24
epochs: 3 train loss: 2.044921875  train f1: 0.50000  lr: 0.0004724792465535337 batch: 24 
epochs: 3 val loss: 5.66796875  val f1:0.08333  lr: 0.0004724792465535337 batch: 24
epochs: 4 train loss: 0.01128387451171875  train f1: 1.00000  lr: 0.0004724792465535337 batch: 24 
epochs: 4 val loss: 5.87109375  val f1:0.08333  lr: 0.0004724792465535337 batch: 24
epochs: 5 train loss: 4.6372413635253906e-05  train f1: 1.00000  lr: 0.0004724792465535337 batch: 24 
epochs: 5 val loss: 6.30078125  val f1:0.08333  lr: 0.0004724792465535337 batch: 24
epochs: 6 train loss: 9.21487808227539e-05  train f1: 1.00000  lr: 0.0004724792465535337 batch: 24 
epochs: 6 val loss: 6.74609375  val f1:0.11111  lr: 0.0004724792465535337 batch: 24
epochs: 7 train loss: 0.00010651350021362305  train f1: 1.00000  lr: 0.0004724792465535337 batch: 24 
epochs: 7 val loss: 7.08984375  val f1:0.11111  lr: 0.0004724792465535337 batch: 24
epochs: 8 train loss: 4.380941390991211e-05  train f1: 1.00000  lr: 0.0004724792465535337 batch: 24 
epochs: 8 val loss: 7.4140625  val f1:0.11111  lr: 0.0004724792465535337 batch: 24
epochs: 9 train loss: 9.524822235107422e-05  train f1: 1.00000  lr: 0.0004724792465535337 batch: 24 
epochs: 9 val loss: 7.62109375  val f1:0.11111  lr: 0.0004724792465535337 batch: 24
epochs: 10 train loss: 5.161762237548828e-05  train f1: 1.00000  lr: 0.0004724792465535337 batch: 24 
epochs: 10 val loss: 7.66796875  val f1:0.14286  lr: 0.0004724792465535337 batch: 24
epochs: 0 train loss: 4.015625  train f1: 0.00000  lr: 0.0005500759639746802 batch: 21 
epochs: 0 val loss: 5.25390625  val f1:0.00000  lr: 0.0005500759639746802 batch: 21
epochs: 1 train loss: 4.12890625  train f1: 0.11111  lr: 0.0005500759639746802 batch: 21 
epochs: 1 val loss: 3.939453125  val f1:0.14286  lr: 0.0005500759639746802 batch: 21
epochs: 2 train loss: 0.5732421875  train f1: 1.00000  lr: 0.0005500759639746802 batch: 21 
epochs: 2 val loss: 4.71875  val f1:0.00000  lr: 0.0005500759639746802 batch: 21
epochs: 3 train loss: 0.442626953125  train f1: 1.00000  lr: 0.0005500759639746802 batch: 21 
epochs: 3 val loss: 9.265625  val f1:0.14286  lr: 0.0005500759639746802 batch: 21
epochs: 4 train loss: 0.0012798309326171875  train f1: 1.00000  lr: 0.0005500759639746802 batch: 21 
epochs: 4 val loss: 8.9609375  val f1:0.14286  lr: 0.0005500759639746802 batch: 21
epochs: 5 train loss: 2.7060508728027344e-05  train f1: 1.00000  lr: 0.0005500759639746802 batch: 21 
epochs: 5 val loss: 8.5234375  val f1:0.14286  lr: 0.0005500759639746802 batch: 21
epochs: 6 train loss: 6.449222564697266e-05  train f1: 1.00000  lr: 0.0005500759639746802 batch: 21 
epochs: 6 val loss: 8.2890625  val f1:0.16667  lr: 0.0005500759639746802 batch: 21
epochs: 7 train loss: 1.4126300811767578e-05  train f1: 1.00000  lr: 0.0005500759639746802 batch: 21 
epochs: 7 val loss: 7.9765625  val f1:0.16667  lr: 0.0005500759639746802 batch: 21
epochs: 8 train loss: 3.30805778503418e-05  train f1: 1.00000  lr: 0.0005500759639746802 batch: 21 
epochs: 8 val loss: 7.33984375  val f1:0.16667  lr: 0.0005500759639746802 batch: 21
epochs: 9 train loss: 0.0001628398895263672  train f1: 1.00000  lr: 0.0005500759639746802 batch: 21 
epochs: 9 val loss: 6.9296875  val f1:0.16667  lr: 0.0005500759639746802 batch: 21
epochs: 0 train loss: 4.46484375  train f1: 0.00000  lr: 0.0007397805635070925 batch: 20 
epochs: 0 val loss: 5.08203125  val f1:0.00000  lr: 0.0007397805635070925 batch: 20
epochs: 1 train loss: 4.51953125  train f1: 0.00000  lr: 0.0007397805635070925 batch: 20 
epochs: 1 val loss: 5.0  val f1:0.00000  lr: 0.0007397805635070925 batch: 20
epochs: 0 train loss: 5.02734375  train f1: 0.00000  lr: 0.0011631562712126951 batch: 24 
epochs: 0 val loss: 4.69140625  val f1:0.00000  lr: 0.0011631562712126951 batch: 24
epochs: 1 train loss: 5.01953125  train f1: 0.00000  lr: 0.0011631562712126951 batch: 24 
epochs: 1 val loss: 7.37890625  val f1:0.11111  lr: 0.0011631562712126951 batch: 24
epochs: 0 train loss: 3.90625  train f1: 0.00000  lr: 0.0005549616102176671 batch: 21 
epochs: 0 val loss: 4.89453125  val f1:0.00000  lr: 0.0005549616102176671 batch: 21
epochs: 1 train loss: 3.87890625  train f1: 0.00000  lr: 0.0005549616102176671 batch: 21 
epochs: 1 val loss: 4.04296875  val f1:0.14286  lr: 0.0005549616102176671 batch: 21
epochs: 2 train loss: 0.3193359375  train f1: 1.00000  lr: 0.0005549616102176671 batch: 21 
epochs: 2 val loss: 9.1640625  val f1:0.00000  lr: 0.0005549616102176671 batch: 21
epochs: 3 train loss: 1.056640625  train f1: 0.50000  lr: 0.0005549616102176671 batch: 21 
epochs: 3 val loss: 8.9296875  val f1:0.14286  lr: 0.0005549616102176671 batch: 21
epochs: 4 train loss: 0.0010366439819335938  train f1: 1.00000  lr: 0.0005549616102176671 batch: 21 
epochs: 4 val loss: 8.484375  val f1:0.14286  lr: 0.0005549616102176671 batch: 21
epochs: 5 train loss: 0.0002319812774658203  train f1: 1.00000  lr: 0.0005549616102176671 batch: 21 
epochs: 5 val loss: 8.09375  val f1:0.14286  lr: 0.0005549616102176671 batch: 21
epochs: 6 train loss: 0.00023543834686279297  train f1: 1.00000  lr: 0.0005549616102176671 batch: 21 
epochs: 6 val loss: 7.515625  val f1:0.14286  lr: 0.0005549616102176671 batch: 21
epochs: 7 train loss: 0.00034737586975097656  train f1: 1.00000  lr: 0.0005549616102176671 batch: 21 
epochs: 7 val loss: 7.41796875  val f1:0.14286  lr: 0.0005549616102176671 batch: 21
epochs: 8 train loss: 0.00024008750915527344  train f1: 1.00000  lr: 0.0005549616102176671 batch: 21 
epochs: 8 val loss: 6.9296875  val f1:0.14286  lr: 0.0005549616102176671 batch: 21
epochs: 9 train loss: 0.0001506805419921875  train f1: 1.00000  lr: 0.0005549616102176671 batch: 21 
epochs: 9 val loss: 6.72265625  val f1:0.14286  lr: 0.0005549616102176671 batch: 21
epochs: 10 train loss: 6.395578384399414e-05  train f1: 1.00000  lr: 0.0005549616102176671 batch: 21 
epochs: 10 val loss: 6.64453125  val f1:0.14286  lr: 0.0005549616102176671 batch: 21
epochs: 11 train loss: 9.679794311523438e-05  train f1: 1.00000  lr: 0.0005549616102176671 batch: 21 
epochs: 11 val loss: 6.65625  val f1:0.14286  lr: 0.0005549616102176671 batch: 21
epochs: 0 train loss: 4.88671875  train f1: 0.00000  lr: 0.0005952869066563985 batch: 23 
epochs: 0 val loss: 5.48046875  val f1:0.00000  lr: 0.0005952869066563985 batch: 23
epochs: 1 train loss: 4.6171875  train f1: 0.00000  lr: 0.0005952869066563985 batch: 23 
epochs: 1 val loss: 4.9453125  val f1:0.14286  lr: 0.0005952869066563985 batch: 23
epochs: 2 train loss: 0.1151123046875  train f1: 1.00000  lr: 0.0005952869066563985 batch: 23 
epochs: 2 val loss: 12.6484375  val f1:0.14286  lr: 0.0005952869066563985 batch: 23
epochs: 3 train loss: 1.21875  train f1: 0.50000  lr: 0.0005952869066563985 batch: 23 
epochs: 3 val loss: 5.28125  val f1:0.14286  lr: 0.0005952869066563985 batch: 23
epochs: 4 train loss: 0.0005588531494140625  train f1: 1.00000  lr: 0.0005952869066563985 batch: 23 
epochs: 4 val loss: 4.1484375  val f1:0.14286  lr: 0.0005952869066563985 batch: 23
epochs: 5 train loss: 0.00024199485778808594  train f1: 1.00000  lr: 0.0005952869066563985 batch: 23 
epochs: 5 val loss: 3.654296875  val f1:0.14286  lr: 0.0005952869066563985 batch: 23
epochs: 6 train loss: 0.00034117698669433594  train f1: 1.00000  lr: 0.0005952869066563985 batch: 23 
epochs: 6 val loss: 3.6171875  val f1:0.14286  lr: 0.0005952869066563985 batch: 23
epochs: 7 train loss: 0.00015628337860107422  train f1: 1.00000  lr: 0.0005952869066563985 batch: 23 
epochs: 7 val loss: 3.505859375  val f1:0.14286  lr: 0.0005952869066563985 batch: 23
epochs: 8 train loss: 8.690357208251953e-05  train f1: 1.00000  lr: 0.0005952869066563985 batch: 23 
epochs: 8 val loss: 3.46484375  val f1:0.14286  lr: 0.0005952869066563985 batch: 23
epochs: 9 train loss: 0.00019943714141845703  train f1: 1.00000  lr: 0.0005952869066563985 batch: 23 
epochs: 9 val loss: 3.4453125  val f1:0.14286  lr: 0.0005952869066563985 batch: 23
epochs: 10 train loss: 0.0001264810562133789  train f1: 1.00000  lr: 0.0005952869066563985 batch: 23 
epochs: 10 val loss: 3.458984375  val f1:0.12500  lr: 0.0005952869066563985 batch: 23
epochs: 11 train loss: 8.90493392944336e-05  train f1: 1.00000  lr: 0.0005952869066563985 batch: 23 
epochs: 11 val loss: 3.478515625  val f1:0.12500  lr: 0.0005952869066563985 batch: 23
epochs: 12 train loss: 0.00015354156494140625  train f1: 1.00000  lr: 0.0005952869066563985 batch: 23 
epochs: 12 val loss: 3.52734375  val f1:0.12500  lr: 0.0005952869066563985 batch: 23
epochs: 0 train loss: 4.984375  train f1: 0.00000  lr: 0.0008545235666030161 batch: 19 
epochs: 0 val loss: 5.31640625  val f1:0.00000  lr: 0.0008545235666030161 batch: 19
epochs: 1 train loss: 4.97265625  train f1: 0.00000  lr: 0.0008545235666030161 batch: 19 
epochs: 1 val loss: 6.0859375  val f1:0.14286  lr: 0.0008545235666030161 batch: 19
epochs: 2 train loss: 0.31396484375  train f1: 1.00000  lr: 0.0008545235666030161 batch: 19 
epochs: 2 val loss: 6.23828125  val f1:0.00000  lr: 0.0008545235666030161 batch: 19
epochs: 3 train loss: 2.66015625  train f1: 0.20000  lr: 0.0008545235666030161 batch: 19 
epochs: 3 val loss: 83.125  val f1:0.00000  lr: 0.0008545235666030161 batch: 19
epochs: 4 train loss: 0.00035953521728515625  train f1: 1.00000  lr: 0.0008545235666030161 batch: 19 
epochs: 4 val loss: 62.34375  val f1:0.00000  lr: 0.0008545235666030161 batch: 19
epochs: 5 train loss: 0.0002493858337402344  train f1: 1.00000  lr: 0.0008545235666030161 batch: 19 
epochs: 5 val loss: 48.71875  val f1:0.00000  lr: 0.0008545235666030161 batch: 19
epochs: 6 train loss: 0.0011568069458007812  train f1: 1.00000  lr: 0.0008545235666030161 batch: 19 
epochs: 6 val loss: 40.46875  val f1:0.00000  lr: 0.0008545235666030161 batch: 19
epochs: 7 train loss: 0.0001862049102783203  train f1: 1.00000  lr: 0.0008545235666030161 batch: 19 
epochs: 7 val loss: 34.84375  val f1:0.00000  lr: 0.0008545235666030161 batch: 19
epochs: 0 train loss: 4.6171875  train f1: 0.00000  lr: 0.0005385970597441343 batch: 21 
epochs: 0 val loss: 5.33984375  val f1:0.00000  lr: 0.0005385970597441343 batch: 21
epochs: 1 train loss: 4.62109375  train f1: 0.00000  lr: 0.0005385970597441343 batch: 21 
epochs: 1 val loss: 5.87109375  val f1:0.14286  lr: 0.0005385970597441343 batch: 21
epochs: 2 train loss: 0.10791015625  train f1: 1.00000  lr: 0.0005385970597441343 batch: 21 
epochs: 2 val loss: 4.35546875  val f1:0.14286  lr: 0.0005385970597441343 batch: 21
epochs: 3 train loss: 0.9423828125  train f1: 1.00000  lr: 0.0005385970597441343 batch: 21 
epochs: 3 val loss: 15.46875  val f1:0.16667  lr: 0.0005385970597441343 batch: 21
epochs: 4 train loss: 0.0002512931823730469  train f1: 1.00000  lr: 0.0005385970597441343 batch: 21 
epochs: 4 val loss: 13.9765625  val f1:0.16667  lr: 0.0005385970597441343 batch: 21
epochs: 5 train loss: 2.4020671844482422e-05  train f1: 1.00000  lr: 0.0005385970597441343 batch: 21 
epochs: 5 val loss: 12.828125  val f1:0.16667  lr: 0.0005385970597441343 batch: 21
epochs: 6 train loss: 9.453296661376953e-05  train f1: 1.00000  lr: 0.0005385970597441343 batch: 21 
epochs: 6 val loss: 11.59375  val f1:0.16667  lr: 0.0005385970597441343 batch: 21
epochs: 7 train loss: 8.636713027954102e-05  train f1: 1.00000  lr: 0.0005385970597441343 batch: 21 
epochs: 7 val loss: 10.5234375  val f1:0.16667  lr: 0.0005385970597441343 batch: 21
epochs: 8 train loss: 2.562999725341797e-05  train f1: 1.00000  lr: 0.0005385970597441343 batch: 21 
epochs: 8 val loss: 9.578125  val f1:0.16667  lr: 0.0005385970597441343 batch: 21
epochs: 9 train loss: 5.424022674560547e-05  train f1: 1.00000  lr: 0.0005385970597441343 batch: 21 
epochs: 9 val loss: 8.7890625  val f1:0.16667  lr: 0.0005385970597441343 batch: 21
epochs: 10 train loss: 2.0742416381835938e-05  train f1: 1.00000  lr: 0.0005385970597441343 batch: 21 
epochs: 10 val loss: 8.4453125  val f1:0.16667  lr: 0.0005385970597441343 batch: 21
epochs: 11 train loss: 1.9788742065429688e-05  train f1: 1.00000  lr: 0.0005385970597441343 batch: 21 
epochs: 11 val loss: 8.40625  val f1:0.16667  lr: 0.0005385970597441343 batch: 21
epochs: 0 train loss: 4.5625  train f1: 0.00000  lr: 0.00036399402203356873 batch: 21 
epochs: 0 val loss: 4.75  val f1:0.00000  lr: 0.00036399402203356873 batch: 21
epochs: 1 train loss: 4.515625  train f1: 0.00000  lr: 0.00036399402203356873 batch: 21 
epochs: 1 val loss: 3.533203125  val f1:0.12500  lr: 0.00036399402203356873 batch: 21
epochs: 0 train loss: 5.14453125  train f1: 0.00000  lr: 0.0006822155850586537 batch: 22 
epochs: 0 val loss: 4.85546875  val f1:0.00000  lr: 0.0006822155850586537 batch: 22
epochs: 1 train loss: 5.0625  train f1: 0.00000  lr: 0.0006822155850586537 batch: 22 
epochs: 1 val loss: 4.94921875  val f1:0.00000  lr: 0.0006822155850586537 batch: 22
epochs: 0 train loss: 4.45703125  train f1: 0.00000  lr: 0.0005203094269510384 batch: 21 
epochs: 0 val loss: 4.4140625  val f1:0.00000  lr: 0.0005203094269510384 batch: 21
epochs: 1 train loss: 4.3828125  train f1: 0.00000  lr: 0.0005203094269510384 batch: 21 
epochs: 1 val loss: 4.296875  val f1:0.12500  lr: 0.0005203094269510384 batch: 21
epochs: 0 train loss: 4.0390625  train f1: 0.11111  lr: 0.0009189302472113862 batch: 23 
epochs: 0 val loss: 4.2421875  val f1:0.00000  lr: 0.0009189302472113862 batch: 23
epochs: 1 train loss: 4.08984375  train f1: 0.00000  lr: 0.0009189302472113862 batch: 23 
epochs: 1 val loss: 4.30859375  val f1:0.08333  lr: 0.0009189302472113862 batch: 23
epochs: 0 train loss: 4.734375  train f1: 0.00000  lr: 0.00042342020655002685 batch: 20 
epochs: 0 val loss: 5.2578125  val f1:0.00000  lr: 0.00042342020655002685 batch: 20
epochs: 1 train loss: 4.8203125  train f1: 0.00000  lr: 0.00042342020655002685 batch: 20 
epochs: 1 val loss: 4.8984375  val f1:0.00000  lr: 0.00042342020655002685 batch: 20
epochs: 0 train loss: 3.896484375  train f1: 0.16667  lr: 0.0007349359758803331 batch: 19 
epochs: 0 val loss: 5.07421875  val f1:0.00000  lr: 0.0007349359758803331 batch: 19
epochs: 1 train loss: 4.06640625  train f1: 0.00000  lr: 0.0007349359758803331 batch: 19 
epochs: 1 val loss: 4.13671875  val f1:0.12500  lr: 0.0007349359758803331 batch: 19
epochs: 0 train loss: 4.0703125  train f1: 0.00000  lr: 0.0005691910280499172 batch: 22 
epochs: 0 val loss: 5.421875  val f1:0.00000  lr: 0.0005691910280499172 batch: 22
epochs: 1 train loss: 4.08203125  train f1: 0.00000  lr: 0.0005691910280499172 batch: 22 
epochs: 1 val loss: 5.1484375  val f1:0.14286  lr: 0.0005691910280499172 batch: 22
epochs: 2 train loss: 0.8505859375  train f1: 1.00000  lr: 0.0005691910280499172 batch: 22 
epochs: 2 val loss: 23.109375  val f1:0.00000  lr: 0.0005691910280499172 batch: 22
epochs: 3 train loss: 1.7607421875  train f1: 0.66667  lr: 0.0005691910280499172 batch: 22 
epochs: 3 val loss: 10.3359375  val f1:0.14286  lr: 0.0005691910280499172 batch: 22
epochs: 4 train loss: 0.0003228187561035156  train f1: 1.00000  lr: 0.0005691910280499172 batch: 22 
epochs: 4 val loss: 10.6796875  val f1:0.14286  lr: 0.0005691910280499172 batch: 22
epochs: 5 train loss: 0.00021064281463623047  train f1: 1.00000  lr: 0.0005691910280499172 batch: 22 
epochs: 5 val loss: 11.0625  val f1:0.14286  lr: 0.0005691910280499172 batch: 22
epochs: 6 train loss: 0.00014793872833251953  train f1: 1.00000  lr: 0.0005691910280499172 batch: 22 
epochs: 6 val loss: 10.7421875  val f1:0.14286  lr: 0.0005691910280499172 batch: 22
epochs: 7 train loss: 0.00022852420806884766  train f1: 1.00000  lr: 0.0005691910280499172 batch: 22 
epochs: 7 val loss: 10.421875  val f1:0.14286  lr: 0.0005691910280499172 batch: 22
epochs: 8 train loss: 0.00017273426055908203  train f1: 1.00000  lr: 0.0005691910280499172 batch: 22 
epochs: 8 val loss: 10.2265625  val f1:0.14286  lr: 0.0005691910280499172 batch: 22
epochs: 9 train loss: 0.0002613067626953125  train f1: 1.00000  lr: 0.0005691910280499172 batch: 22 
epochs: 9 val loss: 10.3046875  val f1:0.14286  lr: 0.0005691910280499172 batch: 22
epochs: 10 train loss: 0.0001671314239501953  train f1: 1.00000  lr: 0.0005691910280499172 batch: 22 
epochs: 10 val loss: 10.34375  val f1:0.14286  lr: 0.0005691910280499172 batch: 22
epochs: 11 train loss: 9.98377799987793e-05  train f1: 1.00000  lr: 0.0005691910280499172 batch: 22 
epochs: 11 val loss: 10.0390625  val f1:0.14286  lr: 0.0005691910280499172 batch: 22
epochs: 0 train loss: 4.51953125  train f1: 0.00000  lr: 0.0009911870294234501 batch: 14 
epochs: 0 val loss: 5.2578125  val f1:0.00000  lr: 0.0009911870294234501 batch: 14
epochs: 1 train loss: 4.3125  train f1: 0.00000  lr: 0.0009911870294234501 batch: 14 
epochs: 1 val loss: 11.3359375  val f1:0.00000  lr: 0.0009911870294234501 batch: 14
epochs: 0 train loss: 4.734375  train f1: 0.00000  lr: 0.00043889429696918704 batch: 22 
epochs: 0 val loss: 4.828125  val f1:0.00000  lr: 0.00043889429696918704 batch: 22
epochs: 1 train loss: 4.68359375  train f1: 0.00000  lr: 0.00043889429696918704 batch: 22 
epochs: 1 val loss: 3.8671875  val f1:0.16667  lr: 0.00043889429696918704 batch: 22
epochs: 2 train loss: 0.1265869140625  train f1: 1.00000  lr: 0.00043889429696918704 batch: 22 
epochs: 2 val loss: 5.16796875  val f1:0.14286  lr: 0.00043889429696918704 batch: 22
epochs: 3 train loss: 1.0830078125  train f1: 1.00000  lr: 0.00043889429696918704 batch: 22 
epochs: 3 val loss: 4.41015625  val f1:0.14286  lr: 0.00043889429696918704 batch: 22
epochs: 4 train loss: 0.396484375  train f1: 1.00000  lr: 0.00043889429696918704 batch: 22 
epochs: 4 val loss: 23.984375  val f1:0.14286  lr: 0.00043889429696918704 batch: 22
epochs: 5 train loss: 3.999471664428711e-05  train f1: 1.00000  lr: 0.00043889429696918704 batch: 22 
epochs: 5 val loss: 17.125  val f1:0.14286  lr: 0.00043889429696918704 batch: 22
epochs: 6 train loss: 2.396106719970703e-05  train f1: 1.00000  lr: 0.00043889429696918704 batch: 22 
epochs: 6 val loss: 13.078125  val f1:0.14286  lr: 0.00043889429696918704 batch: 22
epochs: 7 train loss: 1.3470649719238281e-05  train f1: 1.00000  lr: 0.00043889429696918704 batch: 22 
epochs: 7 val loss: 10.03125  val f1:0.14286  lr: 0.00043889429696918704 batch: 22
epochs: 8 train loss: 2.6702880859375e-05  train f1: 1.00000  lr: 0.00043889429696918704 batch: 22 
epochs: 8 val loss: 8.1953125  val f1:0.14286  lr: 0.00043889429696918704 batch: 22
epochs: 9 train loss: 1.4781951904296875e-05  train f1: 1.00000  lr: 0.00043889429696918704 batch: 22 
epochs: 9 val loss: 6.90625  val f1:0.14286  lr: 0.00043889429696918704 batch: 22
epochs: 10 train loss: 1.8477439880371094e-05  train f1: 1.00000  lr: 0.00043889429696918704 batch: 22 
epochs: 10 val loss: 6.13671875  val f1:0.14286  lr: 0.00043889429696918704 batch: 22
epochs: 11 train loss: 1.817941665649414e-05  train f1: 1.00000  lr: 0.00043889429696918704 batch: 22 
epochs: 11 val loss: 5.39453125  val f1:0.14286  lr: 0.00043889429696918704 batch: 22
epochs: 0 train loss: 4.21875  train f1: 0.13333  lr: 0.0004742969828992103 batch: 21 
epochs: 0 val loss: 4.0625  val f1:0.00000  lr: 0.0004742969828992103 batch: 21
epochs: 1 train loss: 4.34375  train f1: 0.00000  lr: 0.0004742969828992103 batch: 21 
epochs: 1 val loss: 3.34765625  val f1:0.12500  lr: 0.0004742969828992103 batch: 21
epochs: 0 train loss: 5.1796875  train f1: 0.00000  lr: 0.0005241132023931989 batch: 22 
epochs: 0 val loss: 5.18359375  val f1:0.00000  lr: 0.0005241132023931989 batch: 22
epochs: 1 train loss: 5.1484375  train f1: 0.00000  lr: 0.0005241132023931989 batch: 22 
epochs: 1 val loss: 4.59375  val f1:0.11111  lr: 0.0005241132023931989 batch: 22
epochs: 0 train loss: 4.5546875  train f1: 0.00000  lr: 0.0003293188024638008 batch: 21 
epochs: 0 val loss: 4.79296875  val f1:0.00000  lr: 0.0003293188024638008 batch: 21
epochs: 1 train loss: 4.6484375  train f1: 0.00000  lr: 0.0003293188024638008 batch: 21 
epochs: 1 val loss: 3.66015625  val f1:0.11111  lr: 0.0003293188024638008 batch: 21
epochs: 0 train loss: 5.5859375  train f1: 0.00000  lr: 0.0006508189663576729 batch: 27 
epochs: 0 val loss: 4.6875  val f1:0.00000  lr: 0.0006508189663576729 batch: 27
epochs: 1 train loss: 5.40625  train f1: 0.00000  lr: 0.0006508189663576729 batch: 27 
epochs: 1 val loss: 4.46875  val f1:0.11111  lr: 0.0006508189663576729 batch: 27
epochs: 0 train loss: 4.46875  train f1: 0.00000  lr: 0.0004810548273534107 batch: 23 
epochs: 0 val loss: 4.51171875  val f1:0.00000  lr: 0.0004810548273534107 batch: 23
epochs: 1 train loss: 4.4765625  train f1: 0.00000  lr: 0.0004810548273534107 batch: 23 
epochs: 1 val loss: 3.478515625  val f1:0.14286  lr: 0.0004810548273534107 batch: 23
epochs: 2 train loss: 0.578125  train f1: 1.00000  lr: 0.0004810548273534107 batch: 23 
epochs: 2 val loss: 5.9765625  val f1:0.14286  lr: 0.0004810548273534107 batch: 23
epochs: 3 train loss: 0.9091796875  train f1: 1.00000  lr: 0.0004810548273534107 batch: 23 
epochs: 3 val loss: 3.6796875  val f1:0.16667  lr: 0.0004810548273534107 batch: 23
epochs: 4 train loss: 0.319091796875  train f1: 1.00000  lr: 0.0004810548273534107 batch: 23 
epochs: 4 val loss: 3.669921875  val f1:0.12500  lr: 0.0004810548273534107 batch: 23
epochs: 5 train loss: 0.0042724609375  train f1: 1.00000  lr: 0.0004810548273534107 batch: 23 
epochs: 5 val loss: 3.634765625  val f1:0.14286  lr: 0.0004810548273534107 batch: 23
epochs: 6 train loss: 0.0002868175506591797  train f1: 1.00000  lr: 0.0004810548273534107 batch: 23 
epochs: 6 val loss: 3.60546875  val f1:0.14286  lr: 0.0004810548273534107 batch: 23
epochs: 7 train loss: 0.00021946430206298828  train f1: 1.00000  lr: 0.0004810548273534107 batch: 23 
epochs: 7 val loss: 3.59765625  val f1:0.14286  lr: 0.0004810548273534107 batch: 23
epochs: 8 train loss: 0.00013315677642822266  train f1: 1.00000  lr: 0.0004810548273534107 batch: 23 
epochs: 8 val loss: 3.578125  val f1:0.14286  lr: 0.0004810548273534107 batch: 23
epochs: 9 train loss: 0.00016176700592041016  train f1: 1.00000  lr: 0.0004810548273534107 batch: 23 
epochs: 9 val loss: 3.548828125  val f1:0.14286  lr: 0.0004810548273534107 batch: 23
epochs: 10 train loss: 0.0001062154769897461  train f1: 1.00000  lr: 0.0004810548273534107 batch: 23 
epochs: 10 val loss: 3.53515625  val f1:0.14286  lr: 0.0004810548273534107 batch: 23
epochs: 0 train loss: 4.4375  train f1: 0.00000  lr: 0.0007205699003537233 batch: 25 
epochs: 0 val loss: 4.77734375  val f1:0.00000  lr: 0.0007205699003537233 batch: 25
epochs: 1 train loss: 4.53515625  train f1: 0.00000  lr: 0.0007205699003537233 batch: 25 
epochs: 1 val loss: 6.98046875  val f1:0.11111  lr: 0.0007205699003537233 batch: 25
epochs: 0 train loss: 5.046875  train f1: 0.00000  lr: 0.0003663791818997311 batch: 12 
epochs: 0 val loss: 5.0546875  val f1:0.00000  lr: 0.0003663791818997311 batch: 12
epochs: 1 train loss: 4.953125  train f1: 0.00000  lr: 0.0003663791818997311 batch: 12 
epochs: 1 val loss: 4.82421875  val f1:0.11111  lr: 0.0003663791818997311 batch: 12
epochs: 0 train loss: 5.2578125  train f1: 0.00000  lr: 0.00020011547510332602 batch: 31 
epochs: 0 val loss: 5.29296875  val f1:0.00000  lr: 0.00020011547510332602 batch: 31
epochs: 1 train loss: 5.13671875  train f1: 0.00000  lr: 0.00020011547510332602 batch: 31 
epochs: 1 val loss: 4.7734375  val f1:0.11111  lr: 0.00020011547510332602 batch: 31
epochs: 0 train loss: 4.2109375  train f1: 0.00000  lr: 0.00040379384998410984 batch: 25 
epochs: 0 val loss: 5.06640625  val f1:0.00000  lr: 0.00040379384998410984 batch: 25
epochs: 1 train loss: 4.19921875  train f1: 0.00000  lr: 0.00040379384998410984 batch: 25 
epochs: 1 val loss: 4.484375  val f1:0.12500  lr: 0.00040379384998410984 batch: 25
epochs: 0 train loss: 4.6875  train f1: 0.16667  lr: 0.00024989956042872685 batch: 23 
epochs: 0 val loss: 5.359375  val f1:0.00000  lr: 0.00024989956042872685 batch: 23
epochs: 1 train loss: 4.703125  train f1: 0.16667  lr: 0.00024989956042872685 batch: 23 
epochs: 1 val loss: 4.90234375  val f1:0.14286  lr: 0.00024989956042872685 batch: 23
epochs: 2 train loss: 0.677734375  train f1: 1.00000  lr: 0.00024989956042872685 batch: 23 
epochs: 2 val loss: 4.203125  val f1:0.12500  lr: 0.00024989956042872685 batch: 23
epochs: 3 train loss: 0.521484375  train f1: 1.00000  lr: 0.00024989956042872685 batch: 23 
epochs: 3 val loss: 4.73046875  val f1:0.14286  lr: 0.00024989956042872685 batch: 23
epochs: 4 train loss: 0.0011777877807617188  train f1: 1.00000  lr: 0.00024989956042872685 batch: 23 
epochs: 4 val loss: 4.62890625  val f1:0.14286  lr: 0.00024989956042872685 batch: 23
epochs: 5 train loss: 0.0006356239318847656  train f1: 1.00000  lr: 0.00024989956042872685 batch: 23 
epochs: 5 val loss: 4.5703125  val f1:0.12500  lr: 0.00024989956042872685 batch: 23
epochs: 6 train loss: 0.0013294219970703125  train f1: 1.00000  lr: 0.00024989956042872685 batch: 23 
epochs: 6 val loss: 4.55078125  val f1:0.12500  lr: 0.00024989956042872685 batch: 23
epochs: 7 train loss: 0.0010547637939453125  train f1: 1.00000  lr: 0.00024989956042872685 batch: 23 
epochs: 7 val loss: 4.5  val f1:0.12500  lr: 0.00024989956042872685 batch: 23
epochs: 0 train loss: 3.734375  train f1: 0.20000  lr: 0.0006340786617430455 batch: 24 
epochs: 0 val loss: 4.3046875  val f1:0.14286  lr: 0.0006340786617430455 batch: 24
epochs: 1 train loss: 3.73828125  train f1: 0.11111  lr: 0.0006340786617430455 batch: 24 
epochs: 1 val loss: 3.947265625  val f1:0.12500  lr: 0.0006340786617430455 batch: 24
epochs: 2 train loss: 1.5400390625  train f1: 0.50000  lr: 0.0006340786617430455 batch: 24 
epochs: 2 val loss: 22.234375  val f1:0.00000  lr: 0.0006340786617430455 batch: 24
epochs: 3 train loss: 3.228515625  train f1: 0.40000  lr: 0.0006340786617430455 batch: 24 
epochs: 3 val loss: 9.6171875  val f1:0.00000  lr: 0.0006340786617430455 batch: 24
epochs: 4 train loss: 0.0247039794921875  train f1: 1.00000  lr: 0.0006340786617430455 batch: 24 
epochs: 4 val loss: 10.71875  val f1:0.00000  lr: 0.0006340786617430455 batch: 24
epochs: 5 train loss: 0.0005545616149902344  train f1: 1.00000  lr: 0.0006340786617430455 batch: 24 
epochs: 5 val loss: 12.046875  val f1:0.00000  lr: 0.0006340786617430455 batch: 24
epochs: 6 train loss: 0.0003497600555419922  train f1: 1.00000  lr: 0.0006340786617430455 batch: 24 
epochs: 6 val loss: 12.53125  val f1:0.00000  lr: 0.0006340786617430455 batch: 24
epochs: 7 train loss: 0.00030231475830078125  train f1: 1.00000  lr: 0.0006340786617430455 batch: 24 
epochs: 7 val loss: 12.3359375  val f1:0.00000  lr: 0.0006340786617430455 batch: 24
epochs: 8 train loss: 0.00036334991455078125  train f1: 1.00000  lr: 0.0006340786617430455 batch: 24 
epochs: 8 val loss: 12.1328125  val f1:0.00000  lr: 0.0006340786617430455 batch: 24
epochs: 0 train loss: 4.60546875  train f1: 0.00000  lr: 0.00036038875363512507 batch: 22 
epochs: 0 val loss: 4.6796875  val f1:0.00000  lr: 0.00036038875363512507 batch: 22
epochs: 1 train loss: 4.5703125  train f1: 0.00000  lr: 0.00036038875363512507 batch: 22 
epochs: 1 val loss: 4.140625  val f1:0.14286  lr: 0.00036038875363512507 batch: 22
epochs: 2 train loss: 0.34033203125  train f1: 1.00000  lr: 0.00036038875363512507 batch: 22 
epochs: 2 val loss: 7.26953125  val f1:0.16667  lr: 0.00036038875363512507 batch: 22
epochs: 3 train loss: 2.05078125  train f1: 0.66667  lr: 0.00036038875363512507 batch: 22 
epochs: 3 val loss: 4.80859375  val f1:0.16667  lr: 0.00036038875363512507 batch: 22
epochs: 4 train loss: 0.00460052490234375  train f1: 1.00000  lr: 0.00036038875363512507 batch: 22 
epochs: 4 val loss: 4.8203125  val f1:0.16667  lr: 0.00036038875363512507 batch: 22
epochs: 5 train loss: 0.0009264945983886719  train f1: 1.00000  lr: 0.00036038875363512507 batch: 22 
epochs: 5 val loss: 4.65625  val f1:0.14286  lr: 0.00036038875363512507 batch: 22
epochs: 6 train loss: 0.000659942626953125  train f1: 1.00000  lr: 0.00036038875363512507 batch: 22 
epochs: 6 val loss: 4.48828125  val f1:0.14286  lr: 0.00036038875363512507 batch: 22
epochs: 7 train loss: 0.0005931854248046875  train f1: 1.00000  lr: 0.00036038875363512507 batch: 22 
epochs: 7 val loss: 4.3359375  val f1:0.14286  lr: 0.00036038875363512507 batch: 22
epochs: 8 train loss: 0.0005631446838378906  train f1: 1.00000  lr: 0.00036038875363512507 batch: 22 
epochs: 8 val loss: 4.21484375  val f1:0.14286  lr: 0.00036038875363512507 batch: 22
epochs: 9 train loss: 0.0005717277526855469  train f1: 1.00000  lr: 0.00036038875363512507 batch: 22 
epochs: 9 val loss: 4.09765625  val f1:0.14286  lr: 0.00036038875363512507 batch: 22
epochs: 0 train loss: 4.6796875  train f1: 0.00000  lr: 0.0004532708133021527 batch: 20 
epochs: 0 val loss: 4.55078125  val f1:0.12500  lr: 0.0004532708133021527 batch: 20
epochs: 1 train loss: 4.7734375  train f1: 0.00000  lr: 0.0004532708133021527 batch: 20 
epochs: 1 val loss: 4.05859375  val f1:0.12500  lr: 0.0004532708133021527 batch: 20
epochs: 0 train loss: 4.92578125  train f1: 0.00000  lr: 0.0008342050095254618 batch: 21 
epochs: 0 val loss: 4.95703125  val f1:0.00000  lr: 0.0008342050095254618 batch: 21
epochs: 1 train loss: 4.9765625  train f1: 0.00000  lr: 0.0008342050095254618 batch: 21 
epochs: 1 val loss: 7.84765625  val f1:0.16667  lr: 0.0008342050095254618 batch: 21
epochs: 2 train loss: 0.53173828125  train f1: 1.00000  lr: 0.0008342050095254618 batch: 21 
epochs: 2 val loss: 13.6953125  val f1:0.06667  lr: 0.0008342050095254618 batch: 21
epochs: 3 train loss: 2.5625  train f1: 0.20000  lr: 0.0008342050095254618 batch: 21 
epochs: 3 val loss: 30.453125  val f1:0.00000  lr: 0.0008342050095254618 batch: 21
epochs: 4 train loss: 0.0019626617431640625  train f1: 1.00000  lr: 0.0008342050095254618 batch: 21 
epochs: 4 val loss: 20.59375  val f1:0.00000  lr: 0.0008342050095254618 batch: 21
epochs: 5 train loss: 0.0006532669067382812  train f1: 1.00000  lr: 0.0008342050095254618 batch: 21 
epochs: 5 val loss: 16.265625  val f1:0.00000  lr: 0.0008342050095254618 batch: 21
epochs: 6 train loss: 0.00042438507080078125  train f1: 1.00000  lr: 0.0008342050095254618 batch: 21 
epochs: 6 val loss: 10.46875  val f1:0.00000  lr: 0.0008342050095254618 batch: 21
epochs: 7 train loss: 0.0004017353057861328  train f1: 1.00000  lr: 0.0008342050095254618 batch: 21 
epochs: 7 val loss: 8.453125  val f1:0.14286  lr: 0.0008342050095254618 batch: 21
epochs: 8 train loss: 0.0003070831298828125  train f1: 1.00000  lr: 0.0008342050095254618 batch: 21 
epochs: 8 val loss: 7.60546875  val f1:0.14286  lr: 0.0008342050095254618 batch: 21
epochs: 9 train loss: 0.0002732276916503906  train f1: 1.00000  lr: 0.0008342050095254618 batch: 21 
epochs: 9 val loss: 6.91796875  val f1:0.16667  lr: 0.0008342050095254618 batch: 21
epochs: 10 train loss: 0.00022685527801513672  train f1: 1.00000  lr: 0.0008342050095254618 batch: 21 
epochs: 10 val loss: 6.35546875  val f1:0.16667  lr: 0.0008342050095254618 batch: 21
epochs: 11 train loss: 0.00019121170043945312  train f1: 1.00000  lr: 0.0008342050095254618 batch: 21 
epochs: 11 val loss: 5.8984375  val f1:0.16667  lr: 0.0008342050095254618 batch: 21
epochs: 0 train loss: 4.5  train f1: 0.00000  lr: 0.0008427089959662509 batch: 21 
epochs: 0 val loss: 5.48046875  val f1:0.00000  lr: 0.0008427089959662509 batch: 21
epochs: 1 train loss: 4.44921875  train f1: 0.00000  lr: 0.0008427089959662509 batch: 21 
epochs: 1 val loss: 5.29296875  val f1:0.00000  lr: 0.0008427089959662509 batch: 21
epochs: 0 train loss: 3.67578125  train f1: 0.20000  lr: 0.001225107657960148 batch: 22 
epochs: 0 val loss: 4.76953125  val f1:0.00000  lr: 0.001225107657960148 batch: 22
epochs: 1 train loss: 3.771484375  train f1: 0.11111  lr: 0.001225107657960148 batch: 22 
epochs: 1 val loss: 12.09375  val f1:0.00000  lr: 0.001225107657960148 batch: 22
epochs: 0 train loss: 5.2890625  train f1: 0.00000  lr: 0.0005712991222542242 batch: 22 
epochs: 0 val loss: 4.94921875  val f1:0.00000  lr: 0.0005712991222542242 batch: 22
epochs: 1 train loss: 5.1875  train f1: 0.00000  lr: 0.0005712991222542242 batch: 22 
epochs: 1 val loss: 4.94921875  val f1:0.00000  lr: 0.0005712991222542242 batch: 22
epochs: 0 train loss: 5.0234375  train f1: 0.00000  lr: 0.0005286619783907931 batch: 21 
epochs: 0 val loss: 5.33203125  val f1:0.00000  lr: 0.0005286619783907931 batch: 21
epochs: 1 train loss: 5.14453125  train f1: 0.00000  lr: 0.0005286619783907931 batch: 21 
epochs: 1 val loss: 5.3203125  val f1:0.14286  lr: 0.0005286619783907931 batch: 21
epochs: 2 train loss: 0.88134765625  train f1: 1.00000  lr: 0.0005286619783907931 batch: 21 
epochs: 2 val loss: 4.0625  val f1:0.12500  lr: 0.0005286619783907931 batch: 21
epochs: 3 train loss: 1.921875  train f1: 0.50000  lr: 0.0005286619783907931 batch: 21 
epochs: 3 val loss: 5.39453125  val f1:0.16667  lr: 0.0005286619783907931 batch: 21
epochs: 4 train loss: 0.011932373046875  train f1: 1.00000  lr: 0.0005286619783907931 batch: 21 
epochs: 4 val loss: 4.546875  val f1:0.14286  lr: 0.0005286619783907931 batch: 21
epochs: 5 train loss: 0.0002346038818359375  train f1: 1.00000  lr: 0.0005286619783907931 batch: 21 
epochs: 5 val loss: 4.24609375  val f1:0.14286  lr: 0.0005286619783907931 batch: 21
epochs: 6 train loss: 0.00012022256851196289  train f1: 1.00000  lr: 0.0005286619783907931 batch: 21 
epochs: 6 val loss: 4.09765625  val f1:0.14286  lr: 0.0005286619783907931 batch: 21
epochs: 7 train loss: 9.72747802734375e-05  train f1: 1.00000  lr: 0.0005286619783907931 batch: 21 
epochs: 7 val loss: 4.0625  val f1:0.14286  lr: 0.0005286619783907931 batch: 21
epochs: 8 train loss: 0.0001016855239868164  train f1: 1.00000  lr: 0.0005286619783907931 batch: 21 
epochs: 8 val loss: 4.0703125  val f1:0.12500  lr: 0.0005286619783907931 batch: 21
epochs: 9 train loss: 8.082389831542969e-05  train f1: 1.00000  lr: 0.0005286619783907931 batch: 21 
epochs: 9 val loss: 4.0859375  val f1:0.12500  lr: 0.0005286619783907931 batch: 21
epochs: 10 train loss: 8.869171142578125e-05  train f1: 1.00000  lr: 0.0005286619783907931 batch: 21 
epochs: 10 val loss: 4.1171875  val f1:0.12500  lr: 0.0005286619783907931 batch: 21
epochs: 11 train loss: 9.41157341003418e-05  train f1: 1.00000  lr: 0.0005286619783907931 batch: 21 
epochs: 11 val loss: 4.1328125  val f1:0.12500  lr: 0.0005286619783907931 batch: 21
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0009658050734550771 batch: 20 
epochs: 0 val loss: 5.625  val f1:0.00000  lr: 0.0009658050734550771 batch: 20
epochs: 1 train loss: 4.109375  train f1: 0.10000  lr: 0.0009658050734550771 batch: 20 
epochs: 1 val loss: 5.296875  val f1:0.00000  lr: 0.0009658050734550771 batch: 20
epochs: 0 train loss: 4.53125  train f1: 0.00000  lr: 0.0007371370194772804 batch: 21 
epochs: 0 val loss: 5.16015625  val f1:0.00000  lr: 0.0007371370194772804 batch: 21
epochs: 1 train loss: 4.44140625  train f1: 0.00000  lr: 0.0007371370194772804 batch: 21 
epochs: 1 val loss: 3.447265625  val f1:0.11111  lr: 0.0007371370194772804 batch: 21
epochs: 0 train loss: 4.73828125  train f1: 0.00000  lr: 0.0006322936108241056 batch: 26 
epochs: 0 val loss: 5.53125  val f1:0.00000  lr: 0.0006322936108241056 batch: 26
epochs: 1 train loss: 4.7734375  train f1: 0.00000  lr: 0.0006322936108241056 batch: 26 
epochs: 1 val loss: 5.4921875  val f1:0.14286  lr: 0.0006322936108241056 batch: 26
epochs: 2 train loss: 0.6162109375  train f1: 1.00000  lr: 0.0006322936108241056 batch: 26 
epochs: 2 val loss: 18.890625  val f1:0.16667  lr: 0.0006322936108241056 batch: 26
epochs: 3 train loss: 0.0859375  train f1: 1.00000  lr: 0.0006322936108241056 batch: 26 
epochs: 3 val loss: 7.79296875  val f1:0.12500  lr: 0.0006322936108241056 batch: 26
epochs: 4 train loss: 1.0751953125  train f1: 0.50000  lr: 0.0006322936108241056 batch: 26 
epochs: 4 val loss: 19.78125  val f1:0.14286  lr: 0.0006322936108241056 batch: 26
epochs: 5 train loss: 0.001583099365234375  train f1: 1.00000  lr: 0.0006322936108241056 batch: 26 
epochs: 5 val loss: 13.6484375  val f1:0.14286  lr: 0.0006322936108241056 batch: 26
epochs: 6 train loss: 7.545948028564453e-05  train f1: 1.00000  lr: 0.0006322936108241056 batch: 26 
epochs: 6 val loss: 9.4296875  val f1:0.14286  lr: 0.0006322936108241056 batch: 26
epochs: 7 train loss: 0.0001220703125  train f1: 1.00000  lr: 0.0006322936108241056 batch: 26 
epochs: 7 val loss: 7.1875  val f1:0.14286  lr: 0.0006322936108241056 batch: 26
epochs: 8 train loss: 0.00010144710540771484  train f1: 1.00000  lr: 0.0006322936108241056 batch: 26 
epochs: 8 val loss: 5.93359375  val f1:0.14286  lr: 0.0006322936108241056 batch: 26
epochs: 9 train loss: 0.0001316070556640625  train f1: 1.00000  lr: 0.0006322936108241056 batch: 26 
epochs: 9 val loss: 5.38671875  val f1:0.14286  lr: 0.0006322936108241056 batch: 26
epochs: 10 train loss: 0.0001163482666015625  train f1: 1.00000  lr: 0.0006322936108241056 batch: 26 
epochs: 10 val loss: 5.265625  val f1:0.14286  lr: 0.0006322936108241056 batch: 26
epochs: 11 train loss: 6.42538070678711e-05  train f1: 1.00000  lr: 0.0006322936108241056 batch: 26 
epochs: 11 val loss: 5.21484375  val f1:0.16667  lr: 0.0006322936108241056 batch: 26
epochs: 12 train loss: 0.0002727508544921875  train f1: 1.00000  lr: 0.0006322936108241056 batch: 26 
epochs: 12 val loss: 5.203125  val f1:0.16667  lr: 0.0006322936108241056 batch: 26
epochs: 13 train loss: 7.033348083496094e-05  train f1: 1.00000  lr: 0.0006322936108241056 batch: 26 
epochs: 13 val loss: 5.16015625  val f1:0.16667  lr: 0.0006322936108241056 batch: 26
epochs: 0 train loss: 4.63671875  train f1: 0.00000  lr: 0.0006977894356370945 batch: 24 
epochs: 0 val loss: 4.6953125  val f1:0.00000  lr: 0.0006977894356370945 batch: 24
epochs: 1 train loss: 4.63671875  train f1: 0.20000  lr: 0.0006977894356370945 batch: 24 
epochs: 1 val loss: 4.58203125  val f1:0.12500  lr: 0.0006977894356370945 batch: 24
epochs: 0 train loss: 4.4609375  train f1: 0.00000  lr: 0.0006007825133786956 batch: 26 
epochs: 0 val loss: 5.0859375  val f1:0.00000  lr: 0.0006007825133786956 batch: 26
epochs: 1 train loss: 4.46875  train f1: 0.00000  lr: 0.0006007825133786956 batch: 26 
epochs: 1 val loss: 3.580078125  val f1:0.16667  lr: 0.0006007825133786956 batch: 26
epochs: 2 train loss: 0.356689453125  train f1: 1.00000  lr: 0.0006007825133786956 batch: 26 
epochs: 2 val loss: 19.765625  val f1:0.00000  lr: 0.0006007825133786956 batch: 26
epochs: 3 train loss: 0.423095703125  train f1: 1.00000  lr: 0.0006007825133786956 batch: 26 
epochs: 3 val loss: 6.83203125  val f1:0.16667  lr: 0.0006007825133786956 batch: 26
epochs: 4 train loss: 0.00479888916015625  train f1: 1.00000  lr: 0.0006007825133786956 batch: 26 
epochs: 4 val loss: 8.3828125  val f1:0.16667  lr: 0.0006007825133786956 batch: 26
epochs: 5 train loss: 2.5510787963867188e-05  train f1: 1.00000  lr: 0.0006007825133786956 batch: 26 
epochs: 5 val loss: 8.484375  val f1:0.16667  lr: 0.0006007825133786956 batch: 26
epochs: 6 train loss: 5.161762237548828e-05  train f1: 1.00000  lr: 0.0006007825133786956 batch: 26 
epochs: 6 val loss: 8.2734375  val f1:0.16667  lr: 0.0006007825133786956 batch: 26
epochs: 7 train loss: 3.641843795776367e-05  train f1: 1.00000  lr: 0.0006007825133786956 batch: 26 
epochs: 7 val loss: 8.1015625  val f1:0.16667  lr: 0.0006007825133786956 batch: 26
epochs: 8 train loss: 1.7881393432617188e-05  train f1: 1.00000  lr: 0.0006007825133786956 batch: 26 
epochs: 8 val loss: 7.921875  val f1:0.16667  lr: 0.0006007825133786956 batch: 26
epochs: 9 train loss: 2.2172927856445312e-05  train f1: 1.00000  lr: 0.0006007825133786956 batch: 26 
epochs: 9 val loss: 7.69921875  val f1:0.16667  lr: 0.0006007825133786956 batch: 26
epochs: 10 train loss: 4.494190216064453e-05  train f1: 1.00000  lr: 0.0006007825133786956 batch: 26 
epochs: 10 val loss: 7.33203125  val f1:0.16667  lr: 0.0006007825133786956 batch: 26
epochs: 11 train loss: 2.187490463256836e-05  train f1: 1.00000  lr: 0.0006007825133786956 batch: 26 
epochs: 11 val loss: 7.0703125  val f1:0.16667  lr: 0.0006007825133786956 batch: 26
epochs: 12 train loss: 1.7881393432617188e-05  train f1: 1.00000  lr: 0.0006007825133786956 batch: 26 
epochs: 12 val loss: 6.87109375  val f1:0.16667  lr: 0.0006007825133786956 batch: 26
epochs: 13 train loss: 3.4332275390625e-05  train f1: 1.00000  lr: 0.0006007825133786956 batch: 26 
epochs: 13 val loss: 6.78515625  val f1:0.16667  lr: 0.0006007825133786956 batch: 26
epochs: 0 train loss: 4.5234375  train f1: 0.00000  lr: 0.0014099401575056738 batch: 26 
epochs: 0 val loss: 5.1640625  val f1:0.00000  lr: 0.0014099401575056738 batch: 26
epochs: 1 train loss: 4.4765625  train f1: 0.00000  lr: 0.0014099401575056738 batch: 26 
epochs: 1 val loss: 7.8046875  val f1:0.16667  lr: 0.0014099401575056738 batch: 26
epochs: 2 train loss: 0.424072265625  train f1: 1.00000  lr: 0.0014099401575056738 batch: 26 
epochs: 2 val loss: 2756.0  val f1:0.11111  lr: 0.0014099401575056738 batch: 26
epochs: 3 train loss: 0.46337890625  train f1: 1.00000  lr: 0.0014099401575056738 batch: 26 
epochs: 3 val loss: 505.0  val f1:0.06667  lr: 0.0014099401575056738 batch: 26
epochs: 4 train loss: 0.00110626220703125  train f1: 1.00000  lr: 0.0014099401575056738 batch: 26 
epochs: 4 val loss: 272.75  val f1:0.06667  lr: 0.0014099401575056738 batch: 26
epochs: 5 train loss: 8.344650268554688e-07  train f1: 1.00000  lr: 0.0014099401575056738 batch: 26 
epochs: 5 val loss: 75.875  val f1:0.00000  lr: 0.0014099401575056738 batch: 26
epochs: 6 train loss: 1.5497207641601562e-06  train f1: 1.00000  lr: 0.0014099401575056738 batch: 26 
epochs: 6 val loss: 29.984375  val f1:0.00000  lr: 0.0014099401575056738 batch: 26
epochs: 7 train loss: 2.6226043701171875e-06  train f1: 1.00000  lr: 0.0014099401575056738 batch: 26 
epochs: 7 val loss: 18.421875  val f1:0.00000  lr: 0.0014099401575056738 batch: 26
epochs: 8 train loss: 9.5367431640625e-07  train f1: 1.00000  lr: 0.0014099401575056738 batch: 26 
epochs: 8 val loss: 15.2890625  val f1:0.00000  lr: 0.0014099401575056738 batch: 26
epochs: 9 train loss: 3.5762786865234375e-07  train f1: 1.00000  lr: 0.0014099401575056738 batch: 26 
epochs: 9 val loss: 14.8828125  val f1:0.00000  lr: 0.0014099401575056738 batch: 26
epochs: 10 train loss: 1.430511474609375e-06  train f1: 1.00000  lr: 0.0014099401575056738 batch: 26 
epochs: 10 val loss: 16.875  val f1:0.00000  lr: 0.0014099401575056738 batch: 26
epochs: 11 train loss: 1.1324882507324219e-06  train f1: 1.00000  lr: 0.0014099401575056738 batch: 26 
epochs: 11 val loss: 19.484375  val f1:0.00000  lr: 0.0014099401575056738 batch: 26
epochs: 12 train loss: 1.4901161193847656e-06  train f1: 1.00000  lr: 0.0014099401575056738 batch: 26 
epochs: 12 val loss: 20.53125  val f1:0.00000  lr: 0.0014099401575056738 batch: 26
epochs: 13 train loss: 5.960464477539062e-07  train f1: 1.00000  lr: 0.0014099401575056738 batch: 26 
epochs: 13 val loss: 20.640625  val f1:0.00000  lr: 0.0014099401575056738 batch: 26
epochs: 0 train loss: 4.3203125  train f1: 0.00000  lr: 0.0009115144341934852 batch: 27 
epochs: 0 val loss: 4.453125  val f1:0.00000  lr: 0.0009115144341934852 batch: 27
epochs: 1 train loss: 4.28125  train f1: 0.00000  lr: 0.0009115144341934852 batch: 27 
epochs: 1 val loss: 3.78515625  val f1:0.11111  lr: 0.0009115144341934852 batch: 27
epochs: 0 train loss: 4.2890625  train f1: 0.20000  lr: 0.0004964168480179929 batch: 26 
epochs: 0 val loss: 5.05859375  val f1:0.00000  lr: 0.0004964168480179929 batch: 26
epochs: 1 train loss: 4.38671875  train f1: 0.16667  lr: 0.0004964168480179929 batch: 26 
epochs: 1 val loss: 5.81640625  val f1:0.16667  lr: 0.0004964168480179929 batch: 26
epochs: 2 train loss: 0.1827392578125  train f1: 1.00000  lr: 0.0004964168480179929 batch: 26 
epochs: 2 val loss: 3.73828125  val f1:0.11111  lr: 0.0004964168480179929 batch: 26
epochs: 3 train loss: 0.705078125  train f1: 1.00000  lr: 0.0004964168480179929 batch: 26 
epochs: 3 val loss: 4.3515625  val f1:0.12500  lr: 0.0004964168480179929 batch: 26
epochs: 4 train loss: 0.0654296875  train f1: 1.00000  lr: 0.0004964168480179929 batch: 26 
epochs: 4 val loss: 9.0625  val f1:0.14286  lr: 0.0004964168480179929 batch: 26
epochs: 5 train loss: 0.0006961822509765625  train f1: 1.00000  lr: 0.0004964168480179929 batch: 26 
epochs: 5 val loss: 6.2890625  val f1:0.14286  lr: 0.0004964168480179929 batch: 26
epochs: 6 train loss: 0.0004627704620361328  train f1: 1.00000  lr: 0.0004964168480179929 batch: 26 
epochs: 6 val loss: 5.18359375  val f1:0.14286  lr: 0.0004964168480179929 batch: 26
epochs: 7 train loss: 0.000614166259765625  train f1: 1.00000  lr: 0.0004964168480179929 batch: 26 
epochs: 7 val loss: 4.640625  val f1:0.12500  lr: 0.0004964168480179929 batch: 26
epochs: 8 train loss: 0.000301361083984375  train f1: 1.00000  lr: 0.0004964168480179929 batch: 26 
epochs: 8 val loss: 4.29296875  val f1:0.12500  lr: 0.0004964168480179929 batch: 26
epochs: 9 train loss: 0.0001800060272216797  train f1: 1.00000  lr: 0.0004964168480179929 batch: 26 
epochs: 9 val loss: 4.2109375  val f1:0.12500  lr: 0.0004964168480179929 batch: 26
epochs: 10 train loss: 0.000152587890625  train f1: 1.00000  lr: 0.0004964168480179929 batch: 26 
epochs: 10 val loss: 4.2109375  val f1:0.12500  lr: 0.0004964168480179929 batch: 26
epochs: 11 train loss: 0.00011408329010009766  train f1: 1.00000  lr: 0.0004964168480179929 batch: 26 
epochs: 11 val loss: 4.24609375  val f1:0.11111  lr: 0.0004964168480179929 batch: 26
epochs: 12 train loss: 0.00018680095672607422  train f1: 1.00000  lr: 0.0004964168480179929 batch: 26 
epochs: 12 val loss: 4.24609375  val f1:0.11111  lr: 0.0004964168480179929 batch: 26
epochs: 13 train loss: 0.00014352798461914062  train f1: 1.00000  lr: 0.0004964168480179929 batch: 26 
epochs: 13 val loss: 4.265625  val f1:0.11111  lr: 0.0004964168480179929 batch: 26
epochs: 0 train loss: 4.2421875  train f1: 0.00000  lr: 0.0010990558778152775 batch: 20 
epochs: 0 val loss: 3.912109375  val f1:0.00000  lr: 0.0010990558778152775 batch: 20
epochs: 1 train loss: 4.1484375  train f1: 0.00000  lr: 0.0010990558778152775 batch: 20 
epochs: 1 val loss: 10.2734375  val f1:0.16667  lr: 0.0010990558778152775 batch: 20
epochs: 2 train loss: 0.1907958984375  train f1: 1.00000  lr: 0.0010990558778152775 batch: 20 
epochs: 2 val loss: 42.53125  val f1:0.00000  lr: 0.0010990558778152775 batch: 20
epochs: 3 train loss: 1.0  train f1: 0.50000  lr: 0.0010990558778152775 batch: 20 
epochs: 3 val loss: 58.4375  val f1:0.14286  lr: 0.0010990558778152775 batch: 20
epochs: 4 train loss: 2.76171875  train f1: 0.41667  lr: 0.0010990558778152775 batch: 20 
epochs: 4 val loss: 189.125  val f1:0.00000  lr: 0.0010990558778152775 batch: 20
epochs: 5 train loss: 0.56689453125  train f1: 1.00000  lr: 0.0010990558778152775 batch: 20 
epochs: 5 val loss: 57.78125  val f1:0.00000  lr: 0.0010990558778152775 batch: 20
epochs: 6 train loss: 0.65087890625  train f1: 1.00000  lr: 0.0010990558778152775 batch: 20 
epochs: 6 val loss: 688.5  val f1:0.00000  lr: 0.0010990558778152775 batch: 20
epochs: 7 train loss: 0.0097503662109375  train f1: 1.00000  lr: 0.0010990558778152775 batch: 20 
epochs: 7 val loss: 995.5  val f1:0.00000  lr: 0.0010990558778152775 batch: 20
epochs: 8 train loss: 7.808208465576172e-06  train f1: 1.00000  lr: 0.0010990558778152775 batch: 20 
epochs: 8 val loss: 437.5  val f1:0.00000  lr: 0.0010990558778152775 batch: 20
epochs: 9 train loss: 7.450580596923828e-06  train f1: 1.00000  lr: 0.0010990558778152775 batch: 20 
epochs: 9 val loss: 224.25  val f1:0.00000  lr: 0.0010990558778152775 batch: 20
epochs: 10 train loss: 8.940696716308594e-06  train f1: 1.00000  lr: 0.0010990558778152775 batch: 20 
epochs: 10 val loss: 125.6875  val f1:0.00000  lr: 0.0010990558778152775 batch: 20
epochs: 11 train loss: 8.225440979003906e-06  train f1: 1.00000  lr: 0.0010990558778152775 batch: 20 
epochs: 11 val loss: 79.4375  val f1:0.00000  lr: 0.0010990558778152775 batch: 20
epochs: 12 train loss: 8.821487426757812e-06  train f1: 1.00000  lr: 0.0010990558778152775 batch: 20 
epochs: 12 val loss: 51.15625  val f1:0.00000  lr: 0.0010990558778152775 batch: 20
epochs: 13 train loss: 8.58306884765625e-06  train f1: 1.00000  lr: 0.0010990558778152775 batch: 20 
epochs: 13 val loss: 36.59375  val f1:0.00000  lr: 0.0010990558778152775 batch: 20
epochs: 0 train loss: 4.12890625  train f1: 0.00000  lr: 0.00029945725611196246 batch: 26 
epochs: 0 val loss: 4.40625  val f1:0.00000  lr: 0.00029945725611196246 batch: 26
epochs: 1 train loss: 4.1171875  train f1: 0.00000  lr: 0.00029945725611196246 batch: 26 
epochs: 1 val loss: 3.91015625  val f1:0.12500  lr: 0.00029945725611196246 batch: 26
epochs: 0 train loss: 4.6171875  train f1: 0.00000  lr: 0.0006169319199874657 batch: 21 
epochs: 0 val loss: 4.00390625  val f1:0.00000  lr: 0.0006169319199874657 batch: 21
epochs: 1 train loss: 4.640625  train f1: 0.00000  lr: 0.0006169319199874657 batch: 21 
epochs: 1 val loss: 3.37890625  val f1:0.12500  lr: 0.0006169319199874657 batch: 21
epochs: 0 train loss: 4.65234375  train f1: 0.00000  lr: 0.0005670997910933715 batch: 21 
epochs: 0 val loss: 5.109375  val f1:0.00000  lr: 0.0005670997910933715 batch: 21
epochs: 1 train loss: 4.7109375  train f1: 0.00000  lr: 0.0005670997910933715 batch: 21 
epochs: 1 val loss: 5.9765625  val f1:0.14286  lr: 0.0005670997910933715 batch: 21
epochs: 2 train loss: 0.399658203125  train f1: 1.00000  lr: 0.0005670997910933715 batch: 21 
epochs: 2 val loss: 21.21875  val f1:0.00000  lr: 0.0005670997910933715 batch: 21
epochs: 3 train loss: 0.62841796875  train f1: 1.00000  lr: 0.0005670997910933715 batch: 21 
epochs: 3 val loss: 10.3828125  val f1:0.14286  lr: 0.0005670997910933715 batch: 21
epochs: 4 train loss: 3.647804260253906e-05  train f1: 1.00000  lr: 0.0005670997910933715 batch: 21 
epochs: 4 val loss: 8.9375  val f1:0.14286  lr: 0.0005670997910933715 batch: 21
epochs: 5 train loss: 5.316734313964844e-05  train f1: 1.00000  lr: 0.0005670997910933715 batch: 21 
epochs: 5 val loss: 7.6796875  val f1:0.14286  lr: 0.0005670997910933715 batch: 21
epochs: 6 train loss: 3.886222839355469e-05  train f1: 1.00000  lr: 0.0005670997910933715 batch: 21 
epochs: 6 val loss: 7.11328125  val f1:0.14286  lr: 0.0005670997910933715 batch: 21
epochs: 7 train loss: 7.605552673339844e-05  train f1: 1.00000  lr: 0.0005670997910933715 batch: 21 
epochs: 7 val loss: 6.421875  val f1:0.14286  lr: 0.0005670997910933715 batch: 21
epochs: 8 train loss: 5.8531761169433594e-05  train f1: 1.00000  lr: 0.0005670997910933715 batch: 21 
epochs: 8 val loss: 6.07421875  val f1:0.14286  lr: 0.0005670997910933715 batch: 21
epochs: 9 train loss: 2.1517276763916016e-05  train f1: 1.00000  lr: 0.0005670997910933715 batch: 21 
epochs: 9 val loss: 5.5625  val f1:0.14286  lr: 0.0005670997910933715 batch: 21
epochs: 10 train loss: 3.7550926208496094e-05  train f1: 1.00000  lr: 0.0005670997910933715 batch: 21 
epochs: 10 val loss: 5.26171875  val f1:0.14286  lr: 0.0005670997910933715 batch: 21
epochs: 11 train loss: 3.838539123535156e-05  train f1: 1.00000  lr: 0.0005670997910933715 batch: 21 
epochs: 11 val loss: 5.22265625  val f1:0.14286  lr: 0.0005670997910933715 batch: 21
epochs: 12 train loss: 5.370378494262695e-05  train f1: 1.00000  lr: 0.0005670997910933715 batch: 21 
epochs: 12 val loss: 5.16015625  val f1:0.14286  lr: 0.0005670997910933715 batch: 21
epochs: 0 train loss: 4.6640625  train f1: 0.00000  lr: 0.0008070912333811624 batch: 22 
epochs: 0 val loss: 4.63671875  val f1:0.00000  lr: 0.0008070912333811624 batch: 22
epochs: 1 train loss: 4.6328125  train f1: 0.00000  lr: 0.0008070912333811624 batch: 22 
epochs: 1 val loss: 4.13671875  val f1:0.14286  lr: 0.0008070912333811624 batch: 22
epochs: 2 train loss: 0.5576171875  train f1: 1.00000  lr: 0.0008070912333811624 batch: 22 
epochs: 2 val loss: 145.0  val f1:0.00000  lr: 0.0008070912333811624 batch: 22
epochs: 3 train loss: 3.142578125  train f1: 0.40000  lr: 0.0008070912333811624 batch: 22 
epochs: 3 val loss: 16.046875  val f1:0.00000  lr: 0.0008070912333811624 batch: 22
epochs: 4 train loss: 1.1826171875  train f1: 0.50000  lr: 0.0008070912333811624 batch: 22 
epochs: 4 val loss: 30.765625  val f1:0.00000  lr: 0.0008070912333811624 batch: 22
epochs: 5 train loss: 0.005161285400390625  train f1: 1.00000  lr: 0.0008070912333811624 batch: 22 
epochs: 5 val loss: 23.71875  val f1:0.00000  lr: 0.0008070912333811624 batch: 22
epochs: 6 train loss: 0.0010890960693359375  train f1: 1.00000  lr: 0.0008070912333811624 batch: 22 
epochs: 6 val loss: 19.078125  val f1:0.00000  lr: 0.0008070912333811624 batch: 22
epochs: 7 train loss: 0.001079559326171875  train f1: 1.00000  lr: 0.0008070912333811624 batch: 22 
epochs: 7 val loss: 16.234375  val f1:0.14286  lr: 0.0008070912333811624 batch: 22
epochs: 8 train loss: 0.0002856254577636719  train f1: 1.00000  lr: 0.0008070912333811624 batch: 22 
epochs: 8 val loss: 14.6015625  val f1:0.14286  lr: 0.0008070912333811624 batch: 22
epochs: 9 train loss: 0.00033092498779296875  train f1: 1.00000  lr: 0.0008070912333811624 batch: 22 
epochs: 9 val loss: 10.9140625  val f1:0.14286  lr: 0.0008070912333811624 batch: 22
epochs: 10 train loss: 0.00026869773864746094  train f1: 1.00000  lr: 0.0008070912333811624 batch: 22 
epochs: 10 val loss: 7.73828125  val f1:0.14286  lr: 0.0008070912333811624 batch: 22
epochs: 11 train loss: 0.0002467632293701172  train f1: 1.00000  lr: 0.0008070912333811624 batch: 22 
epochs: 11 val loss: 6.484375  val f1:0.12500  lr: 0.0008070912333811624 batch: 22
epochs: 12 train loss: 0.00033736228942871094  train f1: 1.00000  lr: 0.0008070912333811624 batch: 22 
epochs: 12 val loss: 5.71875  val f1:0.12500  lr: 0.0008070912333811624 batch: 22
epochs: 0 train loss: 4.01953125  train f1: 0.16667  lr: 0.04420220826376741 batch: 24 
epochs: 0 val loss: 4.36328125  val f1:0.00000  lr: 0.04420220826376741 batch: 24
epochs: 1 train loss: 4.015625  train f1: 0.16667  lr: 0.04420220826376741 batch: 24 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.04420220826376741 batch: 24
epochs: 0 train loss: 4.14453125  train f1: 0.00000  lr: 0.0004338715112094483 batch: 22 
epochs: 0 val loss: 4.67578125  val f1:0.12500  lr: 0.0004338715112094483 batch: 22
epochs: 1 train loss: 4.10546875  train f1: 0.00000  lr: 0.0004338715112094483 batch: 22 
epochs: 1 val loss: 3.416015625  val f1:0.14286  lr: 0.0004338715112094483 batch: 22
epochs: 2 train loss: 1.2998046875  train f1: 1.00000  lr: 0.0004338715112094483 batch: 22 
epochs: 2 val loss: 14.1640625  val f1:0.16667  lr: 0.0004338715112094483 batch: 22
epochs: 3 train loss: 1.2177734375  train f1: 1.00000  lr: 0.0004338715112094483 batch: 22 
epochs: 3 val loss: 3.904296875  val f1:0.14286  lr: 0.0004338715112094483 batch: 22
epochs: 4 train loss: 0.0017175674438476562  train f1: 1.00000  lr: 0.0004338715112094483 batch: 22 
epochs: 4 val loss: 3.91796875  val f1:0.14286  lr: 0.0004338715112094483 batch: 22
epochs: 5 train loss: 0.001392364501953125  train f1: 1.00000  lr: 0.0004338715112094483 batch: 22 
epochs: 5 val loss: 3.9375  val f1:0.16667  lr: 0.0004338715112094483 batch: 22
epochs: 6 train loss: 0.0011415481567382812  train f1: 1.00000  lr: 0.0004338715112094483 batch: 22 
epochs: 6 val loss: 4.00390625  val f1:0.16667  lr: 0.0004338715112094483 batch: 22
epochs: 7 train loss: 0.0007662773132324219  train f1: 1.00000  lr: 0.0004338715112094483 batch: 22 
epochs: 7 val loss: 4.03125  val f1:0.16667  lr: 0.0004338715112094483 batch: 22
epochs: 8 train loss: 0.0008320808410644531  train f1: 1.00000  lr: 0.0004338715112094483 batch: 22 
epochs: 8 val loss: 4.09765625  val f1:0.16667  lr: 0.0004338715112094483 batch: 22
epochs: 9 train loss: 0.0009455680847167969  train f1: 1.00000  lr: 0.0004338715112094483 batch: 22 
epochs: 9 val loss: 4.19921875  val f1:0.16667  lr: 0.0004338715112094483 batch: 22
epochs: 0 train loss: 4.93359375  train f1: 0.00000  lr: 0.000382814168464816 batch: 32 
epochs: 0 val loss: 5.140625  val f1:0.00000  lr: 0.000382814168464816 batch: 32
epochs: 1 train loss: 4.890625  train f1: 0.00000  lr: 0.000382814168464816 batch: 32 
epochs: 1 val loss: 3.8046875  val f1:0.12500  lr: 0.000382814168464816 batch: 32
epochs: 0 train loss: 4.4765625  train f1: 0.00000  lr: 0.0004355474676266003 batch: 22 
epochs: 0 val loss: 4.10546875  val f1:0.07143  lr: 0.0004355474676266003 batch: 22
epochs: 1 train loss: 4.484375  train f1: 0.00000  lr: 0.0004355474676266003 batch: 22 
epochs: 1 val loss: 3.93359375  val f1:0.14286  lr: 0.0004355474676266003 batch: 22
epochs: 2 train loss: 0.63818359375  train f1: 1.00000  lr: 0.0004355474676266003 batch: 22 
epochs: 2 val loss: 5.11328125  val f1:0.16667  lr: 0.0004355474676266003 batch: 22
epochs: 3 train loss: 0.93115234375  train f1: 1.00000  lr: 0.0004355474676266003 batch: 22 
epochs: 3 val loss: 4.28515625  val f1:0.16667  lr: 0.0004355474676266003 batch: 22
epochs: 4 train loss: 0.0182037353515625  train f1: 1.00000  lr: 0.0004355474676266003 batch: 22 
epochs: 4 val loss: 4.69140625  val f1:0.16667  lr: 0.0004355474676266003 batch: 22
epochs: 5 train loss: 9.22083854675293e-05  train f1: 1.00000  lr: 0.0004355474676266003 batch: 22 
epochs: 5 val loss: 4.54296875  val f1:0.16667  lr: 0.0004355474676266003 batch: 22
epochs: 6 train loss: 5.936622619628906e-05  train f1: 1.00000  lr: 0.0004355474676266003 batch: 22 
epochs: 6 val loss: 4.37109375  val f1:0.16667  lr: 0.0004355474676266003 batch: 22
epochs: 7 train loss: 7.832050323486328e-05  train f1: 1.00000  lr: 0.0004355474676266003 batch: 22 
epochs: 7 val loss: 4.24609375  val f1:0.16667  lr: 0.0004355474676266003 batch: 22
epochs: 8 train loss: 7.05718994140625e-05  train f1: 1.00000  lr: 0.0004355474676266003 batch: 22 
epochs: 8 val loss: 4.14453125  val f1:0.16667  lr: 0.0004355474676266003 batch: 22
epochs: 9 train loss: 6.341934204101562e-05  train f1: 1.00000  lr: 0.0004355474676266003 batch: 22 
epochs: 9 val loss: 4.07421875  val f1:0.16667  lr: 0.0004355474676266003 batch: 22
epochs: 10 train loss: 6.461143493652344e-05  train f1: 1.00000  lr: 0.0004355474676266003 batch: 22 
epochs: 10 val loss: 4.015625  val f1:0.16667  lr: 0.0004355474676266003 batch: 22
epochs: 11 train loss: 4.649162292480469e-05  train f1: 1.00000  lr: 0.0004355474676266003 batch: 22 
epochs: 11 val loss: 3.96875  val f1:0.16667  lr: 0.0004355474676266003 batch: 22
epochs: 0 train loss: 4.37109375  train f1: 0.00000  lr: 0.0007357983375135471 batch: 27 
epochs: 0 val loss: 4.91015625  val f1:0.00000  lr: 0.0007357983375135471 batch: 27
epochs: 1 train loss: 4.3046875  train f1: 0.00000  lr: 0.0007357983375135471 batch: 27 
epochs: 1 val loss: 4.52734375  val f1:0.12500  lr: 0.0007357983375135471 batch: 27
epochs: 0 train loss: 4.01953125  train f1: 0.00000  lr: 0.0004328176001410148 batch: 22 
epochs: 0 val loss: 4.53125  val f1:0.00000  lr: 0.0004328176001410148 batch: 22
epochs: 1 train loss: 3.982421875  train f1: 0.11111  lr: 0.0004328176001410148 batch: 22 
epochs: 1 val loss: 3.423828125  val f1:0.25000  lr: 0.0004328176001410148 batch: 22
epochs: 2 train loss: 0.984375  train f1: 1.00000  lr: 0.0004328176001410148 batch: 22 
epochs: 2 val loss: 7.1171875  val f1:0.14286  lr: 0.0004328176001410148 batch: 22
epochs: 3 train loss: 2.37890625  train f1: 0.50000  lr: 0.0004328176001410148 batch: 22 
epochs: 3 val loss: 3.85546875  val f1:0.14286  lr: 0.0004328176001410148 batch: 22
epochs: 4 train loss: 0.0235443115234375  train f1: 1.00000  lr: 0.0004328176001410148 batch: 22 
epochs: 4 val loss: 4.37890625  val f1:0.14286  lr: 0.0004328176001410148 batch: 22
epochs: 5 train loss: 0.0006775856018066406  train f1: 1.00000  lr: 0.0004328176001410148 batch: 22 
epochs: 5 val loss: 4.5390625  val f1:0.14286  lr: 0.0004328176001410148 batch: 22
epochs: 6 train loss: 0.00040531158447265625  train f1: 1.00000  lr: 0.0004328176001410148 batch: 22 
epochs: 6 val loss: 4.66796875  val f1:0.16667  lr: 0.0004328176001410148 batch: 22
epochs: 7 train loss: 0.0004017353057861328  train f1: 1.00000  lr: 0.0004328176001410148 batch: 22 
epochs: 7 val loss: 4.75390625  val f1:0.16667  lr: 0.0004328176001410148 batch: 22
epochs: 8 train loss: 0.00032329559326171875  train f1: 1.00000  lr: 0.0004328176001410148 batch: 22 
epochs: 8 val loss: 4.76171875  val f1:0.16667  lr: 0.0004328176001410148 batch: 22
epochs: 9 train loss: 0.0003657341003417969  train f1: 1.00000  lr: 0.0004328176001410148 batch: 22 
epochs: 9 val loss: 4.72265625  val f1:0.16667  lr: 0.0004328176001410148 batch: 22
epochs: 10 train loss: 0.00033473968505859375  train f1: 1.00000  lr: 0.0004328176001410148 batch: 22 
epochs: 10 val loss: 4.76171875  val f1:0.16667  lr: 0.0004328176001410148 batch: 22
epochs: 11 train loss: 0.00031495094299316406  train f1: 1.00000  lr: 0.0004328176001410148 batch: 22 
epochs: 11 val loss: 4.74609375  val f1:0.16667  lr: 0.0004328176001410148 batch: 22
epochs: 0 train loss: 4.29296875  train f1: 0.00000  lr: 0.00042688994895586567 batch: 28 
epochs: 0 val loss: 4.921875  val f1:0.00000  lr: 0.00042688994895586567 batch: 28
epochs: 1 train loss: 4.27734375  train f1: 0.00000  lr: 0.00042688994895586567 batch: 28 
epochs: 1 val loss: 4.06640625  val f1:0.14286  lr: 0.00042688994895586567 batch: 28
epochs: 2 train loss: 0.1279296875  train f1: 1.00000  lr: 0.00042688994895586567 batch: 28 
epochs: 2 val loss: 5.87890625  val f1:0.14286  lr: 0.00042688994895586567 batch: 28
epochs: 3 train loss: 0.88671875  train f1: 1.00000  lr: 0.00042688994895586567 batch: 28 
epochs: 3 val loss: 7.921875  val f1:0.16667  lr: 0.00042688994895586567 batch: 28
epochs: 4 train loss: 0.0013074874877929688  train f1: 1.00000  lr: 0.00042688994895586567 batch: 28 
epochs: 4 val loss: 7.60546875  val f1:0.16667  lr: 0.00042688994895586567 batch: 28
epochs: 5 train loss: 0.0008544921875  train f1: 1.00000  lr: 0.00042688994895586567 batch: 28 
epochs: 5 val loss: 6.94921875  val f1:0.16667  lr: 0.00042688994895586567 batch: 28
epochs: 6 train loss: 0.01110076904296875  train f1: 1.00000  lr: 0.00042688994895586567 batch: 28 
epochs: 6 val loss: 5.78125  val f1:0.16667  lr: 0.00042688994895586567 batch: 28
epochs: 7 train loss: 8.153915405273438e-05  train f1: 1.00000  lr: 0.00042688994895586567 batch: 28 
epochs: 7 val loss: 5.234375  val f1:0.16667  lr: 0.00042688994895586567 batch: 28
epochs: 8 train loss: 8.7738037109375e-05  train f1: 1.00000  lr: 0.00042688994895586567 batch: 28 
epochs: 8 val loss: 4.88671875  val f1:0.16667  lr: 0.00042688994895586567 batch: 28
epochs: 9 train loss: 0.0003952980041503906  train f1: 1.00000  lr: 0.00042688994895586567 batch: 28 
epochs: 9 val loss: 4.69140625  val f1:0.16667  lr: 0.00042688994895586567 batch: 28
epochs: 10 train loss: 5.269050598144531e-05  train f1: 1.00000  lr: 0.00042688994895586567 batch: 28 
epochs: 10 val loss: 4.53125  val f1:0.16667  lr: 0.00042688994895586567 batch: 28
epochs: 0 train loss: 4.65625  train f1: 0.00000  lr: 0.0004243903535285105 batch: 29 
epochs: 0 val loss: 4.9765625  val f1:0.00000  lr: 0.0004243903535285105 batch: 29
epochs: 1 train loss: 4.53515625  train f1: 0.00000  lr: 0.0004243903535285105 batch: 29 
epochs: 1 val loss: 4.51171875  val f1:0.25000  lr: 0.0004243903535285105 batch: 29
epochs: 2 train loss: 0.308837890625  train f1: 1.00000  lr: 0.0004243903535285105 batch: 29 
epochs: 2 val loss: 4.21875  val f1:0.14286  lr: 0.0004243903535285105 batch: 29
epochs: 3 train loss: 1.1298828125  train f1: 0.50000  lr: 0.0004243903535285105 batch: 29 
epochs: 3 val loss: 4.1875  val f1:0.12500  lr: 0.0004243903535285105 batch: 29
epochs: 4 train loss: 0.0168609619140625  train f1: 1.00000  lr: 0.0004243903535285105 batch: 29 
epochs: 4 val loss: 4.26953125  val f1:0.12500  lr: 0.0004243903535285105 batch: 29
epochs: 5 train loss: 0.00017905235290527344  train f1: 1.00000  lr: 0.0004243903535285105 batch: 29 
epochs: 5 val loss: 4.21875  val f1:0.12500  lr: 0.0004243903535285105 batch: 29
epochs: 6 train loss: 6.002187728881836e-05  train f1: 1.00000  lr: 0.0004243903535285105 batch: 29 
epochs: 6 val loss: 4.22265625  val f1:0.12500  lr: 0.0004243903535285105 batch: 29
epochs: 7 train loss: 0.0001704692840576172  train f1: 1.00000  lr: 0.0004243903535285105 batch: 29 
epochs: 7 val loss: 4.2265625  val f1:0.12500  lr: 0.0004243903535285105 batch: 29
epochs: 8 train loss: 8.106231689453125e-05  train f1: 1.00000  lr: 0.0004243903535285105 batch: 29 
epochs: 8 val loss: 4.2578125  val f1:0.12500  lr: 0.0004243903535285105 batch: 29
epochs: 9 train loss: 9.071826934814453e-05  train f1: 1.00000  lr: 0.0004243903535285105 batch: 29 
epochs: 9 val loss: 4.23828125  val f1:0.12500  lr: 0.0004243903535285105 batch: 29
epochs: 10 train loss: 7.998943328857422e-05  train f1: 1.00000  lr: 0.0004243903535285105 batch: 29 
epochs: 10 val loss: 4.25  val f1:0.12500  lr: 0.0004243903535285105 batch: 29
epochs: 0 train loss: 4.625  train f1: 0.00000  lr: 0.000598991043096494 batch: 28 
epochs: 0 val loss: 4.5  val f1:0.00000  lr: 0.000598991043096494 batch: 28
epochs: 1 train loss: 4.55859375  train f1: 0.00000  lr: 0.000598991043096494 batch: 28 
epochs: 1 val loss: 4.19921875  val f1:0.12500  lr: 0.000598991043096494 batch: 28
epochs: 0 train loss: 4.87109375  train f1: 0.00000  lr: 0.00046702273665221247 batch: 22 
epochs: 0 val loss: 5.171875  val f1:0.00000  lr: 0.00046702273665221247 batch: 22
epochs: 1 train loss: 4.82421875  train f1: 0.00000  lr: 0.00046702273665221247 batch: 22 
epochs: 1 val loss: 4.171875  val f1:0.00000  lr: 0.00046702273665221247 batch: 22
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.00031951642580091975 batch: 28 
epochs: 0 val loss: 4.79296875  val f1:0.00000  lr: 0.00031951642580091975 batch: 28
epochs: 1 train loss: 4.35546875  train f1: 0.00000  lr: 0.00031951642580091975 batch: 28 
epochs: 1 val loss: 4.41796875  val f1:0.14286  lr: 0.00031951642580091975 batch: 28
epochs: 2 train loss: 0.1939697265625  train f1: 1.00000  lr: 0.00031951642580091975 batch: 28 
epochs: 2 val loss: 4.11328125  val f1:0.14286  lr: 0.00031951642580091975 batch: 28
epochs: 3 train loss: 0.79443359375  train f1: 1.00000  lr: 0.00031951642580091975 batch: 28 
epochs: 3 val loss: 7.25390625  val f1:0.16667  lr: 0.00031951642580091975 batch: 28
epochs: 4 train loss: 0.002651214599609375  train f1: 1.00000  lr: 0.00031951642580091975 batch: 28 
epochs: 4 val loss: 6.140625  val f1:0.16667  lr: 0.00031951642580091975 batch: 28
epochs: 5 train loss: 0.0021877288818359375  train f1: 1.00000  lr: 0.00031951642580091975 batch: 28 
epochs: 5 val loss: 5.3359375  val f1:0.16667  lr: 0.00031951642580091975 batch: 28
epochs: 6 train loss: 0.0009045600891113281  train f1: 1.00000  lr: 0.00031951642580091975 batch: 28 
epochs: 6 val loss: 4.70703125  val f1:0.16667  lr: 0.00031951642580091975 batch: 28
epochs: 7 train loss: 0.002349853515625  train f1: 1.00000  lr: 0.00031951642580091975 batch: 28 
epochs: 7 val loss: 4.44140625  val f1:0.16667  lr: 0.00031951642580091975 batch: 28
epochs: 8 train loss: 0.0004520416259765625  train f1: 1.00000  lr: 0.00031951642580091975 batch: 28 
epochs: 8 val loss: 4.3671875  val f1:0.16667  lr: 0.00031951642580091975 batch: 28
epochs: 9 train loss: 0.0005726814270019531  train f1: 1.00000  lr: 0.00031951642580091975 batch: 28 
epochs: 9 val loss: 4.33984375  val f1:0.16667  lr: 0.00031951642580091975 batch: 28
epochs: 10 train loss: 0.00038170814514160156  train f1: 1.00000  lr: 0.00031951642580091975 batch: 28 
epochs: 10 val loss: 4.31640625  val f1:0.16667  lr: 0.00031951642580091975 batch: 28
epochs: 0 train loss: 4.97265625  train f1: 0.00000  lr: 0.0003390811455783414 batch: 28 
epochs: 0 val loss: 4.6328125  val f1:0.00000  lr: 0.0003390811455783414 batch: 28
epochs: 1 train loss: 4.953125  train f1: 0.00000  lr: 0.0003390811455783414 batch: 28 
epochs: 1 val loss: 3.9375  val f1:0.11111  lr: 0.0003390811455783414 batch: 28
epochs: 0 train loss: 4.8828125  train f1: 0.00000  lr: 0.00039115497120091543 batch: 28 
epochs: 0 val loss: 5.26953125  val f1:0.00000  lr: 0.00039115497120091543 batch: 28
epochs: 1 train loss: 5.015625  train f1: 0.00000  lr: 0.00039115497120091543 batch: 28 
epochs: 1 val loss: 4.0  val f1:0.12500  lr: 0.00039115497120091543 batch: 28
epochs: 0 train loss: 4.875  train f1: 0.00000  lr: 0.000268398889765318 batch: 22 
epochs: 0 val loss: 4.54296875  val f1:0.00000  lr: 0.000268398889765318 batch: 22
epochs: 1 train loss: 4.7578125  train f1: 0.00000  lr: 0.000268398889765318 batch: 22 
epochs: 1 val loss: 3.576171875  val f1:0.11111  lr: 0.000268398889765318 batch: 22
epochs: 0 train loss: 4.96875  train f1: 0.00000  lr: 0.0003100452783802471 batch: 29 
epochs: 0 val loss: 4.4296875  val f1:0.00000  lr: 0.0003100452783802471 batch: 29
epochs: 1 train loss: 4.875  train f1: 0.00000  lr: 0.0003100452783802471 batch: 29 
epochs: 1 val loss: 3.33203125  val f1:0.12500  lr: 0.0003100452783802471 batch: 29
epochs: 0 train loss: 4.20703125  train f1: 0.00000  lr: 0.0005087306177137705 batch: 28 
epochs: 0 val loss: 4.88671875  val f1:0.00000  lr: 0.0005087306177137705 batch: 28
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0005087306177137705 batch: 28 
epochs: 1 val loss: 4.875  val f1:0.12500  lr: 0.0005087306177137705 batch: 28
epochs: 0 train loss: 4.984375  train f1: 0.00000  lr: 0.0006650320956979479 batch: 27 
epochs: 0 val loss: 5.6328125  val f1:0.00000  lr: 0.0006650320956979479 batch: 27
epochs: 1 train loss: 4.91015625  train f1: 0.00000  lr: 0.0006650320956979479 batch: 27 
epochs: 1 val loss: 4.2109375  val f1:0.14286  lr: 0.0006650320956979479 batch: 27
epochs: 2 train loss: 0.52734375  train f1: 1.00000  lr: 0.0006650320956979479 batch: 27 
epochs: 2 val loss: 9.140625  val f1:0.00000  lr: 0.0006650320956979479 batch: 27
epochs: 3 train loss: 1.4580078125  train f1: 1.00000  lr: 0.0006650320956979479 batch: 27 
epochs: 3 val loss: 4.22265625  val f1:0.00000  lr: 0.0006650320956979479 batch: 27
epochs: 4 train loss: 0.1328125  train f1: 1.00000  lr: 0.0006650320956979479 batch: 27 
epochs: 4 val loss: 19.296875  val f1:0.00000  lr: 0.0006650320956979479 batch: 27
epochs: 5 train loss: 9.28640365600586e-05  train f1: 1.00000  lr: 0.0006650320956979479 batch: 27 
epochs: 5 val loss: 14.2734375  val f1:0.00000  lr: 0.0006650320956979479 batch: 27
epochs: 6 train loss: 0.00010025501251220703  train f1: 1.00000  lr: 0.0006650320956979479 batch: 27 
epochs: 6 val loss: 11.3671875  val f1:0.00000  lr: 0.0006650320956979479 batch: 27
epochs: 7 train loss: 7.87973403930664e-05  train f1: 1.00000  lr: 0.0006650320956979479 batch: 27 
epochs: 7 val loss: 9.40625  val f1:0.16667  lr: 0.0006650320956979479 batch: 27
epochs: 8 train loss: 0.00011742115020751953  train f1: 1.00000  lr: 0.0006650320956979479 batch: 27 
epochs: 8 val loss: 8.0  val f1:0.16667  lr: 0.0006650320956979479 batch: 27
epochs: 9 train loss: 0.00011342763900756836  train f1: 1.00000  lr: 0.0006650320956979479 batch: 27 
epochs: 9 val loss: 7.0390625  val f1:0.16667  lr: 0.0006650320956979479 batch: 27
epochs: 10 train loss: 7.390975952148438e-05  train f1: 1.00000  lr: 0.0006650320956979479 batch: 27 
epochs: 10 val loss: 6.30078125  val f1:0.16667  lr: 0.0006650320956979479 batch: 27
epochs: 0 train loss: 4.1328125  train f1: 0.00000  lr: 0.0007560883530613662 batch: 27 
epochs: 0 val loss: 4.40625  val f1:0.00000  lr: 0.0007560883530613662 batch: 27
epochs: 1 train loss: 4.28125  train f1: 0.00000  lr: 0.0007560883530613662 batch: 27 
epochs: 1 val loss: 4.41015625  val f1:0.00000  lr: 0.0007560883530613662 batch: 27
epochs: 0 train loss: 4.56640625  train f1: 0.00000  lr: 0.00039993646419074036 batch: 28 
epochs: 0 val loss: 5.05078125  val f1:0.00000  lr: 0.00039993646419074036 batch: 28
epochs: 1 train loss: 4.5390625  train f1: 0.00000  lr: 0.00039993646419074036 batch: 28 
epochs: 1 val loss: 3.765625  val f1:0.11111  lr: 0.00039993646419074036 batch: 28
epochs: 0 train loss: 4.7109375  train f1: 0.00000  lr: 0.0006402204551343922 batch: 27 
epochs: 0 val loss: 4.72265625  val f1:0.00000  lr: 0.0006402204551343922 batch: 27
epochs: 1 train loss: 4.78515625  train f1: 0.00000  lr: 0.0006402204551343922 batch: 27 
epochs: 1 val loss: 5.69140625  val f1:0.09524  lr: 0.0006402204551343922 batch: 27
epochs: 0 train loss: 4.875  train f1: 0.00000  lr: 0.0005678207862243825 batch: 30 
epochs: 0 val loss: 4.73046875  val f1:0.00000  lr: 0.0005678207862243825 batch: 30
epochs: 1 train loss: 4.9921875  train f1: 0.00000  lr: 0.0005678207862243825 batch: 30 
epochs: 1 val loss: 4.4609375  val f1:0.14286  lr: 0.0005678207862243825 batch: 30
epochs: 2 train loss: 0.153076171875  train f1: 1.00000  lr: 0.0005678207862243825 batch: 30 
epochs: 2 val loss: 5.65625  val f1:0.00000  lr: 0.0005678207862243825 batch: 30
epochs: 3 train loss: 0.2086181640625  train f1: 1.00000  lr: 0.0005678207862243825 batch: 30 
epochs: 3 val loss: 30.09375  val f1:0.16667  lr: 0.0005678207862243825 batch: 30
epochs: 4 train loss: 0.01451873779296875  train f1: 1.00000  lr: 0.0005678207862243825 batch: 30 
epochs: 4 val loss: 20.609375  val f1:0.16667  lr: 0.0005678207862243825 batch: 30
epochs: 5 train loss: 0.00014853477478027344  train f1: 1.00000  lr: 0.0005678207862243825 batch: 30 
epochs: 5 val loss: 16.03125  val f1:0.16667  lr: 0.0005678207862243825 batch: 30
epochs: 6 train loss: 0.00016069412231445312  train f1: 1.00000  lr: 0.0005678207862243825 batch: 30 
epochs: 6 val loss: 12.46875  val f1:0.16667  lr: 0.0005678207862243825 batch: 30
epochs: 7 train loss: 0.00012874603271484375  train f1: 1.00000  lr: 0.0005678207862243825 batch: 30 
epochs: 7 val loss: 9.671875  val f1:0.16667  lr: 0.0005678207862243825 batch: 30
epochs: 8 train loss: 8.803606033325195e-05  train f1: 1.00000  lr: 0.0005678207862243825 batch: 30 
epochs: 8 val loss: 7.37109375  val f1:0.16667  lr: 0.0005678207862243825 batch: 30
epochs: 9 train loss: 8.952617645263672e-05  train f1: 1.00000  lr: 0.0005678207862243825 batch: 30 
epochs: 9 val loss: 5.98046875  val f1:0.14286  lr: 0.0005678207862243825 batch: 30
epochs: 10 train loss: 8.380413055419922e-05  train f1: 1.00000  lr: 0.0005678207862243825 batch: 30 
epochs: 10 val loss: 5.26953125  val f1:0.14286  lr: 0.0005678207862243825 batch: 30
epochs: 0 train loss: 4.51953125  train f1: 0.00000  lr: 0.0008156312061147669 batch: 29 
epochs: 0 val loss: 4.625  val f1:0.00000  lr: 0.0008156312061147669 batch: 29
epochs: 1 train loss: 4.38671875  train f1: 0.00000  lr: 0.0008156312061147669 batch: 29 
epochs: 1 val loss: 5.59765625  val f1:0.00000  lr: 0.0008156312061147669 batch: 29
epochs: 0 train loss: 4.8359375  train f1: 0.00000  lr: 0.0004604419146643806 batch: 26 
epochs: 0 val loss: 5.7890625  val f1:0.00000  lr: 0.0004604419146643806 batch: 26
epochs: 1 train loss: 4.828125  train f1: 0.00000  lr: 0.0004604419146643806 batch: 26 
epochs: 1 val loss: 5.98046875  val f1:0.14286  lr: 0.0004604419146643806 batch: 26
epochs: 2 train loss: 0.708984375  train f1: 1.00000  lr: 0.0004604419146643806 batch: 26 
epochs: 2 val loss: 4.0390625  val f1:0.11111  lr: 0.0004604419146643806 batch: 26
epochs: 3 train loss: 1.9052734375  train f1: 0.50000  lr: 0.0004604419146643806 batch: 26 
epochs: 3 val loss: 8.1875  val f1:0.14286  lr: 0.0004604419146643806 batch: 26
epochs: 4 train loss: 0.00047326087951660156  train f1: 1.00000  lr: 0.0004604419146643806 batch: 26 
epochs: 4 val loss: 8.2109375  val f1:0.14286  lr: 0.0004604419146643806 batch: 26
epochs: 5 train loss: 0.0004608631134033203  train f1: 1.00000  lr: 0.0004604419146643806 batch: 26 
epochs: 5 val loss: 8.1015625  val f1:0.14286  lr: 0.0004604419146643806 batch: 26
epochs: 6 train loss: 0.00045108795166015625  train f1: 1.00000  lr: 0.0004604419146643806 batch: 26 
epochs: 6 val loss: 7.89453125  val f1:0.14286  lr: 0.0004604419146643806 batch: 26
epochs: 7 train loss: 0.0005240440368652344  train f1: 1.00000  lr: 0.0004604419146643806 batch: 26 
epochs: 7 val loss: 7.4453125  val f1:0.14286  lr: 0.0004604419146643806 batch: 26
epochs: 8 train loss: 0.000560760498046875  train f1: 1.00000  lr: 0.0004604419146643806 batch: 26 
epochs: 8 val loss: 6.91015625  val f1:0.14286  lr: 0.0004604419146643806 batch: 26
epochs: 0 train loss: 4.64453125  train f1: 0.00000  lr: 0.0010150727156427062 batch: 27 
epochs: 0 val loss: 4.8515625  val f1:0.00000  lr: 0.0010150727156427062 batch: 27
epochs: 1 train loss: 4.7421875  train f1: 0.00000  lr: 0.0010150727156427062 batch: 27 
epochs: 1 val loss: 7.22265625  val f1:0.16667  lr: 0.0010150727156427062 batch: 27
epochs: 2 train loss: 1.259765625  train f1: 1.00000  lr: 0.0010150727156427062 batch: 27 
epochs: 2 val loss: 88.8125  val f1:0.00000  lr: 0.0010150727156427062 batch: 27
epochs: 3 train loss: 3.01171875  train f1: 0.50000  lr: 0.0010150727156427062 batch: 27 
epochs: 3 val loss: 16.15625  val f1:0.00000  lr: 0.0010150727156427062 batch: 27
epochs: 4 train loss: 6.89453125  train f1: 0.00000  lr: 0.0010150727156427062 batch: 27 
epochs: 4 val loss: 17.09375  val f1:0.00000  lr: 0.0010150727156427062 batch: 27
epochs: 5 train loss: 8.453125  train f1: 0.00000  lr: 0.0010150727156427062 batch: 27 
epochs: 5 val loss: 15.7890625  val f1:0.00000  lr: 0.0010150727156427062 batch: 27
epochs: 6 train loss: 8.328125  train f1: 0.00000  lr: 0.0010150727156427062 batch: 27 
epochs: 6 val loss: 45.28125  val f1:0.11111  lr: 0.0010150727156427062 batch: 27
epochs: 7 train loss: 12.84375  train f1: 0.00000  lr: 0.0010150727156427062 batch: 27 
epochs: 7 val loss: 267.0  val f1:0.06667  lr: 0.0010150727156427062 batch: 27
epochs: 8 train loss: 2.23828125  train f1: 0.25000  lr: 0.0010150727156427062 batch: 27 
epochs: 8 val loss: 91.25  val f1:0.06667  lr: 0.0010150727156427062 batch: 27
epochs: 9 train loss: 2.00390625  train f1: 0.38889  lr: 0.0010150727156427062 batch: 27 
epochs: 9 val loss: 14.078125  val f1:0.00000  lr: 0.0010150727156427062 batch: 27
epochs: 0 train loss: 4.3203125  train f1: 0.00000  lr: 0.0006335647941366128 batch: 26 
epochs: 0 val loss: 4.2890625  val f1:0.00000  lr: 0.0006335647941366128 batch: 26
epochs: 1 train loss: 4.4453125  train f1: 0.00000  lr: 0.0006335647941366128 batch: 26 
epochs: 1 val loss: 4.05859375  val f1:0.12500  lr: 0.0006335647941366128 batch: 26
epochs: 0 train loss: 5.0  train f1: 0.00000  lr: 0.00034111578866733084 batch: 21 
epochs: 0 val loss: 4.90625  val f1:0.00000  lr: 0.00034111578866733084 batch: 21
epochs: 1 train loss: 4.9453125  train f1: 0.00000  lr: 0.00034111578866733084 batch: 21 
epochs: 1 val loss: 4.1171875  val f1:0.11111  lr: 0.00034111578866733084 batch: 21
epochs: 0 train loss: 4.62109375  train f1: 0.00000  lr: 0.0005283763244891285 batch: 23 
epochs: 0 val loss: 4.79296875  val f1:0.00000  lr: 0.0005283763244891285 batch: 23
epochs: 1 train loss: 4.57421875  train f1: 0.00000  lr: 0.0005283763244891285 batch: 23 
epochs: 1 val loss: 4.09375  val f1:0.08333  lr: 0.0005283763244891285 batch: 23
epochs: 0 train loss: 4.078125  train f1: 0.16667  lr: 0.0004200833886610787 batch: 28 
epochs: 0 val loss: 3.84765625  val f1:0.14286  lr: 0.0004200833886610787 batch: 28
epochs: 1 train loss: 4.01953125  train f1: 0.16667  lr: 0.0004200833886610787 batch: 28 
epochs: 1 val loss: 4.0546875  val f1:0.14286  lr: 0.0004200833886610787 batch: 28
epochs: 2 train loss: 0.281494140625  train f1: 1.00000  lr: 0.0004200833886610787 batch: 28 
epochs: 2 val loss: 6.27734375  val f1:0.16667  lr: 0.0004200833886610787 batch: 28
epochs: 3 train loss: 0.91064453125  train f1: 1.00000  lr: 0.0004200833886610787 batch: 28 
epochs: 3 val loss: 6.47265625  val f1:0.16667  lr: 0.0004200833886610787 batch: 28
epochs: 4 train loss: 0.0004017353057861328  train f1: 1.00000  lr: 0.0004200833886610787 batch: 28 
epochs: 4 val loss: 6.59765625  val f1:0.16667  lr: 0.0004200833886610787 batch: 28
epochs: 5 train loss: 0.00022673606872558594  train f1: 1.00000  lr: 0.0004200833886610787 batch: 28 
epochs: 5 val loss: 6.53125  val f1:0.16667  lr: 0.0004200833886610787 batch: 28
epochs: 6 train loss: 0.00023627281188964844  train f1: 1.00000  lr: 0.0004200833886610787 batch: 28 
epochs: 6 val loss: 6.66796875  val f1:0.16667  lr: 0.0004200833886610787 batch: 28
epochs: 7 train loss: 0.0008440017700195312  train f1: 1.00000  lr: 0.0004200833886610787 batch: 28 
epochs: 7 val loss: 6.7578125  val f1:0.16667  lr: 0.0004200833886610787 batch: 28
epochs: 0 train loss: 4.5390625  train f1: 0.00000  lr: 0.0006451577636108927 batch: 28 
epochs: 0 val loss: 5.33984375  val f1:0.00000  lr: 0.0006451577636108927 batch: 28
epochs: 1 train loss: 4.65625  train f1: 0.00000  lr: 0.0006451577636108927 batch: 28 
epochs: 1 val loss: 3.283203125  val f1:0.25000  lr: 0.0006451577636108927 batch: 28
epochs: 2 train loss: 0.237548828125  train f1: 1.00000  lr: 0.0006451577636108927 batch: 28 
epochs: 2 val loss: 4.73828125  val f1:0.11111  lr: 0.0006451577636108927 batch: 28
epochs: 3 train loss: 1.0107421875  train f1: 0.50000  lr: 0.0006451577636108927 batch: 28 
epochs: 3 val loss: 23.5625  val f1:0.11111  lr: 0.0006451577636108927 batch: 28
epochs: 4 train loss: 3.6835670471191406e-05  train f1: 1.00000  lr: 0.0006451577636108927 batch: 28 
epochs: 4 val loss: 24.03125  val f1:0.11111  lr: 0.0006451577636108927 batch: 28
epochs: 5 train loss: 4.1425228118896484e-05  train f1: 1.00000  lr: 0.0006451577636108927 batch: 28 
epochs: 5 val loss: 22.671875  val f1:0.11111  lr: 0.0006451577636108927 batch: 28
epochs: 6 train loss: 0.00012540817260742188  train f1: 1.00000  lr: 0.0006451577636108927 batch: 28 
epochs: 6 val loss: 21.484375  val f1:0.11111  lr: 0.0006451577636108927 batch: 28
epochs: 7 train loss: 2.5451183319091797e-05  train f1: 1.00000  lr: 0.0006451577636108927 batch: 28 
epochs: 7 val loss: 19.984375  val f1:0.14286  lr: 0.0006451577636108927 batch: 28
epochs: 0 train loss: 4.55859375  train f1: 0.00000  lr: 0.00048140086777893415 batch: 27 
epochs: 0 val loss: 4.15625  val f1:0.00000  lr: 0.00048140086777893415 batch: 27
epochs: 1 train loss: 4.546875  train f1: 0.00000  lr: 0.00048140086777893415 batch: 27 
epochs: 1 val loss: 3.61328125  val f1:0.11111  lr: 0.00048140086777893415 batch: 27
epochs: 0 train loss: 4.8125  train f1: 0.00000  lr: 0.0008197350530066493 batch: 21 
epochs: 0 val loss: 4.2265625  val f1:0.08333  lr: 0.0008197350530066493 batch: 21
epochs: 1 train loss: 4.7890625  train f1: 0.00000  lr: 0.0008197350530066493 batch: 21 
epochs: 1 val loss: 5.54296875  val f1:0.00000  lr: 0.0008197350530066493 batch: 21
epochs: 0 train loss: 4.58984375  train f1: 0.00000  lr: 0.0004466853105611403 batch: 26 
epochs: 0 val loss: 4.6875  val f1:0.00000  lr: 0.0004466853105611403 batch: 26
epochs: 1 train loss: 4.6953125  train f1: 0.00000  lr: 0.0004466853105611403 batch: 26 
epochs: 1 val loss: 3.958984375  val f1:0.12500  lr: 0.0004466853105611403 batch: 26
epochs: 0 train loss: 4.7734375  train f1: 0.00000  lr: 0.000655051165576677 batch: 29 
epochs: 0 val loss: 5.10546875  val f1:0.00000  lr: 0.000655051165576677 batch: 29
epochs: 1 train loss: 4.78515625  train f1: 0.00000  lr: 0.000655051165576677 batch: 29 
epochs: 1 val loss: 4.77734375  val f1:0.11111  lr: 0.000655051165576677 batch: 29
epochs: 0 train loss: 4.828125  train f1: 0.00000  lr: 0.00041847926868594223 batch: 28 
epochs: 0 val loss: 5.578125  val f1:0.00000  lr: 0.00041847926868594223 batch: 28
epochs: 1 train loss: 4.77734375  train f1: 0.00000  lr: 0.00041847926868594223 batch: 28 
epochs: 1 val loss: 4.57421875  val f1:0.12500  lr: 0.00041847926868594223 batch: 28
epochs: 0 train loss: 4.80078125  train f1: 0.00000  lr: 0.0005487663741867201 batch: 27 
epochs: 0 val loss: 4.98828125  val f1:0.00000  lr: 0.0005487663741867201 batch: 27
epochs: 1 train loss: 4.7265625  train f1: 0.00000  lr: 0.0005487663741867201 batch: 27 
epochs: 1 val loss: 4.640625  val f1:0.16667  lr: 0.0005487663741867201 batch: 27
epochs: 2 train loss: 0.09893798828125  train f1: 1.00000  lr: 0.0005487663741867201 batch: 27 
epochs: 2 val loss: 9.1640625  val f1:0.14286  lr: 0.0005487663741867201 batch: 27
epochs: 3 train loss: 0.198974609375  train f1: 1.00000  lr: 0.0005487663741867201 batch: 27 
epochs: 3 val loss: 3.7578125  val f1:0.12500  lr: 0.0005487663741867201 batch: 27
epochs: 4 train loss: 0.445068359375  train f1: 1.00000  lr: 0.0005487663741867201 batch: 27 
epochs: 4 val loss: 8.640625  val f1:0.14286  lr: 0.0005487663741867201 batch: 27
epochs: 5 train loss: 0.0005931854248046875  train f1: 1.00000  lr: 0.0005487663741867201 batch: 27 
epochs: 5 val loss: 6.2421875  val f1:0.14286  lr: 0.0005487663741867201 batch: 27
epochs: 6 train loss: 5.3763389587402344e-05  train f1: 1.00000  lr: 0.0005487663741867201 batch: 27 
epochs: 6 val loss: 5.125  val f1:0.14286  lr: 0.0005487663741867201 batch: 27
epochs: 7 train loss: 0.00012636184692382812  train f1: 1.00000  lr: 0.0005487663741867201 batch: 27 
epochs: 7 val loss: 4.66015625  val f1:0.14286  lr: 0.0005487663741867201 batch: 27
epochs: 8 train loss: 5.1975250244140625e-05  train f1: 1.00000  lr: 0.0005487663741867201 batch: 27 
epochs: 8 val loss: 4.74609375  val f1:0.14286  lr: 0.0005487663741867201 batch: 27
epochs: 0 train loss: 4.9296875  train f1: 0.00000  lr: 0.0003532502707260196 batch: 20 
epochs: 0 val loss: 4.5546875  val f1:0.00000  lr: 0.0003532502707260196 batch: 20
epochs: 1 train loss: 4.75  train f1: 0.00000  lr: 0.0003532502707260196 batch: 20 
epochs: 1 val loss: 3.767578125  val f1:0.11111  lr: 0.0003532502707260196 batch: 20
epochs: 0 train loss: 4.70703125  train f1: 0.00000  lr: 0.00041939874359706427 batch: 10 
epochs: 0 val loss: 4.58984375  val f1:0.00000  lr: 0.00041939874359706427 batch: 10
epochs: 1 train loss: 4.55859375  train f1: 0.00000  lr: 0.00041939874359706427 batch: 10 
epochs: 1 val loss: 3.6875  val f1:0.14286  lr: 0.00041939874359706427 batch: 10
epochs: 2 train loss: 0.1719970703125  train f1: 1.00000  lr: 0.00041939874359706427 batch: 10 
epochs: 2 val loss: 9.46875  val f1:0.16667  lr: 0.00041939874359706427 batch: 10
epochs: 3 train loss: 1.4677734375  train f1: 1.00000  lr: 0.00041939874359706427 batch: 10 
epochs: 3 val loss: 4.578125  val f1:0.16667  lr: 0.00041939874359706427 batch: 10
epochs: 4 train loss: 0.0239715576171875  train f1: 1.00000  lr: 0.00041939874359706427 batch: 10 
epochs: 4 val loss: 4.6953125  val f1:0.16667  lr: 0.00041939874359706427 batch: 10
epochs: 5 train loss: 0.00043892860412597656  train f1: 1.00000  lr: 0.00041939874359706427 batch: 10 
epochs: 5 val loss: 4.4453125  val f1:0.16667  lr: 0.00041939874359706427 batch: 10
epochs: 6 train loss: 0.00024390220642089844  train f1: 1.00000  lr: 0.00041939874359706427 batch: 10 
epochs: 6 val loss: 4.3203125  val f1:0.16667  lr: 0.00041939874359706427 batch: 10
epochs: 7 train loss: 0.00022172927856445312  train f1: 1.00000  lr: 0.00041939874359706427 batch: 10 
epochs: 7 val loss: 4.3125  val f1:0.14286  lr: 0.00041939874359706427 batch: 10
epochs: 0 train loss: 4.6015625  train f1: 0.00000  lr: 0.0005469143266060078 batch: 22 
epochs: 0 val loss: 4.71484375  val f1:0.00000  lr: 0.0005469143266060078 batch: 22
epochs: 1 train loss: 4.58203125  train f1: 0.00000  lr: 0.0005469143266060078 batch: 22 
epochs: 1 val loss: 4.30859375  val f1:0.12500  lr: 0.0005469143266060078 batch: 22
epochs: 0 train loss: 4.1484375  train f1: 0.00000  lr: 0.0006875288638930355 batch: 21 
epochs: 0 val loss: 5.1953125  val f1:0.00000  lr: 0.0006875288638930355 batch: 21
epochs: 1 train loss: 4.046875  train f1: 0.00000  lr: 0.0006875288638930355 batch: 21 
epochs: 1 val loss: 8.4453125  val f1:0.14286  lr: 0.0006875288638930355 batch: 21
epochs: 2 train loss: 0.1533203125  train f1: 1.00000  lr: 0.0006875288638930355 batch: 21 
epochs: 2 val loss: 3.78515625  val f1:0.12500  lr: 0.0006875288638930355 batch: 21
epochs: 3 train loss: 2.26953125  train f1: 0.20000  lr: 0.0006875288638930355 batch: 21 
epochs: 3 val loss: 10.734375  val f1:0.14286  lr: 0.0006875288638930355 batch: 21
epochs: 4 train loss: 0.0006442070007324219  train f1: 1.00000  lr: 0.0006875288638930355 batch: 21 
epochs: 4 val loss: 9.171875  val f1:0.14286  lr: 0.0006875288638930355 batch: 21
epochs: 5 train loss: 0.00026106834411621094  train f1: 1.00000  lr: 0.0006875288638930355 batch: 21 
epochs: 5 val loss: 8.375  val f1:0.14286  lr: 0.0006875288638930355 batch: 21
epochs: 6 train loss: 0.00016117095947265625  train f1: 1.00000  lr: 0.0006875288638930355 batch: 21 
epochs: 6 val loss: 7.78125  val f1:0.16667  lr: 0.0006875288638930355 batch: 21
epochs: 7 train loss: 9.882450103759766e-05  train f1: 1.00000  lr: 0.0006875288638930355 batch: 21 
epochs: 7 val loss: 7.27734375  val f1:0.16667  lr: 0.0006875288638930355 batch: 21
epochs: 8 train loss: 0.0012331008911132812  train f1: 1.00000  lr: 0.0006875288638930355 batch: 21 
epochs: 8 val loss: 7.26171875  val f1:0.16667  lr: 0.0006875288638930355 batch: 21
epochs: 9 train loss: 5.233287811279297e-05  train f1: 1.00000  lr: 0.0006875288638930355 batch: 21 
epochs: 9 val loss: 7.07421875  val f1:0.16667  lr: 0.0006875288638930355 batch: 21
epochs: 10 train loss: 5.0902366638183594e-05  train f1: 1.00000  lr: 0.0006875288638930355 batch: 21 
epochs: 10 val loss: 6.9453125  val f1:0.16667  lr: 0.0006875288638930355 batch: 21
epochs: 0 train loss: 4.6015625  train f1: 0.00000  lr: 0.0007276729874155724 batch: 21 
epochs: 0 val loss: 5.1171875  val f1:0.00000  lr: 0.0007276729874155724 batch: 21
epochs: 1 train loss: 4.734375  train f1: 0.00000  lr: 0.0007276729874155724 batch: 21 
epochs: 1 val loss: 5.89453125  val f1:0.14286  lr: 0.0007276729874155724 batch: 21
epochs: 2 train loss: 0.208984375  train f1: 1.00000  lr: 0.0007276729874155724 batch: 21 
epochs: 2 val loss: 7.9375  val f1:0.11111  lr: 0.0007276729874155724 batch: 21
epochs: 3 train loss: 1.3466796875  train f1: 0.50000  lr: 0.0007276729874155724 batch: 21 
epochs: 3 val loss: 13.109375  val f1:0.14286  lr: 0.0007276729874155724 batch: 21
epochs: 4 train loss: 0.0025997161865234375  train f1: 1.00000  lr: 0.0007276729874155724 batch: 21 
epochs: 4 val loss: 10.7734375  val f1:0.14286  lr: 0.0007276729874155724 batch: 21
epochs: 5 train loss: 0.0002770423889160156  train f1: 1.00000  lr: 0.0007276729874155724 batch: 21 
epochs: 5 val loss: 9.796875  val f1:0.16667  lr: 0.0007276729874155724 batch: 21
epochs: 6 train loss: 0.00010710954666137695  train f1: 1.00000  lr: 0.0007276729874155724 batch: 21 
epochs: 6 val loss: 8.9296875  val f1:0.16667  lr: 0.0007276729874155724 batch: 21
epochs: 7 train loss: 0.00010204315185546875  train f1: 1.00000  lr: 0.0007276729874155724 batch: 21 
epochs: 7 val loss: 8.125  val f1:0.16667  lr: 0.0007276729874155724 batch: 21
epochs: 8 train loss: 0.00010764598846435547  train f1: 1.00000  lr: 0.0007276729874155724 batch: 21 
epochs: 8 val loss: 7.359375  val f1:0.16667  lr: 0.0007276729874155724 batch: 21
epochs: 9 train loss: 0.00014209747314453125  train f1: 1.00000  lr: 0.0007276729874155724 batch: 21 
epochs: 9 val loss: 6.64453125  val f1:0.16667  lr: 0.0007276729874155724 batch: 21
epochs: 10 train loss: 0.00011527538299560547  train f1: 1.00000  lr: 0.0007276729874155724 batch: 21 
epochs: 10 val loss: 5.703125  val f1:0.14286  lr: 0.0007276729874155724 batch: 21
epochs: 11 train loss: 6.508827209472656e-05  train f1: 1.00000  lr: 0.0007276729874155724 batch: 21 
epochs: 11 val loss: 5.00390625  val f1:0.14286  lr: 0.0007276729874155724 batch: 21
epochs: 0 train loss: 4.70703125  train f1: 0.00000  lr: 0.00051072962894921 batch: 22 
epochs: 0 val loss: 4.3984375  val f1:0.00000  lr: 0.00051072962894921 batch: 22
epochs: 1 train loss: 4.60546875  train f1: 0.00000  lr: 0.00051072962894921 batch: 22 
epochs: 1 val loss: 3.54296875  val f1:0.11111  lr: 0.00051072962894921 batch: 22
epochs: 0 train loss: 4.25  train f1: 0.00000  lr: 0.0009088969946066058 batch: 20 
epochs: 0 val loss: 4.703125  val f1:0.00000  lr: 0.0009088969946066058 batch: 20
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0009088969946066058 batch: 20 
epochs: 1 val loss: 14.2421875  val f1:0.00000  lr: 0.0009088969946066058 batch: 20
epochs: 0 train loss: 4.98046875  train f1: 0.00000  lr: 0.0002938744732390558 batch: 21 
epochs: 0 val loss: 5.0859375  val f1:0.00000  lr: 0.0002938744732390558 batch: 21
epochs: 1 train loss: 4.9921875  train f1: 0.00000  lr: 0.0002938744732390558 batch: 21 
epochs: 1 val loss: 3.962890625  val f1:0.12500  lr: 0.0002938744732390558 batch: 21
epochs: 0 train loss: 4.515625  train f1: 0.00000  lr: 0.0003795013412303891 batch: 23 
epochs: 0 val loss: 5.34375  val f1:0.00000  lr: 0.0003795013412303891 batch: 23
epochs: 1 train loss: 4.5078125  train f1: 0.00000  lr: 0.0003795013412303891 batch: 23 
epochs: 1 val loss: 4.0  val f1:0.11111  lr: 0.0003795013412303891 batch: 23
epochs: 0 train loss: 4.6328125  train f1: 0.00000  lr: 0.0006907762528771141 batch: 27 
epochs: 0 val loss: 5.05859375  val f1:0.00000  lr: 0.0006907762528771141 batch: 27
epochs: 1 train loss: 4.6484375  train f1: 0.00000  lr: 0.0006907762528771141 batch: 27 
epochs: 1 val loss: 4.2890625  val f1:0.16667  lr: 0.0006907762528771141 batch: 27
epochs: 2 train loss: 0.15234375  train f1: 1.00000  lr: 0.0006907762528771141 batch: 27 
epochs: 2 val loss: 30.421875  val f1:0.00000  lr: 0.0006907762528771141 batch: 27
epochs: 3 train loss: 1.634765625  train f1: 1.00000  lr: 0.0006907762528771141 batch: 27 
epochs: 3 val loss: 4.5859375  val f1:0.00000  lr: 0.0006907762528771141 batch: 27
epochs: 4 train loss: 1.029296875  train f1: 0.50000  lr: 0.0006907762528771141 batch: 27 
epochs: 4 val loss: 4.49609375  val f1:0.00000  lr: 0.0006907762528771141 batch: 27
epochs: 5 train loss: 0.0128936767578125  train f1: 1.00000  lr: 0.0006907762528771141 batch: 27 
epochs: 5 val loss: 4.4140625  val f1:0.14286  lr: 0.0006907762528771141 batch: 27
epochs: 6 train loss: 7.528066635131836e-05  train f1: 1.00000  lr: 0.0006907762528771141 batch: 27 
epochs: 6 val loss: 4.42578125  val f1:0.14286  lr: 0.0006907762528771141 batch: 27
epochs: 7 train loss: 6.473064422607422e-05  train f1: 1.00000  lr: 0.0006907762528771141 batch: 27 
epochs: 7 val loss: 4.45703125  val f1:0.14286  lr: 0.0006907762528771141 batch: 27
epochs: 8 train loss: 6.473064422607422e-05  train f1: 1.00000  lr: 0.0006907762528771141 batch: 27 
epochs: 8 val loss: 4.16796875  val f1:0.14286  lr: 0.0006907762528771141 batch: 27
epochs: 9 train loss: 3.9696693420410156e-05  train f1: 1.00000  lr: 0.0006907762528771141 batch: 27 
epochs: 9 val loss: 3.939453125  val f1:0.08333  lr: 0.0006907762528771141 batch: 27
epochs: 10 train loss: 3.3020973205566406e-05  train f1: 1.00000  lr: 0.0006907762528771141 batch: 27 
epochs: 10 val loss: 3.875  val f1:0.08333  lr: 0.0006907762528771141 batch: 27
epochs: 0 train loss: 4.16796875  train f1: 0.00000  lr: 0.0005872000737186243 batch: 19 
epochs: 0 val loss: 4.83203125  val f1:0.00000  lr: 0.0005872000737186243 batch: 19
epochs: 1 train loss: 4.3046875  train f1: 0.00000  lr: 0.0005872000737186243 batch: 19 
epochs: 1 val loss: 5.5  val f1:0.16667  lr: 0.0005872000737186243 batch: 19
epochs: 2 train loss: 0.337890625  train f1: 1.00000  lr: 0.0005872000737186243 batch: 19 
epochs: 2 val loss: 7.84375  val f1:0.14286  lr: 0.0005872000737186243 batch: 19
epochs: 3 train loss: 0.380615234375  train f1: 1.00000  lr: 0.0005872000737186243 batch: 19 
epochs: 3 val loss: 10.03125  val f1:0.00000  lr: 0.0005872000737186243 batch: 19
epochs: 4 train loss: 1.525390625  train f1: 1.00000  lr: 0.0005872000737186243 batch: 19 
epochs: 4 val loss: 10.390625  val f1:0.14286  lr: 0.0005872000737186243 batch: 19
epochs: 5 train loss: 0.4365234375  train f1: 1.00000  lr: 0.0005872000737186243 batch: 19 
epochs: 5 val loss: 12.171875  val f1:0.14286  lr: 0.0005872000737186243 batch: 19
epochs: 6 train loss: 0.00010001659393310547  train f1: 1.00000  lr: 0.0005872000737186243 batch: 19 
epochs: 6 val loss: 10.6796875  val f1:0.14286  lr: 0.0005872000737186243 batch: 19
epochs: 7 train loss: 8.988380432128906e-05  train f1: 1.00000  lr: 0.0005872000737186243 batch: 19 
epochs: 7 val loss: 10.3984375  val f1:0.14286  lr: 0.0005872000737186243 batch: 19
epochs: 8 train loss: 0.0001074671745300293  train f1: 1.00000  lr: 0.0005872000737186243 batch: 19 
epochs: 8 val loss: 11.28125  val f1:0.16667  lr: 0.0005872000737186243 batch: 19
epochs: 9 train loss: 8.380413055419922e-05  train f1: 1.00000  lr: 0.0005872000737186243 batch: 19 
epochs: 9 val loss: 13.296875  val f1:0.16667  lr: 0.0005872000737186243 batch: 19
epochs: 10 train loss: 8.26120376586914e-05  train f1: 1.00000  lr: 0.0005872000737186243 batch: 19 
epochs: 10 val loss: 14.640625  val f1:0.16667  lr: 0.0005872000737186243 batch: 19
epochs: 0 train loss: 4.76953125  train f1: 0.00000  lr: 0.0008320492004369242 batch: 15 
epochs: 0 val loss: 4.60546875  val f1:0.00000  lr: 0.0008320492004369242 batch: 15
epochs: 1 train loss: 4.546875  train f1: 0.00000  lr: 0.0008320492004369242 batch: 15 
epochs: 1 val loss: 5.57421875  val f1:0.16667  lr: 0.0008320492004369242 batch: 15
epochs: 2 train loss: 0.183837890625  train f1: 1.00000  lr: 0.0008320492004369242 batch: 15 
epochs: 2 val loss: 39.96875  val f1:0.00000  lr: 0.0008320492004369242 batch: 15
epochs: 3 train loss: 1.044921875  train f1: 1.00000  lr: 0.0008320492004369242 batch: 15 
epochs: 3 val loss: 31.21875  val f1:0.00000  lr: 0.0008320492004369242 batch: 15
epochs: 4 train loss: 0.0023555755615234375  train f1: 1.00000  lr: 0.0008320492004369242 batch: 15 
epochs: 4 val loss: 19.21875  val f1:0.00000  lr: 0.0008320492004369242 batch: 15
epochs: 5 train loss: 4.351139068603516e-06  train f1: 1.00000  lr: 0.0008320492004369242 batch: 15 
epochs: 5 val loss: 14.671875  val f1:0.00000  lr: 0.0008320492004369242 batch: 15
epochs: 6 train loss: 2.6226043701171875e-06  train f1: 1.00000  lr: 0.0008320492004369242 batch: 15 
epochs: 6 val loss: 13.921875  val f1:0.00000  lr: 0.0008320492004369242 batch: 15
epochs: 7 train loss: 4.887580871582031e-06  train f1: 1.00000  lr: 0.0008320492004369242 batch: 15 
epochs: 7 val loss: 12.2265625  val f1:0.00000  lr: 0.0008320492004369242 batch: 15
epochs: 8 train loss: 4.291534423828125e-06  train f1: 1.00000  lr: 0.0008320492004369242 batch: 15 
epochs: 8 val loss: 12.234375  val f1:0.00000  lr: 0.0008320492004369242 batch: 15
epochs: 9 train loss: 3.516674041748047e-06  train f1: 1.00000  lr: 0.0008320492004369242 batch: 15 
epochs: 9 val loss: 13.328125  val f1:0.16667  lr: 0.0008320492004369242 batch: 15
epochs: 0 train loss: 4.375  train f1: 0.00000  lr: 0.0011916038121814862 batch: 14 
epochs: 0 val loss: 4.98046875  val f1:0.14286  lr: 0.0011916038121814862 batch: 14
epochs: 1 train loss: 4.2109375  train f1: 0.00000  lr: 0.0011916038121814862 batch: 14 
epochs: 1 val loss: 9.9375  val f1:0.06667  lr: 0.0011916038121814862 batch: 14
epochs: 2 train loss: 1.091796875  train f1: 1.00000  lr: 0.0011916038121814862 batch: 14 
epochs: 2 val loss: 365.25  val f1:0.06667  lr: 0.0011916038121814862 batch: 14
epochs: 3 train loss: 3.533203125  train f1: 0.00000  lr: 0.0011916038121814862 batch: 14 
epochs: 3 val loss: 75.5625  val f1:0.06667  lr: 0.0011916038121814862 batch: 14
epochs: 4 train loss: 6.35546875  train f1: 0.00000  lr: 0.0011916038121814862 batch: 14 
epochs: 4 val loss: 31.875  val f1:0.06667  lr: 0.0011916038121814862 batch: 14
epochs: 5 train loss: 5.9375  train f1: 0.00000  lr: 0.0011916038121814862 batch: 14 
epochs: 5 val loss: 11.7265625  val f1:0.07143  lr: 0.0011916038121814862 batch: 14
epochs: 6 train loss: 4.203125  train f1: 0.12500  lr: 0.0011916038121814862 batch: 14 
epochs: 6 val loss: 2436.0  val f1:0.06667  lr: 0.0011916038121814862 batch: 14
epochs: 7 train loss: 2.408203125  train f1: 0.26667  lr: 0.0011916038121814862 batch: 14 
epochs: 7 val loss: nan  val f1:0.00000  lr: 0.0011916038121814862 batch: 14
epochs: 8 train loss: 1.9765625  train f1: 0.55556  lr: 0.0011916038121814862 batch: 14 
epochs: 8 val loss: nan  val f1:0.00000  lr: 0.0011916038121814862 batch: 14
epochs: 9 train loss: 2.662109375  train f1: 0.25000  lr: 0.0011916038121814862 batch: 14 
epochs: 9 val loss: 3184.0  val f1:0.06667  lr: 0.0011916038121814862 batch: 14
epochs: 0 train loss: 4.484375  train f1: 0.00000  lr: 0.000850718284606768 batch: 17 
epochs: 0 val loss: 4.80078125  val f1:0.00000  lr: 0.000850718284606768 batch: 17
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.000850718284606768 batch: 17 
epochs: 1 val loss: 4.72265625  val f1:0.00000  lr: 0.000850718284606768 batch: 17
epochs: 0 train loss: 4.41796875  train f1: 0.00000  lr: 0.0004980771100373451 batch: 9 
epochs: 0 val loss: 5.7890625  val f1:0.00000  lr: 0.0004980771100373451 batch: 9
epochs: 1 train loss: 4.32421875  train f1: 0.00000  lr: 0.0004980771100373451 batch: 9 
epochs: 1 val loss: 4.578125  val f1:0.14286  lr: 0.0004980771100373451 batch: 9
epochs: 2 train loss: 0.1912841796875  train f1: 1.00000  lr: 0.0004980771100373451 batch: 9 
epochs: 2 val loss: 4.82421875  val f1:0.12500  lr: 0.0004980771100373451 batch: 9
epochs: 3 train loss: 0.35546875  train f1: 1.00000  lr: 0.0004980771100373451 batch: 9 
epochs: 3 val loss: 11.1875  val f1:0.00000  lr: 0.0004980771100373451 batch: 9
epochs: 4 train loss: 0.1455078125  train f1: 1.00000  lr: 0.0004980771100373451 batch: 9 
epochs: 4 val loss: 6.1953125  val f1:0.14286  lr: 0.0004980771100373451 batch: 9
epochs: 5 train loss: 0.0004982948303222656  train f1: 1.00000  lr: 0.0004980771100373451 batch: 9 
epochs: 5 val loss: 5.60546875  val f1:0.14286  lr: 0.0004980771100373451 batch: 9
epochs: 6 train loss: 0.00022554397583007812  train f1: 1.00000  lr: 0.0004980771100373451 batch: 9 
epochs: 6 val loss: 5.0703125  val f1:0.14286  lr: 0.0004980771100373451 batch: 9
epochs: 7 train loss: 7.414817810058594e-05  train f1: 1.00000  lr: 0.0004980771100373451 batch: 9 
epochs: 7 val loss: 4.74609375  val f1:0.14286  lr: 0.0004980771100373451 batch: 9
epochs: 8 train loss: 0.00014138221740722656  train f1: 1.00000  lr: 0.0004980771100373451 batch: 9 
epochs: 8 val loss: 4.55859375  val f1:0.14286  lr: 0.0004980771100373451 batch: 9
epochs: 9 train loss: 7.259845733642578e-05  train f1: 1.00000  lr: 0.0004980771100373451 batch: 9 
epochs: 9 val loss: 4.484375  val f1:0.14286  lr: 0.0004980771100373451 batch: 9
epochs: 10 train loss: 5.698204040527344e-05  train f1: 1.00000  lr: 0.0004980771100373451 batch: 9 
epochs: 10 val loss: 4.4453125  val f1:0.14286  lr: 0.0004980771100373451 batch: 9
epochs: 11 train loss: 9.113550186157227e-05  train f1: 1.00000  lr: 0.0004980771100373451 batch: 9 
epochs: 11 val loss: 4.41015625  val f1:0.14286  lr: 0.0004980771100373451 batch: 9
epochs: 0 train loss: 3.96875  train f1: 0.20000  lr: 0.0006350164431159584 batch: 25 
epochs: 0 val loss: 5.33984375  val f1:0.00000  lr: 0.0006350164431159584 batch: 25
epochs: 1 train loss: 4.140625  train f1: 0.00000  lr: 0.0006350164431159584 batch: 25 
epochs: 1 val loss: 5.4765625  val f1:0.16667  lr: 0.0006350164431159584 batch: 25
epochs: 2 train loss: 0.1851806640625  train f1: 1.00000  lr: 0.0006350164431159584 batch: 25 
epochs: 2 val loss: 47.28125  val f1:0.00000  lr: 0.0006350164431159584 batch: 25
epochs: 3 train loss: 2.1640625  train f1: 0.40000  lr: 0.0006350164431159584 batch: 25 
epochs: 3 val loss: 12.078125  val f1:0.14286  lr: 0.0006350164431159584 batch: 25
epochs: 4 train loss: 0.0025806427001953125  train f1: 1.00000  lr: 0.0006350164431159584 batch: 25 
epochs: 4 val loss: 12.90625  val f1:0.16667  lr: 0.0006350164431159584 batch: 25
epochs: 5 train loss: 0.0010271072387695312  train f1: 1.00000  lr: 0.0006350164431159584 batch: 25 
epochs: 5 val loss: 12.4375  val f1:0.16667  lr: 0.0006350164431159584 batch: 25
epochs: 6 train loss: 0.0002186298370361328  train f1: 1.00000  lr: 0.0006350164431159584 batch: 25 
epochs: 6 val loss: 12.234375  val f1:0.16667  lr: 0.0006350164431159584 batch: 25
epochs: 7 train loss: 0.00021958351135253906  train f1: 1.00000  lr: 0.0006350164431159584 batch: 25 
epochs: 7 val loss: 11.9921875  val f1:0.16667  lr: 0.0006350164431159584 batch: 25
epochs: 8 train loss: 0.00016033649444580078  train f1: 1.00000  lr: 0.0006350164431159584 batch: 25 
epochs: 8 val loss: 11.5546875  val f1:0.16667  lr: 0.0006350164431159584 batch: 25
epochs: 9 train loss: 0.00024127960205078125  train f1: 1.00000  lr: 0.0006350164431159584 batch: 25 
epochs: 9 val loss: 11.625  val f1:0.16667  lr: 0.0006350164431159584 batch: 25
epochs: 10 train loss: 0.00015556812286376953  train f1: 1.00000  lr: 0.0006350164431159584 batch: 25 
epochs: 10 val loss: 11.53125  val f1:0.14286  lr: 0.0006350164431159584 batch: 25
epochs: 11 train loss: 0.00013875961303710938  train f1: 1.00000  lr: 0.0006350164431159584 batch: 25 
epochs: 11 val loss: 11.7578125  val f1:0.14286  lr: 0.0006350164431159584 batch: 25
epochs: 0 train loss: 4.671875  train f1: 0.00000  lr: 0.0005680203312470337 batch: 22 
epochs: 0 val loss: 5.0078125  val f1:0.00000  lr: 0.0005680203312470337 batch: 22
epochs: 1 train loss: 4.59765625  train f1: 0.00000  lr: 0.0005680203312470337 batch: 22 
epochs: 1 val loss: 4.078125  val f1:0.12500  lr: 0.0005680203312470337 batch: 22
epochs: 0 train loss: 5.1953125  train f1: 0.00000  lr: 0.0009970018318553203 batch: 15 
epochs: 0 val loss: 4.84765625  val f1:0.00000  lr: 0.0009970018318553203 batch: 15
epochs: 1 train loss: 5.1328125  train f1: 0.00000  lr: 0.0009970018318553203 batch: 15 
epochs: 1 val loss: 10.0390625  val f1:0.00000  lr: 0.0009970018318553203 batch: 15
epochs: 0 train loss: 4.8671875  train f1: 0.00000  lr: 0.00042261642237933513 batch: 12 
epochs: 0 val loss: 5.55859375  val f1:0.00000  lr: 0.00042261642237933513 batch: 12
epochs: 1 train loss: 4.9140625  train f1: 0.00000  lr: 0.00042261642237933513 batch: 12 
epochs: 1 val loss: 4.140625  val f1:0.11111  lr: 0.00042261642237933513 batch: 12
epochs: 0 train loss: 4.48046875  train f1: 0.00000  lr: 0.0007475606977176546 batch: 16 
epochs: 0 val loss: 4.62109375  val f1:0.00000  lr: 0.0007475606977176546 batch: 16
epochs: 1 train loss: 4.36328125  train f1: 0.00000  lr: 0.0007475606977176546 batch: 16 
epochs: 1 val loss: 4.48046875  val f1:0.16667  lr: 0.0007475606977176546 batch: 16
epochs: 2 train loss: 0.68505859375  train f1: 1.00000  lr: 0.0007475606977176546 batch: 16 
epochs: 2 val loss: 5.90625  val f1:0.16667  lr: 0.0007475606977176546 batch: 16
epochs: 3 train loss: 2.62109375  train f1: 0.40000  lr: 0.0007475606977176546 batch: 16 
epochs: 3 val loss: 7.5625  val f1:0.06667  lr: 0.0007475606977176546 batch: 16
epochs: 4 train loss: 0.94970703125  train f1: 0.50000  lr: 0.0007475606977176546 batch: 16 
epochs: 4 val loss: 11.8828125  val f1:0.06667  lr: 0.0007475606977176546 batch: 16
epochs: 5 train loss: 0.0009927749633789062  train f1: 1.00000  lr: 0.0007475606977176546 batch: 16 
epochs: 5 val loss: 7.125  val f1:0.11111  lr: 0.0007475606977176546 batch: 16
epochs: 6 train loss: 0.0002734661102294922  train f1: 1.00000  lr: 0.0007475606977176546 batch: 16 
epochs: 6 val loss: 9.640625  val f1:0.16667  lr: 0.0007475606977176546 batch: 16
epochs: 7 train loss: 0.0003540515899658203  train f1: 1.00000  lr: 0.0007475606977176546 batch: 16 
epochs: 7 val loss: 10.7109375  val f1:0.16667  lr: 0.0007475606977176546 batch: 16
epochs: 8 train loss: 0.0002841949462890625  train f1: 1.00000  lr: 0.0007475606977176546 batch: 16 
epochs: 8 val loss: 10.8203125  val f1:0.16667  lr: 0.0007475606977176546 batch: 16
epochs: 0 train loss: 4.62890625  train f1: 0.00000  lr: 0.0006153828845739743 batch: 19 
epochs: 0 val loss: 4.55859375  val f1:0.00000  lr: 0.0006153828845739743 batch: 19
epochs: 1 train loss: 4.6953125  train f1: 0.00000  lr: 0.0006153828845739743 batch: 19 
epochs: 1 val loss: 5.60546875  val f1:0.00000  lr: 0.0006153828845739743 batch: 19
epochs: 0 train loss: 4.40234375  train f1: 0.00000  lr: 0.0007791133041045238 batch: 14 
epochs: 0 val loss: 5.15625  val f1:0.00000  lr: 0.0007791133041045238 batch: 14
epochs: 1 train loss: 4.43359375  train f1: 0.00000  lr: 0.0007791133041045238 batch: 14 
epochs: 1 val loss: 4.1875  val f1:0.09524  lr: 0.0007791133041045238 batch: 14
epochs: 0 train loss: 4.30078125  train f1: 0.16667  lr: 0.0010466243714930719 batch: 18 
epochs: 0 val loss: 5.421875  val f1:0.00000  lr: 0.0010466243714930719 batch: 18
epochs: 1 train loss: 4.37109375  train f1: 0.00000  lr: 0.0010466243714930719 batch: 18 
epochs: 1 val loss: 5.328125  val f1:0.00000  lr: 0.0010466243714930719 batch: 18
epochs: 0 train loss: 4.37890625  train f1: 0.00000  lr: 0.00047731170842772925 batch: 21 
epochs: 0 val loss: 5.17578125  val f1:0.00000  lr: 0.00047731170842772925 batch: 21
epochs: 1 train loss: 4.58203125  train f1: 0.00000  lr: 0.00047731170842772925 batch: 21 
epochs: 1 val loss: 3.466796875  val f1:0.12500  lr: 0.00047731170842772925 batch: 21
epochs: 0 train loss: 4.546875  train f1: 0.00000  lr: 0.009499917499703055 batch: 21 
epochs: 0 val loss: 5.09765625  val f1:0.00000  lr: 0.009499917499703055 batch: 21
epochs: 1 train loss: 4.53125  train f1: 0.00000  lr: 0.009499917499703055 batch: 21 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.009499917499703055 batch: 21
epochs: 0 train loss: 5.07421875  train f1: 0.00000  lr: 0.0007647692599780103 batch: 28 
epochs: 0 val loss: 4.82421875  val f1:0.00000  lr: 0.0007647692599780103 batch: 28
epochs: 1 train loss: 5.08203125  train f1: 0.00000  lr: 0.0007647692599780103 batch: 28 
epochs: 1 val loss: 5.0078125  val f1:0.00000  lr: 0.0007647692599780103 batch: 28
epochs: 0 train loss: 4.69140625  train f1: 0.00000  lr: 0.000678513601793287 batch: 13 
epochs: 0 val loss: 5.19921875  val f1:0.00000  lr: 0.000678513601793287 batch: 13
epochs: 1 train loss: 4.70703125  train f1: 0.00000  lr: 0.000678513601793287 batch: 13 
epochs: 1 val loss: 5.8984375  val f1:0.00000  lr: 0.000678513601793287 batch: 13
epochs: 0 train loss: 4.515625  train f1: 0.00000  lr: 0.0003567853187703319 batch: 16 
epochs: 0 val loss: 4.921875  val f1:0.00000  lr: 0.0003567853187703319 batch: 16
epochs: 1 train loss: 4.484375  train f1: 0.00000  lr: 0.0003567853187703319 batch: 16 
epochs: 1 val loss: 3.779296875  val f1:0.12500  lr: 0.0003567853187703319 batch: 16
epochs: 0 train loss: 4.92578125  train f1: 0.00000  lr: 0.0005354762648777811 batch: 22 
epochs: 0 val loss: 4.70703125  val f1:0.00000  lr: 0.0005354762648777811 batch: 22
epochs: 1 train loss: 4.859375  train f1: 0.00000  lr: 0.0005354762648777811 batch: 22 
epochs: 1 val loss: 4.37109375  val f1:0.11111  lr: 0.0005354762648777811 batch: 22
epochs: 0 train loss: 4.578125  train f1: 0.00000  lr: 0.0008548608356381016 batch: 29 
epochs: 0 val loss: 4.69921875  val f1:0.00000  lr: 0.0008548608356381016 batch: 29
epochs: 1 train loss: 4.58984375  train f1: 0.00000  lr: 0.0008548608356381016 batch: 29 
epochs: 1 val loss: 4.83984375  val f1:0.00000  lr: 0.0008548608356381016 batch: 29
epochs: 0 train loss: 4.328125  train f1: 0.00000  lr: 0.00044083474344290877 batch: 11 
epochs: 0 val loss: 3.974609375  val f1:0.00000  lr: 0.00044083474344290877 batch: 11
epochs: 1 train loss: 4.3125  train f1: 0.00000  lr: 0.00044083474344290877 batch: 11 
epochs: 1 val loss: 4.5703125  val f1:0.14286  lr: 0.00044083474344290877 batch: 11
epochs: 2 train loss: 0.11859130859375  train f1: 1.00000  lr: 0.00044083474344290877 batch: 11 
epochs: 2 val loss: 4.7578125  val f1:0.16667  lr: 0.00044083474344290877 batch: 11
epochs: 3 train loss: 0.96875  train f1: 0.50000  lr: 0.00044083474344290877 batch: 11 
epochs: 3 val loss: 3.521484375  val f1:0.16667  lr: 0.00044083474344290877 batch: 11
epochs: 4 train loss: 0.05218505859375  train f1: 1.00000  lr: 0.00044083474344290877 batch: 11 
epochs: 4 val loss: 3.583984375  val f1:0.16667  lr: 0.00044083474344290877 batch: 11
epochs: 5 train loss: 0.0027484893798828125  train f1: 1.00000  lr: 0.00044083474344290877 batch: 11 
epochs: 5 val loss: 3.740234375  val f1:0.16667  lr: 0.00044083474344290877 batch: 11
epochs: 6 train loss: 0.00022113323211669922  train f1: 1.00000  lr: 0.00044083474344290877 batch: 11 
epochs: 6 val loss: 3.763671875  val f1:0.14286  lr: 0.00044083474344290877 batch: 11
epochs: 7 train loss: 0.00029158592224121094  train f1: 1.00000  lr: 0.00044083474344290877 batch: 11 
epochs: 7 val loss: 3.673828125  val f1:0.14286  lr: 0.00044083474344290877 batch: 11
epochs: 8 train loss: 0.0002598762512207031  train f1: 1.00000  lr: 0.00044083474344290877 batch: 11 
epochs: 8 val loss: 3.66796875  val f1:0.14286  lr: 0.00044083474344290877 batch: 11
epochs: 9 train loss: 0.0007424354553222656  train f1: 1.00000  lr: 0.00044083474344290877 batch: 11 
epochs: 9 val loss: 3.650390625  val f1:0.14286  lr: 0.00044083474344290877 batch: 11
epochs: 10 train loss: 0.0001666545867919922  train f1: 1.00000  lr: 0.00044083474344290877 batch: 11 
epochs: 10 val loss: 3.55859375  val f1:0.16667  lr: 0.00044083474344290877 batch: 11
epochs: 0 train loss: 4.1015625  train f1: 0.00000  lr: 0.00047266706494980494 batch: 13 
epochs: 0 val loss: 3.984375  val f1:0.08333  lr: 0.00047266706494980494 batch: 13
epochs: 1 train loss: 4.08984375  train f1: 0.00000  lr: 0.00047266706494980494 batch: 13 
epochs: 1 val loss: 3.8515625  val f1:0.12500  lr: 0.00047266706494980494 batch: 13
epochs: 0 train loss: 4.7578125  train f1: 0.00000  lr: 0.0005624707380064436 batch: 26 
epochs: 0 val loss: 5.26171875  val f1:0.00000  lr: 0.0005624707380064436 batch: 26
epochs: 1 train loss: 4.80859375  train f1: 0.00000  lr: 0.0005624707380064436 batch: 26 
epochs: 1 val loss: 4.390625  val f1:0.11111  lr: 0.0005624707380064436 batch: 26
epochs: 0 train loss: 5.00390625  train f1: 0.00000  lr: 0.0006982420913732132 batch: 26 
epochs: 0 val loss: 4.23046875  val f1:0.12500  lr: 0.0006982420913732132 batch: 26
epochs: 1 train loss: 4.9453125  train f1: 0.00000  lr: 0.0006982420913732132 batch: 26 
epochs: 1 val loss: 5.375  val f1:0.00000  lr: 0.0006982420913732132 batch: 26
epochs: 0 train loss: 4.69140625  train f1: 0.00000  lr: 0.000827667869771209 batch: 15 
epochs: 0 val loss: 4.953125  val f1:0.00000  lr: 0.000827667869771209 batch: 15
epochs: 1 train loss: 4.8046875  train f1: 0.00000  lr: 0.000827667869771209 batch: 15 
epochs: 1 val loss: 4.4296875  val f1:0.11111  lr: 0.000827667869771209 batch: 15
epochs: 0 train loss: 4.171875  train f1: 0.00000  lr: 0.00038278647598377884 batch: 11 
epochs: 0 val loss: 4.62890625  val f1:0.00000  lr: 0.00038278647598377884 batch: 11
epochs: 1 train loss: 4.03515625  train f1: 0.00000  lr: 0.00038278647598377884 batch: 11 
epochs: 1 val loss: 3.4765625  val f1:0.11111  lr: 0.00038278647598377884 batch: 11
epochs: 0 train loss: 4.765625  train f1: 0.00000  lr: 0.0002904467259547024 batch: 8 
epochs: 0 val loss: 5.0390625  val f1:0.00000  lr: 0.0002904467259547024 batch: 8
epochs: 1 train loss: 4.640625  train f1: 0.00000  lr: 0.0002904467259547024 batch: 8 
epochs: 1 val loss: 4.13671875  val f1:0.12500  lr: 0.0002904467259547024 batch: 8
epochs: 0 train loss: 4.75  train f1: 0.00000  lr: 0.0004280326504245757 batch: 9 
epochs: 0 val loss: 4.53515625  val f1:0.00000  lr: 0.0004280326504245757 batch: 9
epochs: 1 train loss: 4.734375  train f1: 0.00000  lr: 0.0004280326504245757 batch: 9 
epochs: 1 val loss: 4.7734375  val f1:0.14286  lr: 0.0004280326504245757 batch: 9
epochs: 2 train loss: 0.73095703125  train f1: 1.00000  lr: 0.0004280326504245757 batch: 9 
epochs: 2 val loss: 3.693359375  val f1:0.11111  lr: 0.0004280326504245757 batch: 9
epochs: 3 train loss: 1.4033203125  train f1: 1.00000  lr: 0.0004280326504245757 batch: 9 
epochs: 3 val loss: 27.75  val f1:0.16667  lr: 0.0004280326504245757 batch: 9
epochs: 4 train loss: 7.069110870361328e-05  train f1: 1.00000  lr: 0.0004280326504245757 batch: 9 
epochs: 4 val loss: 23.625  val f1:0.16667  lr: 0.0004280326504245757 batch: 9
epochs: 5 train loss: 8.96453857421875e-05  train f1: 1.00000  lr: 0.0004280326504245757 batch: 9 
epochs: 5 val loss: 20.171875  val f1:0.14286  lr: 0.0004280326504245757 batch: 9
epochs: 6 train loss: 5.7220458984375e-05  train f1: 1.00000  lr: 0.0004280326504245757 batch: 9 
epochs: 6 val loss: 17.328125  val f1:0.14286  lr: 0.0004280326504245757 batch: 9
epochs: 7 train loss: 7.140636444091797e-05  train f1: 1.00000  lr: 0.0004280326504245757 batch: 9 
epochs: 7 val loss: 14.9765625  val f1:0.14286  lr: 0.0004280326504245757 batch: 9
epochs: 8 train loss: 6.54458999633789e-05  train f1: 1.00000  lr: 0.0004280326504245757 batch: 9 
epochs: 8 val loss: 13.0234375  val f1:0.14286  lr: 0.0004280326504245757 batch: 9
epochs: 9 train loss: 5.9664249420166016e-05  train f1: 1.00000  lr: 0.0004280326504245757 batch: 9 
epochs: 9 val loss: 11.1640625  val f1:0.14286  lr: 0.0004280326504245757 batch: 9
epochs: 10 train loss: 5.4717063903808594e-05  train f1: 1.00000  lr: 0.0004280326504245757 batch: 9 
epochs: 10 val loss: 9.546875  val f1:0.14286  lr: 0.0004280326504245757 batch: 9
epochs: 0 train loss: 4.41015625  train f1: 0.00000  lr: 0.0005779935887059377 batch: 20 
epochs: 0 val loss: 4.0859375  val f1:0.00000  lr: 0.0005779935887059377 batch: 20
epochs: 1 train loss: 4.4765625  train f1: 0.00000  lr: 0.0005779935887059377 batch: 20 
epochs: 1 val loss: 4.4140625  val f1:0.14286  lr: 0.0005779935887059377 batch: 20
epochs: 2 train loss: 0.10418701171875  train f1: 1.00000  lr: 0.0005779935887059377 batch: 20 
epochs: 2 val loss: 11.890625  val f1:0.00000  lr: 0.0005779935887059377 batch: 20
epochs: 3 train loss: 2.583984375  train f1: 0.50000  lr: 0.0005779935887059377 batch: 20 
epochs: 3 val loss: 4.078125  val f1:0.14286  lr: 0.0005779935887059377 batch: 20
epochs: 4 train loss: 0.67919921875  train f1: 1.00000  lr: 0.0005779935887059377 batch: 20 
epochs: 4 val loss: 8.03125  val f1:0.14286  lr: 0.0005779935887059377 batch: 20
epochs: 5 train loss: 0.00039005279541015625  train f1: 1.00000  lr: 0.0005779935887059377 batch: 20 
epochs: 5 val loss: 6.0859375  val f1:0.14286  lr: 0.0005779935887059377 batch: 20
epochs: 6 train loss: 0.0003769397735595703  train f1: 1.00000  lr: 0.0005779935887059377 batch: 20 
epochs: 6 val loss: 5.453125  val f1:0.14286  lr: 0.0005779935887059377 batch: 20
epochs: 7 train loss: 0.00037407875061035156  train f1: 1.00000  lr: 0.0005779935887059377 batch: 20 
epochs: 7 val loss: 5.2109375  val f1:0.14286  lr: 0.0005779935887059377 batch: 20
epochs: 8 train loss: 0.00039076805114746094  train f1: 1.00000  lr: 0.0005779935887059377 batch: 20 
epochs: 8 val loss: 5.13671875  val f1:0.14286  lr: 0.0005779935887059377 batch: 20
epochs: 9 train loss: 0.0004260540008544922  train f1: 1.00000  lr: 0.0005779935887059377 batch: 20 
epochs: 9 val loss: 5.0390625  val f1:0.14286  lr: 0.0005779935887059377 batch: 20
epochs: 10 train loss: 0.0005884170532226562  train f1: 1.00000  lr: 0.0005779935887059377 batch: 20 
epochs: 10 val loss: 4.9375  val f1:0.14286  lr: 0.0005779935887059377 batch: 20
epochs: 0 train loss: 5.16796875  train f1: 0.00000  lr: 0.0005982729571077869 batch: 19 
epochs: 0 val loss: 5.359375  val f1:0.00000  lr: 0.0005982729571077869 batch: 19
epochs: 1 train loss: 5.1640625  train f1: 0.00000  lr: 0.0005982729571077869 batch: 19 
epochs: 1 val loss: 5.91796875  val f1:0.00000  lr: 0.0005982729571077869 batch: 19
epochs: 0 train loss: 4.546875  train f1: 0.00000  lr: 0.0013802906238404066 batch: 16 
epochs: 0 val loss: 3.900390625  val f1:0.00000  lr: 0.0013802906238404066 batch: 16
epochs: 1 train loss: 4.62109375  train f1: 0.00000  lr: 0.0013802906238404066 batch: 16 
epochs: 1 val loss: 43.59375  val f1:0.06667  lr: 0.0013802906238404066 batch: 16
epochs: 0 train loss: 4.43359375  train f1: 0.00000  lr: 0.000500674840533793 batch: 10 
epochs: 0 val loss: 5.3828125  val f1:0.00000  lr: 0.000500674840533793 batch: 10
epochs: 1 train loss: 4.39453125  train f1: 0.00000  lr: 0.000500674840533793 batch: 10 
epochs: 1 val loss: 4.70703125  val f1:0.14286  lr: 0.000500674840533793 batch: 10
epochs: 2 train loss: 0.984375  train f1: 1.00000  lr: 0.000500674840533793 batch: 10 
epochs: 2 val loss: 10.6171875  val f1:0.00000  lr: 0.000500674840533793 batch: 10
epochs: 3 train loss: 1.005859375  train f1: 1.00000  lr: 0.000500674840533793 batch: 10 
epochs: 3 val loss: 11.3125  val f1:0.00000  lr: 0.000500674840533793 batch: 10
epochs: 4 train loss: 0.187255859375  train f1: 1.00000  lr: 0.000500674840533793 batch: 10 
epochs: 4 val loss: 5.53125  val f1:0.16667  lr: 0.000500674840533793 batch: 10
epochs: 5 train loss: 8.291006088256836e-05  train f1: 1.00000  lr: 0.000500674840533793 batch: 10 
epochs: 5 val loss: 5.31640625  val f1:0.16667  lr: 0.000500674840533793 batch: 10
epochs: 6 train loss: 6.330013275146484e-05  train f1: 1.00000  lr: 0.000500674840533793 batch: 10 
epochs: 6 val loss: 4.75  val f1:0.16667  lr: 0.000500674840533793 batch: 10
epochs: 7 train loss: 7.361173629760742e-05  train f1: 1.00000  lr: 0.000500674840533793 batch: 10 
epochs: 7 val loss: 4.5234375  val f1:0.16667  lr: 0.000500674840533793 batch: 10
epochs: 8 train loss: 5.614757537841797e-05  train f1: 1.00000  lr: 0.000500674840533793 batch: 10 
epochs: 8 val loss: 4.37890625  val f1:0.16667  lr: 0.000500674840533793 batch: 10
epochs: 9 train loss: 5.537271499633789e-05  train f1: 1.00000  lr: 0.000500674840533793 batch: 10 
epochs: 9 val loss: 4.29296875  val f1:0.16667  lr: 0.000500674840533793 batch: 10
epochs: 10 train loss: 5.811452865600586e-05  train f1: 1.00000  lr: 0.000500674840533793 batch: 10 
epochs: 10 val loss: 4.234375  val f1:0.16667  lr: 0.000500674840533793 batch: 10
epochs: 11 train loss: 6.282329559326172e-05  train f1: 1.00000  lr: 0.000500674840533793 batch: 10 
epochs: 11 val loss: 4.17578125  val f1:0.16667  lr: 0.000500674840533793 batch: 10
epochs: 0 train loss: 4.79296875  train f1: 0.00000  lr: 0.0003380313515695671 batch: 27 
epochs: 0 val loss: 4.78125  val f1:0.00000  lr: 0.0003380313515695671 batch: 27
epochs: 1 train loss: 4.6015625  train f1: 0.00000  lr: 0.0003380313515695671 batch: 27 
epochs: 1 val loss: 4.41796875  val f1:0.12500  lr: 0.0003380313515695671 batch: 27
epochs: 0 train loss: 4.64453125  train f1: 0.00000  lr: 0.00025180351291254993 batch: 9 
epochs: 0 val loss: 5.14453125  val f1:0.00000  lr: 0.00025180351291254993 batch: 9
epochs: 1 train loss: 4.6328125  train f1: 0.00000  lr: 0.00025180351291254993 batch: 9 
epochs: 1 val loss: 3.734375  val f1:0.12500  lr: 0.00025180351291254993 batch: 9
epochs: 0 train loss: 5.03515625  train f1: 0.00000  lr: 0.0009500578688130768 batch: 17 
epochs: 0 val loss: 5.26171875  val f1:0.00000  lr: 0.0009500578688130768 batch: 17
epochs: 1 train loss: 4.98828125  train f1: 0.00000  lr: 0.0009500578688130768 batch: 17 
epochs: 1 val loss: 4.24609375  val f1:0.14286  lr: 0.0009500578688130768 batch: 17
epochs: 2 train loss: 1.2001953125  train f1: 1.00000  lr: 0.0009500578688130768 batch: 17 
epochs: 2 val loss: 48.15625  val f1:0.06667  lr: 0.0009500578688130768 batch: 17
epochs: 3 train loss: 1.5791015625  train f1: 0.50000  lr: 0.0009500578688130768 batch: 17 
epochs: 3 val loss: 44.71875  val f1:0.06667  lr: 0.0009500578688130768 batch: 17
epochs: 4 train loss: 1.1630859375  train f1: 0.66667  lr: 0.0009500578688130768 batch: 17 
epochs: 4 val loss: 17.09375  val f1:0.06667  lr: 0.0009500578688130768 batch: 17
epochs: 5 train loss: 0.12261962890625  train f1: 1.00000  lr: 0.0009500578688130768 batch: 17 
epochs: 5 val loss: 13.8828125  val f1:0.08333  lr: 0.0009500578688130768 batch: 17
epochs: 6 train loss: 0.5439453125  train f1: 1.00000  lr: 0.0009500578688130768 batch: 17 
epochs: 6 val loss: 42.53125  val f1:0.00000  lr: 0.0009500578688130768 batch: 17
epochs: 7 train loss: 1.2470703125  train f1: 0.50000  lr: 0.0009500578688130768 batch: 17 
epochs: 7 val loss: 33.0625  val f1:0.00000  lr: 0.0009500578688130768 batch: 17
epochs: 8 train loss: 4.088878631591797e-05  train f1: 1.00000  lr: 0.0009500578688130768 batch: 17 
epochs: 8 val loss: 31.46875  val f1:0.16667  lr: 0.0009500578688130768 batch: 17
epochs: 9 train loss: 4.8279762268066406e-05  train f1: 1.00000  lr: 0.0009500578688130768 batch: 17 
epochs: 9 val loss: 29.375  val f1:0.16667  lr: 0.0009500578688130768 batch: 17
epochs: 10 train loss: 4.673004150390625e-05  train f1: 1.00000  lr: 0.0009500578688130768 batch: 17 
epochs: 10 val loss: 26.40625  val f1:0.16667  lr: 0.0009500578688130768 batch: 17
epochs: 0 train loss: 4.8203125  train f1: 0.00000  lr: 0.00048570367096642476 batch: 8 
epochs: 0 val loss: 5.41796875  val f1:0.00000  lr: 0.00048570367096642476 batch: 8
epochs: 1 train loss: 4.83984375  train f1: 0.00000  lr: 0.00048570367096642476 batch: 8 
epochs: 1 val loss: 5.26953125  val f1:0.16667  lr: 0.00048570367096642476 batch: 8
epochs: 2 train loss: 0.260986328125  train f1: 1.00000  lr: 0.00048570367096642476 batch: 8 
epochs: 2 val loss: 4.6875  val f1:0.14286  lr: 0.00048570367096642476 batch: 8
epochs: 3 train loss: 0.58935546875  train f1: 1.00000  lr: 0.00048570367096642476 batch: 8 
epochs: 3 val loss: 12.28125  val f1:0.16667  lr: 0.00048570367096642476 batch: 8
epochs: 4 train loss: 0.00604248046875  train f1: 1.00000  lr: 0.00048570367096642476 batch: 8 
epochs: 4 val loss: 10.0234375  val f1:0.16667  lr: 0.00048570367096642476 batch: 8
epochs: 5 train loss: 0.0007734298706054688  train f1: 1.00000  lr: 0.00048570367096642476 batch: 8 
epochs: 5 val loss: 8.046875  val f1:0.16667  lr: 0.00048570367096642476 batch: 8
epochs: 6 train loss: 0.00046372413635253906  train f1: 1.00000  lr: 0.00048570367096642476 batch: 8 
epochs: 6 val loss: 6.6875  val f1:0.14286  lr: 0.00048570367096642476 batch: 8
epochs: 7 train loss: 0.00042700767517089844  train f1: 1.00000  lr: 0.00048570367096642476 batch: 8 
epochs: 7 val loss: 5.88671875  val f1:0.14286  lr: 0.00048570367096642476 batch: 8
epochs: 8 train loss: 0.0003364086151123047  train f1: 1.00000  lr: 0.00048570367096642476 batch: 8 
epochs: 8 val loss: 5.48046875  val f1:0.14286  lr: 0.00048570367096642476 batch: 8
epochs: 9 train loss: 0.00021576881408691406  train f1: 1.00000  lr: 0.00048570367096642476 batch: 8 
epochs: 9 val loss: 5.36328125  val f1:0.14286  lr: 0.00048570367096642476 batch: 8
epochs: 10 train loss: 0.0006756782531738281  train f1: 1.00000  lr: 0.00048570367096642476 batch: 8 
epochs: 10 val loss: 5.2890625  val f1:0.14286  lr: 0.00048570367096642476 batch: 8
epochs: 11 train loss: 0.00026917457580566406  train f1: 1.00000  lr: 0.00048570367096642476 batch: 8 
epochs: 11 val loss: 5.78515625  val f1:0.14286  lr: 0.00048570367096642476 batch: 8
epochs: 0 train loss: 4.2890625  train f1: 0.00000  lr: 0.0010985444490533476 batch: 28 
epochs: 0 val loss: 4.578125  val f1:0.00000  lr: 0.0010985444490533476 batch: 28
epochs: 1 train loss: 4.2890625  train f1: 0.00000  lr: 0.0010985444490533476 batch: 28 
epochs: 1 val loss: 3.783203125  val f1:0.11111  lr: 0.0010985444490533476 batch: 28
epochs: 0 train loss: 5.0078125  train f1: 0.00000  lr: 0.0006809384814427631 batch: 25 
epochs: 0 val loss: 5.36328125  val f1:0.00000  lr: 0.0006809384814427631 batch: 25
epochs: 1 train loss: 4.87890625  train f1: 0.00000  lr: 0.0006809384814427631 batch: 25 
epochs: 1 val loss: 5.85546875  val f1:0.14286  lr: 0.0006809384814427631 batch: 25
epochs: 2 train loss: 0.332275390625  train f1: 1.00000  lr: 0.0006809384814427631 batch: 25 
epochs: 2 val loss: 11.15625  val f1:0.00000  lr: 0.0006809384814427631 batch: 25
epochs: 3 train loss: 0.9365234375  train f1: 0.50000  lr: 0.0006809384814427631 batch: 25 
epochs: 3 val loss: 6.6171875  val f1:0.00000  lr: 0.0006809384814427631 batch: 25
epochs: 4 train loss: 0.00013136863708496094  train f1: 1.00000  lr: 0.0006809384814427631 batch: 25 
epochs: 4 val loss: 6.37109375  val f1:0.16667  lr: 0.0006809384814427631 batch: 25
epochs: 5 train loss: 0.0001327991485595703  train f1: 1.00000  lr: 0.0006809384814427631 batch: 25 
epochs: 5 val loss: 7.125  val f1:0.16667  lr: 0.0006809384814427631 batch: 25
epochs: 6 train loss: 5.7756900787353516e-05  train f1: 1.00000  lr: 0.0006809384814427631 batch: 25 
epochs: 6 val loss: 7.85546875  val f1:0.16667  lr: 0.0006809384814427631 batch: 25
epochs: 7 train loss: 8.386373519897461e-05  train f1: 1.00000  lr: 0.0006809384814427631 batch: 25 
epochs: 7 val loss: 8.671875  val f1:0.16667  lr: 0.0006809384814427631 batch: 25
epochs: 8 train loss: 0.00013625621795654297  train f1: 1.00000  lr: 0.0006809384814427631 batch: 25 
epochs: 8 val loss: 9.0625  val f1:0.16667  lr: 0.0006809384814427631 batch: 25
epochs: 9 train loss: 2.9146671295166016e-05  train f1: 1.00000  lr: 0.0006809384814427631 batch: 25 
epochs: 9 val loss: 9.1953125  val f1:0.16667  lr: 0.0006809384814427631 batch: 25
epochs: 10 train loss: 0.00013399124145507812  train f1: 1.00000  lr: 0.0006809384814427631 batch: 25 
epochs: 10 val loss: 9.0859375  val f1:0.16667  lr: 0.0006809384814427631 batch: 25
epochs: 11 train loss: 3.129243850708008e-05  train f1: 1.00000  lr: 0.0006809384814427631 batch: 25 
epochs: 11 val loss: 9.109375  val f1:0.16667  lr: 0.0006809384814427631 batch: 25
epochs: 12 train loss: 6.091594696044922e-05  train f1: 1.00000  lr: 0.0006809384814427631 batch: 25 
epochs: 12 val loss: 8.9140625  val f1:0.16667  lr: 0.0006809384814427631 batch: 25
epochs: 0 train loss: 4.69140625  train f1: 0.00000  lr: 0.0007051619659419997 batch: 11 
epochs: 0 val loss: 4.71875  val f1:0.00000  lr: 0.0007051619659419997 batch: 11
epochs: 1 train loss: 4.75390625  train f1: 0.00000  lr: 0.0007051619659419997 batch: 11 
epochs: 1 val loss: 4.34375  val f1:0.14286  lr: 0.0007051619659419997 batch: 11
epochs: 2 train loss: 0.1556396484375  train f1: 1.00000  lr: 0.0007051619659419997 batch: 11 
epochs: 2 val loss: 48.125  val f1:0.16667  lr: 0.0007051619659419997 batch: 11
epochs: 3 train loss: 1.287109375  train f1: 0.50000  lr: 0.0007051619659419997 batch: 11 
epochs: 3 val loss: 15.4375  val f1:0.00000  lr: 0.0007051619659419997 batch: 11
epochs: 4 train loss: 0.0169677734375  train f1: 1.00000  lr: 0.0007051619659419997 batch: 11 
epochs: 4 val loss: 11.984375  val f1:0.00000  lr: 0.0007051619659419997 batch: 11
epochs: 5 train loss: 3.6954879760742188e-06  train f1: 1.00000  lr: 0.0007051619659419997 batch: 11 
epochs: 5 val loss: 12.5859375  val f1:0.00000  lr: 0.0007051619659419997 batch: 11
epochs: 6 train loss: 4.172325134277344e-06  train f1: 1.00000  lr: 0.0007051619659419997 batch: 11 
epochs: 6 val loss: 13.015625  val f1:0.00000  lr: 0.0007051619659419997 batch: 11
epochs: 7 train loss: 3.6954879760742188e-06  train f1: 1.00000  lr: 0.0007051619659419997 batch: 11 
epochs: 7 val loss: 12.7265625  val f1:0.00000  lr: 0.0007051619659419997 batch: 11
epochs: 8 train loss: 3.516674041748047e-06  train f1: 1.00000  lr: 0.0007051619659419997 batch: 11 
epochs: 8 val loss: 12.21875  val f1:0.00000  lr: 0.0007051619659419997 batch: 11
epochs: 9 train loss: 3.0994415283203125e-06  train f1: 1.00000  lr: 0.0007051619659419997 batch: 11 
epochs: 9 val loss: 12.1875  val f1:0.00000  lr: 0.0007051619659419997 batch: 11
epochs: 10 train loss: 3.6954879760742188e-06  train f1: 1.00000  lr: 0.0007051619659419997 batch: 11 
epochs: 10 val loss: 11.890625  val f1:0.00000  lr: 0.0007051619659419997 batch: 11
epochs: 11 train loss: 3.814697265625e-06  train f1: 1.00000  lr: 0.0007051619659419997 batch: 11 
epochs: 11 val loss: 11.84375  val f1:0.00000  lr: 0.0007051619659419997 batch: 11
epochs: 12 train loss: 3.337860107421875e-06  train f1: 1.00000  lr: 0.0007051619659419997 batch: 11 
epochs: 12 val loss: 11.734375  val f1:0.00000  lr: 0.0007051619659419997 batch: 11
epochs: 0 train loss: 4.40234375  train f1: 0.00000  lr: 0.0004501924673295685 batch: 17 
epochs: 0 val loss: 4.62890625  val f1:0.00000  lr: 0.0004501924673295685 batch: 17
epochs: 1 train loss: 4.48046875  train f1: 0.00000  lr: 0.0004501924673295685 batch: 17 
epochs: 1 val loss: 3.853515625  val f1:0.11111  lr: 0.0004501924673295685 batch: 17
epochs: 0 train loss: 4.640625  train f1: 0.00000  lr: 0.0005480300078197782 batch: 10 
epochs: 0 val loss: 4.54296875  val f1:0.00000  lr: 0.0005480300078197782 batch: 10
epochs: 1 train loss: 4.69140625  train f1: 0.00000  lr: 0.0005480300078197782 batch: 10 
epochs: 1 val loss: 3.8671875  val f1:0.12500  lr: 0.0005480300078197782 batch: 10
epochs: 0 train loss: 4.9375  train f1: 0.00000  lr: 0.000357045766885678 batch: 11 
epochs: 0 val loss: 5.546875  val f1:0.00000  lr: 0.000357045766885678 batch: 11
epochs: 1 train loss: 4.9296875  train f1: 0.00000  lr: 0.000357045766885678 batch: 11 
epochs: 1 val loss: 5.4609375  val f1:0.00000  lr: 0.000357045766885678 batch: 11
epochs: 0 train loss: 4.68359375  train f1: 0.00000  lr: 0.0008302192858750354 batch: 23 
epochs: 0 val loss: 5.2578125  val f1:0.00000  lr: 0.0008302192858750354 batch: 23
epochs: 1 train loss: 4.7421875  train f1: 0.00000  lr: 0.0008302192858750354 batch: 23 
epochs: 1 val loss: 5.99609375  val f1:0.11111  lr: 0.0008302192858750354 batch: 23
epochs: 0 train loss: 4.88671875  train f1: 0.00000  lr: 0.0006813492478040613 batch: 9 
epochs: 0 val loss: 5.23046875  val f1:0.00000  lr: 0.0006813492478040613 batch: 9
epochs: 1 train loss: 4.8125  train f1: 0.00000  lr: 0.0006813492478040613 batch: 9 
epochs: 1 val loss: 5.203125  val f1:0.00000  lr: 0.0006813492478040613 batch: 9
epochs: 0 train loss: 5.2421875  train f1: 0.00000  lr: 0.0005067571271763856 batch: 11 
epochs: 0 val loss: 4.9140625  val f1:0.00000  lr: 0.0005067571271763856 batch: 11
epochs: 1 train loss: 5.16796875  train f1: 0.00000  lr: 0.0005067571271763856 batch: 11 
epochs: 1 val loss: 3.18359375  val f1:0.09524  lr: 0.0005067571271763856 batch: 11
epochs: 0 train loss: 4.203125  train f1: 0.00000  lr: 0.000927783427305943 batch: 18 
epochs: 0 val loss: 4.97265625  val f1:0.00000  lr: 0.000927783427305943 batch: 18
epochs: 1 train loss: 4.125  train f1: 0.00000  lr: 0.000927783427305943 batch: 18 
epochs: 1 val loss: 3.46875  val f1:0.09524  lr: 0.000927783427305943 batch: 18
epochs: 0 train loss: 4.1328125  train f1: 0.00000  lr: 0.00092780270020604 batch: 20 
epochs: 0 val loss: 4.296875  val f1:0.00000  lr: 0.00092780270020604 batch: 20
epochs: 1 train loss: 4.16796875  train f1: 0.00000  lr: 0.00092780270020604 batch: 20 
epochs: 1 val loss: 10.96875  val f1:0.07143  lr: 0.00092780270020604 batch: 20
epochs: 0 train loss: 4.5546875  train f1: 0.16667  lr: 0.0006441388011085242 batch: 25 
epochs: 0 val loss: 4.85546875  val f1:0.00000  lr: 0.0006441388011085242 batch: 25
epochs: 1 train loss: 4.74609375  train f1: 0.00000  lr: 0.0006441388011085242 batch: 25 
epochs: 1 val loss: 5.078125  val f1:0.00000  lr: 0.0006441388011085242 batch: 25
epochs: 0 train loss: 4.85546875  train f1: 0.00000  lr: 0.001080391767094591 batch: 17 
epochs: 0 val loss: 4.8125  val f1:0.00000  lr: 0.001080391767094591 batch: 17
epochs: 1 train loss: 4.7265625  train f1: 0.00000  lr: 0.001080391767094591 batch: 17 
epochs: 1 val loss: 4.51171875  val f1:0.00000  lr: 0.001080391767094591 batch: 17
epochs: 0 train loss: 4.51171875  train f1: 0.00000  lr: 0.0004168011712884677 batch: 10 
epochs: 0 val loss: 4.66796875  val f1:0.00000  lr: 0.0004168011712884677 batch: 10
epochs: 1 train loss: 4.4296875  train f1: 0.00000  lr: 0.0004168011712884677 batch: 10 
epochs: 1 val loss: 4.375  val f1:0.00000  lr: 0.0004168011712884677 batch: 10
epochs: 0 train loss: 4.5078125  train f1: 0.00000  lr: 0.00031044553962727034 batch: 16 
epochs: 0 val loss: 4.09765625  val f1:0.00000  lr: 0.00031044553962727034 batch: 16
epochs: 1 train loss: 4.484375  train f1: 0.00000  lr: 0.00031044553962727034 batch: 16 
epochs: 1 val loss: 3.544921875  val f1:0.12500  lr: 0.00031044553962727034 batch: 16
epochs: 0 train loss: 4.0078125  train f1: 0.00000  lr: 0.0005686005940417131 batch: 13 
epochs: 0 val loss: 5.1328125  val f1:0.00000  lr: 0.0005686005940417131 batch: 13
epochs: 1 train loss: 4.2890625  train f1: 0.00000  lr: 0.0005686005940417131 batch: 13 
epochs: 1 val loss: 5.33984375  val f1:0.00000  lr: 0.0005686005940417131 batch: 13
epochs: 0 train loss: 4.828125  train f1: 0.00000  lr: 0.0003920046676159838 batch: 8 
epochs: 0 val loss: 4.734375  val f1:0.00000  lr: 0.0003920046676159838 batch: 8
epochs: 1 train loss: 4.828125  train f1: 0.00000  lr: 0.0003920046676159838 batch: 8 
epochs: 1 val loss: 4.24609375  val f1:0.12500  lr: 0.0003920046676159838 batch: 8
epochs: 0 train loss: 4.640625  train f1: 0.00000  lr: 0.00042791634318282566 batch: 31 
epochs: 0 val loss: 5.14453125  val f1:0.00000  lr: 0.00042791634318282566 batch: 31
epochs: 1 train loss: 4.6640625  train f1: 0.00000  lr: 0.00042791634318282566 batch: 31 
epochs: 1 val loss: 4.8046875  val f1:0.11111  lr: 0.00042791634318282566 batch: 31
epochs: 0 train loss: 4.53515625  train f1: 0.00000  lr: 0.00032095929048269167 batch: 22 
epochs: 0 val loss: 4.62109375  val f1:0.00000  lr: 0.00032095929048269167 batch: 22
epochs: 1 train loss: 4.4140625  train f1: 0.00000  lr: 0.00032095929048269167 batch: 22 
epochs: 1 val loss: 3.83203125  val f1:0.12500  lr: 0.00032095929048269167 batch: 22
epochs: 0 train loss: 4.2890625  train f1: 0.00000  lr: 0.000727590484306587 batch: 21 
epochs: 0 val loss: 5.4296875  val f1:0.00000  lr: 0.000727590484306587 batch: 21
epochs: 1 train loss: 4.30859375  train f1: 0.00000  lr: 0.000727590484306587 batch: 21 
epochs: 1 val loss: 3.91796875  val f1:0.12500  lr: 0.000727590484306587 batch: 21
epochs: 0 train loss: 4.6875  train f1: 0.00000  lr: 0.0005213820721214604 batch: 22 
epochs: 0 val loss: 5.328125  val f1:0.00000  lr: 0.0005213820721214604 batch: 22
epochs: 1 train loss: 4.73828125  train f1: 0.00000  lr: 0.0005213820721214604 batch: 22 
epochs: 1 val loss: 4.5703125  val f1:0.14286  lr: 0.0005213820721214604 batch: 22
epochs: 2 train loss: 0.61669921875  train f1: 1.00000  lr: 0.0005213820721214604 batch: 22 
epochs: 2 val loss: 20.96875  val f1:0.00000  lr: 0.0005213820721214604 batch: 22
epochs: 3 train loss: 2.62109375  train f1: 0.40000  lr: 0.0005213820721214604 batch: 22 
epochs: 3 val loss: 4.8125  val f1:0.00000  lr: 0.0005213820721214604 batch: 22
epochs: 4 train loss: 0.01763916015625  train f1: 1.00000  lr: 0.0005213820721214604 batch: 22 
epochs: 4 val loss: 8.7734375  val f1:0.00000  lr: 0.0005213820721214604 batch: 22
epochs: 5 train loss: 0.0007014274597167969  train f1: 1.00000  lr: 0.0005213820721214604 batch: 22 
epochs: 5 val loss: 7.70703125  val f1:0.00000  lr: 0.0005213820721214604 batch: 22
epochs: 6 train loss: 0.0006966590881347656  train f1: 1.00000  lr: 0.0005213820721214604 batch: 22 
epochs: 6 val loss: 6.953125  val f1:0.00000  lr: 0.0005213820721214604 batch: 22
epochs: 7 train loss: 0.0005555152893066406  train f1: 1.00000  lr: 0.0005213820721214604 batch: 22 
epochs: 7 val loss: 6.453125  val f1:0.14286  lr: 0.0005213820721214604 batch: 22
epochs: 0 train loss: 4.84375  train f1: 0.00000  lr: 0.0005875370954193341 batch: 23 
epochs: 0 val loss: 5.2265625  val f1:0.00000  lr: 0.0005875370954193341 batch: 23
epochs: 1 train loss: 4.890625  train f1: 0.00000  lr: 0.0005875370954193341 batch: 23 
epochs: 1 val loss: 6.26953125  val f1:0.16667  lr: 0.0005875370954193341 batch: 23
epochs: 2 train loss: 0.1103515625  train f1: 1.00000  lr: 0.0005875370954193341 batch: 23 
epochs: 2 val loss: 7.83203125  val f1:0.12500  lr: 0.0005875370954193341 batch: 23
epochs: 3 train loss: 0.65380859375  train f1: 1.00000  lr: 0.0005875370954193341 batch: 23 
epochs: 3 val loss: 8.5859375  val f1:0.14286  lr: 0.0005875370954193341 batch: 23
epochs: 4 train loss: 0.640625  train f1: 1.00000  lr: 0.0005875370954193341 batch: 23 
epochs: 4 val loss: 4.33984375  val f1:0.14286  lr: 0.0005875370954193341 batch: 23
epochs: 5 train loss: 0.1383056640625  train f1: 1.00000  lr: 0.0005875370954193341 batch: 23 
epochs: 5 val loss: 55.5625  val f1:0.16667  lr: 0.0005875370954193341 batch: 23
epochs: 6 train loss: 5.9604644775390625e-06  train f1: 1.00000  lr: 0.0005875370954193341 batch: 23 
epochs: 6 val loss: 40.71875  val f1:0.16667  lr: 0.0005875370954193341 batch: 23
epochs: 7 train loss: 7.867813110351562e-06  train f1: 1.00000  lr: 0.0005875370954193341 batch: 23 
epochs: 7 val loss: 31.375  val f1:0.14286  lr: 0.0005875370954193341 batch: 23
epochs: 8 train loss: 6.67572021484375e-06  train f1: 1.00000  lr: 0.0005875370954193341 batch: 23 
epochs: 8 val loss: 24.484375  val f1:0.14286  lr: 0.0005875370954193341 batch: 23
epochs: 9 train loss: 5.9604644775390625e-06  train f1: 1.00000  lr: 0.0005875370954193341 batch: 23 
epochs: 9 val loss: 19.09375  val f1:0.14286  lr: 0.0005875370954193341 batch: 23
epochs: 0 train loss: 4.7578125  train f1: 0.00000  lr: 0.0004802762597222199 batch: 22 
epochs: 0 val loss: 5.22265625  val f1:0.00000  lr: 0.0004802762597222199 batch: 22
epochs: 1 train loss: 4.85546875  train f1: 0.00000  lr: 0.0004802762597222199 batch: 22 
epochs: 1 val loss: 4.4765625  val f1:0.12500  lr: 0.0004802762597222199 batch: 22
epochs: 0 train loss: 4.5390625  train f1: 0.00000  lr: 0.0013373740155965131 batch: 26 
epochs: 0 val loss: 5.375  val f1:0.00000  lr: 0.0013373740155965131 batch: 26
epochs: 1 train loss: 4.34765625  train f1: 0.00000  lr: 0.0013373740155965131 batch: 26 
epochs: 1 val loss: 7.27734375  val f1:0.07143  lr: 0.0013373740155965131 batch: 26
epochs: 0 train loss: 4.6875  train f1: 0.00000  lr: 0.0002155333770826224 batch: 29 
epochs: 0 val loss: 5.1640625  val f1:0.00000  lr: 0.0002155333770826224 batch: 29
epochs: 1 train loss: 4.5859375  train f1: 0.00000  lr: 0.0002155333770826224 batch: 29 
epochs: 1 val loss: 4.6796875  val f1:0.14286  lr: 0.0002155333770826224 batch: 29
epochs: 2 train loss: 0.1954345703125  train f1: 1.00000  lr: 0.0002155333770826224 batch: 29 
epochs: 2 val loss: 5.15625  val f1:0.14286  lr: 0.0002155333770826224 batch: 29
epochs: 3 train loss: 0.0703125  train f1: 1.00000  lr: 0.0002155333770826224 batch: 29 
epochs: 3 val loss: 4.890625  val f1:0.14286  lr: 0.0002155333770826224 batch: 29
epochs: 4 train loss: 0.089111328125  train f1: 1.00000  lr: 0.0002155333770826224 batch: 29 
epochs: 4 val loss: 4.4765625  val f1:0.14286  lr: 0.0002155333770826224 batch: 29
epochs: 5 train loss: 0.059356689453125  train f1: 1.00000  lr: 0.0002155333770826224 batch: 29 
epochs: 5 val loss: 4.45703125  val f1:0.14286  lr: 0.0002155333770826224 batch: 29
epochs: 6 train loss: 0.0006427764892578125  train f1: 1.00000  lr: 0.0002155333770826224 batch: 29 
epochs: 6 val loss: 4.34765625  val f1:0.14286  lr: 0.0002155333770826224 batch: 29
epochs: 7 train loss: 0.0018310546875  train f1: 1.00000  lr: 0.0002155333770826224 batch: 29 
epochs: 7 val loss: 4.2421875  val f1:0.14286  lr: 0.0002155333770826224 batch: 29
epochs: 0 train loss: 5.421875  train f1: 0.00000  lr: 0.00039567561798338957 batch: 27 
epochs: 0 val loss: 5.16796875  val f1:0.00000  lr: 0.00039567561798338957 batch: 27
epochs: 1 train loss: 5.50390625  train f1: 0.00000  lr: 0.00039567561798338957 batch: 27 
epochs: 1 val loss: 5.10546875  val f1:0.00000  lr: 0.00039567561798338957 batch: 27
epochs: 0 train loss: 4.28125  train f1: 0.00000  lr: 0.0007747945888566738 batch: 25 
epochs: 0 val loss: 4.625  val f1:0.00000  lr: 0.0007747945888566738 batch: 25
epochs: 1 train loss: 4.52734375  train f1: 0.00000  lr: 0.0007747945888566738 batch: 25 
epochs: 1 val loss: 3.525390625  val f1:0.12500  lr: 0.0007747945888566738 batch: 25
epochs: 0 train loss: 5.20703125  train f1: 0.00000  lr: 0.00027427945588622877 batch: 28 
epochs: 0 val loss: 4.66796875  val f1:0.00000  lr: 0.00027427945588622877 batch: 28
epochs: 1 train loss: 5.19921875  train f1: 0.00000  lr: 0.00027427945588622877 batch: 28 
epochs: 1 val loss: 3.677734375  val f1:0.12500  lr: 0.00027427945588622877 batch: 28
epochs: 0 train loss: 4.81640625  train f1: 0.00000  lr: 0.000988142745616544 batch: 16 
epochs: 0 val loss: 4.41015625  val f1:0.00000  lr: 0.000988142745616544 batch: 16
epochs: 1 train loss: 4.68359375  train f1: 0.00000  lr: 0.000988142745616544 batch: 16 
epochs: 1 val loss: 5.2890625  val f1:0.00000  lr: 0.000988142745616544 batch: 16
epochs: 0 train loss: 4.609375  train f1: 0.00000  lr: 0.0018372432961759617 batch: 18 
epochs: 0 val loss: 4.71484375  val f1:0.00000  lr: 0.0018372432961759617 batch: 18
epochs: 1 train loss: 4.58984375  train f1: 0.00000  lr: 0.0018372432961759617 batch: 18 
epochs: 1 val loss: 120.4375  val f1:0.06667  lr: 0.0018372432961759617 batch: 18
epochs: 0 train loss: 4.5859375  train f1: 0.00000  lr: 0.0008723968733513889 batch: 15 
epochs: 0 val loss: 5.0859375  val f1:0.00000  lr: 0.0008723968733513889 batch: 15
epochs: 1 train loss: 4.6796875  train f1: 0.00000  lr: 0.0008723968733513889 batch: 15 
epochs: 1 val loss: 6.71875  val f1:0.14286  lr: 0.0008723968733513889 batch: 15
epochs: 2 train loss: 0.4140625  train f1: 1.00000  lr: 0.0008723968733513889 batch: 15 
epochs: 2 val loss: 7.8359375  val f1:0.00000  lr: 0.0008723968733513889 batch: 15
epochs: 3 train loss: 2.56640625  train f1: 0.25000  lr: 0.0008723968733513889 batch: 15 
epochs: 3 val loss: 31.53125  val f1:0.00000  lr: 0.0008723968733513889 batch: 15
epochs: 4 train loss: 0.022705078125  train f1: 1.00000  lr: 0.0008723968733513889 batch: 15 
epochs: 4 val loss: 34.0625  val f1:0.00000  lr: 0.0008723968733513889 batch: 15
epochs: 5 train loss: 0.00024509429931640625  train f1: 1.00000  lr: 0.0008723968733513889 batch: 15 
epochs: 5 val loss: 26.1875  val f1:0.00000  lr: 0.0008723968733513889 batch: 15
epochs: 6 train loss: 0.00045990943908691406  train f1: 1.00000  lr: 0.0008723968733513889 batch: 15 
epochs: 6 val loss: 20.578125  val f1:0.14286  lr: 0.0008723968733513889 batch: 15
epochs: 7 train loss: 0.00013458728790283203  train f1: 1.00000  lr: 0.0008723968733513889 batch: 15 
epochs: 7 val loss: 17.1875  val f1:0.14286  lr: 0.0008723968733513889 batch: 15
epochs: 8 train loss: 9.429454803466797e-05  train f1: 1.00000  lr: 0.0008723968733513889 batch: 15 
epochs: 8 val loss: 14.03125  val f1:0.14286  lr: 0.0008723968733513889 batch: 15
epochs: 9 train loss: 0.0002644062042236328  train f1: 1.00000  lr: 0.0008723968733513889 batch: 15 
epochs: 9 val loss: 11.0625  val f1:0.14286  lr: 0.0008723968733513889 batch: 15
epochs: 0 train loss: 4.46484375  train f1: 0.00000  lr: 0.0012032016617259207 batch: 21 
epochs: 0 val loss: 4.3359375  val f1:0.00000  lr: 0.0012032016617259207 batch: 21
epochs: 1 train loss: 4.71875  train f1: 0.00000  lr: 0.0012032016617259207 batch: 21 
epochs: 1 val loss: 8.8515625  val f1:0.08333  lr: 0.0012032016617259207 batch: 21
epochs: 0 train loss: 4.1796875  train f1: 0.11111  lr: 0.000492248032891045 batch: 26 
epochs: 0 val loss: 4.140625  val f1:0.00000  lr: 0.000492248032891045 batch: 26
epochs: 1 train loss: 4.33984375  train f1: 0.11111  lr: 0.000492248032891045 batch: 26 
epochs: 1 val loss: 4.296875  val f1:0.14286  lr: 0.000492248032891045 batch: 26
epochs: 2 train loss: 0.9912109375  train f1: 1.00000  lr: 0.000492248032891045 batch: 26 
epochs: 2 val loss: 14.890625  val f1:0.00000  lr: 0.000492248032891045 batch: 26
epochs: 3 train loss: 1.966796875  train f1: 0.50000  lr: 0.000492248032891045 batch: 26 
epochs: 3 val loss: 4.37109375  val f1:0.12500  lr: 0.000492248032891045 batch: 26
epochs: 4 train loss: 0.10089111328125  train f1: 1.00000  lr: 0.000492248032891045 batch: 26 
epochs: 4 val loss: 5.234375  val f1:0.14286  lr: 0.000492248032891045 batch: 26
epochs: 5 train loss: 0.00922393798828125  train f1: 1.00000  lr: 0.000492248032891045 batch: 26 
epochs: 5 val loss: 4.8046875  val f1:0.14286  lr: 0.000492248032891045 batch: 26
epochs: 6 train loss: 0.00022411346435546875  train f1: 1.00000  lr: 0.000492248032891045 batch: 26 
epochs: 6 val loss: 4.65234375  val f1:0.16667  lr: 0.000492248032891045 batch: 26
epochs: 7 train loss: 0.0001900196075439453  train f1: 1.00000  lr: 0.000492248032891045 batch: 26 
epochs: 7 val loss: 4.703125  val f1:0.16667  lr: 0.000492248032891045 batch: 26
epochs: 8 train loss: 0.0001684427261352539  train f1: 1.00000  lr: 0.000492248032891045 batch: 26 
epochs: 8 val loss: 4.72265625  val f1:0.16667  lr: 0.000492248032891045 batch: 26
epochs: 9 train loss: 0.00017452239990234375  train f1: 1.00000  lr: 0.000492248032891045 batch: 26 
epochs: 9 val loss: 4.67578125  val f1:0.16667  lr: 0.000492248032891045 batch: 26
epochs: 10 train loss: 0.00016355514526367188  train f1: 1.00000  lr: 0.000492248032891045 batch: 26 
epochs: 10 val loss: 4.58984375  val f1:0.16667  lr: 0.000492248032891045 batch: 26
epochs: 11 train loss: 0.000133514404296875  train f1: 1.00000  lr: 0.000492248032891045 batch: 26 
epochs: 11 val loss: 4.5078125  val f1:0.16667  lr: 0.000492248032891045 batch: 26
epochs: 12 train loss: 0.00040912628173828125  train f1: 1.00000  lr: 0.000492248032891045 batch: 26 
epochs: 12 val loss: 4.37890625  val f1:0.16667  lr: 0.000492248032891045 batch: 26
epochs: 0 train loss: 4.5859375  train f1: 0.00000  lr: 0.00037727403074096303 batch: 27 
epochs: 0 val loss: 5.46484375  val f1:0.00000  lr: 0.00037727403074096303 batch: 27
epochs: 1 train loss: 4.5  train f1: 0.00000  lr: 0.00037727403074096303 batch: 27 
epochs: 1 val loss: 3.619140625  val f1:0.12500  lr: 0.00037727403074096303 batch: 27
epochs: 0 train loss: 5.5078125  train f1: 0.00000  lr: 0.0006729863080331907 batch: 17 
epochs: 0 val loss: 4.9765625  val f1:0.00000  lr: 0.0006729863080331907 batch: 17
epochs: 1 train loss: 5.3828125  train f1: 0.00000  lr: 0.0006729863080331907 batch: 17 
epochs: 1 val loss: 4.5625  val f1:0.00000  lr: 0.0006729863080331907 batch: 17
epochs: 0 train loss: 4.86328125  train f1: 0.00000  lr: 0.0005945289830444358 batch: 26 
epochs: 0 val loss: 5.640625  val f1:0.00000  lr: 0.0005945289830444358 batch: 26
epochs: 1 train loss: 4.90625  train f1: 0.00000  lr: 0.0005945289830444358 batch: 26 
epochs: 1 val loss: 4.8203125  val f1:0.07143  lr: 0.0005945289830444358 batch: 26
epochs: 0 train loss: 4.6171875  train f1: 0.00000  lr: 0.0004742246019787095 batch: 26 
epochs: 0 val loss: 4.8515625  val f1:0.00000  lr: 0.0004742246019787095 batch: 26
epochs: 1 train loss: 4.78515625  train f1: 0.00000  lr: 0.0004742246019787095 batch: 26 
epochs: 1 val loss: 4.6953125  val f1:0.12500  lr: 0.0004742246019787095 batch: 26
epochs: 0 train loss: 3.896484375  train f1: 0.00000  lr: 0.0003287195544515155 batch: 27 
epochs: 0 val loss: 4.71484375  val f1:0.11111  lr: 0.0003287195544515155 batch: 27
epochs: 1 train loss: 3.98046875  train f1: 0.00000  lr: 0.0003287195544515155 batch: 27 
epochs: 1 val loss: 3.875  val f1:0.14286  lr: 0.0003287195544515155 batch: 27
epochs: 2 train loss: 0.9814453125  train f1: 1.00000  lr: 0.0003287195544515155 batch: 27 
epochs: 2 val loss: 5.09375  val f1:0.16667  lr: 0.0003287195544515155 batch: 27
epochs: 3 train loss: 0.63818359375  train f1: 1.00000  lr: 0.0003287195544515155 batch: 27 
epochs: 3 val loss: 4.24609375  val f1:0.14286  lr: 0.0003287195544515155 batch: 27
epochs: 4 train loss: 0.01055145263671875  train f1: 1.00000  lr: 0.0003287195544515155 batch: 27 
epochs: 4 val loss: 4.48046875  val f1:0.12500  lr: 0.0003287195544515155 batch: 27
epochs: 5 train loss: 0.0017061233520507812  train f1: 1.00000  lr: 0.0003287195544515155 batch: 27 
epochs: 5 val loss: 4.6328125  val f1:0.14286  lr: 0.0003287195544515155 batch: 27
epochs: 6 train loss: 0.0008835792541503906  train f1: 1.00000  lr: 0.0003287195544515155 batch: 27 
epochs: 6 val loss: 4.671875  val f1:0.14286  lr: 0.0003287195544515155 batch: 27
epochs: 7 train loss: 0.001255035400390625  train f1: 1.00000  lr: 0.0003287195544515155 batch: 27 
epochs: 7 val loss: 4.6171875  val f1:0.14286  lr: 0.0003287195544515155 batch: 27
epochs: 8 train loss: 0.0008473396301269531  train f1: 1.00000  lr: 0.0003287195544515155 batch: 27 
epochs: 8 val loss: 4.55859375  val f1:0.14286  lr: 0.0003287195544515155 batch: 27
epochs: 9 train loss: 0.0007233619689941406  train f1: 1.00000  lr: 0.0003287195544515155 batch: 27 
epochs: 9 val loss: 4.375  val f1:0.14286  lr: 0.0003287195544515155 batch: 27
epochs: 10 train loss: 0.0006461143493652344  train f1: 1.00000  lr: 0.0003287195544515155 batch: 27 
epochs: 10 val loss: 4.29296875  val f1:0.14286  lr: 0.0003287195544515155 batch: 27
epochs: 0 train loss: 4.98828125  train f1: 0.00000  lr: 0.0005893811323845373 batch: 25 
epochs: 0 val loss: 5.59765625  val f1:0.00000  lr: 0.0005893811323845373 batch: 25
epochs: 1 train loss: 4.92578125  train f1: 0.00000  lr: 0.0005893811323845373 batch: 25 
epochs: 1 val loss: 5.8515625  val f1:0.16667  lr: 0.0005893811323845373 batch: 25
epochs: 2 train loss: 1.0283203125  train f1: 1.00000  lr: 0.0005893811323845373 batch: 25 
epochs: 2 val loss: 6.765625  val f1:0.08333  lr: 0.0005893811323845373 batch: 25
epochs: 3 train loss: 1.869140625  train f1: 0.50000  lr: 0.0005893811323845373 batch: 25 
epochs: 3 val loss: 8.875  val f1:0.11111  lr: 0.0005893811323845373 batch: 25
epochs: 4 train loss: 0.002803802490234375  train f1: 1.00000  lr: 0.0005893811323845373 batch: 25 
epochs: 4 val loss: 7.43359375  val f1:0.11111  lr: 0.0005893811323845373 batch: 25
epochs: 5 train loss: 0.0019321441650390625  train f1: 1.00000  lr: 0.0005893811323845373 batch: 25 
epochs: 5 val loss: 5.90234375  val f1:0.11111  lr: 0.0005893811323845373 batch: 25
epochs: 6 train loss: 8.90493392944336e-05  train f1: 1.00000  lr: 0.0005893811323845373 batch: 25 
epochs: 6 val loss: 4.765625  val f1:0.11111  lr: 0.0005893811323845373 batch: 25
epochs: 7 train loss: 9.834766387939453e-05  train f1: 1.00000  lr: 0.0005893811323845373 batch: 25 
epochs: 7 val loss: 3.98828125  val f1:0.11111  lr: 0.0005893811323845373 batch: 25
epochs: 8 train loss: 8.153915405273438e-05  train f1: 1.00000  lr: 0.0005893811323845373 batch: 25 
epochs: 8 val loss: 3.70703125  val f1:0.11111  lr: 0.0005893811323845373 batch: 25
epochs: 9 train loss: 8.90493392944336e-05  train f1: 1.00000  lr: 0.0005893811323845373 batch: 25 
epochs: 9 val loss: 3.658203125  val f1:0.14286  lr: 0.0005893811323845373 batch: 25
epochs: 10 train loss: 9.572505950927734e-05  train f1: 1.00000  lr: 0.0005893811323845373 batch: 25 
epochs: 10 val loss: 3.638671875  val f1:0.14286  lr: 0.0005893811323845373 batch: 25
epochs: 11 train loss: 6.604194641113281e-05  train f1: 1.00000  lr: 0.0005893811323845373 batch: 25 
epochs: 11 val loss: 3.640625  val f1:0.14286  lr: 0.0005893811323845373 batch: 25
epochs: 12 train loss: 0.00012564659118652344  train f1: 1.00000  lr: 0.0005893811323845373 batch: 25 
epochs: 12 val loss: 3.73046875  val f1:0.14286  lr: 0.0005893811323845373 batch: 25
epochs: 0 train loss: 4.70703125  train f1: 0.00000  lr: 0.0006631298447073752 batch: 25 
epochs: 0 val loss: 4.40234375  val f1:0.00000  lr: 0.0006631298447073752 batch: 25
epochs: 1 train loss: 4.5  train f1: 0.00000  lr: 0.0006631298447073752 batch: 25 
epochs: 1 val loss: 3.50390625  val f1:0.14286  lr: 0.0006631298447073752 batch: 25
epochs: 2 train loss: 0.96728515625  train f1: 0.50000  lr: 0.0006631298447073752 batch: 25 
epochs: 2 val loss: 22.234375  val f1:0.00000  lr: 0.0006631298447073752 batch: 25
epochs: 3 train loss: 2.263671875  train f1: 0.40000  lr: 0.0006631298447073752 batch: 25 
epochs: 3 val loss: 6.43359375  val f1:0.14286  lr: 0.0006631298447073752 batch: 25
epochs: 4 train loss: 0.10162353515625  train f1: 1.00000  lr: 0.0006631298447073752 batch: 25 
epochs: 4 val loss: 10.75  val f1:0.14286  lr: 0.0006631298447073752 batch: 25
epochs: 5 train loss: 0.0162811279296875  train f1: 1.00000  lr: 0.0006631298447073752 batch: 25 
epochs: 5 val loss: 10.8828125  val f1:0.14286  lr: 0.0006631298447073752 batch: 25
epochs: 6 train loss: 1.3768672943115234e-05  train f1: 1.00000  lr: 0.0006631298447073752 batch: 25 
epochs: 6 val loss: 9.0625  val f1:0.14286  lr: 0.0006631298447073752 batch: 25
epochs: 0 train loss: 4.703125  train f1: 0.00000  lr: 0.0004279728226237908 batch: 28 
epochs: 0 val loss: 5.015625  val f1:0.00000  lr: 0.0004279728226237908 batch: 28
epochs: 1 train loss: 4.7421875  train f1: 0.00000  lr: 0.0004279728226237908 batch: 28 
epochs: 1 val loss: 4.140625  val f1:0.12500  lr: 0.0004279728226237908 batch: 28
epochs: 0 train loss: 4.93359375  train f1: 0.00000  lr: 0.0007874291239830523 batch: 10 
epochs: 0 val loss: 4.76171875  val f1:0.00000  lr: 0.0007874291239830523 batch: 10
epochs: 1 train loss: 4.9921875  train f1: 0.00000  lr: 0.0007874291239830523 batch: 10 
epochs: 1 val loss: 4.56640625  val f1:0.12500  lr: 0.0007874291239830523 batch: 10
epochs: 0 train loss: 4.6640625  train f1: 0.00000  lr: 0.0007585761489385328 batch: 23 
epochs: 0 val loss: 5.16015625  val f1:0.00000  lr: 0.0007585761489385328 batch: 23
epochs: 1 train loss: 4.68359375  train f1: 0.00000  lr: 0.0007585761489385328 batch: 23 
epochs: 1 val loss: 3.94921875  val f1:0.09524  lr: 0.0007585761489385328 batch: 23
epochs: 0 train loss: 4.5625  train f1: 0.00000  lr: 0.0016287826524333687 batch: 12 
epochs: 0 val loss: 4.44140625  val f1:0.00000  lr: 0.0016287826524333687 batch: 12
epochs: 1 train loss: 4.4140625  train f1: 0.00000  lr: 0.0016287826524333687 batch: 12 
epochs: 1 val loss: 18.734375  val f1:0.00000  lr: 0.0016287826524333687 batch: 12
epochs: 0 train loss: 5.1171875  train f1: 0.00000  lr: 0.0010462619584543872 batch: 20 
epochs: 0 val loss: 5.61328125  val f1:0.00000  lr: 0.0010462619584543872 batch: 20
epochs: 1 train loss: 5.0625  train f1: 0.00000  lr: 0.0010462619584543872 batch: 20 
epochs: 1 val loss: 5.28125  val f1:0.16667  lr: 0.0010462619584543872 batch: 20
epochs: 2 train loss: 0.09625244140625  train f1: 1.00000  lr: 0.0010462619584543872 batch: 20 
epochs: 2 val loss: 12.8125  val f1:0.00000  lr: 0.0010462619584543872 batch: 20
epochs: 3 train loss: 0.00018990039825439453  train f1: 1.00000  lr: 0.0010462619584543872 batch: 20 
epochs: 3 val loss: 12.0546875  val f1:0.00000  lr: 0.0010462619584543872 batch: 20
epochs: 4 train loss: 0.00025200843811035156  train f1: 1.00000  lr: 0.0010462619584543872 batch: 20 
epochs: 4 val loss: 11.703125  val f1:0.00000  lr: 0.0010462619584543872 batch: 20
epochs: 5 train loss: 9.131431579589844e-05  train f1: 1.00000  lr: 0.0010462619584543872 batch: 20 
epochs: 5 val loss: 11.78125  val f1:0.00000  lr: 0.0010462619584543872 batch: 20
epochs: 6 train loss: 8.934736251831055e-05  train f1: 1.00000  lr: 0.0010462619584543872 batch: 20 
epochs: 6 val loss: 12.1796875  val f1:0.00000  lr: 0.0010462619584543872 batch: 20
epochs: 7 train loss: 4.51207160949707e-05  train f1: 1.00000  lr: 0.0010462619584543872 batch: 20 
epochs: 7 val loss: 12.6796875  val f1:0.00000  lr: 0.0010462619584543872 batch: 20
epochs: 8 train loss: 4.9114227294921875e-05  train f1: 1.00000  lr: 0.0010462619584543872 batch: 20 
epochs: 8 val loss: 13.375  val f1:0.00000  lr: 0.0010462619584543872 batch: 20
epochs: 9 train loss: 3.421306610107422e-05  train f1: 1.00000  lr: 0.0010462619584543872 batch: 20 
epochs: 9 val loss: 14.078125  val f1:0.00000  lr: 0.0010462619584543872 batch: 20
epochs: 10 train loss: 6.580352783203125e-05  train f1: 1.00000  lr: 0.0010462619584543872 batch: 20 
epochs: 10 val loss: 14.0390625  val f1:0.00000  lr: 0.0010462619584543872 batch: 20
epochs: 0 train loss: 4.50390625  train f1: 0.00000  lr: 0.0002668271890442907 batch: 30 
epochs: 0 val loss: 5.72265625  val f1:0.00000  lr: 0.0002668271890442907 batch: 30
epochs: 1 train loss: 4.65234375  train f1: 0.00000  lr: 0.0002668271890442907 batch: 30 
epochs: 1 val loss: 4.16796875  val f1:0.12500  lr: 0.0002668271890442907 batch: 30
epochs: 0 train loss: 4.8671875  train f1: 0.00000  lr: 0.00038475669679465674 batch: 27 
epochs: 0 val loss: 4.41015625  val f1:0.00000  lr: 0.00038475669679465674 batch: 27
epochs: 1 train loss: 4.8828125  train f1: 0.00000  lr: 0.00038475669679465674 batch: 27 
epochs: 1 val loss: 4.65234375  val f1:0.14286  lr: 0.00038475669679465674 batch: 27
epochs: 2 train loss: 0.14306640625  train f1: 1.00000  lr: 0.00038475669679465674 batch: 27 
epochs: 2 val loss: 5.86328125  val f1:0.14286  lr: 0.00038475669679465674 batch: 27
epochs: 3 train loss: 0.1116943359375  train f1: 1.00000  lr: 0.00038475669679465674 batch: 27 
epochs: 3 val loss: 5.68359375  val f1:0.14286  lr: 0.00038475669679465674 batch: 27
epochs: 4 train loss: 0.05340576171875  train f1: 1.00000  lr: 0.00038475669679465674 batch: 27 
epochs: 4 val loss: 4.0234375  val f1:0.14286  lr: 0.00038475669679465674 batch: 27
epochs: 5 train loss: 0.0008053779602050781  train f1: 1.00000  lr: 0.00038475669679465674 batch: 27 
epochs: 5 val loss: 4.140625  val f1:0.14286  lr: 0.00038475669679465674 batch: 27
epochs: 6 train loss: 0.00027298927307128906  train f1: 1.00000  lr: 0.00038475669679465674 batch: 27 
epochs: 6 val loss: 4.16015625  val f1:0.14286  lr: 0.00038475669679465674 batch: 27
epochs: 7 train loss: 0.00023317337036132812  train f1: 1.00000  lr: 0.00038475669679465674 batch: 27 
epochs: 7 val loss: 4.15625  val f1:0.14286  lr: 0.00038475669679465674 batch: 27
epochs: 8 train loss: 0.0002446174621582031  train f1: 1.00000  lr: 0.00038475669679465674 batch: 27 
epochs: 8 val loss: 4.14453125  val f1:0.12500  lr: 0.00038475669679465674 batch: 27
epochs: 0 train loss: 5.24609375  train f1: 0.00000  lr: 0.0006104818065273043 batch: 32 
epochs: 0 val loss: 4.61328125  val f1:0.00000  lr: 0.0006104818065273043 batch: 32
epochs: 1 train loss: 5.3046875  train f1: 0.00000  lr: 0.0006104818065273043 batch: 32 
epochs: 1 val loss: 4.9921875  val f1:0.00000  lr: 0.0006104818065273043 batch: 32
epochs: 0 train loss: 4.52734375  train f1: 0.00000  lr: 0.0004568608484910513 batch: 21 
epochs: 0 val loss: 4.65234375  val f1:0.00000  lr: 0.0004568608484910513 batch: 21
epochs: 1 train loss: 4.4609375  train f1: 0.00000  lr: 0.0004568608484910513 batch: 21 
epochs: 1 val loss: 3.826171875  val f1:0.12500  lr: 0.0004568608484910513 batch: 21
epochs: 0 train loss: 4.63671875  train f1: 0.00000  lr: 0.00044525283524280747 batch: 22 
epochs: 0 val loss: 5.2734375  val f1:0.00000  lr: 0.00044525283524280747 batch: 22
epochs: 1 train loss: 4.28515625  train f1: 0.00000  lr: 0.00044525283524280747 batch: 22 
epochs: 1 val loss: 5.16796875  val f1:0.00000  lr: 0.00044525283524280747 batch: 22
epochs: 0 train loss: 4.66796875  train f1: 0.00000  lr: 0.0005282192339063988 batch: 21 
epochs: 0 val loss: 5.01171875  val f1:0.00000  lr: 0.0005282192339063988 batch: 21
epochs: 1 train loss: 4.72265625  train f1: 0.00000  lr: 0.0005282192339063988 batch: 21 
epochs: 1 val loss: 3.939453125  val f1:0.12500  lr: 0.0005282192339063988 batch: 21
epochs: 0 train loss: 4.62890625  train f1: 0.00000  lr: 0.00034114131896146845 batch: 18 
epochs: 0 val loss: 4.46875  val f1:0.08333  lr: 0.00034114131896146845 batch: 18
epochs: 1 train loss: 4.421875  train f1: 0.00000  lr: 0.00034114131896146845 batch: 18 
epochs: 1 val loss: 4.0234375  val f1:0.14286  lr: 0.00034114131896146845 batch: 18
epochs: 2 train loss: 0.6484375  train f1: 1.00000  lr: 0.00034114131896146845 batch: 18 
epochs: 2 val loss: 7.3984375  val f1:0.00000  lr: 0.00034114131896146845 batch: 18
epochs: 3 train loss: 0.90625  train f1: 1.00000  lr: 0.00034114131896146845 batch: 18 
epochs: 3 val loss: 3.748046875  val f1:0.12500  lr: 0.00034114131896146845 batch: 18
epochs: 4 train loss: 1.0283203125  train f1: 1.00000  lr: 0.00034114131896146845 batch: 18 
epochs: 4 val loss: 4.55859375  val f1:0.16667  lr: 0.00034114131896146845 batch: 18
epochs: 5 train loss: 0.001110076904296875  train f1: 1.00000  lr: 0.00034114131896146845 batch: 18 
epochs: 5 val loss: 4.33984375  val f1:0.16667  lr: 0.00034114131896146845 batch: 18
epochs: 6 train loss: 0.0006861686706542969  train f1: 1.00000  lr: 0.00034114131896146845 batch: 18 
epochs: 6 val loss: 4.24609375  val f1:0.16667  lr: 0.00034114131896146845 batch: 18
epochs: 7 train loss: 0.0005006790161132812  train f1: 1.00000  lr: 0.00034114131896146845 batch: 18 
epochs: 7 val loss: 4.16796875  val f1:0.16667  lr: 0.00034114131896146845 batch: 18
epochs: 8 train loss: 0.00029087066650390625  train f1: 1.00000  lr: 0.00034114131896146845 batch: 18 
epochs: 8 val loss: 4.1796875  val f1:0.16667  lr: 0.00034114131896146845 batch: 18
epochs: 0 train loss: 4.2734375  train f1: 0.00000  lr: 0.0002250238719279255 batch: 19 
epochs: 0 val loss: 4.59765625  val f1:0.00000  lr: 0.0002250238719279255 batch: 19
epochs: 1 train loss: 4.12890625  train f1: 0.00000  lr: 0.0002250238719279255 batch: 19 
epochs: 1 val loss: 4.48046875  val f1:0.16667  lr: 0.0002250238719279255 batch: 19
epochs: 2 train loss: 0.228515625  train f1: 1.00000  lr: 0.0002250238719279255 batch: 19 
epochs: 2 val loss: 4.23046875  val f1:0.14286  lr: 0.0002250238719279255 batch: 19
epochs: 3 train loss: 0.091796875  train f1: 1.00000  lr: 0.0002250238719279255 batch: 19 
epochs: 3 val loss: 4.0234375  val f1:0.12500  lr: 0.0002250238719279255 batch: 19
epochs: 4 train loss: 0.19384765625  train f1: 1.00000  lr: 0.0002250238719279255 batch: 19 
epochs: 4 val loss: 3.794921875  val f1:0.12500  lr: 0.0002250238719279255 batch: 19
epochs: 5 train loss: 0.0172119140625  train f1: 1.00000  lr: 0.0002250238719279255 batch: 19 
epochs: 5 val loss: 3.734375  val f1:0.12500  lr: 0.0002250238719279255 batch: 19
epochs: 6 train loss: 0.03192138671875  train f1: 1.00000  lr: 0.0002250238719279255 batch: 19 
epochs: 6 val loss: 3.693359375  val f1:0.12500  lr: 0.0002250238719279255 batch: 19
epochs: 7 train loss: 0.0007638931274414062  train f1: 1.00000  lr: 0.0002250238719279255 batch: 19 
epochs: 7 val loss: 3.677734375  val f1:0.12500  lr: 0.0002250238719279255 batch: 19
epochs: 8 train loss: 0.0007348060607910156  train f1: 1.00000  lr: 0.0002250238719279255 batch: 19 
epochs: 8 val loss: 3.689453125  val f1:0.12500  lr: 0.0002250238719279255 batch: 19
epochs: 9 train loss: 0.0015201568603515625  train f1: 1.00000  lr: 0.0002250238719279255 batch: 19 
epochs: 9 val loss: 3.7109375  val f1:0.12500  lr: 0.0002250238719279255 batch: 19
epochs: 0 train loss: 4.46875  train f1: 0.00000  lr: 0.00017248257079761266 batch: 20 
epochs: 0 val loss: 4.46484375  val f1:0.07143  lr: 0.00017248257079761266 batch: 20
epochs: 1 train loss: 4.6015625  train f1: 0.00000  lr: 0.00017248257079761266 batch: 20 
epochs: 1 val loss: 3.90625  val f1:0.25000  lr: 0.00017248257079761266 batch: 20
epochs: 2 train loss: 0.453125  train f1: 1.00000  lr: 0.00017248257079761266 batch: 20 
epochs: 2 val loss: 3.4609375  val f1:0.12500  lr: 0.00017248257079761266 batch: 20
epochs: 3 train loss: 0.4951171875  train f1: 1.00000  lr: 0.00017248257079761266 batch: 20 
epochs: 3 val loss: 3.462890625  val f1:0.12500  lr: 0.00017248257079761266 batch: 20
epochs: 4 train loss: 0.0036563873291015625  train f1: 1.00000  lr: 0.00017248257079761266 batch: 20 
epochs: 4 val loss: 3.439453125  val f1:0.12500  lr: 0.00017248257079761266 batch: 20
epochs: 5 train loss: 0.0029163360595703125  train f1: 1.00000  lr: 0.00017248257079761266 batch: 20 
epochs: 5 val loss: 3.46484375  val f1:0.12500  lr: 0.00017248257079761266 batch: 20
epochs: 6 train loss: 0.006732940673828125  train f1: 1.00000  lr: 0.00017248257079761266 batch: 20 
epochs: 6 val loss: 3.45703125  val f1:0.12500  lr: 0.00017248257079761266 batch: 20
epochs: 7 train loss: 0.007904052734375  train f1: 1.00000  lr: 0.00017248257079761266 batch: 20 
epochs: 7 val loss: 3.443359375  val f1:0.12500  lr: 0.00017248257079761266 batch: 20
epochs: 8 train loss: 0.0032482147216796875  train f1: 1.00000  lr: 0.00017248257079761266 batch: 20 
epochs: 8 val loss: 3.43359375  val f1:0.12500  lr: 0.00017248257079761266 batch: 20
epochs: 9 train loss: 0.0019817352294921875  train f1: 1.00000  lr: 0.00017248257079761266 batch: 20 
epochs: 9 val loss: 3.42578125  val f1:0.11111  lr: 0.00017248257079761266 batch: 20
epochs: 10 train loss: 0.0023097991943359375  train f1: 1.00000  lr: 0.00017248257079761266 batch: 20 
epochs: 10 val loss: 3.421875  val f1:0.11111  lr: 0.00017248257079761266 batch: 20
epochs: 11 train loss: 0.0022258758544921875  train f1: 1.00000  lr: 0.00017248257079761266 batch: 20 
epochs: 11 val loss: 3.40625  val f1:0.11111  lr: 0.00017248257079761266 batch: 20
epochs: 12 train loss: 0.001583099365234375  train f1: 1.00000  lr: 0.00017248257079761266 batch: 20 
epochs: 12 val loss: 3.38671875  val f1:0.11111  lr: 0.00017248257079761266 batch: 20
epochs: 13 train loss: 0.0020580291748046875  train f1: 1.00000  lr: 0.00017248257079761266 batch: 20 
epochs: 13 val loss: 3.390625  val f1:0.11111  lr: 0.00017248257079761266 batch: 20
epochs: 14 train loss: 0.0008282661437988281  train f1: 1.00000  lr: 0.00017248257079761266 batch: 20 
epochs: 14 val loss: 3.400390625  val f1:0.11111  lr: 0.00017248257079761266 batch: 20
epochs: 0 train loss: 4.6875  train f1: 0.00000  lr: 0.0008002986233095863 batch: 21 
epochs: 0 val loss: 4.09765625  val f1:0.23810  lr: 0.0008002986233095863 batch: 21
epochs: 1 train loss: 4.75  train f1: 0.00000  lr: 0.0008002986233095863 batch: 21 
epochs: 1 val loss: 4.37890625  val f1:0.00000  lr: 0.0008002986233095863 batch: 21
epochs: 2 train loss: 1.1044921875  train f1: 1.00000  lr: 0.0008002986233095863 batch: 21 
epochs: 2 val loss: 38.5625  val f1:0.00000  lr: 0.0008002986233095863 batch: 21
epochs: 3 train loss: 2.76953125  train f1: 0.50000  lr: 0.0008002986233095863 batch: 21 
epochs: 3 val loss: 12.25  val f1:0.16667  lr: 0.0008002986233095863 batch: 21
epochs: 4 train loss: 0.35791015625  train f1: 1.00000  lr: 0.0008002986233095863 batch: 21 
epochs: 4 val loss: 11.4375  val f1:0.08333  lr: 0.0008002986233095863 batch: 21
epochs: 5 train loss: 0.0038204193115234375  train f1: 1.00000  lr: 0.0008002986233095863 batch: 21 
epochs: 5 val loss: 11.34375  val f1:0.08333  lr: 0.0008002986233095863 batch: 21
epochs: 6 train loss: 0.001781463623046875  train f1: 1.00000  lr: 0.0008002986233095863 batch: 21 
epochs: 6 val loss: 11.0546875  val f1:0.08333  lr: 0.0008002986233095863 batch: 21
epochs: 7 train loss: 0.00014209747314453125  train f1: 1.00000  lr: 0.0008002986233095863 batch: 21 
epochs: 7 val loss: 9.7578125  val f1:0.08333  lr: 0.0008002986233095863 batch: 21
epochs: 8 train loss: 0.00012683868408203125  train f1: 1.00000  lr: 0.0008002986233095863 batch: 21 
epochs: 8 val loss: 8.6015625  val f1:0.08333  lr: 0.0008002986233095863 batch: 21
epochs: 9 train loss: 0.00010222196578979492  train f1: 1.00000  lr: 0.0008002986233095863 batch: 21 
epochs: 9 val loss: 7.95703125  val f1:0.11111  lr: 0.0008002986233095863 batch: 21
epochs: 0 train loss: 4.1171875  train f1: 0.00000  lr: 0.0006845507708605497 batch: 22 
epochs: 0 val loss: 4.61328125  val f1:0.00000  lr: 0.0006845507708605497 batch: 22
epochs: 1 train loss: 4.234375  train f1: 0.00000  lr: 0.0006845507708605497 batch: 22 
epochs: 1 val loss: 5.26953125  val f1:0.00000  lr: 0.0006845507708605497 batch: 22
epochs: 0 train loss: 4.48046875  train f1: 0.00000  lr: 0.0005256689137615842 batch: 18 
epochs: 0 val loss: 4.84375  val f1:0.00000  lr: 0.0005256689137615842 batch: 18
epochs: 1 train loss: 4.52734375  train f1: 0.00000  lr: 0.0005256689137615842 batch: 18 
epochs: 1 val loss: 4.48828125  val f1:0.00000  lr: 0.0005256689137615842 batch: 18
epochs: 0 train loss: 4.578125  train f1: 0.00000  lr: 0.0003152499626121611 batch: 17 
epochs: 0 val loss: 5.68359375  val f1:0.00000  lr: 0.0003152499626121611 batch: 17
epochs: 1 train loss: 4.6953125  train f1: 0.00000  lr: 0.0003152499626121611 batch: 17 
epochs: 1 val loss: 4.05859375  val f1:0.12500  lr: 0.0003152499626121611 batch: 17
epochs: 0 train loss: 3.93359375  train f1: 0.11111  lr: 0.0003510152178697687 batch: 24 
epochs: 0 val loss: 4.98828125  val f1:0.00000  lr: 0.0003510152178697687 batch: 24
epochs: 1 train loss: 4.05078125  train f1: 0.11111  lr: 0.0003510152178697687 batch: 24 
epochs: 1 val loss: 3.8046875  val f1:0.12500  lr: 0.0003510152178697687 batch: 24
epochs: 0 train loss: 4.890625  train f1: 0.00000  lr: 0.0008485090754309911 batch: 22 
epochs: 0 val loss: 4.65625  val f1:0.00000  lr: 0.0008485090754309911 batch: 22
epochs: 1 train loss: 4.87890625  train f1: 0.00000  lr: 0.0008485090754309911 batch: 22 
epochs: 1 val loss: 5.07421875  val f1:0.16667  lr: 0.0008485090754309911 batch: 22
epochs: 2 train loss: 0.546875  train f1: 1.00000  lr: 0.0008485090754309911 batch: 22 
epochs: 2 val loss: 5.73828125  val f1:0.00000  lr: 0.0008485090754309911 batch: 22
epochs: 3 train loss: 0.634765625  train f1: 1.00000  lr: 0.0008485090754309911 batch: 22 
epochs: 3 val loss: 32.8125  val f1:0.11111  lr: 0.0008485090754309911 batch: 22
epochs: 4 train loss: 1.98046875  train f1: 0.55556  lr: 0.0008485090754309911 batch: 22 
epochs: 4 val loss: 30.703125  val f1:0.11111  lr: 0.0008485090754309911 batch: 22
epochs: 5 train loss: 1.9248046875  train f1: 0.55556  lr: 0.0008485090754309911 batch: 22 
epochs: 5 val loss: 17.515625  val f1:0.09524  lr: 0.0008485090754309911 batch: 22
epochs: 6 train loss: 1.75390625  train f1: 0.25000  lr: 0.0008485090754309911 batch: 22 
epochs: 6 val loss: 7.08984375  val f1:0.12500  lr: 0.0008485090754309911 batch: 22
epochs: 7 train loss: 2.08203125  train f1: 0.25000  lr: 0.0008485090754309911 batch: 22 
epochs: 7 val loss: 107.625  val f1:0.14286  lr: 0.0008485090754309911 batch: 22
epochs: 8 train loss: 0.00011968612670898438  train f1: 1.00000  lr: 0.0008485090754309911 batch: 22 
epochs: 8 val loss: 51.78125  val f1:0.14286  lr: 0.0008485090754309911 batch: 22
epochs: 9 train loss: 0.0002446174621582031  train f1: 1.00000  lr: 0.0008485090754309911 batch: 22 
epochs: 9 val loss: 25.59375  val f1:0.14286  lr: 0.0008485090754309911 batch: 22
epochs: 10 train loss: 0.00010967254638671875  train f1: 1.00000  lr: 0.0008485090754309911 batch: 22 
epochs: 10 val loss: 16.75  val f1:0.14286  lr: 0.0008485090754309911 batch: 22
epochs: 0 train loss: 4.94140625  train f1: 0.00000  lr: 0.0005957737130499901 batch: 21 
epochs: 0 val loss: 4.68359375  val f1:0.00000  lr: 0.0005957737130499901 batch: 21
epochs: 1 train loss: 4.86328125  train f1: 0.00000  lr: 0.0005957737130499901 batch: 21 
epochs: 1 val loss: 3.87890625  val f1:0.11111  lr: 0.0005957737130499901 batch: 21
epochs: 0 train loss: 4.734375  train f1: 0.00000  lr: 0.0004595050795679957 batch: 28 
epochs: 0 val loss: 4.4921875  val f1:0.00000  lr: 0.0004595050795679957 batch: 28
epochs: 1 train loss: 4.84375  train f1: 0.00000  lr: 0.0004595050795679957 batch: 28 
epochs: 1 val loss: 3.56640625  val f1:0.12500  lr: 0.0004595050795679957 batch: 28
epochs: 0 train loss: 4.8046875  train f1: 0.00000  lr: 0.0005172903055554942 batch: 20 
epochs: 0 val loss: 4.5546875  val f1:0.00000  lr: 0.0005172903055554942 batch: 20
epochs: 1 train loss: 4.74609375  train f1: 0.00000  lr: 0.0005172903055554942 batch: 20 
epochs: 1 val loss: 3.751953125  val f1:0.14286  lr: 0.0005172903055554942 batch: 20
epochs: 2 train loss: 0.125732421875  train f1: 1.00000  lr: 0.0005172903055554942 batch: 20 
epochs: 2 val loss: 4.9296875  val f1:0.14286  lr: 0.0005172903055554942 batch: 20
epochs: 3 train loss: 0.615234375  train f1: 1.00000  lr: 0.0005172903055554942 batch: 20 
epochs: 3 val loss: 4.98046875  val f1:0.16667  lr: 0.0005172903055554942 batch: 20
epochs: 4 train loss: 0.76953125  train f1: 1.00000  lr: 0.0005172903055554942 batch: 20 
epochs: 4 val loss: 4.62890625  val f1:0.14286  lr: 0.0005172903055554942 batch: 20
epochs: 5 train loss: 0.4443359375  train f1: 1.00000  lr: 0.0005172903055554942 batch: 20 
epochs: 5 val loss: 8.9921875  val f1:0.14286  lr: 0.0005172903055554942 batch: 20
epochs: 6 train loss: 0.0184173583984375  train f1: 1.00000  lr: 0.0005172903055554942 batch: 20 
epochs: 6 val loss: 7.3359375  val f1:0.14286  lr: 0.0005172903055554942 batch: 20
epochs: 7 train loss: 0.00019311904907226562  train f1: 1.00000  lr: 0.0005172903055554942 batch: 20 
epochs: 7 val loss: 6.484375  val f1:0.14286  lr: 0.0005172903055554942 batch: 20
epochs: 8 train loss: 0.00020360946655273438  train f1: 1.00000  lr: 0.0005172903055554942 batch: 20 
epochs: 8 val loss: 5.91796875  val f1:0.14286  lr: 0.0005172903055554942 batch: 20
epochs: 0 train loss: 3.947265625  train f1: 0.00000  lr: 0.0006282756755007609 batch: 21 
epochs: 0 val loss: 4.19140625  val f1:0.00000  lr: 0.0006282756755007609 batch: 21
epochs: 1 train loss: 3.978515625  train f1: 0.00000  lr: 0.0006282756755007609 batch: 21 
epochs: 1 val loss: 5.21484375  val f1:0.14286  lr: 0.0006282756755007609 batch: 21
epochs: 2 train loss: 0.57666015625  train f1: 1.00000  lr: 0.0006282756755007609 batch: 21 
epochs: 2 val loss: 11.4296875  val f1:0.00000  lr: 0.0006282756755007609 batch: 21
epochs: 3 train loss: 0.71728515625  train f1: 1.00000  lr: 0.0006282756755007609 batch: 21 
epochs: 3 val loss: 4.27734375  val f1:0.14286  lr: 0.0006282756755007609 batch: 21
epochs: 4 train loss: 0.0113983154296875  train f1: 1.00000  lr: 0.0006282756755007609 batch: 21 
epochs: 4 val loss: 4.0  val f1:0.14286  lr: 0.0006282756755007609 batch: 21
epochs: 5 train loss: 1.7881393432617188e-06  train f1: 1.00000  lr: 0.0006282756755007609 batch: 21 
epochs: 5 val loss: 5.328125  val f1:0.16667  lr: 0.0006282756755007609 batch: 21
epochs: 6 train loss: 1.1920928955078125e-07  train f1: 1.00000  lr: 0.0006282756755007609 batch: 21 
epochs: 6 val loss: 7.40625  val f1:0.14286  lr: 0.0006282756755007609 batch: 21
epochs: 0 train loss: 4.9296875  train f1: 0.00000  lr: 0.0005970617703750194 batch: 23 
epochs: 0 val loss: 4.5703125  val f1:0.00000  lr: 0.0005970617703750194 batch: 23
epochs: 1 train loss: 4.91015625  train f1: 0.00000  lr: 0.0005970617703750194 batch: 23 
epochs: 1 val loss: 3.72265625  val f1:0.12500  lr: 0.0005970617703750194 batch: 23
epochs: 0 train loss: 4.1171875  train f1: 0.16667  lr: 0.0002624061823256328 batch: 27 
epochs: 0 val loss: 4.828125  val f1:0.00000  lr: 0.0002624061823256328 batch: 27
epochs: 1 train loss: 4.08203125  train f1: 0.16667  lr: 0.0002624061823256328 batch: 27 
epochs: 1 val loss: 4.75  val f1:0.12500  lr: 0.0002624061823256328 batch: 27
epochs: 0 train loss: 4.40625  train f1: 0.00000  lr: 0.0004065129998313216 batch: 26 
epochs: 0 val loss: 4.91015625  val f1:0.00000  lr: 0.0004065129998313216 batch: 26
epochs: 1 train loss: 4.453125  train f1: 0.00000  lr: 0.0004065129998313216 batch: 26 
epochs: 1 val loss: 5.0546875  val f1:0.14286  lr: 0.0004065129998313216 batch: 26
epochs: 2 train loss: 0.222900390625  train f1: 1.00000  lr: 0.0004065129998313216 batch: 26 
epochs: 2 val loss: 8.59375  val f1:0.16667  lr: 0.0004065129998313216 batch: 26
epochs: 3 train loss: 1.8017578125  train f1: 0.66667  lr: 0.0004065129998313216 batch: 26 
epochs: 3 val loss: 4.44140625  val f1:0.14286  lr: 0.0004065129998313216 batch: 26
epochs: 4 train loss: 0.1883544921875  train f1: 1.00000  lr: 0.0004065129998313216 batch: 26 
epochs: 4 val loss: 6.68359375  val f1:0.16667  lr: 0.0004065129998313216 batch: 26
epochs: 5 train loss: 0.00011032819747924805  train f1: 1.00000  lr: 0.0004065129998313216 batch: 26 
epochs: 5 val loss: 6.4375  val f1:0.16667  lr: 0.0004065129998313216 batch: 26
epochs: 6 train loss: 9.775161743164062e-05  train f1: 1.00000  lr: 0.0004065129998313216 batch: 26 
epochs: 6 val loss: 6.265625  val f1:0.16667  lr: 0.0004065129998313216 batch: 26
epochs: 7 train loss: 8.857250213623047e-05  train f1: 1.00000  lr: 0.0004065129998313216 batch: 26 
epochs: 7 val loss: 6.125  val f1:0.16667  lr: 0.0004065129998313216 batch: 26
epochs: 8 train loss: 0.00031495094299316406  train f1: 1.00000  lr: 0.0004065129998313216 batch: 26 
epochs: 8 val loss: 6.1171875  val f1:0.16667  lr: 0.0004065129998313216 batch: 26
epochs: 9 train loss: 8.571147918701172e-05  train f1: 1.00000  lr: 0.0004065129998313216 batch: 26 
epochs: 9 val loss: 6.0390625  val f1:0.16667  lr: 0.0004065129998313216 batch: 26
epochs: 10 train loss: 8.040666580200195e-05  train f1: 1.00000  lr: 0.0004065129998313216 batch: 26 
epochs: 10 val loss: 5.97265625  val f1:0.16667  lr: 0.0004065129998313216 batch: 26
epochs: 11 train loss: 8.082389831542969e-05  train f1: 1.00000  lr: 0.0004065129998313216 batch: 26 
epochs: 11 val loss: 5.87109375  val f1:0.16667  lr: 0.0004065129998313216 batch: 26
epochs: 12 train loss: 8.20159912109375e-05  train f1: 1.00000  lr: 0.0004065129998313216 batch: 26 
epochs: 12 val loss: 5.7421875  val f1:0.16667  lr: 0.0004065129998313216 batch: 26
epochs: 13 train loss: 7.87973403930664e-05  train f1: 1.00000  lr: 0.0004065129998313216 batch: 26 
epochs: 13 val loss: 5.56640625  val f1:0.16667  lr: 0.0004065129998313216 batch: 26
epochs: 0 train loss: 4.078125  train f1: 0.00000  lr: 0.0006886070981484824 batch: 21 
epochs: 0 val loss: 4.36328125  val f1:0.00000  lr: 0.0006886070981484824 batch: 21
epochs: 1 train loss: 4.171875  train f1: 0.00000  lr: 0.0006886070981484824 batch: 21 
epochs: 1 val loss: 5.4921875  val f1:0.14286  lr: 0.0006886070981484824 batch: 21
epochs: 2 train loss: 0.07220458984375  train f1: 1.00000  lr: 0.0006886070981484824 batch: 21 
epochs: 2 val loss: 10.1484375  val f1:0.14286  lr: 0.0006886070981484824 batch: 21
epochs: 3 train loss: 2.13671875  train f1: 1.00000  lr: 0.0006886070981484824 batch: 21 
epochs: 3 val loss: 6.515625  val f1:0.16667  lr: 0.0006886070981484824 batch: 21
epochs: 4 train loss: 1.0322265625  train f1: 0.50000  lr: 0.0006886070981484824 batch: 21 
epochs: 4 val loss: 22.265625  val f1:0.14286  lr: 0.0006886070981484824 batch: 21
epochs: 5 train loss: 4.2557716369628906e-05  train f1: 1.00000  lr: 0.0006886070981484824 batch: 21 
epochs: 5 val loss: 17.203125  val f1:0.14286  lr: 0.0006886070981484824 batch: 21
epochs: 6 train loss: 1.9669532775878906e-05  train f1: 1.00000  lr: 0.0006886070981484824 batch: 21 
epochs: 6 val loss: 13.8828125  val f1:0.14286  lr: 0.0006886070981484824 batch: 21
epochs: 7 train loss: 7.468461990356445e-05  train f1: 1.00000  lr: 0.0006886070981484824 batch: 21 
epochs: 7 val loss: 11.84375  val f1:0.14286  lr: 0.0006886070981484824 batch: 21
epochs: 8 train loss: 5.233287811279297e-05  train f1: 1.00000  lr: 0.0006886070981484824 batch: 21 
epochs: 8 val loss: 10.59375  val f1:0.14286  lr: 0.0006886070981484824 batch: 21
epochs: 9 train loss: 5.14984130859375e-05  train f1: 1.00000  lr: 0.0006886070981484824 batch: 21 
epochs: 9 val loss: 9.6171875  val f1:0.14286  lr: 0.0006886070981484824 batch: 21
epochs: 10 train loss: 3.361701965332031e-05  train f1: 1.00000  lr: 0.0006886070981484824 batch: 21 
epochs: 10 val loss: 9.0390625  val f1:0.14286  lr: 0.0006886070981484824 batch: 21
epochs: 0 train loss: 4.55859375  train f1: 0.00000  lr: 0.0003788344439950328 batch: 26 
epochs: 0 val loss: 5.05078125  val f1:0.00000  lr: 0.0003788344439950328 batch: 26
epochs: 1 train loss: 4.7265625  train f1: 0.00000  lr: 0.0003788344439950328 batch: 26 
epochs: 1 val loss: 3.771484375  val f1:0.12500  lr: 0.0003788344439950328 batch: 26
epochs: 0 train loss: 4.41015625  train f1: 0.00000  lr: 0.0003480094640270252 batch: 19 
epochs: 0 val loss: 4.58203125  val f1:0.00000  lr: 0.0003480094640270252 batch: 19
epochs: 1 train loss: 4.4609375  train f1: 0.00000  lr: 0.0003480094640270252 batch: 19 
epochs: 1 val loss: 3.4453125  val f1:0.12500  lr: 0.0003480094640270252 batch: 19
epochs: 0 train loss: 5.48828125  train f1: 0.00000  lr: 0.0009722363807278748 batch: 17 
epochs: 0 val loss: 4.7890625  val f1:0.00000  lr: 0.0009722363807278748 batch: 17
epochs: 1 train loss: 5.40234375  train f1: 0.00000  lr: 0.0009722363807278748 batch: 17 
epochs: 1 val loss: 6.796875  val f1:0.16667  lr: 0.0009722363807278748 batch: 17
epochs: 2 train loss: 1.5810546875  train f1: 1.00000  lr: 0.0009722363807278748 batch: 17 
epochs: 2 val loss: 38.71875  val f1:0.06667  lr: 0.0009722363807278748 batch: 17
epochs: 3 train loss: 2.396484375  train f1: 0.20000  lr: 0.0009722363807278748 batch: 17 
epochs: 3 val loss: 59.0625  val f1:0.06667  lr: 0.0009722363807278748 batch: 17
epochs: 4 train loss: 0.056793212890625  train f1: 1.00000  lr: 0.0009722363807278748 batch: 17 
epochs: 4 val loss: 53.65625  val f1:0.00000  lr: 0.0009722363807278748 batch: 17
epochs: 5 train loss: 0.00011146068572998047  train f1: 1.00000  lr: 0.0009722363807278748 batch: 17 
epochs: 5 val loss: 42.3125  val f1:0.00000  lr: 0.0009722363807278748 batch: 17
epochs: 6 train loss: 8.702278137207031e-05  train f1: 1.00000  lr: 0.0009722363807278748 batch: 17 
epochs: 6 val loss: 37.96875  val f1:0.00000  lr: 0.0009722363807278748 batch: 17
epochs: 7 train loss: 9.894371032714844e-05  train f1: 1.00000  lr: 0.0009722363807278748 batch: 17 
epochs: 7 val loss: 34.75  val f1:0.00000  lr: 0.0009722363807278748 batch: 17
epochs: 8 train loss: 7.933378219604492e-05  train f1: 1.00000  lr: 0.0009722363807278748 batch: 17 
epochs: 8 val loss: 32.0625  val f1:0.00000  lr: 0.0009722363807278748 batch: 17
epochs: 9 train loss: 0.00012183189392089844  train f1: 1.00000  lr: 0.0009722363807278748 batch: 17 
epochs: 9 val loss: 28.96875  val f1:0.00000  lr: 0.0009722363807278748 batch: 17
epochs: 10 train loss: 0.00010657310485839844  train f1: 1.00000  lr: 0.0009722363807278748 batch: 17 
epochs: 10 val loss: 25.765625  val f1:0.16667  lr: 0.0009722363807278748 batch: 17
epochs: 11 train loss: 7.987022399902344e-05  train f1: 1.00000  lr: 0.0009722363807278748 batch: 17 
epochs: 11 val loss: 22.796875  val f1:0.16667  lr: 0.0009722363807278748 batch: 17
epochs: 12 train loss: 7.015466690063477e-05  train f1: 1.00000  lr: 0.0009722363807278748 batch: 17 
epochs: 12 val loss: 20.265625  val f1:0.16667  lr: 0.0009722363807278748 batch: 17
epochs: 13 train loss: 7.82012939453125e-05  train f1: 1.00000  lr: 0.0009722363807278748 batch: 17 
epochs: 13 val loss: 18.3125  val f1:0.16667  lr: 0.0009722363807278748 batch: 17
epochs: 0 train loss: 4.2578125  train f1: 0.00000  lr: 0.0009583116536676733 batch: 22 
epochs: 0 val loss: 4.47265625  val f1:0.00000  lr: 0.0009583116536676733 batch: 22
epochs: 1 train loss: 4.48828125  train f1: 0.00000  lr: 0.0009583116536676733 batch: 22 
epochs: 1 val loss: 4.515625  val f1:0.00000  lr: 0.0009583116536676733 batch: 22
epochs: 0 train loss: 4.703125  train f1: 0.00000  lr: 0.0003233264184308344 batch: 30 
epochs: 0 val loss: 5.22265625  val f1:0.00000  lr: 0.0003233264184308344 batch: 30
epochs: 1 train loss: 4.60546875  train f1: 0.00000  lr: 0.0003233264184308344 batch: 30 
epochs: 1 val loss: 5.1953125  val f1:0.12500  lr: 0.0003233264184308344 batch: 30
epochs: 0 train loss: 4.390625  train f1: 0.00000  lr: 0.0010699146547049649 batch: 18 
epochs: 0 val loss: 5.203125  val f1:0.00000  lr: 0.0010699146547049649 batch: 18
epochs: 1 train loss: 4.48828125  train f1: 0.00000  lr: 0.0010699146547049649 batch: 18 
epochs: 1 val loss: 6.1015625  val f1:0.08333  lr: 0.0010699146547049649 batch: 18
epochs: 0 train loss: 4.84765625  train f1: 0.00000  lr: 0.00048787031493706867 batch: 26 
epochs: 0 val loss: 4.66015625  val f1:0.00000  lr: 0.00048787031493706867 batch: 26
epochs: 1 train loss: 4.78125  train f1: 0.00000  lr: 0.00048787031493706867 batch: 26 
epochs: 1 val loss: 4.18359375  val f1:0.16667  lr: 0.00048787031493706867 batch: 26
epochs: 2 train loss: 0.68798828125  train f1: 1.00000  lr: 0.00048787031493706867 batch: 26 
epochs: 2 val loss: 6.88671875  val f1:0.00000  lr: 0.00048787031493706867 batch: 26
epochs: 3 train loss: 1.1171875  train f1: 1.00000  lr: 0.00048787031493706867 batch: 26 
epochs: 3 val loss: 4.09375  val f1:0.14286  lr: 0.00048787031493706867 batch: 26
epochs: 4 train loss: 0.74658203125  train f1: 1.00000  lr: 0.00048787031493706867 batch: 26 
epochs: 4 val loss: 6.08984375  val f1:0.16667  lr: 0.00048787031493706867 batch: 26
epochs: 5 train loss: 0.0004763603210449219  train f1: 1.00000  lr: 0.00048787031493706867 batch: 26 
epochs: 5 val loss: 5.9296875  val f1:0.16667  lr: 0.00048787031493706867 batch: 26
epochs: 6 train loss: 0.000545501708984375  train f1: 1.00000  lr: 0.00048787031493706867 batch: 26 
epochs: 6 val loss: 5.8359375  val f1:0.16667  lr: 0.00048787031493706867 batch: 26
epochs: 7 train loss: 0.0004825592041015625  train f1: 1.00000  lr: 0.00048787031493706867 batch: 26 
epochs: 7 val loss: 5.76953125  val f1:0.16667  lr: 0.00048787031493706867 batch: 26
epochs: 8 train loss: 0.000461578369140625  train f1: 1.00000  lr: 0.00048787031493706867 batch: 26 
epochs: 8 val loss: 5.5390625  val f1:0.16667  lr: 0.00048787031493706867 batch: 26
epochs: 9 train loss: 0.00063323974609375  train f1: 1.00000  lr: 0.00048787031493706867 batch: 26 
epochs: 9 val loss: 5.3984375  val f1:0.16667  lr: 0.00048787031493706867 batch: 26
epochs: 10 train loss: 0.00023758411407470703  train f1: 1.00000  lr: 0.00048787031493706867 batch: 26 
epochs: 10 val loss: 5.25390625  val f1:0.16667  lr: 0.00048787031493706867 batch: 26
epochs: 11 train loss: 0.0003821849822998047  train f1: 1.00000  lr: 0.00048787031493706867 batch: 26 
epochs: 11 val loss: 5.12890625  val f1:0.16667  lr: 0.00048787031493706867 batch: 26
epochs: 12 train loss: 0.00023221969604492188  train f1: 1.00000  lr: 0.00048787031493706867 batch: 26 
epochs: 12 val loss: 4.9140625  val f1:0.16667  lr: 0.00048787031493706867 batch: 26
epochs: 0 train loss: 4.265625  train f1: 0.11111  lr: 0.0006895544002502312 batch: 22 
epochs: 0 val loss: 5.16796875  val f1:0.00000  lr: 0.0006895544002502312 batch: 22
epochs: 1 train loss: 4.26953125  train f1: 0.11111  lr: 0.0006895544002502312 batch: 22 
epochs: 1 val loss: 3.66796875  val f1:0.14286  lr: 0.0006895544002502312 batch: 22
epochs: 2 train loss: 0.26611328125  train f1: 1.00000  lr: 0.0006895544002502312 batch: 22 
epochs: 2 val loss: 33.5  val f1:0.00000  lr: 0.0006895544002502312 batch: 22
epochs: 3 train loss: 3.26953125  train f1: 0.40000  lr: 0.0006895544002502312 batch: 22 
epochs: 3 val loss: 4.26953125  val f1:0.09524  lr: 0.0006895544002502312 batch: 22
epochs: 4 train loss: 1.0751953125  train f1: 0.50000  lr: 0.0006895544002502312 batch: 22 
epochs: 4 val loss: 27.40625  val f1:0.00000  lr: 0.0006895544002502312 batch: 22
epochs: 5 train loss: 0.002147674560546875  train f1: 1.00000  lr: 0.0006895544002502312 batch: 22 
epochs: 5 val loss: 10.9375  val f1:0.00000  lr: 0.0006895544002502312 batch: 22
epochs: 6 train loss: 0.001430511474609375  train f1: 1.00000  lr: 0.0006895544002502312 batch: 22 
epochs: 6 val loss: 5.0859375  val f1:0.14286  lr: 0.0006895544002502312 batch: 22
epochs: 7 train loss: 0.0005974769592285156  train f1: 1.00000  lr: 0.0006895544002502312 batch: 22 
epochs: 7 val loss: 4.421875  val f1:0.08333  lr: 0.0006895544002502312 batch: 22
epochs: 8 train loss: 0.00048041343688964844  train f1: 1.00000  lr: 0.0006895544002502312 batch: 22 
epochs: 8 val loss: 4.375  val f1:0.08333  lr: 0.0006895544002502312 batch: 22
epochs: 9 train loss: 0.00049591064453125  train f1: 1.00000  lr: 0.0006895544002502312 batch: 22 
epochs: 9 val loss: 4.33984375  val f1:0.09524  lr: 0.0006895544002502312 batch: 22
epochs: 0 train loss: 4.77734375  train f1: 0.00000  lr: 0.00044479263498134757 batch: 16 
epochs: 0 val loss: 4.234375  val f1:0.00000  lr: 0.00044479263498134757 batch: 16
epochs: 1 train loss: 4.8203125  train f1: 0.00000  lr: 0.00044479263498134757 batch: 16 
epochs: 1 val loss: 3.572265625  val f1:0.14286  lr: 0.00044479263498134757 batch: 16
epochs: 2 train loss: 0.26123046875  train f1: 1.00000  lr: 0.00044479263498134757 batch: 16 
epochs: 2 val loss: 5.03515625  val f1:0.00000  lr: 0.00044479263498134757 batch: 16
epochs: 3 train loss: 1.880859375  train f1: 0.66667  lr: 0.00044479263498134757 batch: 16 
epochs: 3 val loss: 3.58203125  val f1:0.12500  lr: 0.00044479263498134757 batch: 16
epochs: 4 train loss: 0.39306640625  train f1: 1.00000  lr: 0.00044479263498134757 batch: 16 
epochs: 4 val loss: 7.62109375  val f1:0.16667  lr: 0.00044479263498134757 batch: 16
epochs: 5 train loss: 0.0018148422241210938  train f1: 1.00000  lr: 0.00044479263498134757 batch: 16 
epochs: 5 val loss: 6.84375  val f1:0.14286  lr: 0.00044479263498134757 batch: 16
epochs: 6 train loss: 0.0018243789672851562  train f1: 1.00000  lr: 0.00044479263498134757 batch: 16 
epochs: 6 val loss: 6.109375  val f1:0.14286  lr: 0.00044479263498134757 batch: 16
epochs: 7 train loss: 0.0011339187622070312  train f1: 1.00000  lr: 0.00044479263498134757 batch: 16 
epochs: 7 val loss: 5.58984375  val f1:0.14286  lr: 0.00044479263498134757 batch: 16
epochs: 8 train loss: 0.0007152557373046875  train f1: 1.00000  lr: 0.00044479263498134757 batch: 16 
epochs: 8 val loss: 5.05859375  val f1:0.14286  lr: 0.00044479263498134757 batch: 16
epochs: 9 train loss: 0.0006742477416992188  train f1: 1.00000  lr: 0.00044479263498134757 batch: 16 
epochs: 9 val loss: 4.82421875  val f1:0.14286  lr: 0.00044479263498134757 batch: 16
epochs: 10 train loss: 0.0007181167602539062  train f1: 1.00000  lr: 0.00044479263498134757 batch: 16 
epochs: 10 val loss: 4.74609375  val f1:0.14286  lr: 0.00044479263498134757 batch: 16
epochs: 11 train loss: 0.0005435943603515625  train f1: 1.00000  lr: 0.00044479263498134757 batch: 16 
epochs: 11 val loss: 4.6875  val f1:0.12500  lr: 0.00044479263498134757 batch: 16
epochs: 12 train loss: 0.0006775856018066406  train f1: 1.00000  lr: 0.00044479263498134757 batch: 16 
epochs: 12 val loss: 4.66796875  val f1:0.12500  lr: 0.00044479263498134757 batch: 16
epochs: 0 train loss: 4.546875  train f1: 0.00000  lr: 0.0007931117469213441 batch: 23 
epochs: 0 val loss: 5.23046875  val f1:0.00000  lr: 0.0007931117469213441 batch: 23
epochs: 1 train loss: 4.57421875  train f1: 0.00000  lr: 0.0007931117469213441 batch: 23 
epochs: 1 val loss: 4.609375  val f1:0.00000  lr: 0.0007931117469213441 batch: 23
epochs: 0 train loss: 4.734375  train f1: 0.00000  lr: 0.0005607011362720895 batch: 21 
epochs: 0 val loss: 5.0859375  val f1:0.00000  lr: 0.0005607011362720895 batch: 21
epochs: 1 train loss: 4.796875  train f1: 0.00000  lr: 0.0005607011362720895 batch: 21 
epochs: 1 val loss: 7.87890625  val f1:0.00000  lr: 0.0005607011362720895 batch: 21
epochs: 0 train loss: 4.40625  train f1: 0.00000  lr: 0.0006810694905948094 batch: 19 
epochs: 0 val loss: 4.53125  val f1:0.00000  lr: 0.0006810694905948094 batch: 19
epochs: 1 train loss: 4.21875  train f1: 0.00000  lr: 0.0006810694905948094 batch: 19 
epochs: 1 val loss: 4.34375  val f1:0.12500  lr: 0.0006810694905948094 batch: 19
epochs: 0 train loss: 4.86328125  train f1: 0.00000  lr: 0.0012231289868426874 batch: 23 
epochs: 0 val loss: 4.65234375  val f1:0.00000  lr: 0.0012231289868426874 batch: 23
epochs: 1 train loss: 4.76953125  train f1: 0.00000  lr: 0.0012231289868426874 batch: 23 
epochs: 1 val loss: 10.203125  val f1:0.00000  lr: 0.0012231289868426874 batch: 23
epochs: 0 train loss: 5.3515625  train f1: 0.00000  lr: 0.0005309357214409268 batch: 20 
epochs: 0 val loss: 5.03515625  val f1:0.00000  lr: 0.0005309357214409268 batch: 20
epochs: 1 train loss: 5.41796875  train f1: 0.00000  lr: 0.0005309357214409268 batch: 20 
epochs: 1 val loss: 3.568359375  val f1:0.12500  lr: 0.0005309357214409268 batch: 20
epochs: 0 train loss: 3.78515625  train f1: 0.11111  lr: 0.0004099138280082868 batch: 21 
epochs: 0 val loss: 5.15234375  val f1:0.00000  lr: 0.0004099138280082868 batch: 21
epochs: 1 train loss: 3.845703125  train f1: 0.00000  lr: 0.0004099138280082868 batch: 21 
epochs: 1 val loss: 4.69921875  val f1:0.12500  lr: 0.0004099138280082868 batch: 21
epochs: 0 train loss: 4.28125  train f1: 0.00000  lr: 0.0003358974485334013 batch: 27 
epochs: 0 val loss: 4.578125  val f1:0.00000  lr: 0.0003358974485334013 batch: 27
epochs: 1 train loss: 4.390625  train f1: 0.00000  lr: 0.0003358974485334013 batch: 27 
epochs: 1 val loss: 3.703125  val f1:0.11111  lr: 0.0003358974485334013 batch: 27
epochs: 0 train loss: 4.625  train f1: 0.00000  lr: 0.00028086192829345966 batch: 29 
epochs: 0 val loss: 4.34765625  val f1:0.00000  lr: 0.00028086192829345966 batch: 29
epochs: 1 train loss: 4.6484375  train f1: 0.00000  lr: 0.00028086192829345966 batch: 29 
epochs: 1 val loss: 3.509765625  val f1:0.14286  lr: 0.00028086192829345966 batch: 29
epochs: 2 train loss: 1.400390625  train f1: 1.00000  lr: 0.00028086192829345966 batch: 29 
epochs: 2 val loss: 4.06640625  val f1:0.12500  lr: 0.00028086192829345966 batch: 29
epochs: 3 train loss: 0.251953125  train f1: 1.00000  lr: 0.00028086192829345966 batch: 29 
epochs: 3 val loss: 3.98828125  val f1:0.12500  lr: 0.00028086192829345966 batch: 29
epochs: 4 train loss: 0.006351470947265625  train f1: 1.00000  lr: 0.00028086192829345966 batch: 29 
epochs: 4 val loss: 3.80859375  val f1:0.12500  lr: 0.00028086192829345966 batch: 29
epochs: 5 train loss: 0.0029926300048828125  train f1: 1.00000  lr: 0.00028086192829345966 batch: 29 
epochs: 5 val loss: 3.611328125  val f1:0.12500  lr: 0.00028086192829345966 batch: 29
epochs: 6 train loss: 0.003963470458984375  train f1: 1.00000  lr: 0.00028086192829345966 batch: 29 
epochs: 6 val loss: 3.501953125  val f1:0.12500  lr: 0.00028086192829345966 batch: 29
epochs: 7 train loss: 0.0061187744140625  train f1: 1.00000  lr: 0.00028086192829345966 batch: 29 
epochs: 7 val loss: 3.478515625  val f1:0.12500  lr: 0.00028086192829345966 batch: 29
epochs: 0 train loss: 4.77734375  train f1: 0.00000  lr: 0.0005750554465416104 batch: 22 
epochs: 0 val loss: 5.6171875  val f1:0.00000  lr: 0.0005750554465416104 batch: 22
epochs: 1 train loss: 4.78515625  train f1: 0.00000  lr: 0.0005750554465416104 batch: 22 
epochs: 1 val loss: 4.109375  val f1:0.09524  lr: 0.0005750554465416104 batch: 22
epochs: 0 train loss: 4.79296875  train f1: 0.00000  lr: 0.000812481203991724 batch: 20 
epochs: 0 val loss: 4.62890625  val f1:0.00000  lr: 0.000812481203991724 batch: 20
epochs: 1 train loss: 4.9375  train f1: 0.00000  lr: 0.000812481203991724 batch: 20 
epochs: 1 val loss: 8.1328125  val f1:0.00000  lr: 0.000812481203991724 batch: 20
epochs: 0 train loss: 5.15234375  train f1: 0.00000  lr: 0.00044396129750167427 batch: 24 
epochs: 0 val loss: 5.0625  val f1:0.00000  lr: 0.00044396129750167427 batch: 24
epochs: 1 train loss: 5.24609375  train f1: 0.00000  lr: 0.00044396129750167427 batch: 24 
epochs: 1 val loss: 4.5546875  val f1:0.14286  lr: 0.00044396129750167427 batch: 24
epochs: 2 train loss: 0.4072265625  train f1: 1.00000  lr: 0.00044396129750167427 batch: 24 
epochs: 2 val loss: 11.0546875  val f1:0.14286  lr: 0.00044396129750167427 batch: 24
epochs: 3 train loss: 0.48974609375  train f1: 1.00000  lr: 0.00044396129750167427 batch: 24 
epochs: 3 val loss: 9.3125  val f1:0.14286  lr: 0.00044396129750167427 batch: 24
epochs: 4 train loss: 0.07049560546875  train f1: 1.00000  lr: 0.00044396129750167427 batch: 24 
epochs: 4 val loss: 7.80078125  val f1:0.14286  lr: 0.00044396129750167427 batch: 24
epochs: 5 train loss: 0.0005259513854980469  train f1: 1.00000  lr: 0.00044396129750167427 batch: 24 
epochs: 5 val loss: 7.90234375  val f1:0.14286  lr: 0.00044396129750167427 batch: 24
epochs: 6 train loss: 0.0006799697875976562  train f1: 1.00000  lr: 0.00044396129750167427 batch: 24 
epochs: 6 val loss: 7.9453125  val f1:0.14286  lr: 0.00044396129750167427 batch: 24
epochs: 7 train loss: 0.00021767616271972656  train f1: 1.00000  lr: 0.00044396129750167427 batch: 24 
epochs: 7 val loss: 7.96484375  val f1:0.14286  lr: 0.00044396129750167427 batch: 24
epochs: 8 train loss: 0.00032067298889160156  train f1: 1.00000  lr: 0.00044396129750167427 batch: 24 
epochs: 8 val loss: 7.96875  val f1:0.14286  lr: 0.00044396129750167427 batch: 24
epochs: 9 train loss: 0.00017881393432617188  train f1: 1.00000  lr: 0.00044396129750167427 batch: 24 
epochs: 9 val loss: 8.15625  val f1:0.14286  lr: 0.00044396129750167427 batch: 24
epochs: 10 train loss: 0.0002505779266357422  train f1: 1.00000  lr: 0.00044396129750167427 batch: 24 
epochs: 10 val loss: 8.2109375  val f1:0.14286  lr: 0.00044396129750167427 batch: 24
epochs: 11 train loss: 0.0002092123031616211  train f1: 1.00000  lr: 0.00044396129750167427 batch: 24 
epochs: 11 val loss: 8.109375  val f1:0.14286  lr: 0.00044396129750167427 batch: 24
epochs: 12 train loss: 0.00015044212341308594  train f1: 1.00000  lr: 0.00044396129750167427 batch: 24 
epochs: 12 val loss: 8.2109375  val f1:0.14286  lr: 0.00044396129750167427 batch: 24
epochs: 13 train loss: 0.0001277923583984375  train f1: 1.00000  lr: 0.00044396129750167427 batch: 24 
epochs: 13 val loss: 7.9609375  val f1:0.14286  lr: 0.00044396129750167427 batch: 24
epochs: 0 train loss: 4.73828125  train f1: 0.00000  lr: 0.0012890921260787862 batch: 26 
epochs: 0 val loss: 4.67578125  val f1:0.00000  lr: 0.0012890921260787862 batch: 26
epochs: 1 train loss: 4.8203125  train f1: 0.00000  lr: 0.0012890921260787862 batch: 26 
epochs: 1 val loss: 11.2890625  val f1:0.00000  lr: 0.0012890921260787862 batch: 26
epochs: 0 train loss: 4.7578125  train f1: 0.00000  lr: 0.000844273099514385 batch: 25 
epochs: 0 val loss: 5.32421875  val f1:0.00000  lr: 0.000844273099514385 batch: 25
epochs: 1 train loss: 4.74609375  train f1: 0.00000  lr: 0.000844273099514385 batch: 25 
epochs: 1 val loss: 4.921875  val f1:0.07143  lr: 0.000844273099514385 batch: 25
epochs: 0 train loss: 4.62109375  train f1: 0.00000  lr: 0.0015072429105617486 batch: 18 
epochs: 0 val loss: 5.0  val f1:0.00000  lr: 0.0015072429105617486 batch: 18
epochs: 1 train loss: 4.6484375  train f1: 0.00000  lr: 0.0015072429105617486 batch: 18 
epochs: 1 val loss: 8.5  val f1:0.07143  lr: 0.0015072429105617486 batch: 18
epochs: 0 train loss: 4.51171875  train f1: 0.00000  lr: 0.0010493111289278552 batch: 15 
epochs: 0 val loss: 5.13671875  val f1:0.00000  lr: 0.0010493111289278552 batch: 15
epochs: 1 train loss: 4.3828125  train f1: 0.00000  lr: 0.0010493111289278552 batch: 15 
epochs: 1 val loss: 5.7734375  val f1:0.08333  lr: 0.0010493111289278552 batch: 15
epochs: 0 train loss: 5.05078125  train f1: 0.00000  lr: 0.00045107345490818054 batch: 28 
epochs: 0 val loss: 4.8203125  val f1:0.00000  lr: 0.00045107345490818054 batch: 28
epochs: 1 train loss: 4.89453125  train f1: 0.00000  lr: 0.00045107345490818054 batch: 28 
epochs: 1 val loss: 5.03515625  val f1:0.09524  lr: 0.00045107345490818054 batch: 28
epochs: 0 train loss: 4.359375  train f1: 0.00000  lr: 0.00022443245490042388 batch: 8 
epochs: 0 val loss: 4.8359375  val f1:0.00000  lr: 0.00022443245490042388 batch: 8
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.00022443245490042388 batch: 8 
epochs: 1 val loss: 4.7578125  val f1:0.00000  lr: 0.00022443245490042388 batch: 8
epochs: 0 train loss: 5.05078125  train f1: 0.00000  lr: 0.0003711761930493613 batch: 25 
epochs: 0 val loss: 4.55078125  val f1:0.12500  lr: 0.0003711761930493613 batch: 25
epochs: 1 train loss: 5.1640625  train f1: 0.00000  lr: 0.0003711761930493613 batch: 25 
epochs: 1 val loss: 4.2890625  val f1:0.12500  lr: 0.0003711761930493613 batch: 25
epochs: 0 train loss: 4.8046875  train f1: 0.00000  lr: 0.0005129693967353583 batch: 26 
epochs: 0 val loss: 4.94140625  val f1:0.00000  lr: 0.0005129693967353583 batch: 26
epochs: 1 train loss: 4.59375  train f1: 0.00000  lr: 0.0005129693967353583 batch: 26 
epochs: 1 val loss: 4.921875  val f1:0.00000  lr: 0.0005129693967353583 batch: 26
epochs: 0 train loss: 4.90234375  train f1: 0.00000  lr: 0.00036792962368028815 batch: 27 
epochs: 0 val loss: 5.5625  val f1:0.00000  lr: 0.00036792962368028815 batch: 27
epochs: 1 train loss: 4.8515625  train f1: 0.00000  lr: 0.00036792962368028815 batch: 27 
epochs: 1 val loss: 4.01953125  val f1:0.12500  lr: 0.00036792962368028815 batch: 27
epochs: 0 train loss: 3.857421875  train f1: 0.11111  lr: 0.0008740618301195706 batch: 26 
epochs: 0 val loss: 4.45703125  val f1:0.11111  lr: 0.0008740618301195706 batch: 26
epochs: 1 train loss: 4.00390625  train f1: 0.11111  lr: 0.0008740618301195706 batch: 26 
epochs: 1 val loss: 3.46875  val f1:0.33333  lr: 0.0008740618301195706 batch: 26
epochs: 2 train loss: 2.26953125  train f1: 0.20000  lr: 0.0008740618301195706 batch: 26 
epochs: 2 val loss: 51.40625  val f1:0.00000  lr: 0.0008740618301195706 batch: 26
epochs: 3 train loss: 1.8896484375  train f1: 0.66667  lr: 0.0008740618301195706 batch: 26 
epochs: 3 val loss: 15.390625  val f1:0.00000  lr: 0.0008740618301195706 batch: 26
epochs: 4 train loss: 0.03326416015625  train f1: 1.00000  lr: 0.0008740618301195706 batch: 26 
epochs: 4 val loss: 5.1171875  val f1:0.00000  lr: 0.0008740618301195706 batch: 26
epochs: 5 train loss: 0.00020205974578857422  train f1: 1.00000  lr: 0.0008740618301195706 batch: 26 
epochs: 5 val loss: 5.15234375  val f1:0.00000  lr: 0.0008740618301195706 batch: 26
epochs: 6 train loss: 0.0004050731658935547  train f1: 1.00000  lr: 0.0008740618301195706 batch: 26 
epochs: 6 val loss: 5.32421875  val f1:0.00000  lr: 0.0008740618301195706 batch: 26
epochs: 7 train loss: 0.00012922286987304688  train f1: 1.00000  lr: 0.0008740618301195706 batch: 26 
epochs: 7 val loss: 5.33203125  val f1:0.00000  lr: 0.0008740618301195706 batch: 26
epochs: 8 train loss: 0.00013065338134765625  train f1: 1.00000  lr: 0.0008740618301195706 batch: 26 
epochs: 8 val loss: 5.39453125  val f1:0.00000  lr: 0.0008740618301195706 batch: 26
epochs: 0 train loss: 4.90234375  train f1: 0.00000  lr: 0.0002851351624672103 batch: 9 
epochs: 0 val loss: 5.29296875  val f1:0.00000  lr: 0.0002851351624672103 batch: 9
epochs: 1 train loss: 4.9296875  train f1: 0.00000  lr: 0.0002851351624672103 batch: 9 
epochs: 1 val loss: 4.421875  val f1:0.12500  lr: 0.0002851351624672103 batch: 9
epochs: 0 train loss: 4.06640625  train f1: 0.00000  lr: 0.0007113906129759289 batch: 26 
epochs: 0 val loss: 5.171875  val f1:0.00000  lr: 0.0007113906129759289 batch: 26
epochs: 1 train loss: 3.9375  train f1: 0.00000  lr: 0.0007113906129759289 batch: 26 
epochs: 1 val loss: 3.599609375  val f1:0.14286  lr: 0.0007113906129759289 batch: 26
epochs: 2 train loss: 0.3310546875  train f1: 1.00000  lr: 0.0007113906129759289 batch: 26 
epochs: 2 val loss: 32.96875  val f1:0.00000  lr: 0.0007113906129759289 batch: 26
epochs: 3 train loss: 1.9140625  train f1: 0.66667  lr: 0.0007113906129759289 batch: 26 
epochs: 3 val loss: 7.36328125  val f1:0.14286  lr: 0.0007113906129759289 batch: 26
epochs: 4 train loss: 0.00018477439880371094  train f1: 1.00000  lr: 0.0007113906129759289 batch: 26 
epochs: 4 val loss: 8.2421875  val f1:0.14286  lr: 0.0007113906129759289 batch: 26
epochs: 5 train loss: 0.00011301040649414062  train f1: 1.00000  lr: 0.0007113906129759289 batch: 26 
epochs: 5 val loss: 9.5234375  val f1:0.14286  lr: 0.0007113906129759289 batch: 26
epochs: 6 train loss: 0.000156402587890625  train f1: 1.00000  lr: 0.0007113906129759289 batch: 26 
epochs: 6 val loss: 10.0859375  val f1:0.14286  lr: 0.0007113906129759289 batch: 26
epochs: 7 train loss: 0.00011396408081054688  train f1: 1.00000  lr: 0.0007113906129759289 batch: 26 
epochs: 7 val loss: 10.53125  val f1:0.14286  lr: 0.0007113906129759289 batch: 26
epochs: 0 train loss: 4.70703125  train f1: 0.00000  lr: 0.0006576250723125078 batch: 14 
epochs: 0 val loss: 4.46875  val f1:0.00000  lr: 0.0006576250723125078 batch: 14
epochs: 1 train loss: 4.546875  train f1: 0.00000  lr: 0.0006576250723125078 batch: 14 
epochs: 1 val loss: 4.07421875  val f1:0.00000  lr: 0.0006576250723125078 batch: 14
epochs: 0 train loss: 4.76171875  train f1: 0.00000  lr: 5.9393181114058896e-05 batch: 26 
epochs: 0 val loss: 4.6796875  val f1:0.00000  lr: 5.9393181114058896e-05 batch: 26
epochs: 1 train loss: 4.86328125  train f1: 0.00000  lr: 5.9393181114058896e-05 batch: 26 
epochs: 1 val loss: 4.34765625  val f1:0.00000  lr: 5.9393181114058896e-05 batch: 26
epochs: 0 train loss: 4.6015625  train f1: 0.00000  lr: 0.0008781311924706757 batch: 15 
epochs: 0 val loss: 4.296875  val f1:0.12500  lr: 0.0008781311924706757 batch: 15
epochs: 1 train loss: 4.57421875  train f1: 0.00000  lr: 0.0008781311924706757 batch: 15 
epochs: 1 val loss: 4.13671875  val f1:0.11111  lr: 0.0008781311924706757 batch: 15
epochs: 0 train loss: 4.4375  train f1: 0.00000  lr: 0.0011873622441392082 batch: 17 
epochs: 0 val loss: 5.65234375  val f1:0.00000  lr: 0.0011873622441392082 batch: 17
epochs: 1 train loss: 4.44921875  train f1: 0.00000  lr: 0.0011873622441392082 batch: 17 
epochs: 1 val loss: 4.27734375  val f1:0.00000  lr: 0.0011873622441392082 batch: 17
epochs: 0 train loss: 4.3203125  train f1: 0.00000  lr: 0.0907542446239506 batch: 27 
epochs: 0 val loss: 5.0625  val f1:0.00000  lr: 0.0907542446239506 batch: 27
epochs: 1 train loss: 4.40625  train f1: 0.00000  lr: 0.0907542446239506 batch: 27 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.0907542446239506 batch: 27
epochs: 0 train loss: 4.75  train f1: 0.00000  lr: 0.003398512713244581 batch: 25 
epochs: 0 val loss: 4.9296875  val f1:0.00000  lr: 0.003398512713244581 batch: 25
epochs: 1 train loss: 4.76953125  train f1: 0.00000  lr: 0.003398512713244581 batch: 25 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.003398512713244581 batch: 25
epochs: 0 train loss: 4.7265625  train f1: 0.00000  lr: 0.0007162164984529137 batch: 27 
epochs: 0 val loss: 5.33984375  val f1:0.00000  lr: 0.0007162164984529137 batch: 27
epochs: 1 train loss: 4.58203125  train f1: 0.00000  lr: 0.0007162164984529137 batch: 27 
epochs: 1 val loss: 4.96484375  val f1:0.14286  lr: 0.0007162164984529137 batch: 27
epochs: 2 train loss: 0.1170654296875  train f1: 1.00000  lr: 0.0007162164984529137 batch: 27 
epochs: 2 val loss: 30.703125  val f1:0.00000  lr: 0.0007162164984529137 batch: 27
epochs: 3 train loss: 3.1015625  train f1: 0.40000  lr: 0.0007162164984529137 batch: 27 
epochs: 3 val loss: 5.2734375  val f1:0.14286  lr: 0.0007162164984529137 batch: 27
epochs: 4 train loss: 0.0219268798828125  train f1: 1.00000  lr: 0.0007162164984529137 batch: 27 
epochs: 4 val loss: 11.8671875  val f1:0.14286  lr: 0.0007162164984529137 batch: 27
epochs: 5 train loss: 0.00019538402557373047  train f1: 1.00000  lr: 0.0007162164984529137 batch: 27 
epochs: 5 val loss: 11.0546875  val f1:0.14286  lr: 0.0007162164984529137 batch: 27
epochs: 6 train loss: 0.000232696533203125  train f1: 1.00000  lr: 0.0007162164984529137 batch: 27 
epochs: 6 val loss: 10.953125  val f1:0.14286  lr: 0.0007162164984529137 batch: 27
epochs: 7 train loss: 0.00015234947204589844  train f1: 1.00000  lr: 0.0007162164984529137 batch: 27 
epochs: 7 val loss: 10.7265625  val f1:0.14286  lr: 0.0007162164984529137 batch: 27
epochs: 8 train loss: 0.0002484321594238281  train f1: 1.00000  lr: 0.0007162164984529137 batch: 27 
epochs: 8 val loss: 10.8515625  val f1:0.14286  lr: 0.0007162164984529137 batch: 27
epochs: 9 train loss: 0.00020384788513183594  train f1: 1.00000  lr: 0.0007162164984529137 batch: 27 
epochs: 9 val loss: 10.5625  val f1:0.14286  lr: 0.0007162164984529137 batch: 27
epochs: 10 train loss: 0.00011134147644042969  train f1: 1.00000  lr: 0.0007162164984529137 batch: 27 
epochs: 10 val loss: 9.9296875  val f1:0.14286  lr: 0.0007162164984529137 batch: 27
epochs: 11 train loss: 0.0001621246337890625  train f1: 1.00000  lr: 0.0007162164984529137 batch: 27 
epochs: 11 val loss: 9.578125  val f1:0.14286  lr: 0.0007162164984529137 batch: 27
epochs: 0 train loss: 4.1484375  train f1: 0.00000  lr: 0.00047598073567157025 batch: 28 
epochs: 0 val loss: 4.91796875  val f1:0.00000  lr: 0.00047598073567157025 batch: 28
epochs: 1 train loss: 3.994140625  train f1: 0.00000  lr: 0.00047598073567157025 batch: 28 
epochs: 1 val loss: 4.41796875  val f1:0.12500  lr: 0.00047598073567157025 batch: 28
epochs: 0 train loss: 4.86328125  train f1: 0.00000  lr: 0.0006354433288620555 batch: 16 
epochs: 0 val loss: 5.4296875  val f1:0.00000  lr: 0.0006354433288620555 batch: 16
epochs: 1 train loss: 4.97265625  train f1: 0.00000  lr: 0.0006354433288620555 batch: 16 
epochs: 1 val loss: 4.421875  val f1:0.09524  lr: 0.0006354433288620555 batch: 16
epochs: 0 train loss: 4.9765625  train f1: 0.00000  lr: 0.0004139121158941141 batch: 29 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.0004139121158941141 batch: 29
epochs: 1 train loss: 5.03515625  train f1: 0.00000  lr: 0.0004139121158941141 batch: 29 
epochs: 1 val loss: 4.5625  val f1:0.12500  lr: 0.0004139121158941141 batch: 29
epochs: 0 train loss: 4.41796875  train f1: 0.00000  lr: 0.000476182521228965 batch: 28 
epochs: 0 val loss: 4.9921875  val f1:0.00000  lr: 0.000476182521228965 batch: 28
epochs: 1 train loss: 4.48828125  train f1: 0.00000  lr: 0.000476182521228965 batch: 28 
epochs: 1 val loss: 4.0703125  val f1:0.14286  lr: 0.000476182521228965 batch: 28
epochs: 2 train loss: 0.3544921875  train f1: 1.00000  lr: 0.000476182521228965 batch: 28 
epochs: 2 val loss: 4.80859375  val f1:0.16667  lr: 0.000476182521228965 batch: 28
epochs: 3 train loss: 1.2646484375  train f1: 0.50000  lr: 0.000476182521228965 batch: 28 
epochs: 3 val loss: 10.984375  val f1:0.16667  lr: 0.000476182521228965 batch: 28
epochs: 4 train loss: 0.0009174346923828125  train f1: 1.00000  lr: 0.000476182521228965 batch: 28 
epochs: 4 val loss: 11.8125  val f1:0.16667  lr: 0.000476182521228965 batch: 28
epochs: 5 train loss: 0.0004048347473144531  train f1: 1.00000  lr: 0.000476182521228965 batch: 28 
epochs: 5 val loss: 11.8828125  val f1:0.16667  lr: 0.000476182521228965 batch: 28
epochs: 6 train loss: 0.00035572052001953125  train f1: 1.00000  lr: 0.000476182521228965 batch: 28 
epochs: 6 val loss: 11.1796875  val f1:0.16667  lr: 0.000476182521228965 batch: 28
epochs: 7 train loss: 0.00038313865661621094  train f1: 1.00000  lr: 0.000476182521228965 batch: 28 
epochs: 7 val loss: 10.109375  val f1:0.16667  lr: 0.000476182521228965 batch: 28
epochs: 8 train loss: 0.0012645721435546875  train f1: 1.00000  lr: 0.000476182521228965 batch: 28 
epochs: 8 val loss: 9.375  val f1:0.16667  lr: 0.000476182521228965 batch: 28
epochs: 9 train loss: 0.00018858909606933594  train f1: 1.00000  lr: 0.000476182521228965 batch: 28 
epochs: 9 val loss: 8.8359375  val f1:0.16667  lr: 0.000476182521228965 batch: 28
epochs: 10 train loss: 0.000164031982421875  train f1: 1.00000  lr: 0.000476182521228965 batch: 28 
epochs: 10 val loss: 8.265625  val f1:0.16667  lr: 0.000476182521228965 batch: 28
epochs: 0 train loss: 4.4609375  train f1: 0.00000  lr: 0.0004805593820658713 batch: 28 
epochs: 0 val loss: 4.85546875  val f1:0.00000  lr: 0.0004805593820658713 batch: 28
epochs: 1 train loss: 4.27734375  train f1: 0.00000  lr: 0.0004805593820658713 batch: 28 
epochs: 1 val loss: 7.3671875  val f1:0.16667  lr: 0.0004805593820658713 batch: 28
epochs: 2 train loss: 0.1488037109375  train f1: 1.00000  lr: 0.0004805593820658713 batch: 28 
epochs: 2 val loss: 4.4375  val f1:0.12500  lr: 0.0004805593820658713 batch: 28
epochs: 3 train loss: 0.96044921875  train f1: 0.50000  lr: 0.0004805593820658713 batch: 28 
epochs: 3 val loss: 8.1640625  val f1:0.14286  lr: 0.0004805593820658713 batch: 28
epochs: 4 train loss: 0.0008592605590820312  train f1: 1.00000  lr: 0.0004805593820658713 batch: 28 
epochs: 4 val loss: 7.1328125  val f1:0.14286  lr: 0.0004805593820658713 batch: 28
epochs: 5 train loss: 0.0007352828979492188  train f1: 1.00000  lr: 0.0004805593820658713 batch: 28 
epochs: 5 val loss: 6.203125  val f1:0.14286  lr: 0.0004805593820658713 batch: 28
epochs: 6 train loss: 0.1954345703125  train f1: 1.00000  lr: 0.0004805593820658713 batch: 28 
epochs: 6 val loss: 4.93359375  val f1:0.14286  lr: 0.0004805593820658713 batch: 28
epochs: 7 train loss: 0.1260986328125  train f1: 1.00000  lr: 0.0004805593820658713 batch: 28 
epochs: 7 val loss: 5.37890625  val f1:0.14286  lr: 0.0004805593820658713 batch: 28
epochs: 8 train loss: 0.00135040283203125  train f1: 1.00000  lr: 0.0004805593820658713 batch: 28 
epochs: 8 val loss: 5.08203125  val f1:0.14286  lr: 0.0004805593820658713 batch: 28
epochs: 9 train loss: 0.0004820823669433594  train f1: 1.00000  lr: 0.0004805593820658713 batch: 28 
epochs: 9 val loss: 4.87890625  val f1:0.14286  lr: 0.0004805593820658713 batch: 28
epochs: 10 train loss: 0.00038695335388183594  train f1: 1.00000  lr: 0.0004805593820658713 batch: 28 
epochs: 10 val loss: 4.7578125  val f1:0.12500  lr: 0.0004805593820658713 batch: 28
epochs: 11 train loss: 0.000392913818359375  train f1: 1.00000  lr: 0.0004805593820658713 batch: 28 
epochs: 11 val loss: 4.640625  val f1:0.12500  lr: 0.0004805593820658713 batch: 28
epochs: 0 train loss: 4.9921875  train f1: 0.00000  lr: 0.0009581305804572637 batch: 29 
epochs: 0 val loss: 4.921875  val f1:0.00000  lr: 0.0009581305804572637 batch: 29
epochs: 1 train loss: 4.9140625  train f1: 0.00000  lr: 0.0009581305804572637 batch: 29 
epochs: 1 val loss: 6.15625  val f1:0.14286  lr: 0.0009581305804572637 batch: 29
epochs: 2 train loss: 0.70361328125  train f1: 1.00000  lr: 0.0009581305804572637 batch: 29 
epochs: 2 val loss: 104.4375  val f1:0.00000  lr: 0.0009581305804572637 batch: 29
epochs: 3 train loss: 2.85546875  train f1: 0.50000  lr: 0.0009581305804572637 batch: 29 
epochs: 3 val loss: 23.796875  val f1:0.00000  lr: 0.0009581305804572637 batch: 29
epochs: 4 train loss: 0.65869140625  train f1: 1.00000  lr: 0.0009581305804572637 batch: 29 
epochs: 4 val loss: 112.3125  val f1:0.00000  lr: 0.0009581305804572637 batch: 29
epochs: 5 train loss: 0.177001953125  train f1: 1.00000  lr: 0.0009581305804572637 batch: 29 
epochs: 5 val loss: 545.0  val f1:0.00000  lr: 0.0009581305804572637 batch: 29
epochs: 6 train loss: 0.303955078125  train f1: 1.00000  lr: 0.0009581305804572637 batch: 29 
epochs: 6 val loss: 79.375  val f1:0.00000  lr: 0.0009581305804572637 batch: 29
epochs: 7 train loss: 0.0  train f1: 1.00000  lr: 0.0009581305804572637 batch: 29 
epochs: 7 val loss: 66.1875  val f1:0.00000  lr: 0.0009581305804572637 batch: 29
epochs: 8 train loss: 4.76837158203125e-07  train f1: 1.00000  lr: 0.0009581305804572637 batch: 29 
epochs: 8 val loss: 50.28125  val f1:0.14286  lr: 0.0009581305804572637 batch: 29
epochs: 9 train loss: 5.960464477539063e-08  train f1: 1.00000  lr: 0.0009581305804572637 batch: 29 
epochs: 9 val loss: 34.59375  val f1:0.11111  lr: 0.0009581305804572637 batch: 29
epochs: 10 train loss: 2.384185791015625e-07  train f1: 1.00000  lr: 0.0009581305804572637 batch: 29 
epochs: 10 val loss: 16.53125  val f1:0.09524  lr: 0.0009581305804572637 batch: 29
epochs: 0 train loss: 5.3125  train f1: 0.00000  lr: 0.0007233473092723409 batch: 27 
epochs: 0 val loss: 4.75  val f1:0.00000  lr: 0.0007233473092723409 batch: 27
epochs: 1 train loss: 5.3984375  train f1: 0.00000  lr: 0.0007233473092723409 batch: 27 
epochs: 1 val loss: 4.8828125  val f1:0.00000  lr: 0.0007233473092723409 batch: 27
epochs: 0 train loss: 5.03125  train f1: 0.00000  lr: 0.0005523579278616775 batch: 12 
epochs: 0 val loss: 5.16015625  val f1:0.00000  lr: 0.0005523579278616775 batch: 12
epochs: 1 train loss: 4.9765625  train f1: 0.00000  lr: 0.0005523579278616775 batch: 12 
epochs: 1 val loss: 3.599609375  val f1:0.14286  lr: 0.0005523579278616775 batch: 12
epochs: 2 train loss: 0.26904296875  train f1: 1.00000  lr: 0.0005523579278616775 batch: 12 
epochs: 2 val loss: 12.3984375  val f1:0.00000  lr: 0.0005523579278616775 batch: 12
epochs: 3 train loss: 1.4912109375  train f1: 1.00000  lr: 0.0005523579278616775 batch: 12 
epochs: 3 val loss: 6.03515625  val f1:0.00000  lr: 0.0005523579278616775 batch: 12
epochs: 4 train loss: 0.716796875  train f1: 1.00000  lr: 0.0005523579278616775 batch: 12 
epochs: 4 val loss: 27.953125  val f1:0.00000  lr: 0.0005523579278616775 batch: 12
epochs: 5 train loss: 0.00037670135498046875  train f1: 1.00000  lr: 0.0005523579278616775 batch: 12 
epochs: 5 val loss: 21.453125  val f1:0.00000  lr: 0.0005523579278616775 batch: 12
epochs: 6 train loss: 0.0003046989440917969  train f1: 1.00000  lr: 0.0005523579278616775 batch: 12 
epochs: 6 val loss: 15.484375  val f1:0.00000  lr: 0.0005523579278616775 batch: 12
epochs: 7 train loss: 0.0004982948303222656  train f1: 1.00000  lr: 0.0005523579278616775 batch: 12 
epochs: 7 val loss: 11.578125  val f1:0.16667  lr: 0.0005523579278616775 batch: 12
epochs: 8 train loss: 0.00011038780212402344  train f1: 1.00000  lr: 0.0005523579278616775 batch: 12 
epochs: 8 val loss: 8.484375  val f1:0.16667  lr: 0.0005523579278616775 batch: 12
epochs: 9 train loss: 0.0003745555877685547  train f1: 1.00000  lr: 0.0005523579278616775 batch: 12 
epochs: 9 val loss: 6.6875  val f1:0.16667  lr: 0.0005523579278616775 batch: 12
epochs: 10 train loss: 0.00022470951080322266  train f1: 1.00000  lr: 0.0005523579278616775 batch: 12 
epochs: 10 val loss: 5.6328125  val f1:0.16667  lr: 0.0005523579278616775 batch: 12
epochs: 11 train loss: 9.000301361083984e-05  train f1: 1.00000  lr: 0.0005523579278616775 batch: 12 
epochs: 11 val loss: 4.90625  val f1:0.14286  lr: 0.0005523579278616775 batch: 12
epochs: 0 train loss: 4.9609375  train f1: 0.00000  lr: 0.0005805135384503779 batch: 21 
epochs: 0 val loss: 4.87109375  val f1:0.00000  lr: 0.0005805135384503779 batch: 21
epochs: 1 train loss: 5.08984375  train f1: 0.00000  lr: 0.0005805135384503779 batch: 21 
epochs: 1 val loss: 4.78515625  val f1:0.00000  lr: 0.0005805135384503779 batch: 21
epochs: 0 train loss: 4.53125  train f1: 0.00000  lr: 0.0007900204640553603 batch: 15 
epochs: 0 val loss: 4.49609375  val f1:0.00000  lr: 0.0007900204640553603 batch: 15
epochs: 1 train loss: 4.53125  train f1: 0.00000  lr: 0.0007900204640553603 batch: 15 
epochs: 1 val loss: 5.98046875  val f1:0.16667  lr: 0.0007900204640553603 batch: 15
epochs: 2 train loss: 0.68603515625  train f1: 1.00000  lr: 0.0007900204640553603 batch: 15 
epochs: 2 val loss: 5.09375  val f1:0.00000  lr: 0.0007900204640553603 batch: 15
epochs: 3 train loss: 0.345458984375  train f1: 1.00000  lr: 0.0007900204640553603 batch: 15 
epochs: 3 val loss: 16.984375  val f1:0.00000  lr: 0.0007900204640553603 batch: 15
epochs: 4 train loss: 1.474609375  train f1: 0.50000  lr: 0.0007900204640553603 batch: 15 
epochs: 4 val loss: 4.53125  val f1:0.09524  lr: 0.0007900204640553603 batch: 15
epochs: 5 train loss: 0.48193359375  train f1: 1.00000  lr: 0.0007900204640553603 batch: 15 
epochs: 5 val loss: 4.1328125  val f1:0.12500  lr: 0.0007900204640553603 batch: 15
epochs: 6 train loss: 0.87109375  train f1: 1.00000  lr: 0.0007900204640553603 batch: 15 
epochs: 6 val loss: 20.5625  val f1:0.00000  lr: 0.0007900204640553603 batch: 15
epochs: 7 train loss: 0.07373046875  train f1: 1.00000  lr: 0.0007900204640553603 batch: 15 
epochs: 7 val loss: 10.53125  val f1:0.16667  lr: 0.0007900204640553603 batch: 15
epochs: 8 train loss: 0.001148223876953125  train f1: 1.00000  lr: 0.0007900204640553603 batch: 15 
epochs: 8 val loss: 10.7421875  val f1:0.16667  lr: 0.0007900204640553603 batch: 15
epochs: 9 train loss: 0.0007877349853515625  train f1: 1.00000  lr: 0.0007900204640553603 batch: 15 
epochs: 9 val loss: 11.6328125  val f1:0.16667  lr: 0.0007900204640553603 batch: 15
epochs: 0 train loss: 4.65625  train f1: 0.00000  lr: 0.0005370784606229013 batch: 15 
epochs: 0 val loss: 4.6796875  val f1:0.00000  lr: 0.0005370784606229013 batch: 15
epochs: 1 train loss: 4.640625  train f1: 0.00000  lr: 0.0005370784606229013 batch: 15 
epochs: 1 val loss: 5.58984375  val f1:0.00000  lr: 0.0005370784606229013 batch: 15
epochs: 0 train loss: 4.70703125  train f1: 0.00000  lr: 0.0002823254404635559 batch: 31 
epochs: 0 val loss: 5.015625  val f1:0.00000  lr: 0.0002823254404635559 batch: 31
epochs: 1 train loss: 4.75  train f1: 0.00000  lr: 0.0002823254404635559 batch: 31 
epochs: 1 val loss: 4.09375  val f1:0.14286  lr: 0.0002823254404635559 batch: 31
epochs: 2 train loss: 0.2105712890625  train f1: 1.00000  lr: 0.0002823254404635559 batch: 31 
epochs: 2 val loss: 4.1875  val f1:0.14286  lr: 0.0002823254404635559 batch: 31
epochs: 3 train loss: 0.0809326171875  train f1: 1.00000  lr: 0.0002823254404635559 batch: 31 
epochs: 3 val loss: 4.46484375  val f1:0.16667  lr: 0.0002823254404635559 batch: 31
epochs: 4 train loss: 0.00140380859375  train f1: 1.00000  lr: 0.0002823254404635559 batch: 31 
epochs: 4 val loss: 4.2890625  val f1:0.16667  lr: 0.0002823254404635559 batch: 31
epochs: 5 train loss: 0.002094268798828125  train f1: 1.00000  lr: 0.0002823254404635559 batch: 31 
epochs: 5 val loss: 4.14453125  val f1:0.16667  lr: 0.0002823254404635559 batch: 31
epochs: 6 train loss: 0.00024008750915527344  train f1: 1.00000  lr: 0.0002823254404635559 batch: 31 
epochs: 6 val loss: 3.98046875  val f1:0.14286  lr: 0.0002823254404635559 batch: 31
epochs: 7 train loss: 0.00023984909057617188  train f1: 1.00000  lr: 0.0002823254404635559 batch: 31 
epochs: 7 val loss: 3.810546875  val f1:0.14286  lr: 0.0002823254404635559 batch: 31
epochs: 0 train loss: 4.84765625  train f1: 0.00000  lr: 0.0005904595053059967 batch: 16 
epochs: 0 val loss: 4.4921875  val f1:0.11111  lr: 0.0005904595053059967 batch: 16
epochs: 1 train loss: 4.8046875  train f1: 0.00000  lr: 0.0005904595053059967 batch: 16 
epochs: 1 val loss: 4.015625  val f1:0.00000  lr: 0.0005904595053059967 batch: 16
epochs: 0 train loss: 3.947265625  train f1: 0.00000  lr: 0.0010200524679367616 batch: 19 
epochs: 0 val loss: 4.625  val f1:0.00000  lr: 0.0010200524679367616 batch: 19
epochs: 1 train loss: 4.1484375  train f1: 0.00000  lr: 0.0010200524679367616 batch: 19 
epochs: 1 val loss: 4.04296875  val f1:0.00000  lr: 0.0010200524679367616 batch: 19
epochs: 0 train loss: 4.99609375  train f1: 0.00000  lr: 0.00033879219159803044 batch: 18 
epochs: 0 val loss: 5.17578125  val f1:0.00000  lr: 0.00033879219159803044 batch: 18
epochs: 1 train loss: 4.82421875  train f1: 0.20000  lr: 0.00033879219159803044 batch: 18 
epochs: 1 val loss: 4.625  val f1:0.12500  lr: 0.00033879219159803044 batch: 18
epochs: 0 train loss: 5.07421875  train f1: 0.00000  lr: 0.0003942631644816004 batch: 17 
epochs: 0 val loss: 4.6171875  val f1:0.00000  lr: 0.0003942631644816004 batch: 17
epochs: 1 train loss: 5.06640625  train f1: 0.00000  lr: 0.0003942631644816004 batch: 17 
epochs: 1 val loss: 3.68359375  val f1:0.11111  lr: 0.0003942631644816004 batch: 17
epochs: 0 train loss: 4.546875  train f1: 0.00000  lr: 0.000625934993854466 batch: 21 
epochs: 0 val loss: 4.359375  val f1:0.00000  lr: 0.000625934993854466 batch: 21
epochs: 1 train loss: 4.3515625  train f1: 0.00000  lr: 0.000625934993854466 batch: 21 
epochs: 1 val loss: 4.44921875  val f1:0.00000  lr: 0.000625934993854466 batch: 21
epochs: 0 train loss: 4.6171875  train f1: 0.00000  lr: 0.0007196328781046893 batch: 20 
epochs: 0 val loss: 5.3125  val f1:0.00000  lr: 0.0007196328781046893 batch: 20
epochs: 1 train loss: 4.66796875  train f1: 0.00000  lr: 0.0007196328781046893 batch: 20 
epochs: 1 val loss: 4.92578125  val f1:0.00000  lr: 0.0007196328781046893 batch: 20
epochs: 0 train loss: 4.3671875  train f1: 0.00000  lr: 0.0012129157466100235 batch: 18 
epochs: 0 val loss: 5.0078125  val f1:0.00000  lr: 0.0012129157466100235 batch: 18
epochs: 1 train loss: 4.40625  train f1: 0.00000  lr: 0.0012129157466100235 batch: 18 
epochs: 1 val loss: 22.171875  val f1:0.00000  lr: 0.0012129157466100235 batch: 18
epochs: 0 train loss: 3.626953125  train f1: 0.11111  lr: 0.0009481182658801255 batch: 17 
epochs: 0 val loss: 4.69921875  val f1:0.00000  lr: 0.0009481182658801255 batch: 17
epochs: 1 train loss: 3.615234375  train f1: 0.11111  lr: 0.0009481182658801255 batch: 17 
epochs: 1 val loss: 4.390625  val f1:0.00000  lr: 0.0009481182658801255 batch: 17
epochs: 0 train loss: 4.7421875  train f1: 0.00000  lr: 0.0005142733564665544 batch: 28 
epochs: 0 val loss: 4.890625  val f1:0.00000  lr: 0.0005142733564665544 batch: 28
epochs: 1 train loss: 4.734375  train f1: 0.00000  lr: 0.0005142733564665544 batch: 28 
epochs: 1 val loss: 3.693359375  val f1:0.11111  lr: 0.0005142733564665544 batch: 28
epochs: 0 train loss: 4.75390625  train f1: 0.00000  lr: 1.0110241791989782e-05 batch: 27 
epochs: 0 val loss: 5.15625  val f1:0.00000  lr: 1.0110241791989782e-05 batch: 27
epochs: 1 train loss: 4.7578125  train f1: 0.00000  lr: 1.0110241791989782e-05 batch: 27 
epochs: 1 val loss: 5.02734375  val f1:0.00000  lr: 1.0110241791989782e-05 batch: 27
epochs: 0 train loss: 4.953125  train f1: 0.00000  lr: 0.0008506551972046538 batch: 25 
epochs: 0 val loss: 5.77734375  val f1:0.00000  lr: 0.0008506551972046538 batch: 25
epochs: 1 train loss: 4.82421875  train f1: 0.00000  lr: 0.0008506551972046538 batch: 25 
epochs: 1 val loss: 5.9296875  val f1:0.07143  lr: 0.0008506551972046538 batch: 25
epochs: 0 train loss: 4.4765625  train f1: 0.00000  lr: 0.0014846883929373782 batch: 17 
epochs: 0 val loss: 5.7734375  val f1:0.00000  lr: 0.0014846883929373782 batch: 17
epochs: 1 train loss: 4.453125  train f1: 0.00000  lr: 0.0014846883929373782 batch: 17 
epochs: 1 val loss: 43.53125  val f1:0.06667  lr: 0.0014846883929373782 batch: 17
epochs: 0 train loss: 4.2890625  train f1: 0.00000  lr: 0.0005025655098419666 batch: 29 
epochs: 0 val loss: 4.234375  val f1:0.00000  lr: 0.0005025655098419666 batch: 29
epochs: 1 train loss: 4.2890625  train f1: 0.00000  lr: 0.0005025655098419666 batch: 29 
epochs: 1 val loss: 3.533203125  val f1:0.12500  lr: 0.0005025655098419666 batch: 29
epochs: 0 train loss: 4.421875  train f1: 0.00000  lr: 0.0006674489867313252 batch: 24 
epochs: 0 val loss: 4.89453125  val f1:0.00000  lr: 0.0006674489867313252 batch: 24
epochs: 1 train loss: 4.45703125  train f1: 0.00000  lr: 0.0006674489867313252 batch: 24 
epochs: 1 val loss: 4.2734375  val f1:0.16667  lr: 0.0006674489867313252 batch: 24
epochs: 2 train loss: 0.0233612060546875  train f1: 1.00000  lr: 0.0006674489867313252 batch: 24 
epochs: 2 val loss: 7.765625  val f1:0.16667  lr: 0.0006674489867313252 batch: 24
epochs: 3 train loss: 0.09600830078125  train f1: 1.00000  lr: 0.0006674489867313252 batch: 24 
epochs: 3 val loss: 4.98828125  val f1:0.14286  lr: 0.0006674489867313252 batch: 24
epochs: 4 train loss: 0.04638671875  train f1: 1.00000  lr: 0.0006674489867313252 batch: 24 
epochs: 4 val loss: 4.53125  val f1:0.16667  lr: 0.0006674489867313252 batch: 24
epochs: 5 train loss: 0.07537841796875  train f1: 1.00000  lr: 0.0006674489867313252 batch: 24 
epochs: 5 val loss: 19.640625  val f1:0.16667  lr: 0.0006674489867313252 batch: 24
epochs: 6 train loss: 4.112720489501953e-06  train f1: 1.00000  lr: 0.0006674489867313252 batch: 24 
epochs: 6 val loss: 13.15625  val f1:0.16667  lr: 0.0006674489867313252 batch: 24
epochs: 0 train loss: 5.1875  train f1: 0.00000  lr: 0.0004141355860843113 batch: 10 
epochs: 0 val loss: 4.80078125  val f1:0.00000  lr: 0.0004141355860843113 batch: 10
epochs: 1 train loss: 5.23046875  train f1: 0.00000  lr: 0.0004141355860843113 batch: 10 
epochs: 1 val loss: 3.779296875  val f1:0.14286  lr: 0.0004141355860843113 batch: 10
epochs: 2 train loss: 0.406494140625  train f1: 1.00000  lr: 0.0004141355860843113 batch: 10 
epochs: 2 val loss: 3.35546875  val f1:0.09524  lr: 0.0004141355860843113 batch: 10
epochs: 3 train loss: 0.8408203125  train f1: 1.00000  lr: 0.0004141355860843113 batch: 10 
epochs: 3 val loss: 5.00390625  val f1:0.14286  lr: 0.0004141355860843113 batch: 10
epochs: 4 train loss: 0.0003981590270996094  train f1: 1.00000  lr: 0.0004141355860843113 batch: 10 
epochs: 4 val loss: 4.5234375  val f1:0.14286  lr: 0.0004141355860843113 batch: 10
epochs: 5 train loss: 0.0004010200500488281  train f1: 1.00000  lr: 0.0004141355860843113 batch: 10 
epochs: 5 val loss: 4.19921875  val f1:0.12500  lr: 0.0004141355860843113 batch: 10
epochs: 6 train loss: 0.0004394054412841797  train f1: 1.00000  lr: 0.0004141355860843113 batch: 10 
epochs: 6 val loss: 3.9609375  val f1:0.12500  lr: 0.0004141355860843113 batch: 10
epochs: 7 train loss: 0.0002498626708984375  train f1: 1.00000  lr: 0.0004141355860843113 batch: 10 
epochs: 7 val loss: 3.798828125  val f1:0.11111  lr: 0.0004141355860843113 batch: 10
epochs: 8 train loss: 0.0002181529998779297  train f1: 1.00000  lr: 0.0004141355860843113 batch: 10 
epochs: 8 val loss: 3.673828125  val f1:0.11111  lr: 0.0004141355860843113 batch: 10
epochs: 9 train loss: 0.00017595291137695312  train f1: 1.00000  lr: 0.0004141355860843113 batch: 10 
epochs: 9 val loss: 3.580078125  val f1:0.12500  lr: 0.0004141355860843113 batch: 10
epochs: 0 train loss: 4.62890625  train f1: 0.00000  lr: 0.03929277507059188 batch: 9 
epochs: 0 val loss: 5.3125  val f1:0.00000  lr: 0.03929277507059188 batch: 9
epochs: 1 train loss: 4.68359375  train f1: 0.00000  lr: 0.03929277507059188 batch: 9 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.03929277507059188 batch: 9
epochs: 0 train loss: 4.828125  train f1: 0.00000  lr: 0.00043394203364850145 batch: 22 
epochs: 0 val loss: 5.04296875  val f1:0.00000  lr: 0.00043394203364850145 batch: 22
epochs: 1 train loss: 4.7578125  train f1: 0.00000  lr: 0.00043394203364850145 batch: 22 
epochs: 1 val loss: 4.03515625  val f1:0.14286  lr: 0.00043394203364850145 batch: 22
epochs: 2 train loss: 0.68310546875  train f1: 1.00000  lr: 0.00043394203364850145 batch: 22 
epochs: 2 val loss: 8.7265625  val f1:0.16667  lr: 0.00043394203364850145 batch: 22
epochs: 3 train loss: 0.39697265625  train f1: 1.00000  lr: 0.00043394203364850145 batch: 22 
epochs: 3 val loss: 4.5078125  val f1:0.14286  lr: 0.00043394203364850145 batch: 22
epochs: 4 train loss: 0.30517578125  train f1: 1.00000  lr: 0.00043394203364850145 batch: 22 
epochs: 4 val loss: 12.71875  val f1:0.16667  lr: 0.00043394203364850145 batch: 22
epochs: 5 train loss: 0.01479339599609375  train f1: 1.00000  lr: 0.00043394203364850145 batch: 22 
epochs: 5 val loss: 11.0234375  val f1:0.16667  lr: 0.00043394203364850145 batch: 22
epochs: 6 train loss: 0.00017309188842773438  train f1: 1.00000  lr: 0.00043394203364850145 batch: 22 
epochs: 6 val loss: 9.515625  val f1:0.16667  lr: 0.00043394203364850145 batch: 22
epochs: 7 train loss: 0.0001323223114013672  train f1: 1.00000  lr: 0.00043394203364850145 batch: 22 
epochs: 7 val loss: 8.25  val f1:0.16667  lr: 0.00043394203364850145 batch: 22
epochs: 8 train loss: 0.0001691579818725586  train f1: 1.00000  lr: 0.00043394203364850145 batch: 22 
epochs: 8 val loss: 7.4921875  val f1:0.16667  lr: 0.00043394203364850145 batch: 22
epochs: 9 train loss: 0.00011199712753295898  train f1: 1.00000  lr: 0.00043394203364850145 batch: 22 
epochs: 9 val loss: 6.78515625  val f1:0.16667  lr: 0.00043394203364850145 batch: 22
epochs: 0 train loss: 5.0390625  train f1: 0.00000  lr: 0.0006238747864093845 batch: 23 
epochs: 0 val loss: 5.5703125  val f1:0.00000  lr: 0.0006238747864093845 batch: 23
epochs: 1 train loss: 5.125  train f1: 0.00000  lr: 0.0006238747864093845 batch: 23 
epochs: 1 val loss: 4.56640625  val f1:0.14286  lr: 0.0006238747864093845 batch: 23
epochs: 2 train loss: 0.359130859375  train f1: 1.00000  lr: 0.0006238747864093845 batch: 23 
epochs: 2 val loss: 9.546875  val f1:0.14286  lr: 0.0006238747864093845 batch: 23
epochs: 3 train loss: 0.378173828125  train f1: 1.00000  lr: 0.0006238747864093845 batch: 23 
epochs: 3 val loss: 24.046875  val f1:0.00000  lr: 0.0006238747864093845 batch: 23
epochs: 4 train loss: 0.08184814453125  train f1: 1.00000  lr: 0.0006238747864093845 batch: 23 
epochs: 4 val loss: 13.9609375  val f1:0.00000  lr: 0.0006238747864093845 batch: 23
epochs: 5 train loss: 0.00010895729064941406  train f1: 1.00000  lr: 0.0006238747864093845 batch: 23 
epochs: 5 val loss: 12.171875  val f1:0.14286  lr: 0.0006238747864093845 batch: 23
epochs: 0 train loss: 4.15625  train f1: 0.00000  lr: 0.0007858661167452685 batch: 13 
epochs: 0 val loss: 4.6328125  val f1:0.00000  lr: 0.0007858661167452685 batch: 13
epochs: 1 train loss: 3.970703125  train f1: 0.00000  lr: 0.0007858661167452685 batch: 13 
epochs: 1 val loss: 4.6328125  val f1:0.00000  lr: 0.0007858661167452685 batch: 13
epochs: 0 train loss: 4.65625  train f1: 0.00000  lr: 0.0009129463330024858 batch: 21 
epochs: 0 val loss: 4.7578125  val f1:0.00000  lr: 0.0009129463330024858 batch: 21
epochs: 1 train loss: 4.671875  train f1: 0.00000  lr: 0.0009129463330024858 batch: 21 
epochs: 1 val loss: 4.7265625  val f1:0.00000  lr: 0.0009129463330024858 batch: 21
epochs: 0 train loss: 4.90234375  train f1: 0.00000  lr: 0.00033921670885734054 batch: 26 
epochs: 0 val loss: 4.609375  val f1:0.00000  lr: 0.00033921670885734054 batch: 26
epochs: 1 train loss: 5.1015625  train f1: 0.00000  lr: 0.00033921670885734054 batch: 26 
epochs: 1 val loss: 3.85546875  val f1:0.11111  lr: 0.00033921670885734054 batch: 26
epochs: 0 train loss: 4.8359375  train f1: 0.00000  lr: 0.00031403869630969354 batch: 26 
epochs: 0 val loss: 5.04296875  val f1:0.00000  lr: 0.00031403869630969354 batch: 26
epochs: 1 train loss: 4.828125  train f1: 0.00000  lr: 0.00031403869630969354 batch: 26 
epochs: 1 val loss: 4.68359375  val f1:0.14286  lr: 0.00031403869630969354 batch: 26
epochs: 2 train loss: 0.410400390625  train f1: 1.00000  lr: 0.00031403869630969354 batch: 26 
epochs: 2 val loss: 4.3671875  val f1:0.14286  lr: 0.00031403869630969354 batch: 26
epochs: 3 train loss: 1.599609375  train f1: 1.00000  lr: 0.00031403869630969354 batch: 26 
epochs: 3 val loss: 5.484375  val f1:0.09524  lr: 0.00031403869630969354 batch: 26
epochs: 4 train loss: 0.0026187896728515625  train f1: 1.00000  lr: 0.00031403869630969354 batch: 26 
epochs: 4 val loss: 4.953125  val f1:0.12500  lr: 0.00031403869630969354 batch: 26
epochs: 5 train loss: 0.0019779205322265625  train f1: 1.00000  lr: 0.00031403869630969354 batch: 26 
epochs: 5 val loss: 4.69140625  val f1:0.12500  lr: 0.00031403869630969354 batch: 26
epochs: 6 train loss: 0.003437042236328125  train f1: 1.00000  lr: 0.00031403869630969354 batch: 26 
epochs: 6 val loss: 4.41015625  val f1:0.12500  lr: 0.00031403869630969354 batch: 26
epochs: 7 train loss: 0.0008692741394042969  train f1: 1.00000  lr: 0.00031403869630969354 batch: 26 
epochs: 7 val loss: 4.25390625  val f1:0.14286  lr: 0.00031403869630969354 batch: 26
epochs: 8 train loss: 0.0005931854248046875  train f1: 1.00000  lr: 0.00031403869630969354 batch: 26 
epochs: 8 val loss: 4.15234375  val f1:0.16667  lr: 0.00031403869630969354 batch: 26
epochs: 9 train loss: 0.0007791519165039062  train f1: 1.00000  lr: 0.00031403869630969354 batch: 26 
epochs: 9 val loss: 4.078125  val f1:0.16667  lr: 0.00031403869630969354 batch: 26
epochs: 10 train loss: 0.0006275177001953125  train f1: 1.00000  lr: 0.00031403869630969354 batch: 26 
epochs: 10 val loss: 4.01953125  val f1:0.16667  lr: 0.00031403869630969354 batch: 26
epochs: 11 train loss: 0.0006918907165527344  train f1: 1.00000  lr: 0.00031403869630969354 batch: 26 
epochs: 11 val loss: 3.966796875  val f1:0.16667  lr: 0.00031403869630969354 batch: 26
epochs: 12 train loss: 0.0005102157592773438  train f1: 1.00000  lr: 0.00031403869630969354 batch: 26 
epochs: 12 val loss: 3.91796875  val f1:0.14286  lr: 0.00031403869630969354 batch: 26
epochs: 13 train loss: 0.000537872314453125  train f1: 1.00000  lr: 0.00031403869630969354 batch: 26 
epochs: 13 val loss: 3.884765625  val f1:0.14286  lr: 0.00031403869630969354 batch: 26
epochs: 14 train loss: 0.000545501708984375  train f1: 1.00000  lr: 0.00031403869630969354 batch: 26 
epochs: 14 val loss: 3.865234375  val f1:0.14286  lr: 0.00031403869630969354 batch: 26
epochs: 0 train loss: 4.83984375  train f1: 0.00000  lr: 0.00024649699950636604 batch: 8 
epochs: 0 val loss: 4.57421875  val f1:0.00000  lr: 0.00024649699950636604 batch: 8
epochs: 1 train loss: 4.9765625  train f1: 0.00000  lr: 0.00024649699950636604 batch: 8 
epochs: 1 val loss: 4.55078125  val f1:0.00000  lr: 0.00024649699950636604 batch: 8
epochs: 0 train loss: 4.77734375  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 0 val loss: 5.0703125  val f1:0.00000  lr: 0.0003890090414239 batch: 26
epochs: 1 train loss: 4.77734375  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 1 val loss: 5.44140625  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 2 train loss: 0.378662109375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 2 val loss: 3.767578125  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 3 train loss: 1.068359375  train f1: 0.50000  lr: 0.0003890090414239 batch: 26 
epochs: 3 val loss: 8.15625  val f1:0.16667  lr: 0.0003890090414239 batch: 26
epochs: 4 train loss: 9.310245513916016e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 4 val loss: 7.0625  val f1:0.16667  lr: 0.0003890090414239 batch: 26
epochs: 5 train loss: 9.655952453613281e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 5 val loss: 6.23828125  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 6 train loss: 4.291534423828125e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 6 val loss: 5.73046875  val f1:0.16667  lr: 0.0003890090414239 batch: 26
epochs: 7 train loss: 5.990266799926758e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 7 val loss: 5.40625  val f1:0.16667  lr: 0.0003890090414239 batch: 26
epochs: 8 train loss: 0.000118255615234375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 8 val loss: 4.953125  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 9 train loss: 8.559226989746094e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 9 val loss: 4.45703125  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 10 train loss: 5.352497100830078e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 10 val loss: 4.08203125  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 11 train loss: 8.559226989746094e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 11 val loss: 3.83203125  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 12 train loss: 5.888938903808594e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 12 val loss: 3.67578125  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 13 train loss: 8.690357208251953e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 13 val loss: 3.70703125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 0 train loss: 5.0859375  train f1: 0.00000  lr: 0.0002945149596040454 batch: 23 
epochs: 0 val loss: 5.0625  val f1:0.00000  lr: 0.0002945149596040454 batch: 23
epochs: 1 train loss: 5.1875  train f1: 0.00000  lr: 0.0002945149596040454 batch: 23 
epochs: 1 val loss: 4.72265625  val f1:0.12500  lr: 0.0002945149596040454 batch: 23
epochs: 0 train loss: 4.6171875  train f1: 0.00000  lr: 0.0014418118416674268 batch: 22 
epochs: 0 val loss: 4.9375  val f1:0.00000  lr: 0.0014418118416674268 batch: 22
epochs: 1 train loss: 4.48828125  train f1: 0.00000  lr: 0.0014418118416674268 batch: 22 
epochs: 1 val loss: 21.9375  val f1:0.06667  lr: 0.0014418118416674268 batch: 22
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.0003890090414239 batch: 26
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 1 val loss: 3.923828125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 2 train loss: 0.109375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 2 val loss: 5.39453125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 3 train loss: 0.022308349609375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 3 val loss: 4.3125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 4 train loss: 0.0006990432739257812  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 4 val loss: 4.26953125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 5 train loss: 0.00016772747039794922  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 5 val loss: 4.2890625  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 6 train loss: 0.0004646778106689453  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 6 val loss: 4.33984375  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 7 train loss: 0.00012069940567016602  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 7 val loss: 4.37109375  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 8 train loss: 0.0002187490463256836  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 8 val loss: 4.35546875  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 9 train loss: 8.237361907958984e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 9 val loss: 4.3359375  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 10 train loss: 0.0001513957977294922  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 10 val loss: 4.2890625  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 11 train loss: 0.00029850006103515625  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 11 val loss: 4.25390625  val f1:0.11111  lr: 0.0003890090414239 batch: 26
epochs: 12 train loss: 7.283687591552734e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 12 val loss: 4.234375  val f1:0.11111  lr: 0.0003890090414239 batch: 26
epochs: 13 train loss: 6.67572021484375e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 13 val loss: 4.22265625  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 0 train loss: 4.734375  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 0 val loss: 4.03125  val f1:0.00000  lr: 0.0003890090414239 batch: 26
epochs: 1 train loss: 4.796875  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 1 val loss: 4.1875  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 2 train loss: 0.277099609375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 2 val loss: 3.8359375  val f1:0.16667  lr: 0.0003890090414239 batch: 26
epochs: 3 train loss: 0.90771484375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 3 val loss: 6.30859375  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 4 train loss: 0.0002052783966064453  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 4 val loss: 5.4296875  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 5 train loss: 0.00017893314361572266  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 5 val loss: 4.8671875  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 6 train loss: 0.00020170211791992188  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 6 val loss: 4.3203125  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 7 train loss: 0.0001881122589111328  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 7 val loss: 3.947265625  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 8 train loss: 0.00014710426330566406  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 8 val loss: 3.669921875  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.0003890090414239 batch: 26
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 1 val loss: 3.923828125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 2 train loss: 0.109375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 2 val loss: 5.39453125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 3 train loss: 0.022308349609375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 3 val loss: 4.3125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 4 train loss: 0.0006990432739257812  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 4 val loss: 4.26953125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 5 train loss: 0.00016772747039794922  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 5 val loss: 4.2890625  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 6 train loss: 0.0004646778106689453  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 6 val loss: 4.33984375  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 7 train loss: 0.00012069940567016602  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 7 val loss: 4.37109375  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 8 train loss: 0.0002187490463256836  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 8 val loss: 4.35546875  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 9 train loss: 8.237361907958984e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 9 val loss: 4.3359375  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 10 train loss: 0.0001513957977294922  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 10 val loss: 4.2890625  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 11 train loss: 0.00029850006103515625  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 11 val loss: 4.25390625  val f1:0.11111  lr: 0.0003890090414239 batch: 26
epochs: 12 train loss: 7.283687591552734e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 12 val loss: 4.234375  val f1:0.11111  lr: 0.0003890090414239 batch: 26
epochs: 13 train loss: 6.67572021484375e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 13 val loss: 4.22265625  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 0 train loss: 4.734375  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 0 val loss: 4.03125  val f1:0.00000  lr: 0.0003890090414239 batch: 26
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.0003890090414239 batch: 26
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 1 val loss: 3.923828125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 2 train loss: 0.109375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 2 val loss: 5.39453125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 3 train loss: 0.022308349609375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 3 val loss: 4.3125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 4 train loss: 0.0006990432739257812  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 4 val loss: 4.26953125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 5 train loss: 0.00016772747039794922  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 5 val loss: 4.2890625  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 6 train loss: 0.0004646778106689453  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 6 val loss: 4.33984375  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 7 train loss: 0.00012069940567016602  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 7 val loss: 4.37109375  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 8 train loss: 0.0002187490463256836  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 8 val loss: 4.35546875  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 9 train loss: 8.237361907958984e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 9 val loss: 4.3359375  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 10 train loss: 0.0001513957977294922  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 10 val loss: 4.2890625  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 11 train loss: 0.00029850006103515625  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 11 val loss: 4.25390625  val f1:0.11111  lr: 0.0003890090414239 batch: 26
epochs: 12 train loss: 7.283687591552734e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 12 val loss: 4.234375  val f1:0.11111  lr: 0.0003890090414239 batch: 26
epochs: 13 train loss: 6.67572021484375e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 13 val loss: 4.22265625  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 0 train loss: 4.734375  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 0 val loss: 4.03125  val f1:0.00000  lr: 0.0003890090414239 batch: 26
epochs: 1 train loss: 4.796875  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 1 val loss: 4.1875  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 2 train loss: 0.277099609375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 2 val loss: 3.8359375  val f1:0.16667  lr: 0.0003890090414239 batch: 26
epochs: 3 train loss: 0.90771484375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 3 val loss: 6.30859375  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 4 train loss: 0.0002052783966064453  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 4 val loss: 5.4296875  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 5 train loss: 0.00017893314361572266  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 5 val loss: 4.8671875  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 6 train loss: 0.00020170211791992188  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 6 val loss: 4.3203125  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 7 train loss: 0.0001881122589111328  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 7 val loss: 3.947265625  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 8 train loss: 0.00014710426330566406  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 8 val loss: 3.669921875  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 9 train loss: 0.00014698505401611328  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 9 val loss: 3.552734375  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 10 train loss: 0.0001964569091796875  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 10 val loss: 3.501953125  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 11 train loss: 0.00015556812286376953  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 11 val loss: 3.484375  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 12 train loss: 0.00014781951904296875  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 12 val loss: 3.474609375  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 13 train loss: 0.00016391277313232422  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 13 val loss: 3.46875  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 0 train loss: 4.53515625  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 0 val loss: 4.57421875  val f1:0.00000  lr: 0.0003890090414239 batch: 26
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.0003890090414239 batch: 26
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 1 val loss: 3.923828125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 2 train loss: 0.109375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 2 val loss: 5.39453125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 3 train loss: 0.022308349609375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 3 val loss: 4.3125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 4 train loss: 0.0006990432739257812  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 4 val loss: 4.26953125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 5 train loss: 0.00016772747039794922  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 5 val loss: 4.2890625  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 6 train loss: 0.0004646778106689453  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 6 val loss: 4.33984375  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 7 train loss: 0.00012069940567016602  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 7 val loss: 4.37109375  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 8 train loss: 0.0002187490463256836  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 8 val loss: 4.35546875  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 9 train loss: 8.237361907958984e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 9 val loss: 4.3359375  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 10 train loss: 0.0001513957977294922  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 10 val loss: 4.2890625  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 11 train loss: 0.00029850006103515625  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 11 val loss: 4.25390625  val f1:0.11111  lr: 0.0003890090414239 batch: 26
epochs: 12 train loss: 7.283687591552734e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 12 val loss: 4.234375  val f1:0.11111  lr: 0.0003890090414239 batch: 26
epochs: 13 train loss: 6.67572021484375e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 13 val loss: 4.22265625  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 0 train loss: 4.734375  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 0 val loss: 4.03125  val f1:0.00000  lr: 0.0003890090414239 batch: 26
epochs: 1 train loss: 4.796875  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 1 val loss: 4.1875  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 2 train loss: 0.277099609375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 2 val loss: 3.8359375  val f1:0.16667  lr: 0.0003890090414239 batch: 26
epochs: 3 train loss: 0.90771484375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 3 val loss: 6.30859375  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 4 train loss: 0.0002052783966064453  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 4 val loss: 5.4296875  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 5 train loss: 0.00017893314361572266  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 5 val loss: 4.8671875  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 6 train loss: 0.00020170211791992188  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 6 val loss: 4.3203125  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 7 train loss: 0.0001881122589111328  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 7 val loss: 3.947265625  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 8 train loss: 0.00014710426330566406  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 8 val loss: 3.669921875  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 9 train loss: 0.00014698505401611328  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 9 val loss: 3.552734375  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 10 train loss: 0.0001964569091796875  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 10 val loss: 3.501953125  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 11 train loss: 0.00015556812286376953  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 11 val loss: 3.484375  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 12 train loss: 0.00014781951904296875  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 12 val loss: 3.474609375  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 13 train loss: 0.00016391277313232422  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 13 val loss: 3.46875  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 0 train loss: 4.53515625  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 0 val loss: 4.57421875  val f1:0.00000  lr: 0.0003890090414239 batch: 26
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.0003890090414239 batch: 26
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 1 val loss: 3.923828125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 2 train loss: 0.109375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 2 val loss: 5.39453125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 3 train loss: 0.022308349609375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 3 val loss: 4.3125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 4 train loss: 0.0006990432739257812  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 4 val loss: 4.26953125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 5 train loss: 0.00016772747039794922  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 5 val loss: 4.2890625  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 6 train loss: 0.0004646778106689453  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 6 val loss: 4.33984375  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 7 train loss: 0.00012069940567016602  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 7 val loss: 4.37109375  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 8 train loss: 0.0002187490463256836  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 8 val loss: 4.35546875  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 9 train loss: 8.237361907958984e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 9 val loss: 4.3359375  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 10 train loss: 0.0001513957977294922  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 10 val loss: 4.2890625  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 11 train loss: 0.00029850006103515625  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 11 val loss: 4.25390625  val f1:0.11111  lr: 0.0003890090414239 batch: 26
epochs: 12 train loss: 7.283687591552734e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 12 val loss: 4.234375  val f1:0.11111  lr: 0.0003890090414239 batch: 26
epochs: 13 train loss: 6.67572021484375e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 13 val loss: 4.22265625  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.0003890090414239 batch: 26
epochs: 1 train loss: 4.296875  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 1 val loss: 3.923828125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 2 train loss: 0.109375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 2 val loss: 5.39453125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 3 train loss: 0.022308349609375  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 3 val loss: 4.3125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 4 train loss: 0.0006990432739257812  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 4 val loss: 4.26953125  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 5 train loss: 0.00016772747039794922  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 5 val loss: 4.2890625  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 6 train loss: 0.0004646778106689453  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 6 val loss: 4.33984375  val f1:0.14286  lr: 0.0003890090414239 batch: 26
epochs: 7 train loss: 0.00012069940567016602  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 7 val loss: 4.37109375  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 8 train loss: 0.0002187490463256836  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 8 val loss: 4.35546875  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 9 train loss: 8.237361907958984e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 9 val loss: 4.3359375  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 10 train loss: 0.0001513957977294922  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 10 val loss: 4.2890625  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 11 train loss: 0.00029850006103515625  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 11 val loss: 4.25390625  val f1:0.11111  lr: 0.0003890090414239 batch: 26
epochs: 12 train loss: 7.283687591552734e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 12 val loss: 4.234375  val f1:0.11111  lr: 0.0003890090414239 batch: 26
epochs: 13 train loss: 6.67572021484375e-05  train f1: 1.00000  lr: 0.0003890090414239 batch: 26 
epochs: 13 val loss: 4.22265625  val f1:0.12500  lr: 0.0003890090414239 batch: 26
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.0003890090414239 batch: 26 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 0.0003890090414239 batch: 26
epochs: 0 train loss: 4.8671875  train f1: 0.00000  lr: 4.7129443448028984e-05 batch: 14 
epochs: 0 val loss: 5.2109375  val f1:0.00000  lr: 4.7129443448028984e-05 batch: 14
epochs: 1 train loss: 4.9609375  train f1: 0.00000  lr: 4.7129443448028984e-05 batch: 14 
epochs: 1 val loss: 4.95703125  val f1:0.00000  lr: 4.7129443448028984e-05 batch: 14
epochs: 2 train loss: 2.263671875  train f1: 1.00000  lr: 4.7129443448028984e-05 batch: 14 
epochs: 2 val loss: 4.76171875  val f1:0.00000  lr: 4.7129443448028984e-05 batch: 14
epochs: 3 train loss: 0.78369140625  train f1: 1.00000  lr: 4.7129443448028984e-05 batch: 14 
epochs: 3 val loss: 4.5234375  val f1:0.00000  lr: 4.7129443448028984e-05 batch: 14
epochs: 4 train loss: 0.288330078125  train f1: 1.00000  lr: 4.7129443448028984e-05 batch: 14 
epochs: 4 val loss: 4.390625  val f1:0.14286  lr: 4.7129443448028984e-05 batch: 14
epochs: 5 train loss: 0.09906005859375  train f1: 1.00000  lr: 4.7129443448028984e-05 batch: 14 
epochs: 5 val loss: 4.2421875  val f1:0.14286  lr: 4.7129443448028984e-05 batch: 14
epochs: 6 train loss: 0.1337890625  train f1: 1.00000  lr: 4.7129443448028984e-05 batch: 14 
epochs: 6 val loss: 4.109375  val f1:0.14286  lr: 4.7129443448028984e-05 batch: 14
epochs: 7 train loss: 0.12646484375  train f1: 1.00000  lr: 4.7129443448028984e-05 batch: 14 
epochs: 7 val loss: 3.9921875  val f1:0.11111  lr: 4.7129443448028984e-05 batch: 14
epochs: 8 train loss: 0.061553955078125  train f1: 1.00000  lr: 4.7129443448028984e-05 batch: 14 
epochs: 8 val loss: 3.900390625  val f1:0.12500  lr: 4.7129443448028984e-05 batch: 14
epochs: 9 train loss: 0.05328369140625  train f1: 1.00000  lr: 4.7129443448028984e-05 batch: 14 
epochs: 9 val loss: 3.822265625  val f1:0.12500  lr: 4.7129443448028984e-05 batch: 14
epochs: 10 train loss: 0.06219482421875  train f1: 1.00000  lr: 4.7129443448028984e-05 batch: 14 
epochs: 10 val loss: 3.72265625  val f1:0.12500  lr: 4.7129443448028984e-05 batch: 14
epochs: 11 train loss: 0.04327392578125  train f1: 1.00000  lr: 4.7129443448028984e-05 batch: 14 
epochs: 11 val loss: 3.66796875  val f1:0.11111  lr: 4.7129443448028984e-05 batch: 14
epochs: 12 train loss: 0.036346435546875  train f1: 1.00000  lr: 4.7129443448028984e-05 batch: 14 
epochs: 12 val loss: 3.6328125  val f1:0.12500  lr: 4.7129443448028984e-05 batch: 14
epochs: 13 train loss: 0.028289794921875  train f1: 1.00000  lr: 4.7129443448028984e-05 batch: 14 
epochs: 13 val loss: 3.6328125  val f1:0.12500  lr: 4.7129443448028984e-05 batch: 14
epochs: 14 train loss: 0.035400390625  train f1: 1.00000  lr: 4.7129443448028984e-05 batch: 14 
epochs: 14 val loss: 3.638671875  val f1:0.12500  lr: 4.7129443448028984e-05 batch: 14
epochs: 15 train loss: 0.0175018310546875  train f1: 1.00000  lr: 4.7129443448028984e-05 batch: 14 
epochs: 15 val loss: 3.693359375  val f1:0.12500  lr: 4.7129443448028984e-05 batch: 14
epochs: 16 train loss: 0.0269012451171875  train f1: 1.00000  lr: 4.7129443448028984e-05 batch: 14 
epochs: 16 val loss: 3.740234375  val f1:0.12500  lr: 4.7129443448028984e-05 batch: 14
epochs: 17 train loss: 0.033843994140625  train f1: 1.00000  lr: 4.7129443448028984e-05 batch: 14 
epochs: 17 val loss: 3.7890625  val f1:0.11111  lr: 4.7129443448028984e-05 batch: 14
epochs: 0 train loss: 3.7578125  train f1: 0.00000  lr: 0.0125332159808465 batch: 17 
epochs: 0 val loss: 5.515625  val f1:0.00000  lr: 0.0125332159808465 batch: 17
epochs: 1 train loss: 3.83984375  train f1: 0.00000  lr: 0.0125332159808465 batch: 17 
epochs: 1 val loss: 5.26953125  val f1:0.00000  lr: 0.0125332159808465 batch: 17
epochs: 2 train loss: 3.0078125  train f1: 1.00000  lr: 0.0125332159808465 batch: 17 
epochs: 2 val loss: 5.046875  val f1:0.11111  lr: 0.0125332159808465 batch: 17
epochs: 3 train loss: 2.41015625  train f1: 1.00000  lr: 0.0125332159808465 batch: 17 
epochs: 3 val loss: 4.8671875  val f1:0.12500  lr: 0.0125332159808465 batch: 17
epochs: 4 train loss: 1.5947265625  train f1: 1.00000  lr: 0.0125332159808465 batch: 17 
epochs: 4 val loss: 4.6640625  val f1:0.12500  lr: 0.0125332159808465 batch: 17
epochs: 5 train loss: 1.2236328125  train f1: 1.00000  lr: 0.0125332159808465 batch: 17 
epochs: 5 val loss: 4.60546875  val f1:0.12500  lr: 0.0125332159808465 batch: 17
epochs: 6 train loss: 1.0439453125  train f1: 1.00000  lr: 0.0125332159808465 batch: 17 
epochs: 6 val loss: 4.45703125  val f1:0.12500  lr: 0.0125332159808465 batch: 17
epochs: 7 train loss: 0.65576171875  train f1: 1.00000  lr: 0.0125332159808465 batch: 17 
epochs: 7 val loss: 4.40234375  val f1:0.12500  lr: 0.0125332159808465 batch: 17
epochs: 8 train loss: 0.5107421875  train f1: 1.00000  lr: 0.0125332159808465 batch: 17 
epochs: 8 val loss: 4.30859375  val f1:0.12500  lr: 0.0125332159808465 batch: 17
epochs: 9 train loss: 0.338623046875  train f1: 1.00000  lr: 0.0125332159808465 batch: 17 
epochs: 9 val loss: 4.25  val f1:0.14286  lr: 0.0125332159808465 batch: 17
epochs: 10 train loss: 0.24658203125  train f1: 1.00000  lr: 0.0125332159808465 batch: 17 
epochs: 10 val loss: 4.17578125  val f1:0.12500  lr: 0.0125332159808465 batch: 17
epochs: 11 train loss: 0.294677734375  train f1: 1.00000  lr: 0.0125332159808465 batch: 17 
epochs: 11 val loss: 4.14453125  val f1:0.11111  lr: 0.0125332159808465 batch: 17
epochs: 12 train loss: 0.1517333984375  train f1: 1.00000  lr: 0.0125332159808465 batch: 17 
epochs: 12 val loss: 4.12109375  val f1:0.11111  lr: 0.0125332159808465 batch: 17
epochs: 0 train loss: 4.44140625  train f1: 0.00000  lr: 0.001189387434477791 batch: 15 
epochs: 0 val loss: 4.65625  val f1:0.00000  lr: 0.001189387434477791 batch: 15
epochs: 1 train loss: 4.3984375  train f1: 0.16667  lr: 0.001189387434477791 batch: 15 
epochs: 1 val loss: 4.640625  val f1:0.00000  lr: 0.001189387434477791 batch: 15
epochs: 2 train loss: 4.36328125  train f1: 0.00000  lr: 0.001189387434477791 batch: 15 
epochs: 2 val loss: 4.625  val f1:0.00000  lr: 0.001189387434477791 batch: 15
epochs: 3 train loss: 4.14453125  train f1: 0.00000  lr: 0.001189387434477791 batch: 15 
epochs: 3 val loss: 4.60546875  val f1:0.00000  lr: 0.001189387434477791 batch: 15
epochs: 4 train loss: 3.982421875  train f1: 0.00000  lr: 0.001189387434477791 batch: 15 
epochs: 4 val loss: 4.58984375  val f1:0.00000  lr: 0.001189387434477791 batch: 15
epochs: 5 train loss: 3.9765625  train f1: 0.00000  lr: 0.001189387434477791 batch: 15 
epochs: 5 val loss: 4.60546875  val f1:0.00000  lr: 0.001189387434477791 batch: 15
epochs: 0 train loss: 4.625  train f1: 0.00000  lr: 8.092892310095835e-05 batch: 25 
epochs: 0 val loss: 4.8828125  val f1:0.00000  lr: 8.092892310095835e-05 batch: 25
epochs: 1 train loss: 4.52734375  train f1: 0.00000  lr: 8.092892310095835e-05 batch: 25 
epochs: 1 val loss: 4.43359375  val f1:0.11111  lr: 8.092892310095835e-05 batch: 25
epochs: 2 train loss: 1.51953125  train f1: 1.00000  lr: 8.092892310095835e-05 batch: 25 
epochs: 2 val loss: 4.16796875  val f1:0.12500  lr: 8.092892310095835e-05 batch: 25
epochs: 3 train loss: 0.397705078125  train f1: 1.00000  lr: 8.092892310095835e-05 batch: 25 
epochs: 3 val loss: 3.9921875  val f1:0.11111  lr: 8.092892310095835e-05 batch: 25
epochs: 4 train loss: 0.30517578125  train f1: 1.00000  lr: 8.092892310095835e-05 batch: 25 
epochs: 4 val loss: 3.94140625  val f1:0.11111  lr: 8.092892310095835e-05 batch: 25
epochs: 5 train loss: 0.03076171875  train f1: 1.00000  lr: 8.092892310095835e-05 batch: 25 
epochs: 5 val loss: 3.927734375  val f1:0.11111  lr: 8.092892310095835e-05 batch: 25
epochs: 6 train loss: 0.0274200439453125  train f1: 1.00000  lr: 8.092892310095835e-05 batch: 25 
epochs: 6 val loss: 3.951171875  val f1:0.12500  lr: 8.092892310095835e-05 batch: 25
epochs: 7 train loss: 0.0209503173828125  train f1: 1.00000  lr: 8.092892310095835e-05 batch: 25 
epochs: 7 val loss: 3.962890625  val f1:0.12500  lr: 8.092892310095835e-05 batch: 25
epochs: 8 train loss: 0.01312255859375  train f1: 1.00000  lr: 8.092892310095835e-05 batch: 25 
epochs: 8 val loss: 4.0078125  val f1:0.12500  lr: 8.092892310095835e-05 batch: 25
epochs: 9 train loss: 0.01064300537109375  train f1: 1.00000  lr: 8.092892310095835e-05 batch: 25 
epochs: 9 val loss: 4.046875  val f1:0.12500  lr: 8.092892310095835e-05 batch: 25
epochs: 10 train loss: 0.0108184814453125  train f1: 1.00000  lr: 8.092892310095835e-05 batch: 25 
epochs: 10 val loss: 4.06640625  val f1:0.11111  lr: 8.092892310095835e-05 batch: 25
epochs: 11 train loss: 0.009429931640625  train f1: 1.00000  lr: 8.092892310095835e-05 batch: 25 
epochs: 11 val loss: 4.08203125  val f1:0.11111  lr: 8.092892310095835e-05 batch: 25
epochs: 12 train loss: 0.00978851318359375  train f1: 1.00000  lr: 8.092892310095835e-05 batch: 25 
epochs: 12 val loss: 4.11328125  val f1:0.11111  lr: 8.092892310095835e-05 batch: 25
epochs: 13 train loss: 0.006561279296875  train f1: 1.00000  lr: 8.092892310095835e-05 batch: 25 
epochs: 13 val loss: 4.16015625  val f1:0.11111  lr: 8.092892310095835e-05 batch: 25
epochs: 14 train loss: 0.0092010498046875  train f1: 1.00000  lr: 8.092892310095835e-05 batch: 25 
epochs: 14 val loss: 4.203125  val f1:0.11111  lr: 8.092892310095835e-05 batch: 25
epochs: 15 train loss: 0.0038738250732421875  train f1: 1.00000  lr: 8.092892310095835e-05 batch: 25 
epochs: 15 val loss: 4.375  val f1:0.11111  lr: 8.092892310095835e-05 batch: 25
epochs: 16 train loss: 0.006931304931640625  train f1: 1.00000  lr: 8.092892310095835e-05 batch: 25 
epochs: 16 val loss: 4.47265625  val f1:0.11111  lr: 8.092892310095835e-05 batch: 25
epochs: 17 train loss: 0.007785797119140625  train f1: 1.00000  lr: 8.092892310095835e-05 batch: 25 
epochs: 17 val loss: 4.4765625  val f1:0.11111  lr: 8.092892310095835e-05 batch: 25
epochs: 0 train loss: 3.81640625  train f1: 0.00000  lr: 0.00033636474570774633 batch: 21 
epochs: 0 val loss: 5.515625  val f1:0.00000  lr: 0.00033636474570774633 batch: 21
epochs: 1 train loss: 3.91796875  train f1: 0.00000  lr: 0.00033636474570774633 batch: 21 
epochs: 1 val loss: 5.25390625  val f1:0.00000  lr: 0.00033636474570774633 batch: 21
epochs: 2 train loss: 1.9453125  train f1: 1.00000  lr: 0.00033636474570774633 batch: 21 
epochs: 2 val loss: 5.015625  val f1:0.12500  lr: 0.00033636474570774633 batch: 21
epochs: 3 train loss: 0.80615234375  train f1: 1.00000  lr: 0.00033636474570774633 batch: 21 
epochs: 3 val loss: 4.80859375  val f1:0.12500  lr: 0.00033636474570774633 batch: 21
epochs: 4 train loss: 0.1717529296875  train f1: 1.00000  lr: 0.00033636474570774633 batch: 21 
epochs: 4 val loss: 4.61328125  val f1:0.12500  lr: 0.00033636474570774633 batch: 21
epochs: 5 train loss: 0.046875  train f1: 1.00000  lr: 0.00033636474570774633 batch: 21 
epochs: 5 val loss: 4.4609375  val f1:0.12500  lr: 0.00033636474570774633 batch: 21
epochs: 6 train loss: 0.0310211181640625  train f1: 1.00000  lr: 0.00033636474570774633 batch: 21 
epochs: 6 val loss: 4.359375  val f1:0.12500  lr: 0.00033636474570774633 batch: 21
epochs: 0 train loss: 4.96875  train f1: 0.00000  lr: 0.000161805568651153 batch: 22 
epochs: 0 val loss: 4.58203125  val f1:0.00000  lr: 0.000161805568651153 batch: 22
epochs: 1 train loss: 5.109375  train f1: 0.00000  lr: 0.000161805568651153 batch: 22 
epochs: 1 val loss: 4.55078125  val f1:0.00000  lr: 0.000161805568651153 batch: 22
epochs: 2 train loss: 4.01953125  train f1: 0.00000  lr: 0.000161805568651153 batch: 22 
epochs: 2 val loss: 4.47265625  val f1:0.00000  lr: 0.000161805568651153 batch: 22
epochs: 3 train loss: 3.111328125  train f1: 1.00000  lr: 0.000161805568651153 batch: 22 
epochs: 3 val loss: 4.390625  val f1:0.00000  lr: 0.000161805568651153 batch: 22
epochs: 4 train loss: 2.2578125  train f1: 1.00000  lr: 0.000161805568651153 batch: 22 
epochs: 4 val loss: 4.296875  val f1:0.12500  lr: 0.000161805568651153 batch: 22
epochs: 5 train loss: 1.33203125  train f1: 1.00000  lr: 0.000161805568651153 batch: 22 
epochs: 5 val loss: 4.21484375  val f1:0.12500  lr: 0.000161805568651153 batch: 22
epochs: 6 train loss: 0.89208984375  train f1: 1.00000  lr: 0.000161805568651153 batch: 22 
epochs: 6 val loss: 4.140625  val f1:0.12500  lr: 0.000161805568651153 batch: 22
epochs: 7 train loss: 0.595703125  train f1: 1.00000  lr: 0.000161805568651153 batch: 22 
epochs: 7 val loss: 4.0859375  val f1:0.12500  lr: 0.000161805568651153 batch: 22
epochs: 8 train loss: 0.254150390625  train f1: 1.00000  lr: 0.000161805568651153 batch: 22 
epochs: 8 val loss: 4.046875  val f1:0.14286  lr: 0.000161805568651153 batch: 22
epochs: 9 train loss: 0.1319580078125  train f1: 1.00000  lr: 0.000161805568651153 batch: 22 
epochs: 9 val loss: 4.0234375  val f1:0.12500  lr: 0.000161805568651153 batch: 22
epochs: 10 train loss: 0.0927734375  train f1: 1.00000  lr: 0.000161805568651153 batch: 22 
epochs: 10 val loss: 4.0078125  val f1:0.12500  lr: 0.000161805568651153 batch: 22
epochs: 11 train loss: 0.08245849609375  train f1: 1.00000  lr: 0.000161805568651153 batch: 22 
epochs: 11 val loss: 4.015625  val f1:0.12500  lr: 0.000161805568651153 batch: 22
epochs: 12 train loss: 0.04339599609375  train f1: 1.00000  lr: 0.000161805568651153 batch: 22 
epochs: 12 val loss: 4.0234375  val f1:0.12500  lr: 0.000161805568651153 batch: 22
epochs: 13 train loss: 0.0305328369140625  train f1: 1.00000  lr: 0.000161805568651153 batch: 22 
epochs: 13 val loss: 4.03515625  val f1:0.12500  lr: 0.000161805568651153 batch: 22
epochs: 14 train loss: 0.020477294921875  train f1: 1.00000  lr: 0.000161805568651153 batch: 22 
epochs: 14 val loss: 4.04296875  val f1:0.12500  lr: 0.000161805568651153 batch: 22
epochs: 15 train loss: 0.01171875  train f1: 1.00000  lr: 0.000161805568651153 batch: 22 
epochs: 15 val loss: 4.0546875  val f1:0.12500  lr: 0.000161805568651153 batch: 22
epochs: 16 train loss: 0.01036834716796875  train f1: 1.00000  lr: 0.000161805568651153 batch: 22 
epochs: 16 val loss: 4.0625  val f1:0.11111  lr: 0.000161805568651153 batch: 22
epochs: 17 train loss: 0.01006317138671875  train f1: 1.00000  lr: 0.000161805568651153 batch: 22 
epochs: 17 val loss: 4.078125  val f1:0.11111  lr: 0.000161805568651153 batch: 22
epochs: 0 train loss: 3.89453125  train f1: 0.00000  lr: 0.0004869467066860754 batch: 25 
epochs: 0 val loss: 5.5  val f1:0.00000  lr: 0.0004869467066860754 batch: 25
epochs: 1 train loss: 3.86328125  train f1: 0.11111  lr: 0.0004869467066860754 batch: 25 
epochs: 1 val loss: 5.390625  val f1:0.00000  lr: 0.0004869467066860754 batch: 25
epochs: 2 train loss: 3.919921875  train f1: 0.00000  lr: 0.0004869467066860754 batch: 25 
epochs: 2 val loss: 5.29296875  val f1:0.00000  lr: 0.0004869467066860754 batch: 25
epochs: 3 train loss: 3.763671875  train f1: 0.00000  lr: 0.0004869467066860754 batch: 25 
epochs: 3 val loss: 5.1875  val f1:0.00000  lr: 0.0004869467066860754 batch: 25
epochs: 4 train loss: 3.798828125  train f1: 0.00000  lr: 0.0004869467066860754 batch: 25 
epochs: 4 val loss: 5.109375  val f1:0.00000  lr: 0.0004869467066860754 batch: 25
epochs: 5 train loss: 3.7421875  train f1: 0.00000  lr: 0.0004869467066860754 batch: 25 
epochs: 5 val loss: 5.0546875  val f1:0.00000  lr: 0.0004869467066860754 batch: 25
epochs: 6 train loss: 3.666015625  train f1: 0.11111  lr: 0.0004869467066860754 batch: 25 
epochs: 6 val loss: 5.0  val f1:0.00000  lr: 0.0004869467066860754 batch: 25
epochs: 7 train loss: 3.78125  train f1: 0.11111  lr: 0.0004869467066860754 batch: 25 
epochs: 7 val loss: 4.94140625  val f1:0.00000  lr: 0.0004869467066860754 batch: 25
epochs: 8 train loss: 3.662109375  train f1: 0.16667  lr: 0.0004869467066860754 batch: 25 
epochs: 8 val loss: 4.87109375  val f1:0.00000  lr: 0.0004869467066860754 batch: 25
epochs: 9 train loss: 3.55078125  train f1: 0.00000  lr: 0.0004869467066860754 batch: 25 
epochs: 9 val loss: 4.77734375  val f1:0.00000  lr: 0.0004869467066860754 batch: 25
epochs: 10 train loss: 3.45703125  train f1: 0.33333  lr: 0.0004869467066860754 batch: 25 
epochs: 10 val loss: 4.69140625  val f1:0.00000  lr: 0.0004869467066860754 batch: 25
epochs: 11 train loss: 3.5078125  train f1: 0.11111  lr: 0.0004869467066860754 batch: 25 
epochs: 11 val loss: 4.609375  val f1:0.00000  lr: 0.0004869467066860754 batch: 25
epochs: 12 train loss: 3.4453125  train f1: 0.20000  lr: 0.0004869467066860754 batch: 25 
epochs: 12 val loss: 4.56640625  val f1:0.00000  lr: 0.0004869467066860754 batch: 25
epochs: 13 train loss: 3.56640625  train f1: 0.11111  lr: 0.0004869467066860754 batch: 25 
epochs: 13 val loss: 4.546875  val f1:0.00000  lr: 0.0004869467066860754 batch: 25
epochs: 0 train loss: 4.921875  train f1: 0.00000  lr: 0.0006786951937186831 batch: 27 
epochs: 0 val loss: 4.59375  val f1:0.00000  lr: 0.0006786951937186831 batch: 27
epochs: 1 train loss: 4.96875  train f1: 0.00000  lr: 0.0006786951937186831 batch: 27 
epochs: 1 val loss: 4.56640625  val f1:0.00000  lr: 0.0006786951937186831 batch: 27
epochs: 2 train loss: 4.9453125  train f1: 0.00000  lr: 0.0006786951937186831 batch: 27 
epochs: 2 val loss: 4.546875  val f1:0.00000  lr: 0.0006786951937186831 batch: 27
epochs: 3 train loss: 4.9140625  train f1: 0.00000  lr: 0.0006786951937186831 batch: 27 
epochs: 3 val loss: 4.57421875  val f1:0.00000  lr: 0.0006786951937186831 batch: 27
epochs: 4 train loss: 4.79296875  train f1: 0.00000  lr: 0.0006786951937186831 batch: 27 
epochs: 4 val loss: 4.57421875  val f1:0.00000  lr: 0.0006786951937186831 batch: 27
epochs: 5 train loss: 4.8125  train f1: 0.00000  lr: 0.0006786951937186831 batch: 27 
epochs: 5 val loss: 4.5625  val f1:0.00000  lr: 0.0006786951937186831 batch: 27
epochs: 6 train loss: 4.71875  train f1: 0.00000  lr: 0.0006786951937186831 batch: 27 
epochs: 6 val loss: 4.52734375  val f1:0.00000  lr: 0.0006786951937186831 batch: 27
epochs: 0 train loss: 5.3984375  train f1: 0.00000  lr: 4.665422763084028e-05 batch: 23 
epochs: 0 val loss: 4.796875  val f1:0.00000  lr: 4.665422763084028e-05 batch: 23
epochs: 1 train loss: 5.46484375  train f1: 0.00000  lr: 4.665422763084028e-05 batch: 23 
epochs: 1 val loss: 4.75  val f1:0.00000  lr: 4.665422763084028e-05 batch: 23
epochs: 2 train loss: 5.25390625  train f1: 0.00000  lr: 4.665422763084028e-05 batch: 23 
epochs: 2 val loss: 4.734375  val f1:0.00000  lr: 4.665422763084028e-05 batch: 23
epochs: 3 train loss: 4.7734375  train f1: 0.00000  lr: 4.665422763084028e-05 batch: 23 
epochs: 3 val loss: 4.68359375  val f1:0.00000  lr: 4.665422763084028e-05 batch: 23
epochs: 4 train loss: 4.53125  train f1: 0.00000  lr: 4.665422763084028e-05 batch: 23 
epochs: 4 val loss: 4.63671875  val f1:0.00000  lr: 4.665422763084028e-05 batch: 23
epochs: 5 train loss: 4.328125  train f1: 0.00000  lr: 4.665422763084028e-05 batch: 23 
epochs: 5 val loss: 4.5546875  val f1:0.00000  lr: 4.665422763084028e-05 batch: 23
epochs: 6 train loss: 4.109375  train f1: 0.00000  lr: 4.665422763084028e-05 batch: 23 
epochs: 6 val loss: 4.52734375  val f1:0.08333  lr: 4.665422763084028e-05 batch: 23
epochs: 7 train loss: 3.513671875  train f1: 0.40000  lr: 4.665422763084028e-05 batch: 23 
epochs: 7 val loss: 4.4921875  val f1:0.07143  lr: 4.665422763084028e-05 batch: 23
epochs: 8 train loss: 3.228515625  train f1: 0.66667  lr: 4.665422763084028e-05 batch: 23 
epochs: 8 val loss: 4.44140625  val f1:0.07143  lr: 4.665422763084028e-05 batch: 23
epochs: 9 train loss: 2.8203125  train f1: 1.00000  lr: 4.665422763084028e-05 batch: 23 
epochs: 9 val loss: 4.4140625  val f1:0.07143  lr: 4.665422763084028e-05 batch: 23
epochs: 10 train loss: 2.71484375  train f1: 1.00000  lr: 4.665422763084028e-05 batch: 23 
epochs: 10 val loss: 4.3984375  val f1:0.00000  lr: 4.665422763084028e-05 batch: 23
epochs: 11 train loss: 2.22265625  train f1: 1.00000  lr: 4.665422763084028e-05 batch: 23 
epochs: 11 val loss: 4.359375  val f1:0.00000  lr: 4.665422763084028e-05 batch: 23
epochs: 12 train loss: 2.04296875  train f1: 1.00000  lr: 4.665422763084028e-05 batch: 23 
epochs: 12 val loss: 4.3125  val f1:0.00000  lr: 4.665422763084028e-05 batch: 23
epochs: 13 train loss: 2.283203125  train f1: 1.00000  lr: 4.665422763084028e-05 batch: 23 
epochs: 13 val loss: 4.27734375  val f1:0.00000  lr: 4.665422763084028e-05 batch: 23
epochs: 14 train loss: 1.6552734375  train f1: 1.00000  lr: 4.665422763084028e-05 batch: 23 
epochs: 14 val loss: 4.23046875  val f1:0.08333  lr: 4.665422763084028e-05 batch: 23
epochs: 15 train loss: 1.203125  train f1: 1.00000  lr: 4.665422763084028e-05 batch: 23 
epochs: 15 val loss: 4.21875  val f1:0.08333  lr: 4.665422763084028e-05 batch: 23
epochs: 16 train loss: 1.169921875  train f1: 1.00000  lr: 4.665422763084028e-05 batch: 23 
epochs: 16 val loss: 4.16796875  val f1:0.08333  lr: 4.665422763084028e-05 batch: 23
epochs: 17 train loss: 0.99658203125  train f1: 1.00000  lr: 4.665422763084028e-05 batch: 23 
epochs: 17 val loss: 4.16015625  val f1:0.08333  lr: 4.665422763084028e-05 batch: 23
epochs: 18 train loss: 1.1669921875  train f1: 1.00000  lr: 4.665422763084028e-05 batch: 23 
epochs: 18 val loss: 4.1171875  val f1:0.08333  lr: 4.665422763084028e-05 batch: 23
epochs: 19 train loss: 0.75830078125  train f1: 1.00000  lr: 4.665422763084028e-05 batch: 23 
epochs: 19 val loss: 4.08203125  val f1:0.08333  lr: 4.665422763084028e-05 batch: 23
epochs: 0 train loss: 4.76171875  train f1: 0.00000  lr: 0.001816846047729374 batch: 8 
epochs: 0 val loss: 4.4140625  val f1:0.00000  lr: 0.001816846047729374 batch: 8
epochs: 1 train loss: 4.59375  train f1: 0.00000  lr: 0.001816846047729374 batch: 8 
epochs: 1 val loss: 4.1484375  val f1:0.00000  lr: 0.001816846047729374 batch: 8
epochs: 2 train loss: 0.6064453125  train f1: 1.00000  lr: 0.001816846047729374 batch: 8 
epochs: 2 val loss: 4.43359375  val f1:0.16667  lr: 0.001816846047729374 batch: 8
epochs: 3 train loss: 0.132080078125  train f1: 1.00000  lr: 0.001816846047729374 batch: 8 
epochs: 3 val loss: 4.921875  val f1:0.16667  lr: 0.001816846047729374 batch: 8
epochs: 4 train loss: 0.005615234375  train f1: 1.00000  lr: 0.001816846047729374 batch: 8 
epochs: 4 val loss: 6.24609375  val f1:0.16667  lr: 0.001816846047729374 batch: 8
epochs: 0 train loss: 4.625  train f1: 0.00000  lr: 0.00031150312736235073 batch: 22 
epochs: 0 val loss: 4.9453125  val f1:0.00000  lr: 0.00031150312736235073 batch: 22
epochs: 1 train loss: 4.6171875  train f1: 0.00000  lr: 0.00031150312736235073 batch: 22 
epochs: 1 val loss: 4.7265625  val f1:0.00000  lr: 0.00031150312736235073 batch: 22
epochs: 2 train loss: 2.826171875  train f1: 1.00000  lr: 0.00031150312736235073 batch: 22 
epochs: 2 val loss: 4.5234375  val f1:0.00000  lr: 0.00031150312736235073 batch: 22
epochs: 3 train loss: 1.138671875  train f1: 1.00000  lr: 0.00031150312736235073 batch: 22 
epochs: 3 val loss: 4.3046875  val f1:0.14286  lr: 0.00031150312736235073 batch: 22
epochs: 4 train loss: 0.40478515625  train f1: 1.00000  lr: 0.00031150312736235073 batch: 22 
epochs: 4 val loss: 4.1640625  val f1:0.14286  lr: 0.00031150312736235073 batch: 22
epochs: 5 train loss: 0.1279296875  train f1: 1.00000  lr: 0.00031150312736235073 batch: 22 
epochs: 5 val loss: 4.0859375  val f1:0.14286  lr: 0.00031150312736235073 batch: 22
epochs: 6 train loss: 0.0645751953125  train f1: 1.00000  lr: 0.00031150312736235073 batch: 22 
epochs: 6 val loss: 3.98828125  val f1:0.14286  lr: 0.00031150312736235073 batch: 22
epochs: 7 train loss: 0.035064697265625  train f1: 1.00000  lr: 0.00031150312736235073 batch: 22 
epochs: 7 val loss: 3.958984375  val f1:0.14286  lr: 0.00031150312736235073 batch: 22
epochs: 8 train loss: 0.02178955078125  train f1: 1.00000  lr: 0.00031150312736235073 batch: 22 
epochs: 8 val loss: 3.9140625  val f1:0.12500  lr: 0.00031150312736235073 batch: 22
epochs: 9 train loss: 0.01236724853515625  train f1: 1.00000  lr: 0.00031150312736235073 batch: 22 
epochs: 9 val loss: 3.91796875  val f1:0.11111  lr: 0.00031150312736235073 batch: 22
epochs: 10 train loss: 0.0069122314453125  train f1: 1.00000  lr: 0.00031150312736235073 batch: 22 
epochs: 10 val loss: 3.921875  val f1:0.12500  lr: 0.00031150312736235073 batch: 22
epochs: 11 train loss: 0.006694793701171875  train f1: 1.00000  lr: 0.00031150312736235073 batch: 22 
epochs: 11 val loss: 3.91015625  val f1:0.12500  lr: 0.00031150312736235073 batch: 22
epochs: 12 train loss: 0.00473785400390625  train f1: 1.00000  lr: 0.00031150312736235073 batch: 22 
epochs: 12 val loss: 3.888671875  val f1:0.12500  lr: 0.00031150312736235073 batch: 22
epochs: 13 train loss: 0.002460479736328125  train f1: 1.00000  lr: 0.00031150312736235073 batch: 22 
epochs: 13 val loss: 3.88671875  val f1:0.12500  lr: 0.00031150312736235073 batch: 22
epochs: 14 train loss: 0.0017557144165039062  train f1: 1.00000  lr: 0.00031150312736235073 batch: 22 
epochs: 14 val loss: 3.8828125  val f1:0.12500  lr: 0.00031150312736235073 batch: 22
epochs: 15 train loss: 0.0014677047729492188  train f1: 1.00000  lr: 0.00031150312736235073 batch: 22 
epochs: 15 val loss: 3.888671875  val f1:0.14286  lr: 0.00031150312736235073 batch: 22
epochs: 0 train loss: 3.896484375  train f1: 0.00000  lr: 2.4927585482654187e-05 batch: 30 
epochs: 0 val loss: 4.421875  val f1:0.00000  lr: 2.4927585482654187e-05 batch: 30
epochs: 1 train loss: 3.98046875  train f1: 0.00000  lr: 2.4927585482654187e-05 batch: 30 
epochs: 1 val loss: 4.515625  val f1:0.00000  lr: 2.4927585482654187e-05 batch: 30
epochs: 2 train loss: 3.720703125  train f1: 0.11111  lr: 2.4927585482654187e-05 batch: 30 
epochs: 2 val loss: 4.55859375  val f1:0.00000  lr: 2.4927585482654187e-05 batch: 30
epochs: 3 train loss: 3.53125  train f1: 0.13333  lr: 2.4927585482654187e-05 batch: 30 
epochs: 3 val loss: 4.55859375  val f1:0.00000  lr: 2.4927585482654187e-05 batch: 30
epochs: 4 train loss: 3.453125  train f1: 0.13333  lr: 2.4927585482654187e-05 batch: 30 
epochs: 4 val loss: 4.54296875  val f1:0.00000  lr: 2.4927585482654187e-05 batch: 30
epochs: 0 train loss: 4.921875  train f1: 0.00000  lr: 3.0246553600689102e-05 batch: 8 
epochs: 0 val loss: 5.44140625  val f1:0.00000  lr: 3.0246553600689102e-05 batch: 8
epochs: 1 train loss: 4.91796875  train f1: 0.00000  lr: 3.0246553600689102e-05 batch: 8 
epochs: 1 val loss: 5.20703125  val f1:0.00000  lr: 3.0246553600689102e-05 batch: 8
epochs: 2 train loss: 2.84765625  train f1: 0.66667  lr: 3.0246553600689102e-05 batch: 8 
epochs: 2 val loss: 5.10546875  val f1:0.00000  lr: 3.0246553600689102e-05 batch: 8
epochs: 3 train loss: 1.9677734375  train f1: 1.00000  lr: 3.0246553600689102e-05 batch: 8 
epochs: 3 val loss: 4.99609375  val f1:0.00000  lr: 3.0246553600689102e-05 batch: 8
epochs: 4 train loss: 1.1259765625  train f1: 1.00000  lr: 3.0246553600689102e-05 batch: 8 
epochs: 4 val loss: 4.87890625  val f1:0.12500  lr: 3.0246553600689102e-05 batch: 8
epochs: 5 train loss: 0.591796875  train f1: 1.00000  lr: 3.0246553600689102e-05 batch: 8 
epochs: 5 val loss: 4.8046875  val f1:0.12500  lr: 3.0246553600689102e-05 batch: 8
epochs: 6 train loss: 0.4365234375  train f1: 1.00000  lr: 3.0246553600689102e-05 batch: 8 
epochs: 6 val loss: 4.7578125  val f1:0.12500  lr: 3.0246553600689102e-05 batch: 8
epochs: 0 train loss: 4.6015625  train f1: 0.00000  lr: 0.0014789193820674193 batch: 17 
epochs: 0 val loss: 5.1484375  val f1:0.00000  lr: 0.0014789193820674193 batch: 17
epochs: 1 train loss: 4.4375  train f1: 0.00000  lr: 0.0014789193820674193 batch: 17 
epochs: 1 val loss: 5.21875  val f1:0.00000  lr: 0.0014789193820674193 batch: 17
epochs: 2 train loss: 4.39453125  train f1: 0.00000  lr: 0.0014789193820674193 batch: 17 
epochs: 2 val loss: 5.3125  val f1:0.00000  lr: 0.0014789193820674193 batch: 17
epochs: 3 train loss: 4.40234375  train f1: 0.16667  lr: 0.0014789193820674193 batch: 17 
epochs: 3 val loss: 5.33984375  val f1:0.00000  lr: 0.0014789193820674193 batch: 17
epochs: 4 train loss: 4.24609375  train f1: 0.16667  lr: 0.0014789193820674193 batch: 17 
epochs: 4 val loss: 5.328125  val f1:0.00000  lr: 0.0014789193820674193 batch: 17
epochs: 5 train loss: 4.0625  train f1: 0.00000  lr: 0.0014789193820674193 batch: 17 
epochs: 5 val loss: 5.265625  val f1:0.00000  lr: 0.0014789193820674193 batch: 17
epochs: 6 train loss: 3.859375  train f1: 0.00000  lr: 0.0014789193820674193 batch: 17 
epochs: 6 val loss: 5.20703125  val f1:0.00000  lr: 0.0014789193820674193 batch: 17
epochs: 7 train loss: 3.859375  train f1: 0.16667  lr: 0.0014789193820674193 batch: 17 
epochs: 7 val loss: 5.140625  val f1:0.00000  lr: 0.0014789193820674193 batch: 17
epochs: 8 train loss: 3.587890625  train f1: 0.16667  lr: 0.0014789193820674193 batch: 17 
epochs: 8 val loss: 5.06640625  val f1:0.00000  lr: 0.0014789193820674193 batch: 17
epochs: 9 train loss: 3.5234375  train f1: 0.40000  lr: 0.0014789193820674193 batch: 17 
epochs: 9 val loss: 4.95703125  val f1:0.00000  lr: 0.0014789193820674193 batch: 17
epochs: 10 train loss: 3.4296875  train f1: 0.40000  lr: 0.0014789193820674193 batch: 17 
epochs: 10 val loss: 4.87890625  val f1:0.00000  lr: 0.0014789193820674193 batch: 17
epochs: 0 train loss: 4.80078125  train f1: 0.00000  lr: 6.828825179029573e-05 batch: 12 
epochs: 0 val loss: 5.46875  val f1:0.00000  lr: 6.828825179029573e-05 batch: 12
epochs: 1 train loss: 4.8359375  train f1: 0.00000  lr: 6.828825179029573e-05 batch: 12 
epochs: 1 val loss: 5.1015625  val f1:0.00000  lr: 6.828825179029573e-05 batch: 12
epochs: 2 train loss: 1.505859375  train f1: 1.00000  lr: 6.828825179029573e-05 batch: 12 
epochs: 2 val loss: 4.96875  val f1:0.12500  lr: 6.828825179029573e-05 batch: 12
epochs: 3 train loss: 0.230712890625  train f1: 1.00000  lr: 6.828825179029573e-05 batch: 12 
epochs: 3 val loss: 4.828125  val f1:0.12500  lr: 6.828825179029573e-05 batch: 12
epochs: 4 train loss: 0.1044921875  train f1: 1.00000  lr: 6.828825179029573e-05 batch: 12 
epochs: 4 val loss: 4.7265625  val f1:0.12500  lr: 6.828825179029573e-05 batch: 12
epochs: 0 train loss: 4.765625  train f1: 0.00000  lr: 0.0001274289015855093 batch: 32 
epochs: 0 val loss: 5.07421875  val f1:0.00000  lr: 0.0001274289015855093 batch: 32
epochs: 1 train loss: 4.75  train f1: 0.00000  lr: 0.0001274289015855093 batch: 32 
epochs: 1 val loss: 4.83203125  val f1:0.12500  lr: 0.0001274289015855093 batch: 32
epochs: 2 train loss: 0.482177734375  train f1: 1.00000  lr: 0.0001274289015855093 batch: 32 
epochs: 2 val loss: 4.3828125  val f1:0.12500  lr: 0.0001274289015855093 batch: 32
epochs: 3 train loss: 0.120849609375  train f1: 1.00000  lr: 0.0001274289015855093 batch: 32 
epochs: 3 val loss: 4.37890625  val f1:0.11111  lr: 0.0001274289015855093 batch: 32
epochs: 4 train loss: 0.03753662109375  train f1: 1.00000  lr: 0.0001274289015855093 batch: 32 
epochs: 4 val loss: 4.28515625  val f1:0.11111  lr: 0.0001274289015855093 batch: 32
epochs: 5 train loss: 0.00931549072265625  train f1: 1.00000  lr: 0.0001274289015855093 batch: 32 
epochs: 5 val loss: 4.1953125  val f1:0.11111  lr: 0.0001274289015855093 batch: 32
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.012092350136860233 batch: 13 
epochs: 0 val loss: 4.59375  val f1:0.00000  lr: 0.012092350136860233 batch: 13
epochs: 1 train loss: 4.0078125  train f1: 0.11111  lr: 0.012092350136860233 batch: 13 
epochs: 1 val loss: 13.9765625  val f1:0.06667  lr: 0.012092350136860233 batch: 13
epochs: 2 train loss: 1.5625  train f1: 0.50000  lr: 0.012092350136860233 batch: 13 
epochs: 2 val loss: 142.625  val f1:0.06667  lr: 0.012092350136860233 batch: 13
epochs: 3 train loss: 9.109375  train f1: 0.20000  lr: 0.012092350136860233 batch: 13 
epochs: 3 val loss: 80.3125  val f1:0.00000  lr: 0.012092350136860233 batch: 13
epochs: 4 train loss: 9.1015625  train f1: 0.20000  lr: 0.012092350136860233 batch: 13 
epochs: 4 val loss: 51.71875  val f1:0.00000  lr: 0.012092350136860233 batch: 13
epochs: 5 train loss: 9.171875  train f1: 0.20000  lr: 0.012092350136860233 batch: 13 
epochs: 5 val loss: 33.0625  val f1:0.00000  lr: 0.012092350136860233 batch: 13
epochs: 6 train loss: 8.9453125  train f1: 0.25000  lr: 0.012092350136860233 batch: 13 
epochs: 6 val loss: 2446.0  val f1:0.00000  lr: 0.012092350136860233 batch: 13
epochs: 7 train loss: 0.037445068359375  train f1: 1.00000  lr: 0.012092350136860233 batch: 13 
epochs: 7 val loss: 6976.0  val f1:0.00000  lr: 0.012092350136860233 batch: 13
epochs: 8 train loss: 0.67041015625  train f1: 0.77778  lr: 0.012092350136860233 batch: 13 
epochs: 8 val loss: nan  val f1:0.00000  lr: 0.012092350136860233 batch: 13
epochs: 0 train loss: 4.95703125  train f1: 0.00000  lr: 0.0141829287602825 batch: 23 
epochs: 0 val loss: 5.3828125  val f1:0.00000  lr: 0.0141829287602825 batch: 23
epochs: 1 train loss: 4.91015625  train f1: 0.00000  lr: 0.0141829287602825 batch: 23 
epochs: 1 val loss: 5.18359375  val f1:0.00000  lr: 0.0141829287602825 batch: 23
epochs: 2 train loss: 3.59765625  train f1: 0.16667  lr: 0.0141829287602825 batch: 23 
epochs: 2 val loss: 5.00390625  val f1:0.00000  lr: 0.0141829287602825 batch: 23
epochs: 3 train loss: 3.037109375  train f1: 0.50000  lr: 0.0141829287602825 batch: 23 
epochs: 3 val loss: 4.96484375  val f1:0.00000  lr: 0.0141829287602825 batch: 23
epochs: 4 train loss: 1.8154296875  train f1: 1.00000  lr: 0.0141829287602825 batch: 23 
epochs: 4 val loss: 4.57421875  val f1:0.00000  lr: 0.0141829287602825 batch: 23
epochs: 5 train loss: 1.6181640625  train f1: 1.00000  lr: 0.0141829287602825 batch: 23 
epochs: 5 val loss: 4.50390625  val f1:0.00000  lr: 0.0141829287602825 batch: 23
epochs: 0 train loss: 4.5078125  train f1: 0.00000  lr: 0.0031440839410729667 batch: 14 
epochs: 0 val loss: 5.109375  val f1:0.00000  lr: 0.0031440839410729667 batch: 14
epochs: 1 train loss: 4.35546875  train f1: 0.00000  lr: 0.0031440839410729667 batch: 14 
epochs: 1 val loss: 4.984375  val f1:0.00000  lr: 0.0031440839410729667 batch: 14
epochs: 2 train loss: 4.12109375  train f1: 0.00000  lr: 0.0031440839410729667 batch: 14 
epochs: 2 val loss: 4.83984375  val f1:0.00000  lr: 0.0031440839410729667 batch: 14
epochs: 0 train loss: 4.984375  train f1: 0.00000  lr: 0.0022075238649615263 batch: 13 
epochs: 0 val loss: 5.44140625  val f1:0.00000  lr: 0.0022075238649615263 batch: 13
epochs: 1 train loss: 4.98828125  train f1: 0.00000  lr: 0.0022075238649615263 batch: 13 
epochs: 1 val loss: 5.328125  val f1:0.00000  lr: 0.0022075238649615263 batch: 13
epochs: 2 train loss: 4.91796875  train f1: 0.00000  lr: 0.0022075238649615263 batch: 13 
epochs: 2 val loss: 5.2109375  val f1:0.00000  lr: 0.0022075238649615263 batch: 13
epochs: 0 train loss: 4.0078125  train f1: 0.00000  lr: 4.268654387645387e-05 batch: 23 
epochs: 0 val loss: 4.5078125  val f1:0.00000  lr: 4.268654387645387e-05 batch: 23
epochs: 1 train loss: 4.125  train f1: 0.00000  lr: 4.268654387645387e-05 batch: 23 
epochs: 1 val loss: 4.296875  val f1:0.00000  lr: 4.268654387645387e-05 batch: 23
epochs: 2 train loss: 1.458984375  train f1: 1.00000  lr: 4.268654387645387e-05 batch: 23 
epochs: 2 val loss: 4.1484375  val f1:0.14286  lr: 4.268654387645387e-05 batch: 23
epochs: 3 train loss: 0.53857421875  train f1: 1.00000  lr: 4.268654387645387e-05 batch: 23 
epochs: 3 val loss: 4.00390625  val f1:0.12500  lr: 4.268654387645387e-05 batch: 23
epochs: 4 train loss: 0.1497802734375  train f1: 1.00000  lr: 4.268654387645387e-05 batch: 23 
epochs: 4 val loss: 3.8671875  val f1:0.28571  lr: 4.268654387645387e-05 batch: 23
epochs: 5 train loss: 0.275146484375  train f1: 1.00000  lr: 4.268654387645387e-05 batch: 23 
epochs: 5 val loss: 3.74609375  val f1:0.28571  lr: 4.268654387645387e-05 batch: 23
epochs: 6 train loss: 0.1414794921875  train f1: 1.00000  lr: 4.268654387645387e-05 batch: 23 
epochs: 6 val loss: 3.654296875  val f1:0.28571  lr: 4.268654387645387e-05 batch: 23
epochs: 0 train loss: 4.35546875  train f1: 0.00000  lr: 0.0075903536849772 batch: 18 
epochs: 0 val loss: 4.4921875  val f1:0.00000  lr: 0.0075903536849772 batch: 18
epochs: 1 train loss: 4.41015625  train f1: 0.00000  lr: 0.0075903536849772 batch: 18 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.0075903536849772 batch: 18
epochs: 2 train loss: 3.6875  train f1: 0.60000  lr: 0.0075903536849772 batch: 18 
epochs: 2 val loss: nan  val f1:0.00000  lr: 0.0075903536849772 batch: 18
epochs: 0 train loss: 4.3671875  train f1: 0.00000  lr: 8.607118260880381e-05 batch: 15 
epochs: 0 val loss: 4.0859375  val f1:0.00000  lr: 8.607118260880381e-05 batch: 15
epochs: 1 train loss: 4.3125  train f1: 0.00000  lr: 8.607118260880381e-05 batch: 15 
epochs: 1 val loss: 4.1015625  val f1:0.00000  lr: 8.607118260880381e-05 batch: 15
epochs: 2 train loss: 4.40625  train f1: 0.00000  lr: 8.607118260880381e-05 batch: 15 
epochs: 2 val loss: 4.1171875  val f1:0.00000  lr: 8.607118260880381e-05 batch: 15
epochs: 0 train loss: 4.71875  train f1: 0.00000  lr: 1.0211683061602217e-05 batch: 24 
epochs: 0 val loss: 4.86328125  val f1:0.00000  lr: 1.0211683061602217e-05 batch: 24
epochs: 1 train loss: 4.8203125  train f1: 0.00000  lr: 1.0211683061602217e-05 batch: 24 
epochs: 1 val loss: 4.87109375  val f1:0.00000  lr: 1.0211683061602217e-05 batch: 24
epochs: 2 train loss: 4.8125  train f1: 0.16667  lr: 1.0211683061602217e-05 batch: 24 
epochs: 2 val loss: 4.92578125  val f1:0.00000  lr: 1.0211683061602217e-05 batch: 24
epochs: 0 train loss: 4.515625  train f1: 0.00000  lr: 0.0001510556577479952 batch: 9 
epochs: 0 val loss: 4.7890625  val f1:0.00000  lr: 0.0001510556577479952 batch: 9
epochs: 1 train loss: 4.57421875  train f1: 0.00000  lr: 0.0001510556577479952 batch: 9 
epochs: 1 val loss: 4.296875  val f1:0.11111  lr: 0.0001510556577479952 batch: 9
epochs: 2 train loss: 0.339599609375  train f1: 1.00000  lr: 0.0001510556577479952 batch: 9 
epochs: 2 val loss: 4.37109375  val f1:0.11111  lr: 0.0001510556577479952 batch: 9
epochs: 3 train loss: 0.09130859375  train f1: 1.00000  lr: 0.0001510556577479952 batch: 9 
epochs: 3 val loss: 4.015625  val f1:0.11111  lr: 0.0001510556577479952 batch: 9
epochs: 4 train loss: 0.00705718994140625  train f1: 1.00000  lr: 0.0001510556577479952 batch: 9 
epochs: 4 val loss: 3.998046875  val f1:0.11111  lr: 0.0001510556577479952 batch: 9
epochs: 5 train loss: 0.006282806396484375  train f1: 1.00000  lr: 0.0001510556577479952 batch: 9 
epochs: 5 val loss: 4.0234375  val f1:0.11111  lr: 0.0001510556577479952 batch: 9
epochs: 6 train loss: 0.005962371826171875  train f1: 1.00000  lr: 0.0001510556577479952 batch: 9 
epochs: 6 val loss: 3.98046875  val f1:0.11111  lr: 0.0001510556577479952 batch: 9
epochs: 7 train loss: 0.0033092498779296875  train f1: 1.00000  lr: 0.0001510556577479952 batch: 9 
epochs: 7 val loss: 3.939453125  val f1:0.11111  lr: 0.0001510556577479952 batch: 9
epochs: 8 train loss: 0.0019054412841796875  train f1: 1.00000  lr: 0.0001510556577479952 batch: 9 
epochs: 8 val loss: 3.861328125  val f1:0.12500  lr: 0.0001510556577479952 batch: 9
epochs: 9 train loss: 0.0023937225341796875  train f1: 1.00000  lr: 0.0001510556577479952 batch: 9 
epochs: 9 val loss: 3.84375  val f1:0.12500  lr: 0.0001510556577479952 batch: 9
epochs: 10 train loss: 0.002796173095703125  train f1: 1.00000  lr: 0.0001510556577479952 batch: 9 
epochs: 10 val loss: 3.861328125  val f1:0.12500  lr: 0.0001510556577479952 batch: 9
epochs: 11 train loss: 0.00240325927734375  train f1: 1.00000  lr: 0.0001510556577479952 batch: 9 
epochs: 11 val loss: 3.861328125  val f1:0.12500  lr: 0.0001510556577479952 batch: 9
epochs: 12 train loss: 0.0020542144775390625  train f1: 1.00000  lr: 0.0001510556577479952 batch: 9 
epochs: 12 val loss: 3.86328125  val f1:0.12500  lr: 0.0001510556577479952 batch: 9
epochs: 13 train loss: 0.0033626556396484375  train f1: 1.00000  lr: 0.0001510556577479952 batch: 9 
epochs: 13 val loss: 3.875  val f1:0.12500  lr: 0.0001510556577479952 batch: 9
epochs: 14 train loss: 0.0010013580322265625  train f1: 1.00000  lr: 0.0001510556577479952 batch: 9 
epochs: 14 val loss: 3.88671875  val f1:0.12500  lr: 0.0001510556577479952 batch: 9
epochs: 15 train loss: 0.0012674331665039062  train f1: 1.00000  lr: 0.0001510556577479952 batch: 9 
epochs: 15 val loss: 3.955078125  val f1:0.12500  lr: 0.0001510556577479952 batch: 9
epochs: 0 train loss: 4.32421875  train f1: 0.00000  lr: 1.708381194468375e-05 batch: 26 
epochs: 0 val loss: 4.890625  val f1:0.00000  lr: 1.708381194468375e-05 batch: 26
epochs: 1 train loss: 4.265625  train f1: 0.00000  lr: 1.708381194468375e-05 batch: 26 
epochs: 1 val loss: 4.828125  val f1:0.00000  lr: 1.708381194468375e-05 batch: 26
epochs: 2 train loss: 3.2890625  train f1: 0.20000  lr: 1.708381194468375e-05 batch: 26 
epochs: 2 val loss: 4.8671875  val f1:0.00000  lr: 1.708381194468375e-05 batch: 26
epochs: 0 train loss: 4.34375  train f1: 0.00000  lr: 0.06203555604683105 batch: 29 
epochs: 0 val loss: 5.5  val f1:0.00000  lr: 0.06203555604683105 batch: 29
epochs: 1 train loss: 4.375  train f1: 0.00000  lr: 0.06203555604683105 batch: 29 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.06203555604683105 batch: 29
epochs: 2 train loss: 123.875  train f1: 0.22222  lr: 0.06203555604683105 batch: 29 
epochs: 2 val loss: nan  val f1:0.00000  lr: 0.06203555604683105 batch: 29
epochs: 0 train loss: 4.90625  train f1: 0.00000  lr: 0.0003803918089015554 batch: 8 
epochs: 0 val loss: 6.3046875  val f1:0.00000  lr: 0.0003803918089015554 batch: 8
epochs: 1 train loss: 4.79296875  train f1: 0.00000  lr: 0.0003803918089015554 batch: 8 
epochs: 1 val loss: 5.03515625  val f1:0.11111  lr: 0.0003803918089015554 batch: 8
epochs: 2 train loss: 0.1209716796875  train f1: 1.00000  lr: 0.0003803918089015554 batch: 8 
epochs: 2 val loss: 5.3046875  val f1:0.11111  lr: 0.0003803918089015554 batch: 8
epochs: 3 train loss: 0.33935546875  train f1: 1.00000  lr: 0.0003803918089015554 batch: 8 
epochs: 3 val loss: 3.76953125  val f1:0.11111  lr: 0.0003803918089015554 batch: 8
epochs: 4 train loss: 0.434326171875  train f1: 1.00000  lr: 0.0003803918089015554 batch: 8 
epochs: 4 val loss: 5.015625  val f1:0.16667  lr: 0.0003803918089015554 batch: 8
epochs: 0 train loss: 4.546875  train f1: 0.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 0 val loss: 4.58203125  val f1:0.00000  lr: 0.0003675374977512357 batch: 20
epochs: 1 train loss: 4.171875  train f1: 0.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 1 val loss: 3.611328125  val f1:0.11111  lr: 0.0003675374977512357 batch: 20
epochs: 2 train loss: 1.26171875  train f1: 1.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 2 val loss: 4.51953125  val f1:0.12500  lr: 0.0003675374977512357 batch: 20
epochs: 3 train loss: 0.9912109375  train f1: 1.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 3 val loss: 3.95703125  val f1:0.14286  lr: 0.0003675374977512357 batch: 20
epochs: 4 train loss: 0.011871337890625  train f1: 1.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 4 val loss: 3.916015625  val f1:0.14286  lr: 0.0003675374977512357 batch: 20
epochs: 5 train loss: 0.00089263916015625  train f1: 1.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 5 val loss: 3.845703125  val f1:0.14286  lr: 0.0003675374977512357 batch: 20
epochs: 6 train loss: 0.0006036758422851562  train f1: 1.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 6 val loss: 3.81640625  val f1:0.12500  lr: 0.0003675374977512357 batch: 20
epochs: 7 train loss: 0.0005035400390625  train f1: 1.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 7 val loss: 3.798828125  val f1:0.12500  lr: 0.0003675374977512357 batch: 20
epochs: 8 train loss: 0.0007219314575195312  train f1: 1.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 8 val loss: 3.779296875  val f1:0.12500  lr: 0.0003675374977512357 batch: 20
epochs: 9 train loss: 0.0005583763122558594  train f1: 1.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 9 val loss: 3.76171875  val f1:0.12500  lr: 0.0003675374977512357 batch: 20
epochs: 10 train loss: 0.0005855560302734375  train f1: 1.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 10 val loss: 3.765625  val f1:0.12500  lr: 0.0003675374977512357 batch: 20
epochs: 11 train loss: 0.000545501708984375  train f1: 1.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 11 val loss: 3.763671875  val f1:0.12500  lr: 0.0003675374977512357 batch: 20
epochs: 12 train loss: 0.00036787986755371094  train f1: 1.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 12 val loss: 3.767578125  val f1:0.14286  lr: 0.0003675374977512357 batch: 20
epochs: 13 train loss: 0.00033211708068847656  train f1: 1.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 13 val loss: 3.7578125  val f1:0.14286  lr: 0.0003675374977512357 batch: 20
epochs: 14 train loss: 0.0003108978271484375  train f1: 1.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 14 val loss: 3.751953125  val f1:0.14286  lr: 0.0003675374977512357 batch: 20
epochs: 15 train loss: 0.0003581047058105469  train f1: 1.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 15 val loss: 3.751953125  val f1:0.16667  lr: 0.0003675374977512357 batch: 20
epochs: 16 train loss: 0.00034308433532714844  train f1: 1.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 16 val loss: 3.75390625  val f1:0.16667  lr: 0.0003675374977512357 batch: 20
epochs: 17 train loss: 0.0003657341003417969  train f1: 1.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 17 val loss: 3.767578125  val f1:0.16667  lr: 0.0003675374977512357 batch: 20
epochs: 18 train loss: 0.0003235340118408203  train f1: 1.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 18 val loss: 3.802734375  val f1:0.16667  lr: 0.0003675374977512357 batch: 20
epochs: 19 train loss: 0.0002887248992919922  train f1: 1.00000  lr: 0.0003675374977512357 batch: 20 
epochs: 19 val loss: 3.89453125  val f1:0.16667  lr: 0.0003675374977512357 batch: 20
epochs: 0 train loss: 4.484375  train f1: 0.00000  lr: 0.0004938014147564671 batch: 8 
epochs: 0 val loss: 4.7109375  val f1:0.00000  lr: 0.0004938014147564671 batch: 8
epochs: 1 train loss: 4.6015625  train f1: 0.00000  lr: 0.0004938014147564671 batch: 8 
epochs: 1 val loss: 4.30859375  val f1:0.16667  lr: 0.0004938014147564671 batch: 8
epochs: 2 train loss: 0.8232421875  train f1: 1.00000  lr: 0.0004938014147564671 batch: 8 
epochs: 2 val loss: 15.171875  val f1:0.00000  lr: 0.0004938014147564671 batch: 8
epochs: 3 train loss: 2.1640625  train f1: 0.40000  lr: 0.0004938014147564671 batch: 8 
epochs: 3 val loss: 5.98046875  val f1:0.08333  lr: 0.0004938014147564671 batch: 8
epochs: 4 train loss: 0.1368408203125  train f1: 1.00000  lr: 0.0004938014147564671 batch: 8 
epochs: 4 val loss: 5.17578125  val f1:0.14286  lr: 0.0004938014147564671 batch: 8
epochs: 5 train loss: 0.0002073049545288086  train f1: 1.00000  lr: 0.0004938014147564671 batch: 8 
epochs: 5 val loss: 4.9921875  val f1:0.16667  lr: 0.0004938014147564671 batch: 8
epochs: 6 train loss: 0.00022912025451660156  train f1: 1.00000  lr: 0.0004938014147564671 batch: 8 
epochs: 6 val loss: 5.23046875  val f1:0.16667  lr: 0.0004938014147564671 batch: 8
epochs: 0 train loss: 4.21875  train f1: 0.00000  lr: 3.5801421743597014e-05 batch: 22 
epochs: 0 val loss: 4.9375  val f1:0.00000  lr: 3.5801421743597014e-05 batch: 22
epochs: 1 train loss: 4.3203125  train f1: 0.00000  lr: 3.5801421743597014e-05 batch: 22 
epochs: 1 val loss: 4.8515625  val f1:0.00000  lr: 3.5801421743597014e-05 batch: 22
epochs: 0 train loss: 4.3203125  train f1: 0.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 0 val loss: 4.3125  val f1:0.00000  lr: 0.00039198727295440116 batch: 19
epochs: 1 train loss: 4.4140625  train f1: 0.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 1 val loss: 4.09765625  val f1:0.11111  lr: 0.00039198727295440116 batch: 19
epochs: 2 train loss: 0.28564453125  train f1: 1.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 2 val loss: 5.6015625  val f1:0.12500  lr: 0.00039198727295440116 batch: 19
epochs: 3 train loss: 0.54345703125  train f1: 1.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 3 val loss: 3.736328125  val f1:0.07143  lr: 0.00039198727295440116 batch: 19
epochs: 4 train loss: 0.4072265625  train f1: 1.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 4 val loss: 4.3515625  val f1:0.11111  lr: 0.00039198727295440116 batch: 19
epochs: 5 train loss: 1.430511474609375e-05  train f1: 1.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 5 val loss: 3.6171875  val f1:0.16667  lr: 0.00039198727295440116 batch: 19
epochs: 6 train loss: 6.854534149169922e-06  train f1: 1.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 6 val loss: 3.41796875  val f1:0.14286  lr: 0.00039198727295440116 batch: 19
epochs: 7 train loss: 9.059906005859375e-06  train f1: 1.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 7 val loss: 3.33984375  val f1:0.14286  lr: 0.00039198727295440116 batch: 19
epochs: 8 train loss: 8.702278137207031e-06  train f1: 1.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 8 val loss: 3.30859375  val f1:0.12500  lr: 0.00039198727295440116 batch: 19
epochs: 9 train loss: 6.556510925292969e-06  train f1: 1.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 9 val loss: 3.302734375  val f1:0.12500  lr: 0.00039198727295440116 batch: 19
epochs: 10 train loss: 1.3709068298339844e-05  train f1: 1.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 10 val loss: 3.3125  val f1:0.12500  lr: 0.00039198727295440116 batch: 19
epochs: 11 train loss: 9.715557098388672e-06  train f1: 1.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 11 val loss: 3.37109375  val f1:0.12500  lr: 0.00039198727295440116 batch: 19
epochs: 12 train loss: 1.0371208190917969e-05  train f1: 1.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 12 val loss: 3.41015625  val f1:0.12500  lr: 0.00039198727295440116 batch: 19
epochs: 13 train loss: 2.9206275939941406e-05  train f1: 1.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 13 val loss: 3.466796875  val f1:0.11111  lr: 0.00039198727295440116 batch: 19
epochs: 14 train loss: 8.940696716308594e-06  train f1: 1.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 14 val loss: 3.5078125  val f1:0.12500  lr: 0.00039198727295440116 batch: 19
epochs: 15 train loss: 9.417533874511719e-06  train f1: 1.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 15 val loss: 3.56640625  val f1:0.12500  lr: 0.00039198727295440116 batch: 19
epochs: 16 train loss: 1.049041748046875e-05  train f1: 1.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 16 val loss: 3.587890625  val f1:0.12500  lr: 0.00039198727295440116 batch: 19
epochs: 17 train loss: 4.696846008300781e-05  train f1: 1.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 17 val loss: 3.623046875  val f1:0.12500  lr: 0.00039198727295440116 batch: 19
epochs: 18 train loss: 4.0411949157714844e-05  train f1: 1.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 18 val loss: 3.638671875  val f1:0.12500  lr: 0.00039198727295440116 batch: 19
epochs: 19 train loss: 2.9087066650390625e-05  train f1: 1.00000  lr: 0.00039198727295440116 batch: 19 
epochs: 19 val loss: 3.650390625  val f1:0.12500  lr: 0.00039198727295440116 batch: 19
epochs: 0 train loss: 5.28125  train f1: 0.00000  lr: 3.145592183640191e-05 batch: 27 
epochs: 0 val loss: 4.6796875  val f1:0.00000  lr: 3.145592183640191e-05 batch: 27
epochs: 1 train loss: 5.40625  train f1: 0.00000  lr: 3.145592183640191e-05 batch: 27 
epochs: 1 val loss: 4.57421875  val f1:0.00000  lr: 3.145592183640191e-05 batch: 27
epochs: 0 train loss: 4.6171875  train f1: 0.00000  lr: 0.0007227248695763617 batch: 10 
epochs: 0 val loss: 4.66015625  val f1:0.00000  lr: 0.0007227248695763617 batch: 10
epochs: 1 train loss: 4.54296875  train f1: 0.00000  lr: 0.0007227248695763617 batch: 10 
epochs: 1 val loss: 4.421875  val f1:0.11111  lr: 0.0007227248695763617 batch: 10
epochs: 2 train loss: 0.951171875  train f1: 1.00000  lr: 0.0007227248695763617 batch: 10 
epochs: 2 val loss: 4.1640625  val f1:0.11111  lr: 0.0007227248695763617 batch: 10
epochs: 3 train loss: 0.1988525390625  train f1: 1.00000  lr: 0.0007227248695763617 batch: 10 
epochs: 3 val loss: 3.904296875  val f1:0.11111  lr: 0.0007227248695763617 batch: 10
epochs: 4 train loss: 0.0142974853515625  train f1: 1.00000  lr: 0.0007227248695763617 batch: 10 
epochs: 4 val loss: 3.75390625  val f1:0.12500  lr: 0.0007227248695763617 batch: 10
epochs: 5 train loss: 0.004138946533203125  train f1: 1.00000  lr: 0.0007227248695763617 batch: 10 
epochs: 5 val loss: 3.6484375  val f1:0.11111  lr: 0.0007227248695763617 batch: 10
epochs: 6 train loss: 0.0014438629150390625  train f1: 1.00000  lr: 0.0007227248695763617 batch: 10 
epochs: 6 val loss: 3.568359375  val f1:0.11111  lr: 0.0007227248695763617 batch: 10
epochs: 0 train loss: 4.2890625  train f1: 0.00000  lr: 0.00034151775173830426 batch: 21 
epochs: 0 val loss: 4.73046875  val f1:0.00000  lr: 0.00034151775173830426 batch: 21
epochs: 1 train loss: 4.34375  train f1: 0.00000  lr: 0.00034151775173830426 batch: 21 
epochs: 1 val loss: 4.26171875  val f1:0.12500  lr: 0.00034151775173830426 batch: 21
epochs: 2 train loss: 0.188720703125  train f1: 1.00000  lr: 0.00034151775173830426 batch: 21 
epochs: 2 val loss: 4.11328125  val f1:0.14286  lr: 0.00034151775173830426 batch: 21
epochs: 3 train loss: 0.36328125  train f1: 1.00000  lr: 0.00034151775173830426 batch: 21 
epochs: 3 val loss: 4.34375  val f1:0.14286  lr: 0.00034151775173830426 batch: 21
epochs: 4 train loss: 0.05938720703125  train f1: 1.00000  lr: 0.00034151775173830426 batch: 21 
epochs: 4 val loss: 4.89453125  val f1:0.14286  lr: 0.00034151775173830426 batch: 21
epochs: 5 train loss: 0.0216217041015625  train f1: 1.00000  lr: 0.00034151775173830426 batch: 21 
epochs: 5 val loss: 4.40234375  val f1:0.14286  lr: 0.00034151775173830426 batch: 21
epochs: 6 train loss: 0.008056640625  train f1: 1.00000  lr: 0.00034151775173830426 batch: 21 
epochs: 6 val loss: 4.14453125  val f1:0.14286  lr: 0.00034151775173830426 batch: 21
epochs: 7 train loss: 1.537799835205078e-05  train f1: 1.00000  lr: 0.00034151775173830426 batch: 21 
epochs: 7 val loss: 3.93359375  val f1:0.14286  lr: 0.00034151775173830426 batch: 21
epochs: 8 train loss: 2.0384788513183594e-05  train f1: 1.00000  lr: 0.00034151775173830426 batch: 21 
epochs: 8 val loss: 3.87890625  val f1:0.14286  lr: 0.00034151775173830426 batch: 21
epochs: 9 train loss: 4.76837158203125e-05  train f1: 1.00000  lr: 0.00034151775173830426 batch: 21 
epochs: 9 val loss: 3.890625  val f1:0.12500  lr: 0.00034151775173830426 batch: 21
epochs: 0 train loss: 4.9375  train f1: 0.00000  lr: 3.2841339963299346e-05 batch: 28 
epochs: 0 val loss: 4.92578125  val f1:0.00000  lr: 3.2841339963299346e-05 batch: 28
epochs: 1 train loss: 5.02734375  train f1: 0.00000  lr: 3.2841339963299346e-05 batch: 28 
epochs: 1 val loss: 4.85546875  val f1:0.00000  lr: 3.2841339963299346e-05 batch: 28
epochs: 2 train loss: 4.97265625  train f1: 0.00000  lr: 3.2841339963299346e-05 batch: 28 
epochs: 2 val loss: 4.83203125  val f1:0.00000  lr: 3.2841339963299346e-05 batch: 28
epochs: 3 train loss: 4.9453125  train f1: 0.00000  lr: 3.2841339963299346e-05 batch: 28 
epochs: 3 val loss: 4.7890625  val f1:0.00000  lr: 3.2841339963299346e-05 batch: 28
epochs: 4 train loss: 4.8515625  train f1: 0.00000  lr: 3.2841339963299346e-05 batch: 28 
epochs: 4 val loss: 4.77734375  val f1:0.00000  lr: 3.2841339963299346e-05 batch: 28
epochs: 5 train loss: 4.97265625  train f1: 0.00000  lr: 3.2841339963299346e-05 batch: 28 
epochs: 5 val loss: 4.73828125  val f1:0.00000  lr: 3.2841339963299346e-05 batch: 28
epochs: 0 train loss: 4.38671875  train f1: 0.00000  lr: 8.121178156442214e-05 batch: 27 
epochs: 0 val loss: 4.82421875  val f1:0.00000  lr: 8.121178156442214e-05 batch: 27
epochs: 1 train loss: 4.26171875  train f1: 0.00000  lr: 8.121178156442214e-05 batch: 27 
epochs: 1 val loss: 4.38671875  val f1:0.00000  lr: 8.121178156442214e-05 batch: 27
epochs: 2 train loss: 0.98486328125  train f1: 1.00000  lr: 8.121178156442214e-05 batch: 27 
epochs: 2 val loss: 4.23046875  val f1:0.00000  lr: 8.121178156442214e-05 batch: 27
epochs: 3 train loss: 0.1553955078125  train f1: 1.00000  lr: 8.121178156442214e-05 batch: 27 
epochs: 3 val loss: 4.01953125  val f1:0.14286  lr: 8.121178156442214e-05 batch: 27
epochs: 4 train loss: 0.0802001953125  train f1: 1.00000  lr: 8.121178156442214e-05 batch: 27 
epochs: 4 val loss: 3.859375  val f1:0.14286  lr: 8.121178156442214e-05 batch: 27
epochs: 5 train loss: 0.03326416015625  train f1: 1.00000  lr: 8.121178156442214e-05 batch: 27 
epochs: 5 val loss: 3.84765625  val f1:0.14286  lr: 8.121178156442214e-05 batch: 27
epochs: 6 train loss: 0.040435791015625  train f1: 1.00000  lr: 8.121178156442214e-05 batch: 27 
epochs: 6 val loss: 3.771484375  val f1:0.14286  lr: 8.121178156442214e-05 batch: 27
epochs: 7 train loss: 0.025054931640625  train f1: 1.00000  lr: 8.121178156442214e-05 batch: 27 
epochs: 7 val loss: 3.69140625  val f1:0.14286  lr: 8.121178156442214e-05 batch: 27
epochs: 8 train loss: 0.01953125  train f1: 1.00000  lr: 8.121178156442214e-05 batch: 27 
epochs: 8 val loss: 3.6484375  val f1:0.12500  lr: 8.121178156442214e-05 batch: 27
epochs: 9 train loss: 0.01512908935546875  train f1: 1.00000  lr: 8.121178156442214e-05 batch: 27 
epochs: 9 val loss: 3.630859375  val f1:0.14286  lr: 8.121178156442214e-05 batch: 27
epochs: 10 train loss: 0.0127105712890625  train f1: 1.00000  lr: 8.121178156442214e-05 batch: 27 
epochs: 10 val loss: 3.615234375  val f1:0.14286  lr: 8.121178156442214e-05 batch: 27
epochs: 11 train loss: 0.0096588134765625  train f1: 1.00000  lr: 8.121178156442214e-05 batch: 27 
epochs: 11 val loss: 3.607421875  val f1:0.14286  lr: 8.121178156442214e-05 batch: 27
epochs: 12 train loss: 0.0111846923828125  train f1: 1.00000  lr: 8.121178156442214e-05 batch: 27 
epochs: 12 val loss: 3.619140625  val f1:0.14286  lr: 8.121178156442214e-05 batch: 27
epochs: 13 train loss: 0.01041412353515625  train f1: 1.00000  lr: 8.121178156442214e-05 batch: 27 
epochs: 13 val loss: 3.65234375  val f1:0.14286  lr: 8.121178156442214e-05 batch: 27
epochs: 14 train loss: 0.01076507568359375  train f1: 1.00000  lr: 8.121178156442214e-05 batch: 27 
epochs: 14 val loss: 3.6796875  val f1:0.14286  lr: 8.121178156442214e-05 batch: 27
epochs: 15 train loss: 0.0094451904296875  train f1: 1.00000  lr: 8.121178156442214e-05 batch: 27 
epochs: 15 val loss: 3.736328125  val f1:0.12500  lr: 8.121178156442214e-05 batch: 27
epochs: 16 train loss: 0.023956298828125  train f1: 1.00000  lr: 8.121178156442214e-05 batch: 27 
epochs: 16 val loss: 3.708984375  val f1:0.12500  lr: 8.121178156442214e-05 batch: 27
epochs: 17 train loss: 0.005702972412109375  train f1: 1.00000  lr: 8.121178156442214e-05 batch: 27 
epochs: 17 val loss: 3.72265625  val f1:0.12500  lr: 8.121178156442214e-05 batch: 27
epochs: 18 train loss: 0.003856658935546875  train f1: 1.00000  lr: 8.121178156442214e-05 batch: 27 
epochs: 18 val loss: 3.76171875  val f1:0.12500  lr: 8.121178156442214e-05 batch: 27
epochs: 0 train loss: 4.3125  train f1: 0.00000  lr: 0.03149532295551082 batch: 29 
epochs: 0 val loss: 4.875  val f1:0.00000  lr: 0.03149532295551082 batch: 29
epochs: 1 train loss: 4.2890625  train f1: 0.00000  lr: 0.03149532295551082 batch: 29 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.03149532295551082 batch: 29
epochs: 2 train loss: 1.16796875  train f1: 0.60000  lr: 0.03149532295551082 batch: 29 
epochs: 2 val loss: nan  val f1:0.00000  lr: 0.03149532295551082 batch: 29
epochs: 3 train loss: 2.04296875  train f1: 0.50000  lr: 0.03149532295551082 batch: 29 
epochs: 3 val loss: 12176.0  val f1:0.06667  lr: 0.03149532295551082 batch: 29
epochs: 4 train loss: 3.671875  train f1: 0.12500  lr: 0.03149532295551082 batch: 29 
epochs: 4 val loss: 1387.0  val f1:0.06667  lr: 0.03149532295551082 batch: 29
epochs: 5 train loss: 2.80078125  train f1: 0.38889  lr: 0.03149532295551082 batch: 29 
epochs: 5 val loss: nan  val f1:0.00000  lr: 0.03149532295551082 batch: 29
epochs: 6 train loss: 15.8671875  train f1: 0.00000  lr: 0.03149532295551082 batch: 29 
epochs: 6 val loss: nan  val f1:0.00000  lr: 0.03149532295551082 batch: 29
epochs: 7 train loss: 17.671875  train f1: 0.00000  lr: 0.03149532295551082 batch: 29 
epochs: 7 val loss: nan  val f1:0.00000  lr: 0.03149532295551082 batch: 29
epochs: 8 train loss: 13.453125  train f1: 0.13333  lr: 0.03149532295551082 batch: 29 
epochs: 8 val loss: nan  val f1:0.00000  lr: 0.03149532295551082 batch: 29
epochs: 9 train loss: 7.94140625  train f1: 0.13333  lr: 0.03149532295551082 batch: 29 
epochs: 9 val loss: nan  val f1:0.00000  lr: 0.03149532295551082 batch: 29
epochs: 10 train loss: 6.8671875  train f1: 0.00000  lr: 0.03149532295551082 batch: 29 
epochs: 10 val loss: nan  val f1:0.00000  lr: 0.03149532295551082 batch: 29
epochs: 11 train loss: 35.25  train f1: 0.25000  lr: 0.03149532295551082 batch: 29 
epochs: 11 val loss: nan  val f1:0.00000  lr: 0.03149532295551082 batch: 29
epochs: 12 train loss: 24.015625  train f1: 0.00000  lr: 0.03149532295551082 batch: 29 
epochs: 12 val loss: nan  val f1:0.00000  lr: 0.03149532295551082 batch: 29
epochs: 13 train loss: 10.34375  train f1: 0.50000  lr: 0.03149532295551082 batch: 29 
epochs: 13 val loss: nan  val f1:0.00000  lr: 0.03149532295551082 batch: 29
epochs: 14 train loss: 4.046875  train f1: 0.50000  lr: 0.03149532295551082 batch: 29 
epochs: 14 val loss: nan  val f1:0.00000  lr: 0.03149532295551082 batch: 29
epochs: 15 train loss: 1.1884765625  train f1: 0.77778  lr: 0.03149532295551082 batch: 29 
epochs: 15 val loss: nan  val f1:0.00000  lr: 0.03149532295551082 batch: 29
epochs: 0 train loss: 4.69921875  train f1: 0.00000  lr: 2.3912452715906755e-05 batch: 27 
epochs: 0 val loss: 4.98046875  val f1:0.00000  lr: 2.3912452715906755e-05 batch: 27
epochs: 1 train loss: 4.53125  train f1: 0.00000  lr: 2.3912452715906755e-05 batch: 27 
epochs: 1 val loss: 4.9453125  val f1:0.00000  lr: 2.3912452715906755e-05 batch: 27
epochs: 2 train loss: 4.73046875  train f1: 0.00000  lr: 2.3912452715906755e-05 batch: 27 
epochs: 2 val loss: 4.91796875  val f1:0.00000  lr: 2.3912452715906755e-05 batch: 27
epochs: 3 train loss: 4.6015625  train f1: 0.00000  lr: 2.3912452715906755e-05 batch: 27 
epochs: 3 val loss: 4.9140625  val f1:0.00000  lr: 2.3912452715906755e-05 batch: 27
epochs: 4 train loss: 4.6171875  train f1: 0.00000  lr: 2.3912452715906755e-05 batch: 27 
epochs: 4 val loss: 4.91015625  val f1:0.00000  lr: 2.3912452715906755e-05 batch: 27
epochs: 5 train loss: 4.69140625  train f1: 0.00000  lr: 2.3912452715906755e-05 batch: 27 
epochs: 5 val loss: 4.90234375  val f1:0.00000  lr: 2.3912452715906755e-05 batch: 27
epochs: 6 train loss: 4.55078125  train f1: 0.00000  lr: 2.3912452715906755e-05 batch: 27 
epochs: 6 val loss: 4.86328125  val f1:0.00000  lr: 2.3912452715906755e-05 batch: 27
epochs: 7 train loss: 4.609375  train f1: 0.00000  lr: 2.3912452715906755e-05 batch: 27 
epochs: 7 val loss: 4.7734375  val f1:0.00000  lr: 2.3912452715906755e-05 batch: 27
epochs: 8 train loss: 4.3671875  train f1: 0.00000  lr: 2.3912452715906755e-05 batch: 27 
epochs: 8 val loss: 4.70703125  val f1:0.00000  lr: 2.3912452715906755e-05 batch: 27
epochs: 9 train loss: 4.73046875  train f1: 0.00000  lr: 2.3912452715906755e-05 batch: 27 
epochs: 9 val loss: 4.6171875  val f1:0.00000  lr: 2.3912452715906755e-05 batch: 27
epochs: 10 train loss: 4.63671875  train f1: 0.00000  lr: 2.3912452715906755e-05 batch: 27 
epochs: 10 val loss: 4.57421875  val f1:0.00000  lr: 2.3912452715906755e-05 batch: 27
epochs: 11 train loss: 4.4609375  train f1: 0.00000  lr: 2.3912452715906755e-05 batch: 27 
epochs: 11 val loss: 4.5546875  val f1:0.00000  lr: 2.3912452715906755e-05 batch: 27
epochs: 12 train loss: 4.7109375  train f1: 0.00000  lr: 2.3912452715906755e-05 batch: 27 
epochs: 12 val loss: 4.53515625  val f1:0.00000  lr: 2.3912452715906755e-05 batch: 27
epochs: 13 train loss: 4.53125  train f1: 0.00000  lr: 2.3912452715906755e-05 batch: 27 
epochs: 13 val loss: 4.515625  val f1:0.00000  lr: 2.3912452715906755e-05 batch: 27
epochs: 14 train loss: 4.53125  train f1: 0.00000  lr: 2.3912452715906755e-05 batch: 27 
epochs: 14 val loss: 4.546875  val f1:0.00000  lr: 2.3912452715906755e-05 batch: 27
epochs: 15 train loss: 4.69140625  train f1: 0.00000  lr: 2.3912452715906755e-05 batch: 27 
epochs: 15 val loss: 4.52734375  val f1:0.00000  lr: 2.3912452715906755e-05 batch: 27
epochs: 16 train loss: 4.58984375  train f1: 0.00000  lr: 2.3912452715906755e-05 batch: 27 
epochs: 16 val loss: 4.53125  val f1:0.00000  lr: 2.3912452715906755e-05 batch: 27
epochs: 0 train loss: 4.55078125  train f1: 0.00000  lr: 3.1706070495873514e-05 batch: 28 
epochs: 0 val loss: 5.66796875  val f1:0.00000  lr: 3.1706070495873514e-05 batch: 28
epochs: 1 train loss: 4.4921875  train f1: 0.00000  lr: 3.1706070495873514e-05 batch: 28 
epochs: 1 val loss: 5.3671875  val f1:0.00000  lr: 3.1706070495873514e-05 batch: 28
epochs: 2 train loss: 2.634765625  train f1: 1.00000  lr: 3.1706070495873514e-05 batch: 28 
epochs: 2 val loss: 5.1484375  val f1:0.00000  lr: 3.1706070495873514e-05 batch: 28
epochs: 3 train loss: 1.5166015625  train f1: 1.00000  lr: 3.1706070495873514e-05 batch: 28 
epochs: 3 val loss: 4.9765625  val f1:0.00000  lr: 3.1706070495873514e-05 batch: 28
epochs: 4 train loss: 0.7236328125  train f1: 1.00000  lr: 3.1706070495873514e-05 batch: 28 
epochs: 4 val loss: 4.8046875  val f1:0.11111  lr: 3.1706070495873514e-05 batch: 28
epochs: 5 train loss: 0.3466796875  train f1: 1.00000  lr: 3.1706070495873514e-05 batch: 28 
epochs: 5 val loss: 4.625  val f1:0.11111  lr: 3.1706070495873514e-05 batch: 28
epochs: 6 train loss: 0.374755859375  train f1: 1.00000  lr: 3.1706070495873514e-05 batch: 28 
epochs: 6 val loss: 4.53515625  val f1:0.12500  lr: 3.1706070495873514e-05 batch: 28
epochs: 7 train loss: 0.1630859375  train f1: 1.00000  lr: 3.1706070495873514e-05 batch: 28 
epochs: 7 val loss: 4.40625  val f1:0.14286  lr: 3.1706070495873514e-05 batch: 28
epochs: 0 train loss: 4.46875  train f1: 0.00000  lr: 2.0874578901005502e-05 batch: 21 
epochs: 0 val loss: 4.56640625  val f1:0.00000  lr: 2.0874578901005502e-05 batch: 21
epochs: 1 train loss: 4.45703125  train f1: 0.00000  lr: 2.0874578901005502e-05 batch: 21 
epochs: 1 val loss: 4.52734375  val f1:0.00000  lr: 2.0874578901005502e-05 batch: 21
epochs: 2 train loss: 4.484375  train f1: 0.00000  lr: 2.0874578901005502e-05 batch: 21 
epochs: 2 val loss: 4.5  val f1:0.00000  lr: 2.0874578901005502e-05 batch: 21
epochs: 3 train loss: 4.2109375  train f1: 0.20000  lr: 2.0874578901005502e-05 batch: 21 
epochs: 3 val loss: 4.4765625  val f1:0.00000  lr: 2.0874578901005502e-05 batch: 21
epochs: 4 train loss: 4.09765625  train f1: 0.00000  lr: 2.0874578901005502e-05 batch: 21 
epochs: 4 val loss: 4.4453125  val f1:0.00000  lr: 2.0874578901005502e-05 batch: 21
epochs: 0 train loss: 4.625  train f1: 0.16667  lr: 0.062354552868349566 batch: 28 
epochs: 0 val loss: 5.36328125  val f1:0.00000  lr: 0.062354552868349566 batch: 28
epochs: 1 train loss: 4.6875  train f1: 0.00000  lr: 0.062354552868349566 batch: 28 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.062354552868349566 batch: 28
epochs: 2 train loss: 59.125  train f1: 0.22222  lr: 0.062354552868349566 batch: 28 
epochs: 2 val loss: nan  val f1:0.00000  lr: 0.062354552868349566 batch: 28
epochs: 3 train loss: 107.3125  train f1: 0.22222  lr: 0.062354552868349566 batch: 28 
epochs: 3 val loss: nan  val f1:0.00000  lr: 0.062354552868349566 batch: 28
epochs: 4 train loss: 41.28125  train f1: 0.22222  lr: 0.062354552868349566 batch: 28 
epochs: 4 val loss: nan  val f1:0.00000  lr: 0.062354552868349566 batch: 28
epochs: 0 train loss: 4.7421875  train f1: 0.00000  lr: 0.00015188686022249434 batch: 20 
epochs: 0 val loss: 4.7734375  val f1:0.00000  lr: 0.00015188686022249434 batch: 20
epochs: 1 train loss: 4.6015625  train f1: 0.00000  lr: 0.00015188686022249434 batch: 20 
epochs: 1 val loss: 4.73046875  val f1:0.00000  lr: 0.00015188686022249434 batch: 20
epochs: 2 train loss: 4.640625  train f1: 0.00000  lr: 0.00015188686022249434 batch: 20 
epochs: 2 val loss: 4.70703125  val f1:0.00000  lr: 0.00015188686022249434 batch: 20
epochs: 3 train loss: 4.6796875  train f1: 0.00000  lr: 0.00015188686022249434 batch: 20 
epochs: 3 val loss: 4.71484375  val f1:0.00000  lr: 0.00015188686022249434 batch: 20
epochs: 4 train loss: 4.66015625  train f1: 0.00000  lr: 0.00015188686022249434 batch: 20 
epochs: 4 val loss: 4.734375  val f1:0.00000  lr: 0.00015188686022249434 batch: 20
epochs: 0 train loss: 4.7734375  train f1: 0.00000  lr: 0.032879661475939605 batch: 30 
epochs: 0 val loss: 4.8203125  val f1:0.00000  lr: 0.032879661475939605 batch: 30
epochs: 1 train loss: 4.765625  train f1: 0.00000  lr: 0.032879661475939605 batch: 30 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.032879661475939605 batch: 30
epochs: 2 train loss: 5.5703125  train f1: 0.60000  lr: 0.032879661475939605 batch: 30 
epochs: 2 val loss: nan  val f1:0.00000  lr: 0.032879661475939605 batch: 30
epochs: 3 train loss: 4.8828125  train f1: 0.60000  lr: 0.032879661475939605 batch: 30 
epochs: 3 val loss: 6280.0  val f1:0.06667  lr: 0.032879661475939605 batch: 30
epochs: 4 train loss: 4.921875  train f1: 0.60000  lr: 0.032879661475939605 batch: 30 
epochs: 4 val loss: nan  val f1:0.00000  lr: 0.032879661475939605 batch: 30
epochs: 5 train loss: 14.6640625  train f1: 0.10000  lr: 0.032879661475939605 batch: 30 
epochs: 5 val loss: nan  val f1:0.00000  lr: 0.032879661475939605 batch: 30
epochs: 0 train loss: 4.33984375  train f1: 0.12500  lr: 0.038418352103779474 batch: 23 
epochs: 0 val loss: 5.22265625  val f1:0.00000  lr: 0.038418352103779474 batch: 23
epochs: 1 train loss: 4.4765625  train f1: 0.13333  lr: 0.038418352103779474 batch: 23 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.038418352103779474 batch: 23
epochs: 2 train loss: 4.3984375  train f1: 0.16667  lr: 0.038418352103779474 batch: 23 
epochs: 2 val loss: nan  val f1:0.00000  lr: 0.038418352103779474 batch: 23
epochs: 3 train loss: 3.384765625  train f1: 0.25000  lr: 0.038418352103779474 batch: 23 
epochs: 3 val loss: nan  val f1:0.00000  lr: 0.038418352103779474 batch: 23
epochs: 0 train loss: 4.94140625  train f1: 0.00000  lr: 0.000994054423915189 batch: 11 
epochs: 0 val loss: 5.0546875  val f1:0.00000  lr: 0.000994054423915189 batch: 11
epochs: 1 train loss: 4.953125  train f1: 0.00000  lr: 0.000994054423915189 batch: 11 
epochs: 1 val loss: 14.796875  val f1:0.16667  lr: 0.000994054423915189 batch: 11
epochs: 2 train loss: 1.0078125  train f1: 1.00000  lr: 0.000994054423915189 batch: 11 
epochs: 2 val loss: 8.46875  val f1:0.06667  lr: 0.000994054423915189 batch: 11
epochs: 3 train loss: 2.787109375  train f1: 0.20000  lr: 0.000994054423915189 batch: 11 
epochs: 3 val loss: 51.59375  val f1:0.00000  lr: 0.000994054423915189 batch: 11
epochs: 4 train loss: 0.0013713836669921875  train f1: 1.00000  lr: 0.000994054423915189 batch: 11 
epochs: 4 val loss: 45.375  val f1:0.00000  lr: 0.000994054423915189 batch: 11
epochs: 5 train loss: 0.0004711151123046875  train f1: 1.00000  lr: 0.000994054423915189 batch: 11 
epochs: 5 val loss: 43.8125  val f1:0.00000  lr: 0.000994054423915189 batch: 11
epochs: 6 train loss: 0.00029087066650390625  train f1: 1.00000  lr: 0.000994054423915189 batch: 11 
epochs: 6 val loss: 36.5625  val f1:0.00000  lr: 0.000994054423915189 batch: 11
epochs: 0 train loss: 5.5546875  train f1: 0.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 0 val loss: 4.78515625  val f1:0.00000  lr: 0.00017694619654001233 batch: 32
epochs: 1 train loss: 5.4296875  train f1: 0.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 1 val loss: 4.1484375  val f1:0.25000  lr: 0.00017694619654001233 batch: 32
epochs: 2 train loss: 0.7666015625  train f1: 1.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 2 val loss: 3.64453125  val f1:0.23810  lr: 0.00017694619654001233 batch: 32
epochs: 3 train loss: 0.1484375  train f1: 1.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 3 val loss: 3.591796875  val f1:0.23810  lr: 0.00017694619654001233 batch: 32
epochs: 4 train loss: 0.00806427001953125  train f1: 1.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 4 val loss: 3.4609375  val f1:0.25000  lr: 0.00017694619654001233 batch: 32
epochs: 5 train loss: 0.005992889404296875  train f1: 1.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 5 val loss: 3.390625  val f1:0.25000  lr: 0.00017694619654001233 batch: 32
epochs: 6 train loss: 0.0051422119140625  train f1: 1.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 6 val loss: 3.3515625  val f1:0.23810  lr: 0.00017694619654001233 batch: 32
epochs: 7 train loss: 0.003017425537109375  train f1: 1.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 7 val loss: 3.3359375  val f1:0.23810  lr: 0.00017694619654001233 batch: 32
epochs: 8 train loss: 0.0031299591064453125  train f1: 1.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 8 val loss: 3.330078125  val f1:0.23810  lr: 0.00017694619654001233 batch: 32
epochs: 9 train loss: 0.002025604248046875  train f1: 1.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 9 val loss: 3.333984375  val f1:0.23810  lr: 0.00017694619654001233 batch: 32
epochs: 10 train loss: 0.0023288726806640625  train f1: 1.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 10 val loss: 3.34375  val f1:0.22222  lr: 0.00017694619654001233 batch: 32
epochs: 11 train loss: 0.0028209686279296875  train f1: 1.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 11 val loss: 3.359375  val f1:0.22222  lr: 0.00017694619654001233 batch: 32
epochs: 12 train loss: 0.0020465850830078125  train f1: 1.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 12 val loss: 3.365234375  val f1:0.11111  lr: 0.00017694619654001233 batch: 32
epochs: 13 train loss: 0.00183868408203125  train f1: 1.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 13 val loss: 3.38671875  val f1:0.09524  lr: 0.00017694619654001233 batch: 32
epochs: 14 train loss: 0.00122833251953125  train f1: 1.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 14 val loss: 3.4140625  val f1:0.09524  lr: 0.00017694619654001233 batch: 32
epochs: 15 train loss: 0.0012683868408203125  train f1: 1.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 15 val loss: 3.466796875  val f1:0.09524  lr: 0.00017694619654001233 batch: 32
epochs: 16 train loss: 0.0011892318725585938  train f1: 1.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 16 val loss: 3.5078125  val f1:0.09524  lr: 0.00017694619654001233 batch: 32
epochs: 17 train loss: 0.0012664794921875  train f1: 1.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 17 val loss: 3.59375  val f1:0.11111  lr: 0.00017694619654001233 batch: 32
epochs: 18 train loss: 0.0015583038330078125  train f1: 1.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 18 val loss: 3.73828125  val f1:0.09524  lr: 0.00017694619654001233 batch: 32
epochs: 19 train loss: 0.001155853271484375  train f1: 1.00000  lr: 0.00017694619654001233 batch: 32 
epochs: 19 val loss: 3.72265625  val f1:0.11111  lr: 0.00017694619654001233 batch: 32
epochs: 0 train loss: 4.96875  train f1: 0.00000  lr: 0.00019055271893511717 batch: 16 
epochs: 0 val loss: 4.20703125  val f1:0.00000  lr: 0.00019055271893511717 batch: 16
epochs: 1 train loss: 4.98828125  train f1: 0.00000  lr: 0.00019055271893511717 batch: 16 
epochs: 1 val loss: 3.626953125  val f1:0.14286  lr: 0.00019055271893511717 batch: 16
epochs: 2 train loss: 0.49072265625  train f1: 1.00000  lr: 0.00019055271893511717 batch: 16 
epochs: 2 val loss: 3.751953125  val f1:0.14286  lr: 0.00019055271893511717 batch: 16
epochs: 3 train loss: 0.489501953125  train f1: 1.00000  lr: 0.00019055271893511717 batch: 16 
epochs: 3 val loss: 3.595703125  val f1:0.14286  lr: 0.00019055271893511717 batch: 16
epochs: 4 train loss: 0.08477783203125  train f1: 1.00000  lr: 0.00019055271893511717 batch: 16 
epochs: 4 val loss: 3.6328125  val f1:0.14286  lr: 0.00019055271893511717 batch: 16
epochs: 5 train loss: 0.004734039306640625  train f1: 1.00000  lr: 0.00019055271893511717 batch: 16 
epochs: 5 val loss: 3.669921875  val f1:0.14286  lr: 0.00019055271893511717 batch: 16
epochs: 6 train loss: 0.0018329620361328125  train f1: 1.00000  lr: 0.00019055271893511717 batch: 16 
epochs: 6 val loss: 3.703125  val f1:0.16667  lr: 0.00019055271893511717 batch: 16
epochs: 7 train loss: 0.0014286041259765625  train f1: 1.00000  lr: 0.00019055271893511717 batch: 16 
epochs: 7 val loss: 3.72265625  val f1:0.14286  lr: 0.00019055271893511717 batch: 16
epochs: 8 train loss: 0.0012121200561523438  train f1: 1.00000  lr: 0.00019055271893511717 batch: 16 
epochs: 8 val loss: 3.728515625  val f1:0.14286  lr: 0.00019055271893511717 batch: 16
epochs: 9 train loss: 0.0010862350463867188  train f1: 1.00000  lr: 0.00019055271893511717 batch: 16 
epochs: 9 val loss: 3.751953125  val f1:0.12500  lr: 0.00019055271893511717 batch: 16
epochs: 10 train loss: 0.0011491775512695312  train f1: 1.00000  lr: 0.00019055271893511717 batch: 16 
epochs: 10 val loss: 3.763671875  val f1:0.12500  lr: 0.00019055271893511717 batch: 16
epochs: 11 train loss: 0.0009713172912597656  train f1: 1.00000  lr: 0.00019055271893511717 batch: 16 
epochs: 11 val loss: 3.75390625  val f1:0.11111  lr: 0.00019055271893511717 batch: 16
epochs: 12 train loss: 0.00077056884765625  train f1: 1.00000  lr: 0.00019055271893511717 batch: 16 
epochs: 12 val loss: 3.748046875  val f1:0.11111  lr: 0.00019055271893511717 batch: 16
epochs: 13 train loss: 0.0007276535034179688  train f1: 1.00000  lr: 0.00019055271893511717 batch: 16 
epochs: 13 val loss: 3.744140625  val f1:0.11111  lr: 0.00019055271893511717 batch: 16
epochs: 14 train loss: 0.0008907318115234375  train f1: 1.00000  lr: 0.00019055271893511717 batch: 16 
epochs: 14 val loss: 3.732421875  val f1:0.11111  lr: 0.00019055271893511717 batch: 16
epochs: 0 train loss: 4.4375  train f1: 0.00000  lr: 0.0036882872340639377 batch: 25 
epochs: 0 val loss: 4.6015625  val f1:0.00000  lr: 0.0036882872340639377 batch: 25
epochs: 1 train loss: 4.3359375  train f1: 0.00000  lr: 0.0036882872340639377 batch: 25 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.0036882872340639377 batch: 25
epochs: 2 train loss: 1.2294921875  train f1: 0.50000  lr: 0.0036882872340639377 batch: 25 
epochs: 2 val loss: nan  val f1:0.00000  lr: 0.0036882872340639377 batch: 25
epochs: 3 train loss: 1.19921875  train f1: 1.00000  lr: 0.0036882872340639377 batch: 25 
epochs: 3 val loss: 26288.0  val f1:0.06667  lr: 0.0036882872340639377 batch: 25
epochs: 4 train loss: 0.76123046875  train f1: 1.00000  lr: 0.0036882872340639377 batch: 25 
epochs: 4 val loss: nan  val f1:0.00000  lr: 0.0036882872340639377 batch: 25
epochs: 5 train loss: 2.98046875  train f1: 0.50000  lr: 0.0036882872340639377 batch: 25 
epochs: 5 val loss: nan  val f1:0.00000  lr: 0.0036882872340639377 batch: 25
epochs: 6 train loss: 4.15234375  train f1: 0.50000  lr: 0.0036882872340639377 batch: 25 
epochs: 6 val loss: nan  val f1:0.00000  lr: 0.0036882872340639377 batch: 25
epochs: 0 train loss: 4.63671875  train f1: 0.00000  lr: 7.872545639219921e-05 batch: 17 
epochs: 0 val loss: 5.125  val f1:0.00000  lr: 7.872545639219921e-05 batch: 17
epochs: 1 train loss: 4.4921875  train f1: 0.00000  lr: 7.872545639219921e-05 batch: 17 
epochs: 1 val loss: 4.6171875  val f1:0.00000  lr: 7.872545639219921e-05 batch: 17
epochs: 2 train loss: 1.0859375  train f1: 1.00000  lr: 7.872545639219921e-05 batch: 17 
epochs: 2 val loss: 4.375  val f1:0.00000  lr: 7.872545639219921e-05 batch: 17
epochs: 3 train loss: 0.52392578125  train f1: 1.00000  lr: 7.872545639219921e-05 batch: 17 
epochs: 3 val loss: 4.4609375  val f1:0.00000  lr: 7.872545639219921e-05 batch: 17
epochs: 0 train loss: 4.82421875  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 4.953125  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 1 train loss: 4.86328125  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 1 val loss: 4.49609375  val f1:0.12500  lr: 0.0006833364758030707 batch: 32
epochs: 2 train loss: 0.284423828125  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 2 val loss: 47.6875  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 3 train loss: 1.0966796875  train f1: 0.66667  lr: 0.0006833364758030707 batch: 32 
epochs: 3 val loss: 6.99609375  val f1:0.12500  lr: 0.0006833364758030707 batch: 32
epochs: 4 train loss: 0.99560546875  train f1: 0.50000  lr: 0.0006833364758030707 batch: 32 
epochs: 4 val loss: 6.8125  val f1:0.14286  lr: 0.0006833364758030707 batch: 32
epochs: 5 train loss: 0.0013828277587890625  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 5 val loss: 6.22265625  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 6 train loss: 0.00029540061950683594  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 6 val loss: 5.75390625  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 7 train loss: 0.0001838207244873047  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 7 val loss: 5.3671875  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.59765625  train f1: 0.00000  lr: 0.0006404180562189256 batch: 32 
epochs: 0 val loss: 4.859375  val f1:0.00000  lr: 0.0006404180562189256 batch: 32
epochs: 1 train loss: 4.484375  train f1: 0.00000  lr: 0.0006404180562189256 batch: 32 
epochs: 1 val loss: 4.02734375  val f1:0.11111  lr: 0.0006404180562189256 batch: 32
epochs: 2 train loss: 0.215087890625  train f1: 1.00000  lr: 0.0006404180562189256 batch: 32 
epochs: 2 val loss: 17.421875  val f1:0.16667  lr: 0.0006404180562189256 batch: 32
epochs: 3 train loss: 1.642578125  train f1: 0.50000  lr: 0.0006404180562189256 batch: 32 
epochs: 3 val loss: 17.734375  val f1:0.16667  lr: 0.0006404180562189256 batch: 32
epochs: 4 train loss: 0.0018138885498046875  train f1: 1.00000  lr: 0.0006404180562189256 batch: 32 
epochs: 4 val loss: 14.5  val f1:0.16667  lr: 0.0006404180562189256 batch: 32
epochs: 5 train loss: 0.00035858154296875  train f1: 1.00000  lr: 0.0006404180562189256 batch: 32 
epochs: 5 val loss: 12.0390625  val f1:0.16667  lr: 0.0006404180562189256 batch: 32
epochs: 6 train loss: 0.00018799304962158203  train f1: 1.00000  lr: 0.0006404180562189256 batch: 32 
epochs: 6 val loss: 10.296875  val f1:0.16667  lr: 0.0006404180562189256 batch: 32
epochs: 7 train loss: 0.00021028518676757812  train f1: 1.00000  lr: 0.0006404180562189256 batch: 32 
epochs: 7 val loss: 8.7265625  val f1:0.16667  lr: 0.0006404180562189256 batch: 32
epochs: 0 train loss: 4.140625  train f1: 0.00000  lr: 0.001343125484622568 batch: 32 
epochs: 0 val loss: 5.15234375  val f1:0.00000  lr: 0.001343125484622568 batch: 32
epochs: 1 train loss: 4.09765625  train f1: 0.00000  lr: 0.001343125484622568 batch: 32 
epochs: 1 val loss: 60.21875  val f1:0.00000  lr: 0.001343125484622568 batch: 32
epochs: 2 train loss: 1.12890625  train f1: 0.50000  lr: 0.001343125484622568 batch: 32 
epochs: 2 val loss: 45.625  val f1:0.00000  lr: 0.001343125484622568 batch: 32
epochs: 3 train loss: 1.10546875  train f1: 0.50000  lr: 0.001343125484622568 batch: 32 
epochs: 3 val loss: 44.75  val f1:0.00000  lr: 0.001343125484622568 batch: 32
epochs: 0 train loss: 3.953125  train f1: 0.00000  lr: 0.005219887999531381 batch: 24 
epochs: 0 val loss: 5.0234375  val f1:0.00000  lr: 0.005219887999531381 batch: 24
epochs: 1 train loss: 3.8984375  train f1: 0.00000  lr: 0.005219887999531381 batch: 24 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.005219887999531381 batch: 24
epochs: 2 train loss: 3.392578125  train f1: 0.50000  lr: 0.005219887999531381 batch: 24 
epochs: 2 val loss: nan  val f1:0.00000  lr: 0.005219887999531381 batch: 24
epochs: 3 train loss: 3.966796875  train f1: 0.50000  lr: 0.005219887999531381 batch: 24 
epochs: 3 val loss: nan  val f1:0.00000  lr: 0.005219887999531381 batch: 24
epochs: 0 train loss: 4.80078125  train f1: 0.00000  lr: 0.0006901178163233586 batch: 32 
epochs: 0 val loss: 5.23046875  val f1:0.00000  lr: 0.0006901178163233586 batch: 32
epochs: 1 train loss: 4.84375  train f1: 0.00000  lr: 0.0006901178163233586 batch: 32 
epochs: 1 val loss: 5.05078125  val f1:0.00000  lr: 0.0006901178163233586 batch: 32
epochs: 2 train loss: 4.703125  train f1: 0.00000  lr: 0.0006901178163233586 batch: 32 
epochs: 2 val loss: 4.84765625  val f1:0.00000  lr: 0.0006901178163233586 batch: 32
epochs: 3 train loss: 4.56640625  train f1: 0.00000  lr: 0.0006901178163233586 batch: 32 
epochs: 3 val loss: 4.7109375  val f1:0.00000  lr: 0.0006901178163233586 batch: 32
epochs: 0 train loss: 4.71875  train f1: 0.00000  lr: 0.00840798083880766 batch: 11 
epochs: 0 val loss: 4.265625  val f1:0.12500  lr: 0.00840798083880766 batch: 11
epochs: 1 train loss: 4.5078125  train f1: 0.00000  lr: 0.00840798083880766 batch: 11 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.00840798083880766 batch: 11
epochs: 2 train loss: 15.2265625  train f1: 0.00000  lr: 0.00840798083880766 batch: 11 
epochs: 2 val loss: nan  val f1:0.00000  lr: 0.00840798083880766 batch: 11
epochs: 3 train loss: 21.3125  train f1: 0.00000  lr: 0.00840798083880766 batch: 11 
epochs: 3 val loss: nan  val f1:0.00000  lr: 0.00840798083880766 batch: 11
epochs: 4 train loss: 18.0625  train f1: 0.00000  lr: 0.00840798083880766 batch: 11 
epochs: 4 val loss: nan  val f1:0.00000  lr: 0.00840798083880766 batch: 11
epochs: 5 train loss: 19.859375  train f1: 0.00000  lr: 0.00840798083880766 batch: 11 
epochs: 5 val loss: nan  val f1:0.00000  lr: 0.00840798083880766 batch: 11
epochs: 6 train loss: 18.984375  train f1: 0.00000  lr: 0.00840798083880766 batch: 11 
epochs: 6 val loss: nan  val f1:0.00000  lr: 0.00840798083880766 batch: 11
epochs: 0 train loss: 4.34765625  train f1: 0.00000  lr: 0.00045156429679154653 batch: 30 
epochs: 0 val loss: 4.91796875  val f1:0.00000  lr: 0.00045156429679154653 batch: 30
epochs: 1 train loss: 4.3515625  train f1: 0.00000  lr: 0.00045156429679154653 batch: 30 
epochs: 1 val loss: 4.25  val f1:0.12500  lr: 0.00045156429679154653 batch: 30
epochs: 2 train loss: 0.145263671875  train f1: 1.00000  lr: 0.00045156429679154653 batch: 30 
epochs: 2 val loss: 5.28515625  val f1:0.14286  lr: 0.00045156429679154653 batch: 30
epochs: 3 train loss: 0.74072265625  train f1: 1.00000  lr: 0.00045156429679154653 batch: 30 
epochs: 3 val loss: 3.80859375  val f1:0.12500  lr: 0.00045156429679154653 batch: 30
epochs: 4 train loss: 1.166015625  train f1: 1.00000  lr: 0.00045156429679154653 batch: 30 
epochs: 4 val loss: 15.2265625  val f1:0.00000  lr: 0.00045156429679154653 batch: 30
epochs: 5 train loss: 0.00011396408081054688  train f1: 1.00000  lr: 0.00045156429679154653 batch: 30 
epochs: 5 val loss: 12.2421875  val f1:0.00000  lr: 0.00045156429679154653 batch: 30
epochs: 6 train loss: 3.981590270996094e-05  train f1: 1.00000  lr: 0.00045156429679154653 batch: 30 
epochs: 6 val loss: 9.5  val f1:0.00000  lr: 0.00045156429679154653 batch: 30
epochs: 7 train loss: 2.771615982055664e-05  train f1: 1.00000  lr: 0.00045156429679154653 batch: 30 
epochs: 7 val loss: 7.18359375  val f1:0.00000  lr: 0.00045156429679154653 batch: 30
epochs: 0 train loss: 4.40625  train f1: 0.00000  lr: 0.002131623602228667 batch: 32 
epochs: 0 val loss: 5.484375  val f1:0.00000  lr: 0.002131623602228667 batch: 32
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.002131623602228667 batch: 32 
epochs: 1 val loss: 297.75  val f1:0.00000  lr: 0.002131623602228667 batch: 32
epochs: 0 train loss: 4.93359375  train f1: 0.00000  lr: 0.0003902069137297601 batch: 26 
epochs: 0 val loss: 4.484375  val f1:0.00000  lr: 0.0003902069137297601 batch: 26
epochs: 1 train loss: 4.9453125  train f1: 0.00000  lr: 0.0003902069137297601 batch: 26 
epochs: 1 val loss: 3.955078125  val f1:0.12500  lr: 0.0003902069137297601 batch: 26
epochs: 2 train loss: 0.270263671875  train f1: 1.00000  lr: 0.0003902069137297601 batch: 26 
epochs: 2 val loss: 3.525390625  val f1:0.14286  lr: 0.0003902069137297601 batch: 26
epochs: 3 train loss: 0.92626953125  train f1: 0.50000  lr: 0.0003902069137297601 batch: 26 
epochs: 3 val loss: 3.78125  val f1:0.14286  lr: 0.0003902069137297601 batch: 26
epochs: 4 train loss: 0.017181396484375  train f1: 1.00000  lr: 0.0003902069137297601 batch: 26 
epochs: 4 val loss: 3.6640625  val f1:0.14286  lr: 0.0003902069137297601 batch: 26
epochs: 5 train loss: 7.784366607666016e-05  train f1: 1.00000  lr: 0.0003902069137297601 batch: 26 
epochs: 5 val loss: 3.52734375  val f1:0.12500  lr: 0.0003902069137297601 batch: 26
epochs: 6 train loss: 0.00024127960205078125  train f1: 1.00000  lr: 0.0003902069137297601 batch: 26 
epochs: 6 val loss: 3.47265625  val f1:0.12500  lr: 0.0003902069137297601 batch: 26
epochs: 7 train loss: 0.00022780895233154297  train f1: 1.00000  lr: 0.0003902069137297601 batch: 26 
epochs: 7 val loss: 3.427734375  val f1:0.12500  lr: 0.0003902069137297601 batch: 26
epochs: 8 train loss: 0.0002073049545288086  train f1: 1.00000  lr: 0.0003902069137297601 batch: 26 
epochs: 8 val loss: 3.39453125  val f1:0.12500  lr: 0.0003902069137297601 batch: 26
epochs: 0 train loss: 4.734375  train f1: 0.00000  lr: 1.0178739005095555e-05 batch: 30 
epochs: 0 val loss: 4.93359375  val f1:0.00000  lr: 1.0178739005095555e-05 batch: 30
epochs: 1 train loss: 4.76171875  train f1: 0.00000  lr: 1.0178739005095555e-05 batch: 30 
epochs: 1 val loss: 4.9921875  val f1:0.00000  lr: 1.0178739005095555e-05 batch: 30
epochs: 0 train loss: 4.5546875  train f1: 0.00000  lr: 0.01289603862061604 batch: 22 
epochs: 0 val loss: 5.50390625  val f1:0.00000  lr: 0.01289603862061604 batch: 22
epochs: 1 train loss: 4.4609375  train f1: 0.00000  lr: 0.01289603862061604 batch: 22 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.01289603862061604 batch: 22
epochs: 0 train loss: 4.671875  train f1: 0.00000  lr: 5.4244216159758934e-05 batch: 8 
epochs: 0 val loss: 5.5546875  val f1:0.00000  lr: 5.4244216159758934e-05 batch: 8
epochs: 1 train loss: 4.46484375  train f1: 0.00000  lr: 5.4244216159758934e-05 batch: 8 
epochs: 1 val loss: 5.1171875  val f1:0.00000  lr: 5.4244216159758934e-05 batch: 8
epochs: 0 train loss: 4.8671875  train f1: 0.00000  lr: 0.0023432523464128876 batch: 18 
epochs: 0 val loss: 4.25390625  val f1:0.00000  lr: 0.0023432523464128876 batch: 18
epochs: 1 train loss: 4.81640625  train f1: 0.00000  lr: 0.0023432523464128876 batch: 18 
epochs: 1 val loss: 3.845703125  val f1:0.11111  lr: 0.0023432523464128876 batch: 18
epochs: 2 train loss: 0.51611328125  train f1: 1.00000  lr: 0.0023432523464128876 batch: 18 
epochs: 2 val loss: 4.265625  val f1:0.14286  lr: 0.0023432523464128876 batch: 18
epochs: 3 train loss: 0.1636962890625  train f1: 1.00000  lr: 0.0023432523464128876 batch: 18 
epochs: 3 val loss: 4.47265625  val f1:0.14286  lr: 0.0023432523464128876 batch: 18
epochs: 4 train loss: 0.0010004043579101562  train f1: 1.00000  lr: 0.0023432523464128876 batch: 18 
epochs: 4 val loss: 5.19140625  val f1:0.16667  lr: 0.0023432523464128876 batch: 18
epochs: 5 train loss: 0.0002608299255371094  train f1: 1.00000  lr: 0.0023432523464128876 batch: 18 
epochs: 5 val loss: 6.33203125  val f1:0.16667  lr: 0.0023432523464128876 batch: 18
epochs: 6 train loss: 0.0002493858337402344  train f1: 1.00000  lr: 0.0023432523464128876 batch: 18 
epochs: 6 val loss: 7.578125  val f1:0.16667  lr: 0.0023432523464128876 batch: 18
epochs: 7 train loss: 0.00035381317138671875  train f1: 1.00000  lr: 0.0023432523464128876 batch: 18 
epochs: 7 val loss: 8.5546875  val f1:0.16667  lr: 0.0023432523464128876 batch: 18
epochs: 8 train loss: 0.0003647804260253906  train f1: 1.00000  lr: 0.0023432523464128876 batch: 18 
epochs: 8 val loss: 9.1953125  val f1:0.16667  lr: 0.0023432523464128876 batch: 18
epochs: 9 train loss: 0.00038909912109375  train f1: 1.00000  lr: 0.0023432523464128876 batch: 18 
epochs: 9 val loss: 9.6171875  val f1:0.16667  lr: 0.0023432523464128876 batch: 18
epochs: 10 train loss: 0.00022721290588378906  train f1: 1.00000  lr: 0.0023432523464128876 batch: 18 
epochs: 10 val loss: 9.8359375  val f1:0.16667  lr: 0.0023432523464128876 batch: 18
epochs: 0 train loss: 4.6796875  train f1: 0.00000  lr: 0.002027945655538124 batch: 17 
epochs: 0 val loss: 4.8828125  val f1:0.00000  lr: 0.002027945655538124 batch: 17
epochs: 1 train loss: 4.546875  train f1: 0.00000  lr: 0.002027945655538124 batch: 17 
epochs: 1 val loss: 4.21875  val f1:0.12500  lr: 0.002027945655538124 batch: 17
epochs: 2 train loss: 0.224609375  train f1: 1.00000  lr: 0.002027945655538124 batch: 17 
epochs: 2 val loss: 4.41796875  val f1:0.11111  lr: 0.002027945655538124 batch: 17
epochs: 3 train loss: 0.359619140625  train f1: 1.00000  lr: 0.002027945655538124 batch: 17 
epochs: 3 val loss: 4.59765625  val f1:0.14286  lr: 0.002027945655538124 batch: 17
epochs: 4 train loss: 0.0001552104949951172  train f1: 1.00000  lr: 0.002027945655538124 batch: 17 
epochs: 4 val loss: 5.24609375  val f1:0.14286  lr: 0.002027945655538124 batch: 17
epochs: 5 train loss: 0.00016105175018310547  train f1: 1.00000  lr: 0.002027945655538124 batch: 17 
epochs: 5 val loss: 5.83203125  val f1:0.14286  lr: 0.002027945655538124 batch: 17
epochs: 6 train loss: 0.0001506805419921875  train f1: 1.00000  lr: 0.002027945655538124 batch: 17 
epochs: 6 val loss: 6.2265625  val f1:0.14286  lr: 0.002027945655538124 batch: 17
epochs: 7 train loss: 0.0001926422119140625  train f1: 1.00000  lr: 0.002027945655538124 batch: 17 
epochs: 7 val loss: 6.40234375  val f1:0.16667  lr: 0.002027945655538124 batch: 17
epochs: 8 train loss: 0.0002162456512451172  train f1: 1.00000  lr: 0.002027945655538124 batch: 17 
epochs: 8 val loss: 6.3984375  val f1:0.16667  lr: 0.002027945655538124 batch: 17
epochs: 9 train loss: 0.0002582073211669922  train f1: 1.00000  lr: 0.002027945655538124 batch: 17 
epochs: 9 val loss: 6.33984375  val f1:0.16667  lr: 0.002027945655538124 batch: 17
epochs: 10 train loss: 0.0004329681396484375  train f1: 1.00000  lr: 0.002027945655538124 batch: 17 
epochs: 10 val loss: 6.19140625  val f1:0.16667  lr: 0.002027945655538124 batch: 17
epochs: 0 train loss: 4.8359375  train f1: 0.00000  lr: 0.00042221368130464985 batch: 15 
epochs: 0 val loss: 5.703125  val f1:0.00000  lr: 0.00042221368130464985 batch: 15
epochs: 1 train loss: 4.83203125  train f1: 0.00000  lr: 0.00042221368130464985 batch: 15 
epochs: 1 val loss: 5.375  val f1:0.00000  lr: 0.00042221368130464985 batch: 15
epochs: 0 train loss: 4.5  train f1: 0.00000  lr: 0.0027456444798932603 batch: 19 
epochs: 0 val loss: 4.94921875  val f1:0.00000  lr: 0.0027456444798932603 batch: 19
epochs: 1 train loss: 4.625  train f1: 0.00000  lr: 0.0027456444798932603 batch: 19 
epochs: 1 val loss: 4.41796875  val f1:0.14286  lr: 0.0027456444798932603 batch: 19
epochs: 2 train loss: 0.179931640625  train f1: 1.00000  lr: 0.0027456444798932603 batch: 19 
epochs: 2 val loss: 4.4453125  val f1:0.14286  lr: 0.0027456444798932603 batch: 19
epochs: 3 train loss: 0.0087432861328125  train f1: 1.00000  lr: 0.0027456444798932603 batch: 19 
epochs: 3 val loss: 4.85546875  val f1:0.16667  lr: 0.0027456444798932603 batch: 19
epochs: 4 train loss: 0.0010309219360351562  train f1: 1.00000  lr: 0.0027456444798932603 batch: 19 
epochs: 4 val loss: 5.3359375  val f1:0.16667  lr: 0.0027456444798932603 batch: 19
epochs: 5 train loss: 0.0006833076477050781  train f1: 1.00000  lr: 0.0027456444798932603 batch: 19 
epochs: 5 val loss: 6.125  val f1:0.14286  lr: 0.0027456444798932603 batch: 19
epochs: 6 train loss: 9.882450103759766e-05  train f1: 1.00000  lr: 0.0027456444798932603 batch: 19 
epochs: 6 val loss: 6.9296875  val f1:0.14286  lr: 0.0027456444798932603 batch: 19
epochs: 7 train loss: 9.02414321899414e-05  train f1: 1.00000  lr: 0.0027456444798932603 batch: 19 
epochs: 7 val loss: 7.57421875  val f1:0.14286  lr: 0.0027456444798932603 batch: 19
epochs: 8 train loss: 0.0008087158203125  train f1: 1.00000  lr: 0.0027456444798932603 batch: 19 
epochs: 8 val loss: 8.421875  val f1:0.14286  lr: 0.0027456444798932603 batch: 19
epochs: 9 train loss: 0.00038909912109375  train f1: 1.00000  lr: 0.0027456444798932603 batch: 19 
epochs: 9 val loss: 9.203125  val f1:0.14286  lr: 0.0027456444798932603 batch: 19
epochs: 10 train loss: 3.361701965332031e-05  train f1: 1.00000  lr: 0.0027456444798932603 batch: 19 
epochs: 10 val loss: 9.796875  val f1:0.14286  lr: 0.0027456444798932603 batch: 19
epochs: 11 train loss: 1.8656253814697266e-05  train f1: 1.00000  lr: 0.0027456444798932603 batch: 19 
epochs: 11 val loss: 10.375  val f1:0.14286  lr: 0.0027456444798932603 batch: 19
epochs: 12 train loss: 1.8537044525146484e-05  train f1: 1.00000  lr: 0.0027456444798932603 batch: 19 
epochs: 12 val loss: 11.0625  val f1:0.14286  lr: 0.0027456444798932603 batch: 19
epochs: 13 train loss: 1.3232231140136719e-05  train f1: 1.00000  lr: 0.0027456444798932603 batch: 19 
epochs: 13 val loss: 11.6640625  val f1:0.14286  lr: 0.0027456444798932603 batch: 19
epochs: 0 train loss: 4.2578125  train f1: 0.00000  lr: 0.0013743529317487013 batch: 18 
epochs: 0 val loss: 4.203125  val f1:0.00000  lr: 0.0013743529317487013 batch: 18
epochs: 1 train loss: 4.19140625  train f1: 0.16667  lr: 0.0013743529317487013 batch: 18 
epochs: 1 val loss: 3.59375  val f1:0.12500  lr: 0.0013743529317487013 batch: 18
epochs: 2 train loss: 0.483642578125  train f1: 1.00000  lr: 0.0013743529317487013 batch: 18 
epochs: 2 val loss: 3.478515625  val f1:0.12500  lr: 0.0013743529317487013 batch: 18
epochs: 3 train loss: 0.095947265625  train f1: 1.00000  lr: 0.0013743529317487013 batch: 18 
epochs: 3 val loss: 3.62109375  val f1:0.11111  lr: 0.0013743529317487013 batch: 18
epochs: 0 train loss: 5.1875  train f1: 0.00000  lr: 0.00592540293711811 batch: 14 
epochs: 0 val loss: 5.01171875  val f1:0.00000  lr: 0.00592540293711811 batch: 14
epochs: 1 train loss: 4.984375  train f1: 0.00000  lr: 0.00592540293711811 batch: 14 
epochs: 1 val loss: 4.98046875  val f1:0.14286  lr: 0.00592540293711811 batch: 14
epochs: 2 train loss: 0.69384765625  train f1: 1.00000  lr: 0.00592540293711811 batch: 14 
epochs: 2 val loss: 7.4921875  val f1:0.11111  lr: 0.00592540293711811 batch: 14
epochs: 3 train loss: 0.63427734375  train f1: 1.00000  lr: 0.00592540293711811 batch: 14 
epochs: 3 val loss: 7.359375  val f1:0.08333  lr: 0.00592540293711811 batch: 14
epochs: 4 train loss: 0.0005612373352050781  train f1: 1.00000  lr: 0.00592540293711811 batch: 14 
epochs: 4 val loss: 16.171875  val f1:0.00000  lr: 0.00592540293711811 batch: 14
epochs: 5 train loss: 0.005100250244140625  train f1: 1.00000  lr: 0.00592540293711811 batch: 14 
epochs: 5 val loss: 28.453125  val f1:0.00000  lr: 0.00592540293711811 batch: 14
epochs: 6 train loss: 0.0019741058349609375  train f1: 1.00000  lr: 0.00592540293711811 batch: 14 
epochs: 6 val loss: 41.1875  val f1:0.00000  lr: 0.00592540293711811 batch: 14
epochs: 7 train loss: 0.00042319297790527344  train f1: 1.00000  lr: 0.00592540293711811 batch: 14 
epochs: 7 val loss: 61.5  val f1:0.00000  lr: 0.00592540293711811 batch: 14
epochs: 8 train loss: 1.6629695892333984e-05  train f1: 1.00000  lr: 0.00592540293711811 batch: 14 
epochs: 8 val loss: 84.375  val f1:0.00000  lr: 0.00592540293711811 batch: 14
epochs: 0 train loss: 4.625  train f1: 0.00000  lr: 0.013230464415115393 batch: 13 
epochs: 0 val loss: 5.33203125  val f1:0.00000  lr: 0.013230464415115393 batch: 13
epochs: 1 train loss: 4.6484375  train f1: 0.00000  lr: 0.013230464415115393 batch: 13 
epochs: 1 val loss: 5.73828125  val f1:0.00000  lr: 0.013230464415115393 batch: 13
epochs: 0 train loss: 4.30859375  train f1: 0.00000  lr: 0.0007097672263068214 batch: 18 
epochs: 0 val loss: 4.9140625  val f1:0.00000  lr: 0.0007097672263068214 batch: 18
epochs: 1 train loss: 4.3046875  train f1: 0.00000  lr: 0.0007097672263068214 batch: 18 
epochs: 1 val loss: 4.578125  val f1:0.00000  lr: 0.0007097672263068214 batch: 18
epochs: 0 train loss: 4.77734375  train f1: 0.00000  lr: 0.00158124138033465 batch: 20 
epochs: 0 val loss: 4.7578125  val f1:0.00000  lr: 0.00158124138033465 batch: 20
epochs: 1 train loss: 4.9375  train f1: 0.00000  lr: 0.00158124138033465 batch: 20 
epochs: 1 val loss: 4.703125  val f1:0.00000  lr: 0.00158124138033465 batch: 20
epochs: 0 train loss: 4.05859375  train f1: 0.00000  lr: 0.0003121613473482103 batch: 16 
epochs: 0 val loss: 5.234375  val f1:0.00000  lr: 0.0003121613473482103 batch: 16
epochs: 1 train loss: 4.078125  train f1: 0.11111  lr: 0.0003121613473482103 batch: 16 
epochs: 1 val loss: 4.90625  val f1:0.00000  lr: 0.0003121613473482103 batch: 16
epochs: 0 train loss: 4.21484375  train f1: 0.00000  lr: 0.0030199638771238797 batch: 12 
epochs: 0 val loss: 4.94921875  val f1:0.00000  lr: 0.0030199638771238797 batch: 12
epochs: 1 train loss: 4.28125  train f1: 0.00000  lr: 0.0030199638771238797 batch: 12 
epochs: 1 val loss: 5.08203125  val f1:0.12500  lr: 0.0030199638771238797 batch: 12
epochs: 2 train loss: 0.2015380859375  train f1: 1.00000  lr: 0.0030199638771238797 batch: 12 
epochs: 2 val loss: 4.9765625  val f1:0.12500  lr: 0.0030199638771238797 batch: 12
epochs: 3 train loss: 0.282958984375  train f1: 1.00000  lr: 0.0030199638771238797 batch: 12 
epochs: 3 val loss: 10.71875  val f1:0.00000  lr: 0.0030199638771238797 batch: 12
epochs: 4 train loss: 2.5033950805664062e-06  train f1: 1.00000  lr: 0.0030199638771238797 batch: 12 
epochs: 4 val loss: 17.515625  val f1:0.00000  lr: 0.0030199638771238797 batch: 12
epochs: 0 train loss: 4.7109375  train f1: 0.00000  lr: 0.0008569240852679145 batch: 22 
epochs: 0 val loss: 5.1328125  val f1:0.00000  lr: 0.0008569240852679145 batch: 22
epochs: 1 train loss: 4.6484375  train f1: 0.00000  lr: 0.0008569240852679145 batch: 22 
epochs: 1 val loss: 5.08203125  val f1:0.00000  lr: 0.0008569240852679145 batch: 22
epochs: 0 train loss: 4.828125  train f1: 0.00000  lr: 0.0002492955676300096 batch: 28 
epochs: 0 val loss: 4.5234375  val f1:0.00000  lr: 0.0002492955676300096 batch: 28
epochs: 1 train loss: 4.65234375  train f1: 0.00000  lr: 0.0002492955676300096 batch: 28 
epochs: 1 val loss: 4.34765625  val f1:0.00000  lr: 0.0002492955676300096 batch: 28
epochs: 0 train loss: 4.88671875  train f1: 0.00000  lr: 0.00012140680250705733 batch: 26 
epochs: 0 val loss: 4.09765625  val f1:0.00000  lr: 0.00012140680250705733 batch: 26
epochs: 1 train loss: 4.84765625  train f1: 0.00000  lr: 0.00012140680250705733 batch: 26 
epochs: 1 val loss: 4.046875  val f1:0.00000  lr: 0.00012140680250705733 batch: 26
epochs: 0 train loss: 3.87890625  train f1: 0.20000  lr: 1.9238288281921786e-05 batch: 29 
epochs: 0 val loss: 4.62109375  val f1:0.00000  lr: 1.9238288281921786e-05 batch: 29
epochs: 1 train loss: 3.83984375  train f1: 0.13333  lr: 1.9238288281921786e-05 batch: 29 
epochs: 1 val loss: 4.57421875  val f1:0.00000  lr: 1.9238288281921786e-05 batch: 29
epochs: 0 train loss: 4.28125  train f1: 0.00000  lr: 4.933182637821975e-05 batch: 30 
epochs: 0 val loss: 4.09375  val f1:0.00000  lr: 4.933182637821975e-05 batch: 30
epochs: 1 train loss: 4.37890625  train f1: 0.00000  lr: 4.933182637821975e-05 batch: 30 
epochs: 1 val loss: 4.046875  val f1:0.08333  lr: 4.933182637821975e-05 batch: 30
epochs: 0 train loss: 4.28515625  train f1: 0.00000  lr: 0.002343365159815967 batch: 19 
epochs: 0 val loss: 4.875  val f1:0.00000  lr: 0.002343365159815967 batch: 19
epochs: 1 train loss: 4.41015625  train f1: 0.00000  lr: 0.002343365159815967 batch: 19 
epochs: 1 val loss: 4.03515625  val f1:0.12500  lr: 0.002343365159815967 batch: 19
epochs: 2 train loss: 0.141845703125  train f1: 1.00000  lr: 0.002343365159815967 batch: 19 
epochs: 2 val loss: 4.484375  val f1:0.14286  lr: 0.002343365159815967 batch: 19
epochs: 3 train loss: 0.07220458984375  train f1: 1.00000  lr: 0.002343365159815967 batch: 19 
epochs: 3 val loss: 4.94921875  val f1:0.09524  lr: 0.002343365159815967 batch: 19
epochs: 4 train loss: 2.1457672119140625e-05  train f1: 1.00000  lr: 0.002343365159815967 batch: 19 
epochs: 4 val loss: 5.171875  val f1:0.11111  lr: 0.002343365159815967 batch: 19
epochs: 5 train loss: 8.088350296020508e-05  train f1: 1.00000  lr: 0.002343365159815967 batch: 19 
epochs: 5 val loss: 5.43359375  val f1:0.11111  lr: 0.002343365159815967 batch: 19
epochs: 6 train loss: 0.00015270709991455078  train f1: 1.00000  lr: 0.002343365159815967 batch: 19 
epochs: 6 val loss: 5.8046875  val f1:0.14286  lr: 0.002343365159815967 batch: 19
epochs: 7 train loss: 0.0001556873321533203  train f1: 1.00000  lr: 0.002343365159815967 batch: 19 
epochs: 7 val loss: 6.14453125  val f1:0.14286  lr: 0.002343365159815967 batch: 19
epochs: 8 train loss: 0.00018227100372314453  train f1: 1.00000  lr: 0.002343365159815967 batch: 19 
epochs: 8 val loss: 6.49609375  val f1:0.14286  lr: 0.002343365159815967 batch: 19
epochs: 9 train loss: 0.00010335445404052734  train f1: 1.00000  lr: 0.002343365159815967 batch: 19 
epochs: 9 val loss: 6.91015625  val f1:0.14286  lr: 0.002343365159815967 batch: 19
epochs: 10 train loss: 0.0002593994140625  train f1: 1.00000  lr: 0.002343365159815967 batch: 19 
epochs: 10 val loss: 7.02734375  val f1:0.14286  lr: 0.002343365159815967 batch: 19
epochs: 11 train loss: 8.988380432128906e-05  train f1: 1.00000  lr: 0.002343365159815967 batch: 19 
epochs: 11 val loss: 7.17578125  val f1:0.14286  lr: 0.002343365159815967 batch: 19
epochs: 12 train loss: 5.125999450683594e-05  train f1: 1.00000  lr: 0.002343365159815967 batch: 19 
epochs: 12 val loss: 7.44921875  val f1:0.14286  lr: 0.002343365159815967 batch: 19
epochs: 13 train loss: 3.5762786865234375e-05  train f1: 1.00000  lr: 0.002343365159815967 batch: 19 
epochs: 13 val loss: 7.5390625  val f1:0.14286  lr: 0.002343365159815967 batch: 19
epochs: 14 train loss: 3.075599670410156e-05  train f1: 1.00000  lr: 0.002343365159815967 batch: 19 
epochs: 14 val loss: 7.71875  val f1:0.14286  lr: 0.002343365159815967 batch: 19
epochs: 0 train loss: 4.38671875  train f1: 0.00000  lr: 0.0019461985598849929 batch: 19 
epochs: 0 val loss: 4.9765625  val f1:0.00000  lr: 0.0019461985598849929 batch: 19
epochs: 1 train loss: 4.41796875  train f1: 0.00000  lr: 0.0019461985598849929 batch: 19 
epochs: 1 val loss: 4.17578125  val f1:0.11111  lr: 0.0019461985598849929 batch: 19
epochs: 0 train loss: 4.484375  train f1: 0.00000  lr: 0.003976257098885884 batch: 21 
epochs: 0 val loss: 4.60546875  val f1:0.00000  lr: 0.003976257098885884 batch: 21
epochs: 1 train loss: 4.484375  train f1: 0.00000  lr: 0.003976257098885884 batch: 21 
epochs: 1 val loss: 3.8125  val f1:0.14286  lr: 0.003976257098885884 batch: 21
epochs: 2 train loss: 0.56298828125  train f1: 1.00000  lr: 0.003976257098885884 batch: 21 
epochs: 2 val loss: 13.9609375  val f1:0.00000  lr: 0.003976257098885884 batch: 21
epochs: 3 train loss: 1.3994140625  train f1: 1.00000  lr: 0.003976257098885884 batch: 21 
epochs: 3 val loss: 14.1015625  val f1:0.14286  lr: 0.003976257098885884 batch: 21
epochs: 4 train loss: 1.6689300537109375e-06  train f1: 1.00000  lr: 0.003976257098885884 batch: 21 
epochs: 4 val loss: 15.5234375  val f1:0.14286  lr: 0.003976257098885884 batch: 21
epochs: 5 train loss: 4.76837158203125e-06  train f1: 1.00000  lr: 0.003976257098885884 batch: 21 
epochs: 5 val loss: 16.484375  val f1:0.14286  lr: 0.003976257098885884 batch: 21
epochs: 6 train loss: 8.106231689453125e-06  train f1: 1.00000  lr: 0.003976257098885884 batch: 21 
epochs: 6 val loss: 16.625  val f1:0.14286  lr: 0.003976257098885884 batch: 21
epochs: 7 train loss: 1.4007091522216797e-05  train f1: 1.00000  lr: 0.003976257098885884 batch: 21 
epochs: 7 val loss: 16.3125  val f1:0.14286  lr: 0.003976257098885884 batch: 21
epochs: 8 train loss: 1.7404556274414062e-05  train f1: 1.00000  lr: 0.003976257098885884 batch: 21 
epochs: 8 val loss: 15.921875  val f1:0.14286  lr: 0.003976257098885884 batch: 21
epochs: 9 train loss: 2.4318695068359375e-05  train f1: 1.00000  lr: 0.003976257098885884 batch: 21 
epochs: 9 val loss: 14.9296875  val f1:0.14286  lr: 0.003976257098885884 batch: 21
epochs: 10 train loss: 3.069639205932617e-05  train f1: 1.00000  lr: 0.003976257098885884 batch: 21 
epochs: 10 val loss: 13.5546875  val f1:0.14286  lr: 0.003976257098885884 batch: 21
epochs: 11 train loss: 3.337860107421875e-05  train f1: 1.00000  lr: 0.003976257098885884 batch: 21 
epochs: 11 val loss: 11.6953125  val f1:0.14286  lr: 0.003976257098885884 batch: 21
epochs: 12 train loss: 5.14984130859375e-05  train f1: 1.00000  lr: 0.003976257098885884 batch: 21 
epochs: 12 val loss: 9.6953125  val f1:0.14286  lr: 0.003976257098885884 batch: 21
epochs: 13 train loss: 2.3484230041503906e-05  train f1: 1.00000  lr: 0.003976257098885884 batch: 21 
epochs: 13 val loss: 7.76171875  val f1:0.14286  lr: 0.003976257098885884 batch: 21
epochs: 0 train loss: 5.3671875  train f1: 0.00000  lr: 0.004457593395538327 batch: 16 
epochs: 0 val loss: 5.24609375  val f1:0.00000  lr: 0.004457593395538327 batch: 16
epochs: 1 train loss: 5.3046875  train f1: 0.00000  lr: 0.004457593395538327 batch: 16 
epochs: 1 val loss: 4.2421875  val f1:0.12500  lr: 0.004457593395538327 batch: 16
epochs: 2 train loss: 0.74658203125  train f1: 1.00000  lr: 0.004457593395538327 batch: 16 
epochs: 2 val loss: 8.40625  val f1:0.16667  lr: 0.004457593395538327 batch: 16
epochs: 3 train loss: 0.830078125  train f1: 1.00000  lr: 0.004457593395538327 batch: 16 
epochs: 3 val loss: 11.546875  val f1:0.16667  lr: 0.004457593395538327 batch: 16
epochs: 4 train loss: 0.0035953521728515625  train f1: 1.00000  lr: 0.004457593395538327 batch: 16 
epochs: 4 val loss: 13.625  val f1:0.14286  lr: 0.004457593395538327 batch: 16
epochs: 5 train loss: 0.0055999755859375  train f1: 1.00000  lr: 0.004457593395538327 batch: 16 
epochs: 5 val loss: 12.46875  val f1:0.16667  lr: 0.004457593395538327 batch: 16
epochs: 6 train loss: 0.004665374755859375  train f1: 1.00000  lr: 0.004457593395538327 batch: 16 
epochs: 6 val loss: 13.484375  val f1:0.11111  lr: 0.004457593395538327 batch: 16
epochs: 7 train loss: 0.0003101825714111328  train f1: 1.00000  lr: 0.004457593395538327 batch: 16 
epochs: 7 val loss: 16.890625  val f1:0.11111  lr: 0.004457593395538327 batch: 16
epochs: 8 train loss: 0.00011688470840454102  train f1: 1.00000  lr: 0.004457593395538327 batch: 16 
epochs: 8 val loss: 20.890625  val f1:0.00000  lr: 0.004457593395538327 batch: 16
epochs: 9 train loss: 6.318092346191406e-06  train f1: 1.00000  lr: 0.004457593395538327 batch: 16 
epochs: 9 val loss: 22.671875  val f1:0.00000  lr: 0.004457593395538327 batch: 16
epochs: 10 train loss: 3.0338764190673828e-05  train f1: 1.00000  lr: 0.004457593395538327 batch: 16 
epochs: 10 val loss: 24.8125  val f1:0.16667  lr: 0.004457593395538327 batch: 16
epochs: 11 train loss: 2.6226043701171875e-06  train f1: 1.00000  lr: 0.004457593395538327 batch: 16 
epochs: 11 val loss: 26.71875  val f1:0.16667  lr: 0.004457593395538327 batch: 16
epochs: 0 train loss: 4.828125  train f1: 0.00000  lr: 0.01635670714680229 batch: 16 
epochs: 0 val loss: 5.1484375  val f1:0.00000  lr: 0.01635670714680229 batch: 16
epochs: 1 train loss: 4.9140625  train f1: 0.00000  lr: 0.01635670714680229 batch: 16 
epochs: 1 val loss: 77.3125  val f1:0.00000  lr: 0.01635670714680229 batch: 16
epochs: 0 train loss: 3.85546875  train f1: 0.11111  lr: 0.007535383833675359 batch: 17 
epochs: 0 val loss: 4.859375  val f1:0.00000  lr: 0.007535383833675359 batch: 17
epochs: 1 train loss: 3.837890625  train f1: 0.00000  lr: 0.007535383833675359 batch: 17 
epochs: 1 val loss: 4.4765625  val f1:0.00000  lr: 0.007535383833675359 batch: 17
epochs: 0 train loss: 4.87109375  train f1: 0.00000  lr: 0.0005735109686801091 batch: 14 
epochs: 0 val loss: 5.41796875  val f1:0.00000  lr: 0.0005735109686801091 batch: 14
epochs: 1 train loss: 4.9765625  train f1: 0.00000  lr: 0.0005735109686801091 batch: 14 
epochs: 1 val loss: 5.17578125  val f1:0.00000  lr: 0.0005735109686801091 batch: 14
epochs: 0 train loss: 4.5703125  train f1: 0.00000  lr: 0.0010703105846479582 batch: 17 
epochs: 0 val loss: 5.1953125  val f1:0.00000  lr: 0.0010703105846479582 batch: 17
epochs: 1 train loss: 4.6796875  train f1: 0.00000  lr: 0.0010703105846479582 batch: 17 
epochs: 1 val loss: 5.18359375  val f1:0.00000  lr: 0.0010703105846479582 batch: 17
epochs: 0 train loss: 4.96875  train f1: 0.00000  lr: 0.004444718730287059 batch: 21 
epochs: 0 val loss: 5.16796875  val f1:0.00000  lr: 0.004444718730287059 batch: 21
epochs: 1 train loss: 4.85546875  train f1: 0.00000  lr: 0.004444718730287059 batch: 21 
epochs: 1 val loss: 4.37109375  val f1:0.14286  lr: 0.004444718730287059 batch: 21
epochs: 2 train loss: 0.20947265625  train f1: 1.00000  lr: 0.004444718730287059 batch: 21 
epochs: 2 val loss: 4.2578125  val f1:0.12500  lr: 0.004444718730287059 batch: 21
epochs: 3 train loss: 1.3037109375  train f1: 1.00000  lr: 0.004444718730287059 batch: 21 
epochs: 3 val loss: 16.515625  val f1:0.16667  lr: 0.004444718730287059 batch: 21
epochs: 4 train loss: 2.205371856689453e-05  train f1: 1.00000  lr: 0.004444718730287059 batch: 21 
epochs: 4 val loss: 22.59375  val f1:0.16667  lr: 0.004444718730287059 batch: 21
epochs: 5 train loss: 0.0001010894775390625  train f1: 1.00000  lr: 0.004444718730287059 batch: 21 
epochs: 5 val loss: 28.859375  val f1:0.16667  lr: 0.004444718730287059 batch: 21
epochs: 6 train loss: 1.9073486328125e-05  train f1: 1.00000  lr: 0.004444718730287059 batch: 21 
epochs: 6 val loss: 30.890625  val f1:0.16667  lr: 0.004444718730287059 batch: 21
epochs: 7 train loss: 0.0002162456512451172  train f1: 1.00000  lr: 0.004444718730287059 batch: 21 
epochs: 7 val loss: 27.671875  val f1:0.00000  lr: 0.004444718730287059 batch: 21
epochs: 8 train loss: 1.9311904907226562e-05  train f1: 1.00000  lr: 0.004444718730287059 batch: 21 
epochs: 8 val loss: 22.515625  val f1:0.14286  lr: 0.004444718730287059 batch: 21
epochs: 9 train loss: 0.0002465248107910156  train f1: 1.00000  lr: 0.004444718730287059 batch: 21 
epochs: 9 val loss: 21.375  val f1:0.14286  lr: 0.004444718730287059 batch: 21
epochs: 10 train loss: 4.1425228118896484e-05  train f1: 1.00000  lr: 0.004444718730287059 batch: 21 
epochs: 10 val loss: 21.984375  val f1:0.14286  lr: 0.004444718730287059 batch: 21
epochs: 11 train loss: 4.76837158203125e-07  train f1: 1.00000  lr: 0.004444718730287059 batch: 21 
epochs: 11 val loss: 22.203125  val f1:0.14286  lr: 0.004444718730287059 batch: 21
epochs: 12 train loss: 7.152557373046875e-07  train f1: 1.00000  lr: 0.004444718730287059 batch: 21 
epochs: 12 val loss: 21.78125  val f1:0.14286  lr: 0.004444718730287059 batch: 21
epochs: 13 train loss: 1.1920928955078125e-06  train f1: 1.00000  lr: 0.004444718730287059 batch: 21 
epochs: 13 val loss: 22.359375  val f1:0.14286  lr: 0.004444718730287059 batch: 21
epochs: 0 train loss: 5.3828125  train f1: 0.00000  lr: 0.004824123531269283 batch: 15 
epochs: 0 val loss: 5.19921875  val f1:0.00000  lr: 0.004824123531269283 batch: 15
epochs: 1 train loss: 5.375  train f1: 0.00000  lr: 0.004824123531269283 batch: 15 
epochs: 1 val loss: 4.46484375  val f1:0.14286  lr: 0.004824123531269283 batch: 15
epochs: 2 train loss: 0.5927734375  train f1: 1.00000  lr: 0.004824123531269283 batch: 15 
epochs: 2 val loss: 16.3125  val f1:0.00000  lr: 0.004824123531269283 batch: 15
epochs: 3 train loss: 1.1982421875  train f1: 1.00000  lr: 0.004824123531269283 batch: 15 
epochs: 3 val loss: 19.625  val f1:0.16667  lr: 0.004824123531269283 batch: 15
epochs: 4 train loss: 0.0024738311767578125  train f1: 1.00000  lr: 0.004824123531269283 batch: 15 
epochs: 4 val loss: 22.640625  val f1:0.16667  lr: 0.004824123531269283 batch: 15
epochs: 5 train loss: 0.011505126953125  train f1: 1.00000  lr: 0.004824123531269283 batch: 15 
epochs: 5 val loss: 20.40625  val f1:0.11111  lr: 0.004824123531269283 batch: 15
epochs: 6 train loss: 0.0003757476806640625  train f1: 1.00000  lr: 0.004824123531269283 batch: 15 
epochs: 6 val loss: 22.46875  val f1:0.08333  lr: 0.004824123531269283 batch: 15
epochs: 7 train loss: 0.0013341903686523438  train f1: 1.00000  lr: 0.004824123531269283 batch: 15 
epochs: 7 val loss: 33.75  val f1:0.08333  lr: 0.004824123531269283 batch: 15
epochs: 8 train loss: 0.003421783447265625  train f1: 1.00000  lr: 0.004824123531269283 batch: 15 
epochs: 8 val loss: 55.03125  val f1:0.08333  lr: 0.004824123531269283 batch: 15
epochs: 9 train loss: 8.946657180786133e-05  train f1: 1.00000  lr: 0.004824123531269283 batch: 15 
epochs: 9 val loss: 70.3125  val f1:0.08333  lr: 0.004824123531269283 batch: 15
epochs: 10 train loss: 9.119510650634766e-06  train f1: 1.00000  lr: 0.004824123531269283 batch: 15 
epochs: 10 val loss: 81.5  val f1:0.08333  lr: 0.004824123531269283 batch: 15
epochs: 11 train loss: 2.6226043701171875e-06  train f1: 1.00000  lr: 0.004824123531269283 batch: 15 
epochs: 11 val loss: 89.5  val f1:0.11111  lr: 0.004824123531269283 batch: 15
epochs: 12 train loss: 5.960464477539062e-07  train f1: 1.00000  lr: 0.004824123531269283 batch: 15 
epochs: 12 val loss: 88.6875  val f1:0.11111  lr: 0.004824123531269283 batch: 15
epochs: 13 train loss: 2.384185791015625e-07  train f1: 1.00000  lr: 0.004824123531269283 batch: 15 
epochs: 13 val loss: 94.6875  val f1:0.11111  lr: 0.004824123531269283 batch: 15
epochs: 14 train loss: 1.1801719665527344e-05  train f1: 1.00000  lr: 0.004824123531269283 batch: 15 
epochs: 14 val loss: 84.8125  val f1:0.11111  lr: 0.004824123531269283 batch: 15
epochs: 0 train loss: 4.23046875  train f1: 0.00000  lr: 0.022624735084554787 batch: 27 
epochs: 0 val loss: 4.2890625  val f1:0.07143  lr: 0.022624735084554787 batch: 27
epochs: 1 train loss: 4.3046875  train f1: 0.00000  lr: 0.022624735084554787 batch: 27 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.022624735084554787 batch: 27
epochs: 0 train loss: 4.1484375  train f1: 0.00000  lr: 0.00011136608153720044 batch: 31 
epochs: 0 val loss: 5.41015625  val f1:0.00000  lr: 0.00011136608153720044 batch: 31
epochs: 1 train loss: 3.96484375  train f1: 0.16667  lr: 0.00011136608153720044 batch: 31 
epochs: 1 val loss: 5.171875  val f1:0.14286  lr: 0.00011136608153720044 batch: 31
epochs: 2 train loss: 0.57275390625  train f1: 1.00000  lr: 0.00011136608153720044 batch: 31 
epochs: 2 val loss: 4.7421875  val f1:0.14286  lr: 0.00011136608153720044 batch: 31
epochs: 3 train loss: 0.1785888671875  train f1: 1.00000  lr: 0.00011136608153720044 batch: 31 
epochs: 3 val loss: 5.0  val f1:0.14286  lr: 0.00011136608153720044 batch: 31
epochs: 4 train loss: 0.0186309814453125  train f1: 1.00000  lr: 0.00011136608153720044 batch: 31 
epochs: 4 val loss: 4.78515625  val f1:0.16667  lr: 0.00011136608153720044 batch: 31
epochs: 5 train loss: 0.012420654296875  train f1: 1.00000  lr: 0.00011136608153720044 batch: 31 
epochs: 5 val loss: 4.67578125  val f1:0.16667  lr: 0.00011136608153720044 batch: 31
epochs: 0 train loss: 4.32421875  train f1: 0.00000  lr: 0.00010318143525429956 batch: 31 
epochs: 0 val loss: 5.06640625  val f1:0.00000  lr: 0.00010318143525429956 batch: 31
epochs: 1 train loss: 4.4453125  train f1: 0.00000  lr: 0.00010318143525429956 batch: 31 
epochs: 1 val loss: 4.47265625  val f1:0.11111  lr: 0.00010318143525429956 batch: 31
epochs: 0 train loss: 4.6796875  train f1: 0.00000  lr: 0.09682360080788151 batch: 31 
epochs: 0 val loss: 4.734375  val f1:0.00000  lr: 0.09682360080788151 batch: 31
epochs: 1 train loss: 4.6015625  train f1: 0.00000  lr: 0.09682360080788151 batch: 31 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.09682360080788151 batch: 31
epochs: 0 train loss: 4.81640625  train f1: 0.00000  lr: 0.0010417187060348693 batch: 31 
epochs: 0 val loss: 5.296875  val f1:0.00000  lr: 0.0010417187060348693 batch: 31
epochs: 1 train loss: 4.66796875  train f1: 0.00000  lr: 0.0010417187060348693 batch: 31 
epochs: 1 val loss: 5.31640625  val f1:0.00000  lr: 0.0010417187060348693 batch: 31
epochs: 0 train loss: 4.98828125  train f1: 0.00000  lr: 0.0002765097764317202 batch: 29 
epochs: 0 val loss: 5.5  val f1:0.00000  lr: 0.0002765097764317202 batch: 29
epochs: 1 train loss: 4.91796875  train f1: 0.00000  lr: 0.0002765097764317202 batch: 29 
epochs: 1 val loss: 4.6015625  val f1:0.14286  lr: 0.0002765097764317202 batch: 29
epochs: 2 train loss: 0.3759765625  train f1: 1.00000  lr: 0.0002765097764317202 batch: 29 
epochs: 2 val loss: 4.53125  val f1:0.12500  lr: 0.0002765097764317202 batch: 29
epochs: 3 train loss: 0.257080078125  train f1: 1.00000  lr: 0.0002765097764317202 batch: 29 
epochs: 3 val loss: 4.59375  val f1:0.12500  lr: 0.0002765097764317202 batch: 29
epochs: 4 train loss: 0.1845703125  train f1: 1.00000  lr: 0.0002765097764317202 batch: 29 
epochs: 4 val loss: 4.38671875  val f1:0.12500  lr: 0.0002765097764317202 batch: 29
epochs: 5 train loss: 0.04595947265625  train f1: 1.00000  lr: 0.0002765097764317202 batch: 29 
epochs: 5 val loss: 4.40625  val f1:0.12500  lr: 0.0002765097764317202 batch: 29
epochs: 6 train loss: 0.0001316070556640625  train f1: 1.00000  lr: 0.0002765097764317202 batch: 29 
epochs: 6 val loss: 4.35546875  val f1:0.12500  lr: 0.0002765097764317202 batch: 29
epochs: 7 train loss: 0.0001766681671142578  train f1: 1.00000  lr: 0.0002765097764317202 batch: 29 
epochs: 7 val loss: 4.33203125  val f1:0.12500  lr: 0.0002765097764317202 batch: 29
epochs: 8 train loss: 0.000179290771484375  train f1: 1.00000  lr: 0.0002765097764317202 batch: 29 
epochs: 8 val loss: 4.32421875  val f1:0.12500  lr: 0.0002765097764317202 batch: 29
epochs: 0 train loss: 3.994140625  train f1: 0.00000  lr: 0.0016798860839168232 batch: 31 
epochs: 0 val loss: 4.0234375  val f1:0.00000  lr: 0.0016798860839168232 batch: 31
epochs: 1 train loss: 4.12109375  train f1: 0.00000  lr: 0.0016798860839168232 batch: 31 
epochs: 1 val loss: 31.609375  val f1:0.00000  lr: 0.0016798860839168232 batch: 31
epochs: 0 train loss: 4.28125  train f1: 0.00000  lr: 0.008597311341474342 batch: 24 
epochs: 0 val loss: 4.0859375  val f1:0.00000  lr: 0.008597311341474342 batch: 24
epochs: 1 train loss: 4.453125  train f1: 0.00000  lr: 0.008597311341474342 batch: 24 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.008597311341474342 batch: 24
epochs: 0 train loss: 4.6328125  train f1: 0.00000  lr: 0.0022806888596770387 batch: 19 
epochs: 0 val loss: 4.9140625  val f1:0.00000  lr: 0.0022806888596770387 batch: 19
epochs: 1 train loss: 4.43359375  train f1: 0.00000  lr: 0.0022806888596770387 batch: 19 
epochs: 1 val loss: 4.16796875  val f1:0.11111  lr: 0.0022806888596770387 batch: 19
epochs: 0 train loss: 4.4609375  train f1: 0.20000  lr: 0.0030792978779953756 batch: 18 
epochs: 0 val loss: 4.6640625  val f1:0.00000  lr: 0.0030792978779953756 batch: 18
epochs: 1 train loss: 4.5234375  train f1: 0.16667  lr: 0.0030792978779953756 batch: 18 
epochs: 1 val loss: 3.953125  val f1:0.14286  lr: 0.0030792978779953756 batch: 18
epochs: 2 train loss: 0.27978515625  train f1: 1.00000  lr: 0.0030792978779953756 batch: 18 
epochs: 2 val loss: 4.5859375  val f1:0.14286  lr: 0.0030792978779953756 batch: 18
epochs: 3 train loss: 0.39453125  train f1: 1.00000  lr: 0.0030792978779953756 batch: 18 
epochs: 3 val loss: 7.796875  val f1:0.00000  lr: 0.0030792978779953756 batch: 18
epochs: 4 train loss: 0.006847381591796875  train f1: 1.00000  lr: 0.0030792978779953756 batch: 18 
epochs: 4 val loss: 12.5078125  val f1:0.00000  lr: 0.0030792978779953756 batch: 18
epochs: 5 train loss: 0.0042724609375  train f1: 1.00000  lr: 0.0030792978779953756 batch: 18 
epochs: 5 val loss: 13.96875  val f1:0.00000  lr: 0.0030792978779953756 batch: 18
epochs: 6 train loss: 0.0008039474487304688  train f1: 1.00000  lr: 0.0030792978779953756 batch: 18 
epochs: 6 val loss: 13.7578125  val f1:0.00000  lr: 0.0030792978779953756 batch: 18
epochs: 7 train loss: 0.004749298095703125  train f1: 1.00000  lr: 0.0030792978779953756 batch: 18 
epochs: 7 val loss: 12.0390625  val f1:0.00000  lr: 0.0030792978779953756 batch: 18
epochs: 0 train loss: 4.3359375  train f1: 0.00000  lr: 0.0029614326387664876 batch: 20 
epochs: 0 val loss: 4.90234375  val f1:0.00000  lr: 0.0029614326387664876 batch: 20
epochs: 1 train loss: 4.35546875  train f1: 0.00000  lr: 0.0029614326387664876 batch: 20 
epochs: 1 val loss: 4.83203125  val f1:0.00000  lr: 0.0029614326387664876 batch: 20
epochs: 0 train loss: 3.875  train f1: 0.00000  lr: 0.0005333892898081638 batch: 15 
epochs: 0 val loss: 4.82421875  val f1:0.00000  lr: 0.0005333892898081638 batch: 15
epochs: 1 train loss: 4.0078125  train f1: 0.16667  lr: 0.0005333892898081638 batch: 15 
epochs: 1 val loss: 4.6953125  val f1:0.00000  lr: 0.0005333892898081638 batch: 15
epochs: 0 train loss: 4.6171875  train f1: 0.00000  lr: 0.0012371608365234824 batch: 9 
epochs: 0 val loss: 4.69140625  val f1:0.00000  lr: 0.0012371608365234824 batch: 9
epochs: 1 train loss: 4.53515625  train f1: 0.00000  lr: 0.0012371608365234824 batch: 9 
epochs: 1 val loss: 10.53125  val f1:0.14286  lr: 0.0012371608365234824 batch: 9
epochs: 2 train loss: 0.077392578125  train f1: 1.00000  lr: 0.0012371608365234824 batch: 9 
epochs: 2 val loss: 188.75  val f1:0.06667  lr: 0.0012371608365234824 batch: 9
epochs: 3 train loss: 2.6796875  train f1: 0.20000  lr: 0.0012371608365234824 batch: 9 
epochs: 3 val loss: 31.640625  val f1:0.06667  lr: 0.0012371608365234824 batch: 9
epochs: 4 train loss: 0.359619140625  train f1: 1.00000  lr: 0.0012371608365234824 batch: 9 
epochs: 4 val loss: 50.75  val f1:0.00000  lr: 0.0012371608365234824 batch: 9
epochs: 5 train loss: 0.2822265625  train f1: 1.00000  lr: 0.0012371608365234824 batch: 9 
epochs: 5 val loss: 53.125  val f1:0.00000  lr: 0.0012371608365234824 batch: 9
epochs: 6 train loss: 0.3134765625  train f1: 1.00000  lr: 0.0012371608365234824 batch: 9 
epochs: 6 val loss: 73.3125  val f1:0.00000  lr: 0.0012371608365234824 batch: 9
epochs: 7 train loss: 0.00012373924255371094  train f1: 1.00000  lr: 0.0012371608365234824 batch: 9 
epochs: 7 val loss: 22.703125  val f1:0.00000  lr: 0.0012371608365234824 batch: 9
epochs: 8 train loss: 9.644031524658203e-05  train f1: 1.00000  lr: 0.0012371608365234824 batch: 9 
epochs: 8 val loss: 16.671875  val f1:0.00000  lr: 0.0012371608365234824 batch: 9
epochs: 9 train loss: 0.0021648406982421875  train f1: 1.00000  lr: 0.0012371608365234824 batch: 9 
epochs: 9 val loss: 13.3828125  val f1:0.00000  lr: 0.0012371608365234824 batch: 9
epochs: 10 train loss: 0.00010949373245239258  train f1: 1.00000  lr: 0.0012371608365234824 batch: 9 
epochs: 10 val loss: 11.2265625  val f1:0.00000  lr: 0.0012371608365234824 batch: 9
epochs: 11 train loss: 0.0011730194091796875  train f1: 1.00000  lr: 0.0012371608365234824 batch: 9 
epochs: 11 val loss: 10.296875  val f1:0.00000  lr: 0.0012371608365234824 batch: 9
epochs: 12 train loss: 6.747245788574219e-05  train f1: 1.00000  lr: 0.0012371608365234824 batch: 9 
epochs: 12 val loss: 9.671875  val f1:0.00000  lr: 0.0012371608365234824 batch: 9
epochs: 13 train loss: 6.633996963500977e-05  train f1: 1.00000  lr: 0.0012371608365234824 batch: 9 
epochs: 13 val loss: 9.625  val f1:0.00000  lr: 0.0012371608365234824 batch: 9
epochs: 0 train loss: 4.765625  train f1: 0.00000  lr: 0.004890230232305012 batch: 32 
epochs: 0 val loss: 4.82421875  val f1:0.00000  lr: 0.004890230232305012 batch: 32
epochs: 1 train loss: 4.8828125  train f1: 0.00000  lr: 0.004890230232305012 batch: 32 
epochs: 1 val loss: 3.865234375  val f1:0.14286  lr: 0.004890230232305012 batch: 32
epochs: 2 train loss: 0.91845703125  train f1: 1.00000  lr: 0.004890230232305012 batch: 32 
epochs: 2 val loss: 12.5  val f1:0.00000  lr: 0.004890230232305012 batch: 32
epochs: 3 train loss: 1.7177734375  train f1: 0.66667  lr: 0.004890230232305012 batch: 32 
epochs: 3 val loss: 16.984375  val f1:0.00000  lr: 0.004890230232305012 batch: 32
epochs: 4 train loss: 0.00032138824462890625  train f1: 1.00000  lr: 0.004890230232305012 batch: 32 
epochs: 4 val loss: 19.4375  val f1:0.00000  lr: 0.004890230232305012 batch: 32
epochs: 5 train loss: 0.0018138885498046875  train f1: 1.00000  lr: 0.004890230232305012 batch: 32 
epochs: 5 val loss: 17.84375  val f1:0.00000  lr: 0.004890230232305012 batch: 32
epochs: 6 train loss: 0.0034809112548828125  train f1: 1.00000  lr: 0.004890230232305012 batch: 32 
epochs: 6 val loss: 22.625  val f1:0.00000  lr: 0.004890230232305012 batch: 32
epochs: 7 train loss: 8.559226989746094e-05  train f1: 1.00000  lr: 0.004890230232305012 batch: 32 
epochs: 7 val loss: 15.2734375  val f1:0.00000  lr: 0.004890230232305012 batch: 32
epochs: 8 train loss: 3.421306610107422e-05  train f1: 1.00000  lr: 0.004890230232305012 batch: 32 
epochs: 8 val loss: 7.52734375  val f1:0.00000  lr: 0.004890230232305012 batch: 32
epochs: 9 train loss: 3.314018249511719e-05  train f1: 1.00000  lr: 0.004890230232305012 batch: 32 
epochs: 9 val loss: 6.28515625  val f1:0.00000  lr: 0.004890230232305012 batch: 32
epochs: 10 train loss: 2.187490463256836e-05  train f1: 1.00000  lr: 0.004890230232305012 batch: 32 
epochs: 10 val loss: 8.765625  val f1:0.00000  lr: 0.004890230232305012 batch: 32
epochs: 11 train loss: 2.5272369384765625e-05  train f1: 1.00000  lr: 0.004890230232305012 batch: 32 
epochs: 11 val loss: 9.3359375  val f1:0.00000  lr: 0.004890230232305012 batch: 32
epochs: 12 train loss: 1.5497207641601562e-06  train f1: 1.00000  lr: 0.004890230232305012 batch: 32 
epochs: 12 val loss: 11.546875  val f1:0.00000  lr: 0.004890230232305012 batch: 32
epochs: 0 train loss: 4.32421875  train f1: 0.00000  lr: 0.0001994364524085428 batch: 16 
epochs: 0 val loss: 4.84375  val f1:0.00000  lr: 0.0001994364524085428 batch: 16
epochs: 1 train loss: 4.3984375  train f1: 0.00000  lr: 0.0001994364524085428 batch: 16 
epochs: 1 val loss: 4.30859375  val f1:0.11111  lr: 0.0001994364524085428 batch: 16
epochs: 0 train loss: 4.3671875  train f1: 0.00000  lr: 0.0007960455717865567 batch: 18 
epochs: 0 val loss: 4.9140625  val f1:0.00000  lr: 0.0007960455717865567 batch: 18
epochs: 1 train loss: 4.171875  train f1: 0.00000  lr: 0.0007960455717865567 batch: 18 
epochs: 1 val loss: 4.4765625  val f1:0.11111  lr: 0.0007960455717865567 batch: 18
epochs: 0 train loss: 4.625  train f1: 0.00000  lr: 0.00209612666249325 batch: 17 
epochs: 0 val loss: 5.3125  val f1:0.00000  lr: 0.00209612666249325 batch: 17
epochs: 1 train loss: 4.703125  train f1: 0.00000  lr: 0.00209612666249325 batch: 17 
epochs: 1 val loss: 625.0  val f1:0.08333  lr: 0.00209612666249325 batch: 17
epochs: 0 train loss: 4.9765625  train f1: 0.00000  lr: 0.006831750843819559 batch: 29 
epochs: 0 val loss: 5.13671875  val f1:0.00000  lr: 0.006831750843819559 batch: 29
epochs: 1 train loss: 5.0234375  train f1: 0.00000  lr: 0.006831750843819559 batch: 29 
epochs: 1 val loss: 5.1640625  val f1:0.00000  lr: 0.006831750843819559 batch: 29
epochs: 0 train loss: 4.4609375  train f1: 0.00000  lr: 2.549432781005656e-05 batch: 32 
epochs: 0 val loss: 4.4375  val f1:0.00000  lr: 2.549432781005656e-05 batch: 32
epochs: 1 train loss: 4.47265625  train f1: 0.00000  lr: 2.549432781005656e-05 batch: 32 
epochs: 1 val loss: 4.21484375  val f1:0.00000  lr: 2.549432781005656e-05 batch: 32
epochs: 0 train loss: 4.91796875  train f1: 0.00000  lr: 1.400988828248606e-05 batch: 30 
epochs: 0 val loss: 5.29296875  val f1:0.00000  lr: 1.400988828248606e-05 batch: 30
epochs: 1 train loss: 4.99609375  train f1: 0.00000  lr: 1.400988828248606e-05 batch: 30 
epochs: 1 val loss: 5.19140625  val f1:0.00000  lr: 1.400988828248606e-05 batch: 30
epochs: 0 train loss: 4.8984375  train f1: 0.00000  lr: 4.186462675419149e-05 batch: 28 
epochs: 0 val loss: 5.078125  val f1:0.00000  lr: 4.186462675419149e-05 batch: 28
epochs: 1 train loss: 4.97265625  train f1: 0.00000  lr: 4.186462675419149e-05 batch: 28 
epochs: 1 val loss: 4.8828125  val f1:0.00000  lr: 4.186462675419149e-05 batch: 28
epochs: 0 train loss: 4.875  train f1: 0.00000  lr: 6.831242821861754e-05 batch: 27 
epochs: 0 val loss: 4.85546875  val f1:0.00000  lr: 6.831242821861754e-05 batch: 27
epochs: 1 train loss: 4.9453125  train f1: 0.00000  lr: 6.831242821861754e-05 batch: 27 
epochs: 1 val loss: 4.828125  val f1:0.00000  lr: 6.831242821861754e-05 batch: 27
epochs: 0 train loss: 4.8046875  train f1: 0.00000  lr: 0.002545059982384943 batch: 19 
epochs: 0 val loss: 4.66015625  val f1:0.00000  lr: 0.002545059982384943 batch: 19
epochs: 1 train loss: 4.90625  train f1: 0.00000  lr: 0.002545059982384943 batch: 19 
epochs: 1 val loss: 3.80859375  val f1:0.12500  lr: 0.002545059982384943 batch: 19
epochs: 2 train loss: 0.38037109375  train f1: 1.00000  lr: 0.002545059982384943 batch: 19 
epochs: 2 val loss: 3.666015625  val f1:0.12500  lr: 0.002545059982384943 batch: 19
epochs: 3 train loss: 0.2239990234375  train f1: 1.00000  lr: 0.002545059982384943 batch: 19 
epochs: 3 val loss: 4.60546875  val f1:0.16667  lr: 0.002545059982384943 batch: 19
epochs: 4 train loss: 0.0002033710479736328  train f1: 1.00000  lr: 0.002545059982384943 batch: 19 
epochs: 4 val loss: 6.96484375  val f1:0.16667  lr: 0.002545059982384943 batch: 19
epochs: 5 train loss: 0.00021946430206298828  train f1: 1.00000  lr: 0.002545059982384943 batch: 19 
epochs: 5 val loss: 8.953125  val f1:0.16667  lr: 0.002545059982384943 batch: 19
epochs: 6 train loss: 0.0002677440643310547  train f1: 1.00000  lr: 0.002545059982384943 batch: 19 
epochs: 6 val loss: 12.21875  val f1:0.16667  lr: 0.002545059982384943 batch: 19
epochs: 7 train loss: 0.00041747093200683594  train f1: 1.00000  lr: 0.002545059982384943 batch: 19 
epochs: 7 val loss: 16.0625  val f1:0.16667  lr: 0.002545059982384943 batch: 19
epochs: 8 train loss: 0.0008668899536132812  train f1: 1.00000  lr: 0.002545059982384943 batch: 19 
epochs: 8 val loss: 18.765625  val f1:0.16667  lr: 0.002545059982384943 batch: 19
epochs: 9 train loss: 0.0001004934310913086  train f1: 1.00000  lr: 0.002545059982384943 batch: 19 
epochs: 9 val loss: 20.4375  val f1:0.16667  lr: 0.002545059982384943 batch: 19
epochs: 10 train loss: 0.00012254714965820312  train f1: 1.00000  lr: 0.002545059982384943 batch: 19 
epochs: 10 val loss: 20.640625  val f1:0.16667  lr: 0.002545059982384943 batch: 19
epochs: 11 train loss: 0.00010317564010620117  train f1: 1.00000  lr: 0.002545059982384943 batch: 19 
epochs: 11 val loss: 20.84375  val f1:0.16667  lr: 0.002545059982384943 batch: 19
epochs: 12 train loss: 5.6862831115722656e-05  train f1: 1.00000  lr: 0.002545059982384943 batch: 19 
epochs: 12 val loss: 20.796875  val f1:0.16667  lr: 0.002545059982384943 batch: 19
epochs: 13 train loss: 5.316734313964844e-05  train f1: 1.00000  lr: 0.002545059982384943 batch: 19 
epochs: 13 val loss: 20.125  val f1:0.16667  lr: 0.002545059982384943 batch: 19
epochs: 14 train loss: 4.649162292480469e-05  train f1: 1.00000  lr: 0.002545059982384943 batch: 19 
epochs: 14 val loss: 19.171875  val f1:0.16667  lr: 0.002545059982384943 batch: 19
epochs: 15 train loss: 4.1961669921875e-05  train f1: 1.00000  lr: 0.002545059982384943 batch: 19 
epochs: 15 val loss: 18.203125  val f1:0.14286  lr: 0.002545059982384943 batch: 19
epochs: 0 train loss: 4.359375  train f1: 0.00000  lr: 0.001470823024073767 batch: 21 
epochs: 0 val loss: 4.7421875  val f1:0.12500  lr: 0.001470823024073767 batch: 21
epochs: 1 train loss: 4.28125  train f1: 0.00000  lr: 0.001470823024073767 batch: 21 
epochs: 1 val loss: 3.533203125  val f1:0.23810  lr: 0.001470823024073767 batch: 21
epochs: 2 train loss: 0.5419921875  train f1: 1.00000  lr: 0.001470823024073767 batch: 21 
epochs: 2 val loss: 3.470703125  val f1:0.14286  lr: 0.001470823024073767 batch: 21
epochs: 3 train loss: 0.100341796875  train f1: 1.00000  lr: 0.001470823024073767 batch: 21 
epochs: 3 val loss: 3.6171875  val f1:0.14286  lr: 0.001470823024073767 batch: 21
epochs: 4 train loss: 0.0031337738037109375  train f1: 1.00000  lr: 0.001470823024073767 batch: 21 
epochs: 4 val loss: 3.728515625  val f1:0.12500  lr: 0.001470823024073767 batch: 21
epochs: 5 train loss: 0.00035190582275390625  train f1: 1.00000  lr: 0.001470823024073767 batch: 21 
epochs: 5 val loss: 3.7890625  val f1:0.16667  lr: 0.001470823024073767 batch: 21
epochs: 6 train loss: 0.0004477500915527344  train f1: 1.00000  lr: 0.001470823024073767 batch: 21 
epochs: 6 val loss: 3.8671875  val f1:0.16667  lr: 0.001470823024073767 batch: 21
epochs: 7 train loss: 0.0003502368927001953  train f1: 1.00000  lr: 0.001470823024073767 batch: 21 
epochs: 7 val loss: 3.94140625  val f1:0.16667  lr: 0.001470823024073767 batch: 21
epochs: 8 train loss: 0.0286102294921875  train f1: 1.00000  lr: 0.001470823024073767 batch: 21 
epochs: 8 val loss: 4.11328125  val f1:0.16667  lr: 0.001470823024073767 batch: 21
epochs: 9 train loss: 0.000331878662109375  train f1: 1.00000  lr: 0.001470823024073767 batch: 21 
epochs: 9 val loss: 4.30078125  val f1:0.16667  lr: 0.001470823024073767 batch: 21
epochs: 10 train loss: 0.00038886070251464844  train f1: 1.00000  lr: 0.001470823024073767 batch: 21 
epochs: 10 val loss: 4.5  val f1:0.16667  lr: 0.001470823024073767 batch: 21
epochs: 11 train loss: 0.00038361549377441406  train f1: 1.00000  lr: 0.001470823024073767 batch: 21 
epochs: 11 val loss: 4.85546875  val f1:0.16667  lr: 0.001470823024073767 batch: 21
epochs: 12 train loss: 0.0005803108215332031  train f1: 1.00000  lr: 0.001470823024073767 batch: 21 
epochs: 12 val loss: 4.99609375  val f1:0.16667  lr: 0.001470823024073767 batch: 21
epochs: 13 train loss: 0.0004756450653076172  train f1: 1.00000  lr: 0.001470823024073767 batch: 21 
epochs: 13 val loss: 5.1484375  val f1:0.16667  lr: 0.001470823024073767 batch: 21
epochs: 14 train loss: 0.00026226043701171875  train f1: 1.00000  lr: 0.001470823024073767 batch: 21 
epochs: 14 val loss: 5.234375  val f1:0.16667  lr: 0.001470823024073767 batch: 21
epochs: 0 train loss: 4.17578125  train f1: 0.00000  lr: 0.00156017307014516 batch: 22 
epochs: 0 val loss: 5.4765625  val f1:0.00000  lr: 0.00156017307014516 batch: 22
epochs: 1 train loss: 4.17578125  train f1: 0.00000  lr: 0.00156017307014516 batch: 22 
epochs: 1 val loss: 4.4921875  val f1:0.11111  lr: 0.00156017307014516 batch: 22
epochs: 0 train loss: 4.5625  train f1: 0.00000  lr: 0.00035515478767939 batch: 13 
epochs: 0 val loss: 4.92578125  val f1:0.00000  lr: 0.00035515478767939 batch: 13
epochs: 1 train loss: 4.62890625  train f1: 0.00000  lr: 0.00035515478767939 batch: 13 
epochs: 1 val loss: 4.76171875  val f1:0.00000  lr: 0.00035515478767939 batch: 13
epochs: 0 train loss: 4.19140625  train f1: 0.00000  lr: 0.0040445183032184005 batch: 21 
epochs: 0 val loss: 4.15625  val f1:0.00000  lr: 0.0040445183032184005 batch: 21
epochs: 1 train loss: 4.1875  train f1: 0.00000  lr: 0.0040445183032184005 batch: 21 
epochs: 1 val loss: 4.76171875  val f1:0.12500  lr: 0.0040445183032184005 batch: 21
epochs: 2 train loss: 0.1553955078125  train f1: 1.00000  lr: 0.0040445183032184005 batch: 21 
epochs: 2 val loss: 3.82421875  val f1:0.14286  lr: 0.0040445183032184005 batch: 21
epochs: 3 train loss: 1.080078125  train f1: 0.50000  lr: 0.0040445183032184005 batch: 21 
epochs: 3 val loss: 19.0625  val f1:0.14286  lr: 0.0040445183032184005 batch: 21
epochs: 4 train loss: 0.00020062923431396484  train f1: 1.00000  lr: 0.0040445183032184005 batch: 21 
epochs: 4 val loss: 38.0625  val f1:0.14286  lr: 0.0040445183032184005 batch: 21
epochs: 0 train loss: 4.015625  train f1: 0.13333  lr: 0.010181679619226206 batch: 24 
epochs: 0 val loss: 4.8046875  val f1:0.00000  lr: 0.010181679619226206 batch: 24
epochs: 1 train loss: 4.0234375  train f1: 0.00000  lr: 0.010181679619226206 batch: 24 
epochs: 1 val loss: 5.95703125  val f1:0.00000  lr: 0.010181679619226206 batch: 24
epochs: 0 train loss: 4.7265625  train f1: 0.00000  lr: 0.0012536634875162582 batch: 32 
epochs: 0 val loss: 4.7265625  val f1:0.00000  lr: 0.0012536634875162582 batch: 32
epochs: 1 train loss: 4.6640625  train f1: 0.00000  lr: 0.0012536634875162582 batch: 32 
epochs: 1 val loss: 6.42578125  val f1:0.00000  lr: 0.0012536634875162582 batch: 32
epochs: 0 train loss: 4.85546875  train f1: 0.00000  lr: 0.0037491835345365497 batch: 21 
epochs: 0 val loss: 4.50390625  val f1:0.12500  lr: 0.0037491835345365497 batch: 21
epochs: 1 train loss: 5.1171875  train f1: 0.00000  lr: 0.0037491835345365497 batch: 21 
epochs: 1 val loss: 3.85546875  val f1:0.12500  lr: 0.0037491835345365497 batch: 21
epochs: 2 train loss: 0.7451171875  train f1: 1.00000  lr: 0.0037491835345365497 batch: 21 
epochs: 2 val loss: 4.95703125  val f1:0.16667  lr: 0.0037491835345365497 batch: 21
epochs: 3 train loss: 0.0142822265625  train f1: 1.00000  lr: 0.0037491835345365497 batch: 21 
epochs: 3 val loss: 6.5078125  val f1:0.14286  lr: 0.0037491835345365497 batch: 21
epochs: 4 train loss: 0.006927490234375  train f1: 1.00000  lr: 0.0037491835345365497 batch: 21 
epochs: 4 val loss: 8.3984375  val f1:0.14286  lr: 0.0037491835345365497 batch: 21
epochs: 5 train loss: 0.0007905960083007812  train f1: 1.00000  lr: 0.0037491835345365497 batch: 21 
epochs: 5 val loss: 8.0703125  val f1:0.00000  lr: 0.0037491835345365497 batch: 21
epochs: 6 train loss: 5.888938903808594e-05  train f1: 1.00000  lr: 0.0037491835345365497 batch: 21 
epochs: 6 val loss: 8.3671875  val f1:0.00000  lr: 0.0037491835345365497 batch: 21
epochs: 7 train loss: 9.894371032714844e-06  train f1: 1.00000  lr: 0.0037491835345365497 batch: 21 
epochs: 7 val loss: 8.6875  val f1:0.00000  lr: 0.0037491835345365497 batch: 21
epochs: 8 train loss: 5.066394805908203e-06  train f1: 1.00000  lr: 0.0037491835345365497 batch: 21 
epochs: 8 val loss: 8.421875  val f1:0.00000  lr: 0.0037491835345365497 batch: 21
epochs: 9 train loss: 3.337860107421875e-06  train f1: 1.00000  lr: 0.0037491835345365497 batch: 21 
epochs: 9 val loss: 8.59375  val f1:0.00000  lr: 0.0037491835345365497 batch: 21
epochs: 10 train loss: 6.377696990966797e-06  train f1: 1.00000  lr: 0.0037491835345365497 batch: 21 
epochs: 10 val loss: 9.5703125  val f1:0.00000  lr: 0.0037491835345365497 batch: 21
epochs: 11 train loss: 4.1365623474121094e-05  train f1: 1.00000  lr: 0.0037491835345365497 batch: 21 
epochs: 11 val loss: 10.8671875  val f1:0.00000  lr: 0.0037491835345365497 batch: 21
epochs: 12 train loss: 6.4373016357421875e-06  train f1: 1.00000  lr: 0.0037491835345365497 batch: 21 
epochs: 12 val loss: 12.1796875  val f1:0.00000  lr: 0.0037491835345365497 batch: 21
epochs: 13 train loss: 2.6226043701171875e-06  train f1: 1.00000  lr: 0.0037491835345365497 batch: 21 
epochs: 13 val loss: 13.1640625  val f1:0.00000  lr: 0.0037491835345365497 batch: 21
epochs: 14 train loss: 3.814697265625e-06  train f1: 1.00000  lr: 0.0037491835345365497 batch: 21 
epochs: 14 val loss: 13.6953125  val f1:0.00000  lr: 0.0037491835345365497 batch: 21
epochs: 15 train loss: 0.00019478797912597656  train f1: 1.00000  lr: 0.0037491835345365497 batch: 21 
epochs: 15 val loss: 14.2890625  val f1:0.00000  lr: 0.0037491835345365497 batch: 21
epochs: 0 train loss: 4.09375  train f1: 0.00000  lr: 0.0005998526906293672 batch: 20 
epochs: 0 val loss: 4.75  val f1:0.00000  lr: 0.0005998526906293672 batch: 20
epochs: 1 train loss: 4.0390625  train f1: 0.00000  lr: 0.0005998526906293672 batch: 20 
epochs: 1 val loss: 3.53515625  val f1:0.14286  lr: 0.0005998526906293672 batch: 20
epochs: 2 train loss: 0.568359375  train f1: 1.00000  lr: 0.0005998526906293672 batch: 20 
epochs: 2 val loss: 13.796875  val f1:0.00000  lr: 0.0005998526906293672 batch: 20
epochs: 3 train loss: 2.87109375  train f1: 0.40000  lr: 0.0005998526906293672 batch: 20 
epochs: 3 val loss: 7.08984375  val f1:0.16667  lr: 0.0005998526906293672 batch: 20
epochs: 4 train loss: 0.003143310546875  train f1: 1.00000  lr: 0.0005998526906293672 batch: 20 
epochs: 4 val loss: 7.890625  val f1:0.16667  lr: 0.0005998526906293672 batch: 20
epochs: 5 train loss: 0.0004799365997314453  train f1: 1.00000  lr: 0.0005998526906293672 batch: 20 
epochs: 5 val loss: 7.45703125  val f1:0.16667  lr: 0.0005998526906293672 batch: 20
epochs: 6 train loss: 0.00040912628173828125  train f1: 1.00000  lr: 0.0005998526906293672 batch: 20 
epochs: 6 val loss: 6.82421875  val f1:0.16667  lr: 0.0005998526906293672 batch: 20
epochs: 7 train loss: 0.00024020671844482422  train f1: 1.00000  lr: 0.0005998526906293672 batch: 20 
epochs: 7 val loss: 6.35546875  val f1:0.16667  lr: 0.0005998526906293672 batch: 20
epochs: 8 train loss: 0.0003535747528076172  train f1: 1.00000  lr: 0.0005998526906293672 batch: 20 
epochs: 8 val loss: 6.00390625  val f1:0.14286  lr: 0.0005998526906293672 batch: 20
epochs: 9 train loss: 0.00018990039825439453  train f1: 1.00000  lr: 0.0005998526906293672 batch: 20 
epochs: 9 val loss: 5.8515625  val f1:0.14286  lr: 0.0005998526906293672 batch: 20
epochs: 10 train loss: 0.0001499652862548828  train f1: 1.00000  lr: 0.0005998526906293672 batch: 20 
epochs: 10 val loss: 5.796875  val f1:0.14286  lr: 0.0005998526906293672 batch: 20
epochs: 0 train loss: 4.734375  train f1: 0.00000  lr: 0.0017611538244258732 batch: 19 
epochs: 0 val loss: 5.09765625  val f1:0.00000  lr: 0.0017611538244258732 batch: 19
epochs: 1 train loss: 4.859375  train f1: 0.00000  lr: 0.0017611538244258732 batch: 19 
epochs: 1 val loss: 4.4765625  val f1:0.12500  lr: 0.0017611538244258732 batch: 19
epochs: 2 train loss: 0.290283203125  train f1: 1.00000  lr: 0.0017611538244258732 batch: 19 
epochs: 2 val loss: 4.40234375  val f1:0.12500  lr: 0.0017611538244258732 batch: 19
epochs: 3 train loss: 0.005954742431640625  train f1: 1.00000  lr: 0.0017611538244258732 batch: 19 
epochs: 3 val loss: 4.38671875  val f1:0.12500  lr: 0.0017611538244258732 batch: 19
epochs: 0 train loss: 4.4765625  train f1: 0.00000  lr: 0.000878702017362292 batch: 17 
epochs: 0 val loss: 5.3359375  val f1:0.00000  lr: 0.000878702017362292 batch: 17
epochs: 1 train loss: 4.28125  train f1: 0.00000  lr: 0.000878702017362292 batch: 17 
epochs: 1 val loss: 4.8046875  val f1:0.12500  lr: 0.000878702017362292 batch: 17
epochs: 2 train loss: 0.8408203125  train f1: 1.00000  lr: 0.000878702017362292 batch: 17 
epochs: 2 val loss: 4.3515625  val f1:0.11111  lr: 0.000878702017362292 batch: 17
epochs: 3 train loss: 0.07122802734375  train f1: 1.00000  lr: 0.000878702017362292 batch: 17 
epochs: 3 val loss: 4.2109375  val f1:0.12500  lr: 0.000878702017362292 batch: 17
epochs: 0 train loss: 4.5703125  train f1: 0.00000  lr: 0.0023613279738619983 batch: 18 
epochs: 0 val loss: 5.328125  val f1:0.00000  lr: 0.0023613279738619983 batch: 18
epochs: 1 train loss: 4.546875  train f1: 0.00000  lr: 0.0023613279738619983 batch: 18 
epochs: 1 val loss: 4.0390625  val f1:0.12500  lr: 0.0023613279738619983 batch: 18
epochs: 2 train loss: 0.447021484375  train f1: 1.00000  lr: 0.0023613279738619983 batch: 18 
epochs: 2 val loss: 3.927734375  val f1:0.12500  lr: 0.0023613279738619983 batch: 18
epochs: 3 train loss: 0.131103515625  train f1: 1.00000  lr: 0.0023613279738619983 batch: 18 
epochs: 3 val loss: 3.9140625  val f1:0.12500  lr: 0.0023613279738619983 batch: 18
epochs: 0 train loss: 4.98828125  train f1: 0.00000  lr: 0.005816309301587271 batch: 23 
epochs: 0 val loss: 5.03125  val f1:0.00000  lr: 0.005816309301587271 batch: 23
epochs: 1 train loss: 4.984375  train f1: 0.00000  lr: 0.005816309301587271 batch: 23 
epochs: 1 val loss: 4.3359375  val f1:0.14286  lr: 0.005816309301587271 batch: 23
epochs: 2 train loss: 0.413330078125  train f1: 1.00000  lr: 0.005816309301587271 batch: 23 
epochs: 2 val loss: 21.40625  val f1:0.16667  lr: 0.005816309301587271 batch: 23
epochs: 3 train loss: 1.3701171875  train f1: 0.50000  lr: 0.005816309301587271 batch: 23 
epochs: 3 val loss: 29.65625  val f1:0.00000  lr: 0.005816309301587271 batch: 23
epochs: 4 train loss: 0.0006656646728515625  train f1: 1.00000  lr: 0.005816309301587271 batch: 23 
epochs: 4 val loss: 15.875  val f1:0.06667  lr: 0.005816309301587271 batch: 23
epochs: 5 train loss: 0.0166015625  train f1: 1.00000  lr: 0.005816309301587271 batch: 23 
epochs: 5 val loss: 19.046875  val f1:0.06667  lr: 0.005816309301587271 batch: 23
epochs: 6 train loss: 1.1920928955078125e-07  train f1: 1.00000  lr: 0.005816309301587271 batch: 23 
epochs: 6 val loss: 24.34375  val f1:0.00000  lr: 0.005816309301587271 batch: 23
epochs: 7 train loss: 2.205371856689453e-06  train f1: 1.00000  lr: 0.005816309301587271 batch: 23 
epochs: 7 val loss: 38.34375  val f1:0.00000  lr: 0.005816309301587271 batch: 23
epochs: 8 train loss: 8.821487426757812e-06  train f1: 1.00000  lr: 0.005816309301587271 batch: 23 
epochs: 8 val loss: 46.625  val f1:0.00000  lr: 0.005816309301587271 batch: 23
epochs: 9 train loss: 0.00013494491577148438  train f1: 1.00000  lr: 0.005816309301587271 batch: 23 
epochs: 9 val loss: 42.65625  val f1:0.00000  lr: 0.005816309301587271 batch: 23
epochs: 10 train loss: 9.465217590332031e-05  train f1: 1.00000  lr: 0.005816309301587271 batch: 23 
epochs: 10 val loss: 40.65625  val f1:0.00000  lr: 0.005816309301587271 batch: 23
epochs: 11 train loss: 7.617473602294922e-05  train f1: 1.00000  lr: 0.005816309301587271 batch: 23 
epochs: 11 val loss: 31.875  val f1:0.00000  lr: 0.005816309301587271 batch: 23
epochs: 12 train loss: 6.020069122314453e-05  train f1: 1.00000  lr: 0.005816309301587271 batch: 23 
epochs: 12 val loss: 33.125  val f1:0.00000  lr: 0.005816309301587271 batch: 23
epochs: 13 train loss: 3.6835670471191406e-05  train f1: 1.00000  lr: 0.005816309301587271 batch: 23 
epochs: 13 val loss: 35.34375  val f1:0.00000  lr: 0.005816309301587271 batch: 23
epochs: 0 train loss: 5.27734375  train f1: 0.00000  lr: 0.003064958455606977 batch: 23 
epochs: 0 val loss: 5.23046875  val f1:0.00000  lr: 0.003064958455606977 batch: 23
epochs: 1 train loss: 5.38671875  train f1: 0.00000  lr: 0.003064958455606977 batch: 23 
epochs: 1 val loss: 4.3984375  val f1:0.16667  lr: 0.003064958455606977 batch: 23
epochs: 2 train loss: 0.732421875  train f1: 1.00000  lr: 0.003064958455606977 batch: 23 
epochs: 2 val loss: 5.8359375  val f1:0.16667  lr: 0.003064958455606977 batch: 23
epochs: 3 train loss: 0.174072265625  train f1: 1.00000  lr: 0.003064958455606977 batch: 23 
epochs: 3 val loss: 8.7109375  val f1:0.16667  lr: 0.003064958455606977 batch: 23
epochs: 4 train loss: 0.00012481212615966797  train f1: 1.00000  lr: 0.003064958455606977 batch: 23 
epochs: 4 val loss: 11.34375  val f1:0.16667  lr: 0.003064958455606977 batch: 23
epochs: 5 train loss: 6.145238876342773e-05  train f1: 1.00000  lr: 0.003064958455606977 batch: 23 
epochs: 5 val loss: 12.4765625  val f1:0.16667  lr: 0.003064958455606977 batch: 23
epochs: 6 train loss: 5.2809715270996094e-05  train f1: 1.00000  lr: 0.003064958455606977 batch: 23 
epochs: 6 val loss: 12.640625  val f1:0.16667  lr: 0.003064958455606977 batch: 23
epochs: 7 train loss: 0.00010287761688232422  train f1: 1.00000  lr: 0.003064958455606977 batch: 23 
epochs: 7 val loss: 12.7578125  val f1:0.16667  lr: 0.003064958455606977 batch: 23
epochs: 8 train loss: 3.1888484954833984e-05  train f1: 1.00000  lr: 0.003064958455606977 batch: 23 
epochs: 8 val loss: 14.15625  val f1:0.00000  lr: 0.003064958455606977 batch: 23
epochs: 9 train loss: 1.4424324035644531e-05  train f1: 1.00000  lr: 0.003064958455606977 batch: 23 
epochs: 9 val loss: 15.5546875  val f1:0.00000  lr: 0.003064958455606977 batch: 23
epochs: 10 train loss: 2.9385089874267578e-05  train f1: 1.00000  lr: 0.003064958455606977 batch: 23 
epochs: 10 val loss: 16.28125  val f1:0.00000  lr: 0.003064958455606977 batch: 23
epochs: 11 train loss: 1.704692840576172e-05  train f1: 1.00000  lr: 0.003064958455606977 batch: 23 
epochs: 11 val loss: 16.71875  val f1:0.00000  lr: 0.003064958455606977 batch: 23
epochs: 12 train loss: 1.0848045349121094e-05  train f1: 1.00000  lr: 0.003064958455606977 batch: 23 
epochs: 12 val loss: 16.71875  val f1:0.00000  lr: 0.003064958455606977 batch: 23
epochs: 0 train loss: 4.91015625  train f1: 0.00000  lr: 0.0007169315175497208 batch: 20 
epochs: 0 val loss: 5.37109375  val f1:0.00000  lr: 0.0007169315175497208 batch: 20
epochs: 1 train loss: 4.77734375  train f1: 0.00000  lr: 0.0007169315175497208 batch: 20 
epochs: 1 val loss: 5.2890625  val f1:0.00000  lr: 0.0007169315175497208 batch: 20
epochs: 0 train loss: 4.9453125  train f1: 0.00000  lr: 0.000137512980602543 batch: 30 
epochs: 0 val loss: 4.2578125  val f1:0.00000  lr: 0.000137512980602543 batch: 30
epochs: 1 train loss: 4.8203125  train f1: 0.00000  lr: 0.000137512980602543 batch: 30 
epochs: 1 val loss: 3.6796875  val f1:0.11111  lr: 0.000137512980602543 batch: 30
epochs: 0 train loss: 4.453125  train f1: 0.00000  lr: 0.0041951288594918425 batch: 19 
epochs: 0 val loss: 4.89453125  val f1:0.00000  lr: 0.0041951288594918425 batch: 19
epochs: 1 train loss: 4.3046875  train f1: 0.00000  lr: 0.0041951288594918425 batch: 19 
epochs: 1 val loss: 3.5546875  val f1:0.14286  lr: 0.0041951288594918425 batch: 19
epochs: 2 train loss: 0.034942626953125  train f1: 1.00000  lr: 0.0041951288594918425 batch: 19 
epochs: 2 val loss: 3.810546875  val f1:0.12500  lr: 0.0041951288594918425 batch: 19
epochs: 3 train loss: 0.27783203125  train f1: 1.00000  lr: 0.0041951288594918425 batch: 19 
epochs: 3 val loss: 3.376953125  val f1:0.25000  lr: 0.0041951288594918425 batch: 19
epochs: 4 train loss: 0.07440185546875  train f1: 1.00000  lr: 0.0041951288594918425 batch: 19 
epochs: 4 val loss: 3.794921875  val f1:0.27778  lr: 0.0041951288594918425 batch: 19
epochs: 5 train loss: 0.003498077392578125  train f1: 1.00000  lr: 0.0041951288594918425 batch: 19 
epochs: 5 val loss: 5.2109375  val f1:0.14286  lr: 0.0041951288594918425 batch: 19
epochs: 6 train loss: 0.0007181167602539062  train f1: 1.00000  lr: 0.0041951288594918425 batch: 19 
epochs: 6 val loss: 13.046875  val f1:0.14286  lr: 0.0041951288594918425 batch: 19
epochs: 7 train loss: 5.716085433959961e-05  train f1: 1.00000  lr: 0.0041951288594918425 batch: 19 
epochs: 7 val loss: 22.75  val f1:0.14286  lr: 0.0041951288594918425 batch: 19
epochs: 8 train loss: 9.417533874511719e-06  train f1: 1.00000  lr: 0.0041951288594918425 batch: 19 
epochs: 8 val loss: 30.6875  val f1:0.00000  lr: 0.0041951288594918425 batch: 19
epochs: 9 train loss: 1.1920928955078125e-06  train f1: 1.00000  lr: 0.0041951288594918425 batch: 19 
epochs: 9 val loss: 38.78125  val f1:0.00000  lr: 0.0041951288594918425 batch: 19
epochs: 10 train loss: 9.5367431640625e-07  train f1: 1.00000  lr: 0.0041951288594918425 batch: 19 
epochs: 10 val loss: 41.5625  val f1:0.00000  lr: 0.0041951288594918425 batch: 19
epochs: 11 train loss: 1.1920928955078125e-07  train f1: 1.00000  lr: 0.0041951288594918425 batch: 19 
epochs: 11 val loss: 41.1875  val f1:0.00000  lr: 0.0041951288594918425 batch: 19
epochs: 0 train loss: 4.53515625  train f1: 0.00000  lr: 0.002888059286852839 batch: 16 
epochs: 0 val loss: 4.2109375  val f1:0.00000  lr: 0.002888059286852839 batch: 16
epochs: 1 train loss: 4.59765625  train f1: 0.00000  lr: 0.002888059286852839 batch: 16 
epochs: 1 val loss: 3.57421875  val f1:0.14286  lr: 0.002888059286852839 batch: 16
epochs: 2 train loss: 0.5048828125  train f1: 1.00000  lr: 0.002888059286852839 batch: 16 
epochs: 2 val loss: 4.875  val f1:0.14286  lr: 0.002888059286852839 batch: 16
epochs: 3 train loss: 0.32373046875  train f1: 1.00000  lr: 0.002888059286852839 batch: 16 
epochs: 3 val loss: 5.52734375  val f1:0.14286  lr: 0.002888059286852839 batch: 16
epochs: 4 train loss: 0.01177215576171875  train f1: 1.00000  lr: 0.002888059286852839 batch: 16 
epochs: 4 val loss: 7.640625  val f1:0.14286  lr: 0.002888059286852839 batch: 16
epochs: 5 train loss: 0.0018262863159179688  train f1: 1.00000  lr: 0.002888059286852839 batch: 16 
epochs: 5 val loss: 8.953125  val f1:0.14286  lr: 0.002888059286852839 batch: 16
epochs: 6 train loss: 0.00013387203216552734  train f1: 1.00000  lr: 0.002888059286852839 batch: 16 
epochs: 6 val loss: 12.5703125  val f1:0.00000  lr: 0.002888059286852839 batch: 16
epochs: 7 train loss: 5.6743621826171875e-05  train f1: 1.00000  lr: 0.002888059286852839 batch: 16 
epochs: 7 val loss: 13.765625  val f1:0.00000  lr: 0.002888059286852839 batch: 16
epochs: 8 train loss: 1.1324882507324219e-05  train f1: 1.00000  lr: 0.002888059286852839 batch: 16 
epochs: 8 val loss: 14.1328125  val f1:0.00000  lr: 0.002888059286852839 batch: 16
epochs: 9 train loss: 5.602836608886719e-06  train f1: 1.00000  lr: 0.002888059286852839 batch: 16 
epochs: 9 val loss: 13.8203125  val f1:0.00000  lr: 0.002888059286852839 batch: 16
epochs: 10 train loss: 2.2649765014648438e-06  train f1: 1.00000  lr: 0.002888059286852839 batch: 16 
epochs: 10 val loss: 13.328125  val f1:0.00000  lr: 0.002888059286852839 batch: 16
epochs: 11 train loss: 2.5033950805664062e-06  train f1: 1.00000  lr: 0.002888059286852839 batch: 16 
epochs: 11 val loss: 12.609375  val f1:0.00000  lr: 0.002888059286852839 batch: 16
epochs: 12 train loss: 1.9073486328125e-06  train f1: 1.00000  lr: 0.002888059286852839 batch: 16 
epochs: 12 val loss: 12.5390625  val f1:0.00000  lr: 0.002888059286852839 batch: 16
epochs: 13 train loss: 0.0004401206970214844  train f1: 1.00000  lr: 0.002888059286852839 batch: 16 
epochs: 13 val loss: 12.28125  val f1:0.00000  lr: 0.002888059286852839 batch: 16
epochs: 14 train loss: 1.0728836059570312e-06  train f1: 1.00000  lr: 0.002888059286852839 batch: 16 
epochs: 14 val loss: 12.2265625  val f1:0.00000  lr: 0.002888059286852839 batch: 16
epochs: 0 train loss: 4.79296875  train f1: 0.00000  lr: 0.0005160903429727673 batch: 22 
epochs: 0 val loss: 5.421875  val f1:0.00000  lr: 0.0005160903429727673 batch: 22
epochs: 1 train loss: 4.8203125  train f1: 0.00000  lr: 0.0005160903429727673 batch: 22 
epochs: 1 val loss: 4.16796875  val f1:0.14286  lr: 0.0005160903429727673 batch: 22
epochs: 2 train loss: 0.59228515625  train f1: 1.00000  lr: 0.0005160903429727673 batch: 22 
epochs: 2 val loss: 4.39453125  val f1:0.11111  lr: 0.0005160903429727673 batch: 22
epochs: 3 train loss: 1.431640625  train f1: 0.50000  lr: 0.0005160903429727673 batch: 22 
epochs: 3 val loss: 4.46484375  val f1:0.09524  lr: 0.0005160903429727673 batch: 22
epochs: 4 train loss: 0.00028514862060546875  train f1: 1.00000  lr: 0.0005160903429727673 batch: 22 
epochs: 4 val loss: 4.43359375  val f1:0.08333  lr: 0.0005160903429727673 batch: 22
epochs: 5 train loss: 0.00013899803161621094  train f1: 1.00000  lr: 0.0005160903429727673 batch: 22 
epochs: 5 val loss: 4.37890625  val f1:0.09524  lr: 0.0005160903429727673 batch: 22
epochs: 6 train loss: 9.465217590332031e-05  train f1: 1.00000  lr: 0.0005160903429727673 batch: 22 
epochs: 6 val loss: 4.296875  val f1:0.08333  lr: 0.0005160903429727673 batch: 22
epochs: 7 train loss: 8.130073547363281e-05  train f1: 1.00000  lr: 0.0005160903429727673 batch: 22 
epochs: 7 val loss: 4.234375  val f1:0.09524  lr: 0.0005160903429727673 batch: 22
epochs: 8 train loss: 8.928775787353516e-05  train f1: 1.00000  lr: 0.0005160903429727673 batch: 22 
epochs: 8 val loss: 4.23046875  val f1:0.12500  lr: 0.0005160903429727673 batch: 22
epochs: 9 train loss: 8.344650268554688e-05  train f1: 1.00000  lr: 0.0005160903429727673 batch: 22 
epochs: 9 val loss: 4.26171875  val f1:0.12500  lr: 0.0005160903429727673 batch: 22
epochs: 10 train loss: 6.520748138427734e-05  train f1: 1.00000  lr: 0.0005160903429727673 batch: 22 
epochs: 10 val loss: 4.29296875  val f1:0.12500  lr: 0.0005160903429727673 batch: 22
epochs: 0 train loss: 4.39453125  train f1: 0.00000  lr: 2.956838665896304e-05 batch: 25 
epochs: 0 val loss: 5.203125  val f1:0.00000  lr: 2.956838665896304e-05 batch: 25
epochs: 1 train loss: 4.36328125  train f1: 0.00000  lr: 2.956838665896304e-05 batch: 25 
epochs: 1 val loss: 5.078125  val f1:0.00000  lr: 2.956838665896304e-05 batch: 25
epochs: 0 train loss: 4.87109375  train f1: 0.00000  lr: 0.0026439406523498616 batch: 18 
epochs: 0 val loss: 4.26171875  val f1:0.00000  lr: 0.0026439406523498616 batch: 18
epochs: 1 train loss: 4.89453125  train f1: 0.00000  lr: 0.0026439406523498616 batch: 18 
epochs: 1 val loss: 3.36328125  val f1:0.14286  lr: 0.0026439406523498616 batch: 18
epochs: 2 train loss: 1.0341796875  train f1: 1.00000  lr: 0.0026439406523498616 batch: 18 
epochs: 2 val loss: 3.984375  val f1:0.16667  lr: 0.0026439406523498616 batch: 18
epochs: 3 train loss: 0.320556640625  train f1: 1.00000  lr: 0.0026439406523498616 batch: 18 
epochs: 3 val loss: 4.1875  val f1:0.16667  lr: 0.0026439406523498616 batch: 18
epochs: 4 train loss: 0.01097869873046875  train f1: 1.00000  lr: 0.0026439406523498616 batch: 18 
epochs: 4 val loss: 4.7734375  val f1:0.16667  lr: 0.0026439406523498616 batch: 18
epochs: 5 train loss: 0.0010528564453125  train f1: 1.00000  lr: 0.0026439406523498616 batch: 18 
epochs: 5 val loss: 5.8828125  val f1:0.00000  lr: 0.0026439406523498616 batch: 18
epochs: 6 train loss: 5.364418029785156e-05  train f1: 1.00000  lr: 0.0026439406523498616 batch: 18 
epochs: 6 val loss: 6.96875  val f1:0.00000  lr: 0.0026439406523498616 batch: 18
epochs: 7 train loss: 3.993511199951172e-05  train f1: 1.00000  lr: 0.0026439406523498616 batch: 18 
epochs: 7 val loss: 7.91796875  val f1:0.00000  lr: 0.0026439406523498616 batch: 18
epochs: 8 train loss: 2.771615982055664e-05  train f1: 1.00000  lr: 0.0026439406523498616 batch: 18 
epochs: 8 val loss: 9.0234375  val f1:0.00000  lr: 0.0026439406523498616 batch: 18
epochs: 9 train loss: 2.4557113647460938e-05  train f1: 1.00000  lr: 0.0026439406523498616 batch: 18 
epochs: 9 val loss: 9.9140625  val f1:0.00000  lr: 0.0026439406523498616 batch: 18
epochs: 10 train loss: 2.8967857360839844e-05  train f1: 1.00000  lr: 0.0026439406523498616 batch: 18 
epochs: 10 val loss: 9.765625  val f1:0.00000  lr: 0.0026439406523498616 batch: 18
epochs: 11 train loss: 1.817941665649414e-05  train f1: 1.00000  lr: 0.0026439406523498616 batch: 18 
epochs: 11 val loss: 10.09375  val f1:0.00000  lr: 0.0026439406523498616 batch: 18
epochs: 12 train loss: 1.6033649444580078e-05  train f1: 1.00000  lr: 0.0026439406523498616 batch: 18 
epochs: 12 val loss: 9.71875  val f1:0.00000  lr: 0.0026439406523498616 batch: 18
epochs: 13 train loss: 1.3172626495361328e-05  train f1: 1.00000  lr: 0.0026439406523498616 batch: 18 
epochs: 13 val loss: 10.0078125  val f1:0.00000  lr: 0.0026439406523498616 batch: 18
epochs: 0 train loss: 4.30859375  train f1: 0.00000  lr: 0.0006149828495804738 batch: 31 
epochs: 0 val loss: 4.51953125  val f1:0.00000  lr: 0.0006149828495804738 batch: 31
epochs: 1 train loss: 4.18359375  train f1: 0.00000  lr: 0.0006149828495804738 batch: 31 
epochs: 1 val loss: 3.73828125  val f1:0.14286  lr: 0.0006149828495804738 batch: 31
epochs: 2 train loss: 0.483154296875  train f1: 1.00000  lr: 0.0006149828495804738 batch: 31 
epochs: 2 val loss: 37.625  val f1:0.00000  lr: 0.0006149828495804738 batch: 31
epochs: 3 train loss: 2.265625  train f1: 0.40000  lr: 0.0006149828495804738 batch: 31 
epochs: 3 val loss: 6.2109375  val f1:0.00000  lr: 0.0006149828495804738 batch: 31
epochs: 4 train loss: 0.81640625  train f1: 1.00000  lr: 0.0006149828495804738 batch: 31 
epochs: 4 val loss: 55.8125  val f1:0.00000  lr: 0.0006149828495804738 batch: 31
epochs: 5 train loss: 3.4689903259277344e-05  train f1: 1.00000  lr: 0.0006149828495804738 batch: 31 
epochs: 5 val loss: 35.78125  val f1:0.00000  lr: 0.0006149828495804738 batch: 31
epochs: 6 train loss: 5.0067901611328125e-05  train f1: 1.00000  lr: 0.0006149828495804738 batch: 31 
epochs: 6 val loss: 23.53125  val f1:0.00000  lr: 0.0006149828495804738 batch: 31
epochs: 7 train loss: 3.7550926208496094e-05  train f1: 1.00000  lr: 0.0006149828495804738 batch: 31 
epochs: 7 val loss: 15.328125  val f1:0.00000  lr: 0.0006149828495804738 batch: 31
epochs: 8 train loss: 3.695487976074219e-05  train f1: 1.00000  lr: 0.0006149828495804738 batch: 31 
epochs: 8 val loss: 9.8671875  val f1:0.00000  lr: 0.0006149828495804738 batch: 31
epochs: 9 train loss: 5.745887756347656e-05  train f1: 1.00000  lr: 0.0006149828495804738 batch: 31 
epochs: 9 val loss: 7.296875  val f1:0.28571  lr: 0.0006149828495804738 batch: 31
epochs: 10 train loss: 1.7762184143066406e-05  train f1: 1.00000  lr: 0.0006149828495804738 batch: 31 
epochs: 10 val loss: 5.9921875  val f1:0.28571  lr: 0.0006149828495804738 batch: 31
epochs: 11 train loss: 2.3424625396728516e-05  train f1: 1.00000  lr: 0.0006149828495804738 batch: 31 
epochs: 11 val loss: 4.89453125  val f1:0.12500  lr: 0.0006149828495804738 batch: 31
epochs: 0 train loss: 5.59375  train f1: 0.00000  lr: 0.0014570440963901567 batch: 21 
epochs: 0 val loss: 4.80078125  val f1:0.00000  lr: 0.0014570440963901567 batch: 21
epochs: 1 train loss: 5.55078125  train f1: 0.00000  lr: 0.0014570440963901567 batch: 21 
epochs: 1 val loss: 3.984375  val f1:0.12500  lr: 0.0014570440963901567 batch: 21
epochs: 0 train loss: 4.9140625  train f1: 0.00000  lr: 0.001034847872355559 batch: 15 
epochs: 0 val loss: 4.703125  val f1:0.00000  lr: 0.001034847872355559 batch: 15
epochs: 1 train loss: 4.59375  train f1: 0.00000  lr: 0.001034847872355559 batch: 15 
epochs: 1 val loss: 4.1484375  val f1:0.11111  lr: 0.001034847872355559 batch: 15
epochs: 0 train loss: 4.77734375  train f1: 0.00000  lr: 0.00042821761979549184 batch: 20 
epochs: 0 val loss: 4.6796875  val f1:0.00000  lr: 0.00042821761979549184 batch: 20
epochs: 1 train loss: 4.66015625  train f1: 0.00000  lr: 0.00042821761979549184 batch: 20 
epochs: 1 val loss: 4.5390625  val f1:0.12500  lr: 0.00042821761979549184 batch: 20
epochs: 0 train loss: 4.4375  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 5.12890625  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 1 train loss: 4.3515625  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 1 val loss: 4.3828125  val f1:0.11111  lr: 0.0006833364758030707 batch: 32
epochs: 2 train loss: 0.93310546875  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 2 val loss: 8.484375  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 3 train loss: 2.544921875  train f1: 0.40000  lr: 0.0006833364758030707 batch: 32 
epochs: 3 val loss: 3.92578125  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 4 train loss: 0.0167388916015625  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 4 val loss: 4.8515625  val f1:0.14286  lr: 0.0006833364758030707 batch: 32
epochs: 5 train loss: 4.661083221435547e-05  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 5 val loss: 5.4296875  val f1:0.14286  lr: 0.0006833364758030707 batch: 32
epochs: 6 train loss: 2.753734588623047e-05  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 6 val loss: 5.69921875  val f1:0.14286  lr: 0.0006833364758030707 batch: 32
epochs: 7 train loss: 2.777576446533203e-05  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 7 val loss: 5.70703125  val f1:0.14286  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.75  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 4.83984375  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 1 train loss: 4.6015625  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 1 val loss: 4.19921875  val f1:0.14286  lr: 0.0006833364758030707 batch: 32
epochs: 2 train loss: 0.66064453125  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 2 val loss: 40.375  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 3 train loss: 1.359375  train f1: 0.50000  lr: 0.0006833364758030707 batch: 32 
epochs: 3 val loss: 19.859375  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 4 train loss: 0.0004363059997558594  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 4 val loss: 15.4296875  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 5 train loss: 0.00029754638671875  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 5 val loss: 12.0078125  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 6 train loss: 0.00018072128295898438  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 6 val loss: 9.578125  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 7 train loss: 0.00010633468627929688  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 7 val loss: 8.0703125  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.75  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 4.83984375  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.0  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 4.4453125  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 1 train loss: 4.1015625  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 1 val loss: 5.328125  val f1:0.09524  lr: 0.0006833364758030707 batch: 32
epochs: 2 train loss: 0.24267578125  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 2 val loss: 19.90625  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 3 train loss: 0.40283203125  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 3 val loss: 9.28125  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 4 train loss: 0.77783203125  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 4 val loss: 21.71875  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 5 train loss: 0.0003800392150878906  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 5 val loss: 21.21875  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 6 train loss: 2.7894973754882812e-05  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 6 val loss: 20.984375  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 7 train loss: 4.470348358154297e-05  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 7 val loss: 21.046875  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.75  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 4.83984375  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 1 train loss: 4.6015625  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 1 val loss: 4.19921875  val f1:0.14286  lr: 0.0006833364758030707 batch: 32
epochs: 2 train loss: 0.66064453125  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 2 val loss: 40.375  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 3 train loss: 1.359375  train f1: 0.50000  lr: 0.0006833364758030707 batch: 32 
epochs: 3 val loss: 19.859375  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 4 train loss: 0.0004363059997558594  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 4 val loss: 15.4296875  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 5 train loss: 0.00029754638671875  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 5 val loss: 12.0078125  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 6 train loss: 0.00018072128295898438  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 6 val loss: 9.578125  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 7 train loss: 0.00010633468627929688  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 7 val loss: 8.0703125  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.75  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 4.83984375  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 1 train loss: 4.6015625  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 1 val loss: 4.19921875  val f1:0.14286  lr: 0.0006833364758030707 batch: 32
epochs: 2 train loss: 0.66064453125  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 2 val loss: 40.375  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 3 train loss: 1.359375  train f1: 0.50000  lr: 0.0006833364758030707 batch: 32 
epochs: 3 val loss: 19.859375  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 4 train loss: 0.0004363059997558594  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 4 val loss: 15.4296875  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 5 train loss: 0.00029754638671875  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 5 val loss: 12.0078125  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 6 train loss: 0.00018072128295898438  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 6 val loss: 9.578125  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 7 train loss: 0.00010633468627929688  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 7 val loss: 8.0703125  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.75  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 4.83984375  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 1 train loss: 4.6015625  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 1 val loss: 4.19921875  val f1:0.14286  lr: 0.0006833364758030707 batch: 32
epochs: 2 train loss: 0.66064453125  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 2 val loss: 40.375  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 3 train loss: 1.359375  train f1: 0.50000  lr: 0.0006833364758030707 batch: 32 
epochs: 3 val loss: 19.859375  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 4 train loss: 0.0004363059997558594  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 4 val loss: 15.4296875  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 5 train loss: 0.00029754638671875  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 5 val loss: 12.0078125  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 6 train loss: 0.00018072128295898438  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 6 val loss: 9.578125  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 7 train loss: 0.00010633468627929688  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 7 val loss: 8.0703125  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.75  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 4.83984375  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 1 train loss: 4.6015625  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 1 val loss: 4.19921875  val f1:0.14286  lr: 0.0006833364758030707 batch: 32
epochs: 2 train loss: 0.66064453125  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 2 val loss: 40.375  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 3 train loss: 1.359375  train f1: 0.50000  lr: 0.0006833364758030707 batch: 32 
epochs: 3 val loss: 19.859375  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 4 train loss: 0.0004363059997558594  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 4 val loss: 15.4296875  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 5 train loss: 0.00029754638671875  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 5 val loss: 12.0078125  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 6 train loss: 0.00018072128295898438  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 6 val loss: 9.578125  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 7 train loss: 0.00010633468627929688  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 7 val loss: 8.0703125  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.359375  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 5.30859375  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.078125  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 4.5390625  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.98828125  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 5.27734375  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.6171875  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 4.94921875  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 5.17578125  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 5.36328125  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.98046875  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 5.47265625  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 1 train loss: 4.83984375  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 1 val loss: 5.5078125  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 2 train loss: 0.320068359375  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 2 val loss: 39.90625  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 3 train loss: 0.5419921875  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 3 val loss: 3.962890625  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 4 train loss: 1.9326171875  train f1: 0.50000  lr: 0.0006833364758030707 batch: 32 
epochs: 4 val loss: 3.455078125  val f1:0.12500  lr: 0.0006833364758030707 batch: 32
epochs: 5 train loss: 0.001667022705078125  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 5 val loss: 4.26953125  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 6 train loss: 0.001499176025390625  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 6 val loss: 4.94921875  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 7 train loss: 0.0002789497375488281  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 7 val loss: 5.21875  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.4453125  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 4.73828125  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 1 train loss: 4.484375  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 1 val loss: 5.1015625  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.7578125  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 5.125  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 1 train loss: 4.78515625  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 1 val loss: 4.87109375  val f1:0.09524  lr: 0.0006833364758030707 batch: 32
epochs: 2 train loss: 0.342529296875  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 2 val loss: 4.6328125  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 3 train loss: 2.279296875  train f1: 0.50000  lr: 0.0006833364758030707 batch: 32 
epochs: 3 val loss: 28.640625  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.2265625  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 5.58984375  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.69140625  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 4.5859375  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 1 train loss: 4.671875  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 1 val loss: 5.859375  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 2 train loss: 0.2373046875  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 2 val loss: 6.98828125  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 3 train loss: 0.935546875  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 3 val loss: 5.8515625  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 4 train loss: 0.48876953125  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 4 val loss: 45.1875  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 5 train loss: 1.0478515625  train f1: 0.50000  lr: 0.0006833364758030707 batch: 32 
epochs: 5 val loss: 24.0625  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 6 train loss: 0.0001666545867919922  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 6 val loss: 17.0  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 7 train loss: 6.210803985595703e-05  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 7 val loss: 11.1640625  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.4453125  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 4.73828125  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.25390625  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 4.9765625  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 1 train loss: 4.359375  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 1 val loss: 3.56640625  val f1:0.12500  lr: 0.0006833364758030707 batch: 32
epochs: 2 train loss: 1.451171875  train f1: 0.50000  lr: 0.0006833364758030707 batch: 32 
epochs: 2 val loss: 50.125  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 3 train loss: 2.33984375  train f1: 0.40000  lr: 0.0006833364758030707 batch: 32 
epochs: 3 val loss: 8.796875  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 4 train loss: 0.0382080078125  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 4 val loss: 21.5  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 5 train loss: 2.5033950805664062e-06  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 5 val loss: 19.75  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 6 train loss: 1.9669532775878906e-06  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 6 val loss: 16.421875  val f1:0.14286  lr: 0.0006833364758030707 batch: 32
epochs: 7 train loss: 2.2649765014648438e-06  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 7 val loss: 14.7578125  val f1:0.14286  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.4453125  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 4.73828125  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 1 train loss: 4.5234375  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 1 val loss: 4.68359375  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 2 train loss: 0.330322265625  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 2 val loss: 30.234375  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.99609375  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 4.8671875  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 1 train loss: 5.18359375  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 1 val loss: 5.26953125  val f1:0.14286  lr: 0.0006833364758030707 batch: 32
epochs: 2 train loss: 0.20654296875  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 2 val loss: 15.21875  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 3 train loss: 0.6748046875  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 3 val loss: 48.53125  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 4 train loss: 0.322509765625  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 4 val loss: 13.2578125  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 5 train loss: 0.060455322265625  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 5 val loss: 13.859375  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 6 train loss: 7.104873657226562e-05  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 6 val loss: 10.765625  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 7 train loss: 4.0411949157714844e-05  train f1: 1.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 7 val loss: 9.6171875  val f1:0.16667  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.90625  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 4.5859375  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 4.66015625  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 4.2734375  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 1 train loss: 4.73828125  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 1 val loss: 5.06640625  val f1:0.14286  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 5.2890625  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 4.69140625  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 5.0859375  train f1: 0.00000  lr: 0.0006833364758030707 batch: 32 
epochs: 0 val loss: 5.125  val f1:0.00000  lr: 0.0006833364758030707 batch: 32
epochs: 0 train loss: 5.06640625  train f1: 0.00000  lr: 0.00039567570691214585 batch: 8 
epochs: 0 val loss: 4.1328125  val f1:0.00000  lr: 0.00039567570691214585 batch: 8
epochs: 1 train loss: 5.05859375  train f1: 0.00000  lr: 0.00039567570691214585 batch: 8 
epochs: 1 val loss: 4.1875  val f1:0.00000  lr: 0.00039567570691214585 batch: 8
epochs: 2 train loss: 5.078125  train f1: 0.00000  lr: 0.00039567570691214585 batch: 8 
epochs: 2 val loss: 4.234375  val f1:0.00000  lr: 0.00039567570691214585 batch: 8
epochs: 0 train loss: 4.79296875  train f1: 0.00000  lr: 0.0017349914806517098 batch: 29 
epochs: 0 val loss: 5.859375  val f1:0.00000  lr: 0.0017349914806517098 batch: 29
epochs: 0 train loss: 5.08203125  train f1: 0.00000  lr: 0.0241526344294635 batch: 19 
epochs: 0 val loss: 5.25390625  val f1:0.00000  lr: 0.0241526344294635 batch: 19
epochs: 0 train loss: 5.03125  train f1: 0.00000  lr: 0.0061865047623026834 batch: 21 
epochs: 0 val loss: 4.9375  val f1:0.00000  lr: 0.0061865047623026834 batch: 21
epochs: 1 train loss: 4.84375  train f1: 0.00000  lr: 0.0061865047623026834 batch: 21 
epochs: 1 val loss: 3.935546875  val f1:0.11111  lr: 0.0061865047623026834 batch: 21
epochs: 2 train loss: 0.732421875  train f1: 1.00000  lr: 0.0061865047623026834 batch: 21 
epochs: 2 val loss: 14.359375  val f1:0.14286  lr: 0.0061865047623026834 batch: 21
epochs: 3 train loss: 0.41162109375  train f1: 1.00000  lr: 0.0061865047623026834 batch: 21 
epochs: 3 val loss: 27.390625  val f1:0.00000  lr: 0.0061865047623026834 batch: 21
epochs: 4 train loss: 1.430511474609375e-06  train f1: 1.00000  lr: 0.0061865047623026834 batch: 21 
epochs: 4 val loss: 44.5  val f1:0.00000  lr: 0.0061865047623026834 batch: 21
epochs: 5 train loss: 3.5762786865234375e-07  train f1: 1.00000  lr: 0.0061865047623026834 batch: 21 
epochs: 5 val loss: 43.53125  val f1:0.00000  lr: 0.0061865047623026834 batch: 21
epochs: 6 train loss: 3.2782554626464844e-06  train f1: 1.00000  lr: 0.0061865047623026834 batch: 21 
epochs: 6 val loss: 92.3125  val f1:0.00000  lr: 0.0061865047623026834 batch: 21
epochs: 7 train loss: 0.00015151500701904297  train f1: 1.00000  lr: 0.0061865047623026834 batch: 21 
epochs: 7 val loss: 159.25  val f1:0.00000  lr: 0.0061865047623026834 batch: 21
epochs: 0 train loss: 5.56640625  train f1: 0.00000  lr: 0.0002455747415478299 batch: 21 
epochs: 0 val loss: 5.4765625  val f1:0.00000  lr: 0.0002455747415478299 batch: 21
epochs: 1 train loss: 5.49609375  train f1: 0.00000  lr: 0.0002455747415478299 batch: 21 
epochs: 1 val loss: 5.44921875  val f1:0.00000  lr: 0.0002455747415478299 batch: 21
epochs: 2 train loss: 5.6171875  train f1: 0.00000  lr: 0.0002455747415478299 batch: 21 
epochs: 2 val loss: 5.47265625  val f1:0.00000  lr: 0.0002455747415478299 batch: 21
epochs: 3 train loss: 5.62109375  train f1: 0.00000  lr: 0.0002455747415478299 batch: 21 
epochs: 3 val loss: 5.44921875  val f1:0.00000  lr: 0.0002455747415478299 batch: 21
epochs: 4 train loss: 5.60546875  train f1: 0.00000  lr: 0.0002455747415478299 batch: 21 
epochs: 4 val loss: 5.4296875  val f1:0.00000  lr: 0.0002455747415478299 batch: 21
epochs: 5 train loss: 5.625  train f1: 0.00000  lr: 0.0002455747415478299 batch: 21 
epochs: 5 val loss: 5.3671875  val f1:0.00000  lr: 0.0002455747415478299 batch: 21
epochs: 6 train loss: 5.5078125  train f1: 0.00000  lr: 0.0002455747415478299 batch: 21 
epochs: 6 val loss: 5.31640625  val f1:0.00000  lr: 0.0002455747415478299 batch: 21
epochs: 7 train loss: 5.64453125  train f1: 0.00000  lr: 0.0002455747415478299 batch: 21 
epochs: 7 val loss: 5.30859375  val f1:0.00000  lr: 0.0002455747415478299 batch: 21
epochs: 8 train loss: 5.5390625  train f1: 0.00000  lr: 0.0002455747415478299 batch: 21 
epochs: 8 val loss: 5.29296875  val f1:0.00000  lr: 0.0002455747415478299 batch: 21
epochs: 9 train loss: 5.6015625  train f1: 0.00000  lr: 0.0002455747415478299 batch: 21 
epochs: 9 val loss: 5.2734375  val f1:0.00000  lr: 0.0002455747415478299 batch: 21
epochs: 10 train loss: 5.62890625  train f1: 0.00000  lr: 0.0002455747415478299 batch: 21 
epochs: 10 val loss: 5.2421875  val f1:0.00000  lr: 0.0002455747415478299 batch: 21
epochs: 0 train loss: 4.38671875  train f1: 0.00000  lr: 0.00015512587486224782 batch: 25 
epochs: 0 val loss: 4.4296875  val f1:0.00000  lr: 0.00015512587486224782 batch: 25
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.00015512587486224782 batch: 25 
epochs: 1 val loss: 4.3359375  val f1:0.00000  lr: 0.00015512587486224782 batch: 25
epochs: 0 train loss: 4.1484375  train f1: 0.00000  lr: 0.0001175029856017282 batch: 15 
epochs: 0 val loss: 5.0859375  val f1:0.00000  lr: 0.0001175029856017282 batch: 15
epochs: 0 train loss: 4.73828125  train f1: 0.00000  lr: 0.00045946103848236734 batch: 23 
epochs: 0 val loss: 5.171875  val f1:0.00000  lr: 0.00045946103848236734 batch: 23
epochs: 1 train loss: 4.61328125  train f1: 0.00000  lr: 0.00045946103848236734 batch: 23 
epochs: 1 val loss: 5.48828125  val f1:0.14286  lr: 0.00045946103848236734 batch: 23
epochs: 2 train loss: 0.2415771484375  train f1: 1.00000  lr: 0.00045946103848236734 batch: 23 
epochs: 2 val loss: 15.6875  val f1:0.16667  lr: 0.00045946103848236734 batch: 23
epochs: 3 train loss: 0.18701171875  train f1: 1.00000  lr: 0.00045946103848236734 batch: 23 
epochs: 3 val loss: 12.15625  val f1:0.00000  lr: 0.00045946103848236734 batch: 23
epochs: 4 train loss: 0.314208984375  train f1: 1.00000  lr: 0.00045946103848236734 batch: 23 
epochs: 4 val loss: 9.5703125  val f1:0.16667  lr: 0.00045946103848236734 batch: 23
epochs: 5 train loss: 0.0026092529296875  train f1: 1.00000  lr: 0.00045946103848236734 batch: 23 
epochs: 5 val loss: 8.3671875  val f1:0.16667  lr: 0.00045946103848236734 batch: 23
epochs: 6 train loss: 0.00047087669372558594  train f1: 1.00000  lr: 0.00045946103848236734 batch: 23 
epochs: 6 val loss: 7.125  val f1:0.16667  lr: 0.00045946103848236734 batch: 23
epochs: 7 train loss: 0.0001423358917236328  train f1: 1.00000  lr: 0.00045946103848236734 batch: 23 
epochs: 7 val loss: 6.6484375  val f1:0.14286  lr: 0.00045946103848236734 batch: 23
epochs: 8 train loss: 0.00023066997528076172  train f1: 1.00000  lr: 0.00045946103848236734 batch: 23 
epochs: 8 val loss: 5.7109375  val f1:0.14286  lr: 0.00045946103848236734 batch: 23
epochs: 9 train loss: 0.00015211105346679688  train f1: 1.00000  lr: 0.00045946103848236734 batch: 23 
epochs: 9 val loss: 5.1875  val f1:0.14286  lr: 0.00045946103848236734 batch: 23
epochs: 0 train loss: 4.5546875  train f1: 0.00000  lr: 0.0021133115797180107 batch: 26 
epochs: 0 val loss: 5.09375  val f1:0.00000  lr: 0.0021133115797180107 batch: 26
epochs: 1 train loss: 4.3671875  train f1: 0.00000  lr: 0.0021133115797180107 batch: 26 
epochs: 1 val loss: 4.20703125  val f1:0.11111  lr: 0.0021133115797180107 batch: 26
epochs: 2 train loss: 0.1865234375  train f1: 1.00000  lr: 0.0021133115797180107 batch: 26 
epochs: 2 val loss: 4.34765625  val f1:0.12500  lr: 0.0021133115797180107 batch: 26
epochs: 0 train loss: 4.765625  train f1: 0.00000  lr: 0.002395821932607131 batch: 8 
epochs: 0 val loss: 4.84375  val f1:0.00000  lr: 0.002395821932607131 batch: 8
epochs: 1 train loss: 4.7265625  train f1: 0.00000  lr: 0.002395821932607131 batch: 8 
epochs: 1 val loss: 4.2890625  val f1:0.12500  lr: 0.002395821932607131 batch: 8
epochs: 2 train loss: 0.63720703125  train f1: 1.00000  lr: 0.002395821932607131 batch: 8 
epochs: 2 val loss: 6.484375  val f1:0.12500  lr: 0.002395821932607131 batch: 8
epochs: 3 train loss: 0.65576171875  train f1: 1.00000  lr: 0.002395821932607131 batch: 8 
epochs: 3 val loss: 7.4921875  val f1:0.14286  lr: 0.002395821932607131 batch: 8
epochs: 4 train loss: 0.00010585784912109375  train f1: 1.00000  lr: 0.002395821932607131 batch: 8 
epochs: 4 val loss: 8.21875  val f1:0.14286  lr: 0.002395821932607131 batch: 8
epochs: 5 train loss: 8.916854858398438e-05  train f1: 1.00000  lr: 0.002395821932607131 batch: 8 
epochs: 5 val loss: 7.58203125  val f1:0.14286  lr: 0.002395821932607131 batch: 8
epochs: 6 train loss: 0.00017011165618896484  train f1: 1.00000  lr: 0.002395821932607131 batch: 8 
epochs: 6 val loss: 5.5  val f1:0.14286  lr: 0.002395821932607131 batch: 8
epochs: 7 train loss: 9.161233901977539e-05  train f1: 1.00000  lr: 0.002395821932607131 batch: 8 
epochs: 7 val loss: 5.17578125  val f1:0.16667  lr: 0.002395821932607131 batch: 8
epochs: 8 train loss: 6.282329559326172e-05  train f1: 1.00000  lr: 0.002395821932607131 batch: 8 
epochs: 8 val loss: 5.26171875  val f1:0.16667  lr: 0.002395821932607131 batch: 8
epochs: 9 train loss: 2.562999725341797e-05  train f1: 1.00000  lr: 0.002395821932607131 batch: 8 
epochs: 9 val loss: 5.421875  val f1:0.16667  lr: 0.002395821932607131 batch: 8
epochs: 10 train loss: 2.962350845336914e-05  train f1: 1.00000  lr: 0.002395821932607131 batch: 8 
epochs: 10 val loss: 5.41015625  val f1:0.16667  lr: 0.002395821932607131 batch: 8
epochs: 11 train loss: 4.8220157623291016e-05  train f1: 1.00000  lr: 0.002395821932607131 batch: 8 
epochs: 11 val loss: 5.40625  val f1:0.16667  lr: 0.002395821932607131 batch: 8
epochs: 12 train loss: 6.16908073425293e-05  train f1: 1.00000  lr: 0.002395821932607131 batch: 8 
epochs: 12 val loss: 5.6015625  val f1:0.14286  lr: 0.002395821932607131 batch: 8
epochs: 0 train loss: 4.3203125  train f1: 0.00000  lr: 0.004212857467219111 batch: 27 
epochs: 0 val loss: 4.5859375  val f1:0.00000  lr: 0.004212857467219111 batch: 27
epochs: 1 train loss: 4.390625  train f1: 0.00000  lr: 0.004212857467219111 batch: 27 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.004212857467219111 batch: 27
epochs: 2 train loss: 8.7890625  train f1: 0.20000  lr: 0.004212857467219111 batch: 27 
epochs: 2 val loss: nan  val f1:0.00000  lr: 0.004212857467219111 batch: 27
epochs: 3 train loss: 9.265625  train f1: 0.37500  lr: 0.004212857467219111 batch: 27 
epochs: 3 val loss: nan  val f1:0.00000  lr: 0.004212857467219111 batch: 27
epochs: 4 train loss: 7.94140625  train f1: 0.20000  lr: 0.004212857467219111 batch: 27 
epochs: 4 val loss: nan  val f1:0.00000  lr: 0.004212857467219111 batch: 27
epochs: 5 train loss: 6.375  train f1: 0.37500  lr: 0.004212857467219111 batch: 27 
epochs: 5 val loss: nan  val f1:0.00000  lr: 0.004212857467219111 batch: 27
epochs: 6 train loss: 10.90625  train f1: 0.37500  lr: 0.004212857467219111 batch: 27 
epochs: 6 val loss: nan  val f1:0.08333  lr: 0.004212857467219111 batch: 27
epochs: 7 train loss: 11.59375  train f1: 0.37500  lr: 0.004212857467219111 batch: 27 
epochs: 7 val loss: nan  val f1:0.00000  lr: 0.004212857467219111 batch: 27
epochs: 8 train loss: 8.71875  train f1: 0.00000  lr: 0.004212857467219111 batch: 27 
epochs: 8 val loss: nan  val f1:0.00000  lr: 0.004212857467219111 batch: 27
epochs: 9 train loss: 7.29296875  train f1: 0.55556  lr: 0.004212857467219111 batch: 27 
epochs: 9 val loss: nan  val f1:0.00000  lr: 0.004212857467219111 batch: 27
epochs: 10 train loss: 2.390625  train f1: 0.41667  lr: 0.004212857467219111 batch: 27 
epochs: 10 val loss: nan  val f1:0.00000  lr: 0.004212857467219111 batch: 27
epochs: 11 train loss: 10.671875  train f1: 0.00000  lr: 0.004212857467219111 batch: 27 
epochs: 11 val loss: nan  val f1:0.00000  lr: 0.004212857467219111 batch: 27
epochs: 12 train loss: 4.66015625  train f1: 0.55556  lr: 0.004212857467219111 batch: 27 
epochs: 12 val loss: nan  val f1:0.00000  lr: 0.004212857467219111 batch: 27
epochs: 13 train loss: 1.185546875  train f1: 0.55556  lr: 0.004212857467219111 batch: 27 
epochs: 13 val loss: nan  val f1:0.00000  lr: 0.004212857467219111 batch: 27
epochs: 14 train loss: 0.08770751953125  train f1: 1.00000  lr: 0.004212857467219111 batch: 27 
epochs: 14 val loss: 14392.0  val f1:0.06667  lr: 0.004212857467219111 batch: 27
epochs: 15 train loss: 0.00445556640625  train f1: 1.00000  lr: 0.004212857467219111 batch: 27 
epochs: 15 val loss: 2258.0  val f1:0.06667  lr: 0.004212857467219111 batch: 27
epochs: 16 train loss: 0.0035991668701171875  train f1: 1.00000  lr: 0.004212857467219111 batch: 27 
epochs: 16 val loss: 770.5  val f1:0.06667  lr: 0.004212857467219111 batch: 27
epochs: 17 train loss: 0.0032024383544921875  train f1: 1.00000  lr: 0.004212857467219111 batch: 27 
epochs: 17 val loss: 369.25  val f1:0.06667  lr: 0.004212857467219111 batch: 27
epochs: 0 train loss: 4.6640625  train f1: 0.00000  lr: 0.00051261430867269 batch: 25 
epochs: 0 val loss: 4.90625  val f1:0.00000  lr: 0.00051261430867269 batch: 25
epochs: 1 train loss: 4.7578125  train f1: 0.00000  lr: 0.00051261430867269 batch: 25 
epochs: 1 val loss: 5.5234375  val f1:0.00000  lr: 0.00051261430867269 batch: 25
epochs: 2 train loss: 0.2484130859375  train f1: 1.00000  lr: 0.00051261430867269 batch: 25 
epochs: 2 val loss: 3.365234375  val f1:0.16667  lr: 0.00051261430867269 batch: 25
epochs: 3 train loss: 0.85009765625  train f1: 1.00000  lr: 0.00051261430867269 batch: 25 
epochs: 3 val loss: 16.640625  val f1:0.16667  lr: 0.00051261430867269 batch: 25
epochs: 4 train loss: 0.0012636184692382812  train f1: 1.00000  lr: 0.00051261430867269 batch: 25 
epochs: 4 val loss: 15.4453125  val f1:0.16667  lr: 0.00051261430867269 batch: 25
epochs: 5 train loss: 0.0004382133483886719  train f1: 1.00000  lr: 0.00051261430867269 batch: 25 
epochs: 5 val loss: 9.5859375  val f1:0.16667  lr: 0.00051261430867269 batch: 25
epochs: 6 train loss: 0.00036072731018066406  train f1: 1.00000  lr: 0.00051261430867269 batch: 25 
epochs: 6 val loss: 6.4921875  val f1:0.16667  lr: 0.00051261430867269 batch: 25
epochs: 7 train loss: 0.0002646446228027344  train f1: 1.00000  lr: 0.00051261430867269 batch: 25 
epochs: 7 val loss: 5.63671875  val f1:0.14286  lr: 0.00051261430867269 batch: 25
epochs: 8 train loss: 0.0007252693176269531  train f1: 1.00000  lr: 0.00051261430867269 batch: 25 
epochs: 8 val loss: 5.31640625  val f1:0.12500  lr: 0.00051261430867269 batch: 25
epochs: 9 train loss: 0.00017571449279785156  train f1: 1.00000  lr: 0.00051261430867269 batch: 25 
epochs: 9 val loss: 5.078125  val f1:0.12500  lr: 0.00051261430867269 batch: 25
epochs: 0 train loss: 4.1953125  train f1: 0.00000  lr: 0.084789180166588 batch: 13 
epochs: 0 val loss: 4.37109375  val f1:0.00000  lr: 0.084789180166588 batch: 13
epochs: 1 train loss: 4.25390625  train f1: 0.16667  lr: 0.084789180166588 batch: 13 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.084789180166588 batch: 13
epochs: 2 train loss: 153.75  train f1: 0.22222  lr: 0.084789180166588 batch: 13 
epochs: 2 val loss: nan  val f1:0.00000  lr: 0.084789180166588 batch: 13
epochs: 3 train loss: 202.375  train f1: 0.22222  lr: 0.084789180166588 batch: 13 
epochs: 3 val loss: nan  val f1:0.00000  lr: 0.084789180166588 batch: 13
epochs: 4 train loss: 130.125  train f1: 0.22222  lr: 0.084789180166588 batch: 13 
epochs: 4 val loss: nan  val f1:0.00000  lr: 0.084789180166588 batch: 13
epochs: 5 train loss: 141.125  train f1: 0.22222  lr: 0.084789180166588 batch: 13 
epochs: 5 val loss: nan  val f1:0.00000  lr: 0.084789180166588 batch: 13
epochs: 6 train loss: 167.875  train f1: 0.22222  lr: 0.084789180166588 batch: 13 
epochs: 6 val loss: nan  val f1:0.00000  lr: 0.084789180166588 batch: 13
epochs: 7 train loss: 146.5  train f1: 0.22222  lr: 0.084789180166588 batch: 13 
epochs: 7 val loss: nan  val f1:0.00000  lr: 0.084789180166588 batch: 13
epochs: 8 train loss: 176.75  train f1: 0.22222  lr: 0.084789180166588 batch: 13 
epochs: 8 val loss: nan  val f1:0.00000  lr: 0.084789180166588 batch: 13
epochs: 9 train loss: 164.25  train f1: 0.22222  lr: 0.084789180166588 batch: 13 
epochs: 9 val loss: nan  val f1:0.00000  lr: 0.084789180166588 batch: 13
epochs: 10 train loss: 137.25  train f1: 0.22222  lr: 0.084789180166588 batch: 13 
epochs: 10 val loss: nan  val f1:0.00000  lr: 0.084789180166588 batch: 13
epochs: 11 train loss: 131.75  train f1: 0.22222  lr: 0.084789180166588 batch: 13 
epochs: 11 val loss: nan  val f1:0.00000  lr: 0.084789180166588 batch: 13
epochs: 12 train loss: 260.75  train f1: 0.44444  lr: 0.084789180166588 batch: 13 
epochs: 12 val loss: nan  val f1:0.00000  lr: 0.084789180166588 batch: 13
epochs: 13 train loss: 28.46875  train f1: 0.22222  lr: 0.084789180166588 batch: 13 
epochs: 13 val loss: nan  val f1:0.00000  lr: 0.084789180166588 batch: 13
epochs: 14 train loss: 129.625  train f1: 0.12500  lr: 0.084789180166588 batch: 13 
epochs: 14 val loss: nan  val f1:0.00000  lr: 0.084789180166588 batch: 13
epochs: 15 train loss: 74.25  train f1: 0.13333  lr: 0.084789180166588 batch: 13 
epochs: 15 val loss: nan  val f1:0.00000  lr: 0.084789180166588 batch: 13
epochs: 16 train loss: 32.8125  train f1: 0.22222  lr: 0.084789180166588 batch: 13 
epochs: 16 val loss: nan  val f1:0.00000  lr: 0.084789180166588 batch: 13
epochs: 17 train loss: 74.0  train f1: 0.16667  lr: 0.084789180166588 batch: 13 
epochs: 17 val loss: nan  val f1:0.00000  lr: 0.084789180166588 batch: 13
epochs: 0 train loss: 4.4609375  train f1: 0.00000  lr: 0.08783278866076237 batch: 25 
epochs: 0 val loss: 5.2578125  val f1:0.00000  lr: 0.08783278866076237 batch: 25
epochs: 1 train loss: 4.3984375  train f1: 0.00000  lr: 0.08783278866076237 batch: 25 
epochs: 1 val loss: nan  val f1:0.00000  lr: 0.08783278866076237 batch: 25
epochs: 2 train loss: 11.65625  train f1: 0.11111  lr: 0.08783278866076237 batch: 25 
epochs: 2 val loss: nan  val f1:0.00000  lr: 0.08783278866076237 batch: 25
epochs: 3 train loss: 10.1015625  train f1: 0.10000  lr: 0.08783278866076237 batch: 25 
epochs: 3 val loss: nan  val f1:0.00000  lr: 0.08783278866076237 batch: 25
epochs: 4 train loss: 10.40625  train f1: 0.11111  lr: 0.08783278866076237 batch: 25 
epochs: 4 val loss: nan  val f1:0.00000  lr: 0.08783278866076237 batch: 25
epochs: 5 train loss: 6.93359375  train f1: 0.20000  lr: 0.08783278866076237 batch: 25 
epochs: 5 val loss: nan  val f1:0.00000  lr: 0.08783278866076237 batch: 25
epochs: 6 train loss: 14.390625  train f1: 0.13333  lr: 0.08783278866076237 batch: 25 
epochs: 6 val loss: nan  val f1:0.00000  lr: 0.08783278866076237 batch: 25
epochs: 0 train loss: 4.31640625  train f1: 0.00000  lr: 0.000492036883736351 batch: 29 
epochs: 0 val loss: 4.6015625  val f1:0.00000  lr: 0.000492036883736351 batch: 29
epochs: 1 train loss: 4.32421875  train f1: 0.00000  lr: 0.000492036883736351 batch: 29 
epochs: 1 val loss: 4.23046875  val f1:0.11111  lr: 0.000492036883736351 batch: 29
epochs: 2 train loss: 1.3203125  train f1: 1.00000  lr: 0.000492036883736351 batch: 29 
epochs: 2 val loss: 3.962890625  val f1:0.25000  lr: 0.000492036883736351 batch: 29
epochs: 3 train loss: 0.14111328125  train f1: 1.00000  lr: 0.000492036883736351 batch: 29 
epochs: 3 val loss: 3.8359375  val f1:0.25000  lr: 0.000492036883736351 batch: 29
epochs: 4 train loss: 0.0247802734375  train f1: 1.00000  lr: 0.000492036883736351 batch: 29 
epochs: 4 val loss: 3.8515625  val f1:0.11111  lr: 0.000492036883736351 batch: 29
epochs: 5 train loss: 0.016632080078125  train f1: 1.00000  lr: 0.000492036883736351 batch: 29 
epochs: 5 val loss: 3.8984375  val f1:0.11111  lr: 0.000492036883736351 batch: 29
epochs: 6 train loss: 0.007686614990234375  train f1: 1.00000  lr: 0.000492036883736351 batch: 29 
epochs: 6 val loss: 3.912109375  val f1:0.11111  lr: 0.000492036883736351 batch: 29
epochs: 0 train loss: 4.37109375  train f1: 0.00000  lr: 0.001398508254723614 batch: 25 
epochs: 0 val loss: 4.96875  val f1:0.00000  lr: 0.001398508254723614 batch: 25
epochs: 1 train loss: 4.4765625  train f1: 0.00000  lr: 0.001398508254723614 batch: 25 
epochs: 1 val loss: 9.5625  val f1:0.00000  lr: 0.001398508254723614 batch: 25
epochs: 2 train loss: 0.199951171875  train f1: 1.00000  lr: 0.001398508254723614 batch: 25 
epochs: 2 val loss: 305.5  val f1:0.00000  lr: 0.001398508254723614 batch: 25
epochs: 3 train loss: 4.8828125  train f1: 0.50000  lr: 0.001398508254723614 batch: 25 
epochs: 3 val loss: 2172.0  val f1:0.06667  lr: 0.001398508254723614 batch: 25
epochs: 4 train loss: 7.578125  train f1: 0.33333  lr: 0.001398508254723614 batch: 25 
epochs: 4 val loss: 920.0  val f1:0.06667  lr: 0.001398508254723614 batch: 25
epochs: 5 train loss: 7.94921875  train f1: 0.33333  lr: 0.001398508254723614 batch: 25 
epochs: 5 val loss: 388.5  val f1:0.06667  lr: 0.001398508254723614 batch: 25
epochs: 6 train loss: 5.578125  train f1: 0.33333  lr: 0.001398508254723614 batch: 25 
epochs: 6 val loss: 178.25  val f1:0.06667  lr: 0.001398508254723614 batch: 25
epochs: 7 train loss: 2.62890625  train f1: 0.20000  lr: 0.001398508254723614 batch: 25 
epochs: 7 val loss: 360.0  val f1:0.00000  lr: 0.001398508254723614 batch: 25
epochs: 8 train loss: 3.236328125  train f1: 0.77778  lr: 0.001398508254723614 batch: 25 
epochs: 8 val loss: 255.25  val f1:0.00000  lr: 0.001398508254723614 batch: 25
epochs: 9 train loss: 3.07421875  train f1: 0.77778  lr: 0.001398508254723614 batch: 25 
epochs: 9 val loss: nan  val f1:0.00000  lr: 0.001398508254723614 batch: 25
epochs: 10 train loss: 0.02691650390625  train f1: 1.00000  lr: 0.001398508254723614 batch: 25 
epochs: 10 val loss: 758.0  val f1:0.00000  lr: 0.001398508254723614 batch: 25
epochs: 11 train loss: 6.461143493652344e-05  train f1: 1.00000  lr: 0.001398508254723614 batch: 25 
epochs: 11 val loss: 86.1875  val f1:0.00000  lr: 0.001398508254723614 batch: 25
epochs: 12 train loss: 0.00457000732421875  train f1: 1.00000  lr: 0.001398508254723614 batch: 25 
epochs: 12 val loss: 20.4375  val f1:0.00000  lr: 0.001398508254723614 batch: 25
epochs: 0 train loss: 4.48046875  train f1: 0.00000  lr: 0.01265628533003758 batch: 13 
epochs: 0 val loss: 4.96875  val f1:0.00000  lr: 0.01265628533003758 batch: 13
epochs: 1 train loss: 4.34765625  train f1: 0.00000  lr: 0.01265628533003758 batch: 13 
epochs: 1 val loss: 4.8203125  val f1:0.00000  lr: 0.01265628533003758 batch: 13
epochs: 2 train loss: 3.626953125  train f1: 0.11111  lr: 0.01265628533003758 batch: 13 
epochs: 2 val loss: 4.59375  val f1:0.12500  lr: 0.01265628533003758 batch: 13
epochs: 3 train loss: 2.85546875  train f1: 0.50000  lr: 0.01265628533003758 batch: 13 
epochs: 3 val loss: 4.44140625  val f1:0.12500  lr: 0.01265628533003758 batch: 13
epochs: 4 train loss: 2.076171875  train f1: 1.00000  lr: 0.01265628533003758 batch: 13 
epochs: 4 val loss: 4.34375  val f1:0.12500  lr: 0.01265628533003758 batch: 13
epochs: 0 train loss: 4.37890625  train f1: 0.00000  lr: 6.071284367922255e-05 batch: 8 
epochs: 0 val loss: 4.46875  val f1:0.12500  lr: 6.071284367922255e-05 batch: 8
epochs: 1 train loss: 4.20703125  train f1: 0.00000  lr: 6.071284367922255e-05 batch: 8 
epochs: 1 val loss: 4.328125  val f1:0.12500  lr: 6.071284367922255e-05 batch: 8
epochs: 2 train loss: 4.1484375  train f1: 0.00000  lr: 6.071284367922255e-05 batch: 8 
epochs: 2 val loss: 4.2421875  val f1:0.12500  lr: 6.071284367922255e-05 batch: 8
epochs: 3 train loss: 4.32421875  train f1: 0.00000  lr: 6.071284367922255e-05 batch: 8 
epochs: 3 val loss: 4.21484375  val f1:0.12500  lr: 6.071284367922255e-05 batch: 8
epochs: 4 train loss: 4.203125  train f1: 0.00000  lr: 6.071284367922255e-05 batch: 8 
epochs: 4 val loss: 4.12109375  val f1:0.12500  lr: 6.071284367922255e-05 batch: 8
epochs: 5 train loss: 4.13671875  train f1: 0.00000  lr: 6.071284367922255e-05 batch: 8 
epochs: 5 val loss: 4.05078125  val f1:0.12500  lr: 6.071284367922255e-05 batch: 8
epochs: 6 train loss: 4.19921875  train f1: 0.00000  lr: 6.071284367922255e-05 batch: 8 
epochs: 6 val loss: 4.0234375  val f1:0.23810  lr: 6.071284367922255e-05 batch: 8
epochs: 0 train loss: 4.4296875  train f1: 0.00000  lr: 0.0004084863056559251 batch: 15 
epochs: 0 val loss: 4.77734375  val f1:0.00000  lr: 0.0004084863056559251 batch: 15
epochs: 1 train loss: 4.359375  train f1: 0.00000  lr: 0.0004084863056559251 batch: 15 
epochs: 1 val loss: 4.6796875  val f1:0.11111  lr: 0.0004084863056559251 batch: 15
epochs: 2 train loss: 0.97998046875  train f1: 1.00000  lr: 0.0004084863056559251 batch: 15 
epochs: 2 val loss: 8.921875  val f1:0.12500  lr: 0.0004084863056559251 batch: 15
epochs: 0 train loss: 4.41796875  train f1: 0.00000  lr: 0.00022188528061129528 batch: 14 
epochs: 0 val loss: 5.09765625  val f1:0.00000  lr: 0.00022188528061129528 batch: 14
epochs: 0 train loss: 4.12890625  train f1: 0.00000  lr: 3.757466766087728e-05 batch: 11 
epochs: 0 val loss: 4.69140625  val f1:0.00000  lr: 3.757466766087728e-05 batch: 11
epochs: 0 train loss: 0.6190831193300043  train f1: 0.41179  lr: 0.00027819706381843794 batch: 15 
epochs: 0 val loss: 0.974620395236545  val f1:0.55426  lr: 0.00027819706381843794 batch: 15
epochs: 1 train loss: 0.19806468152554235  train f1: 0.73836  lr: 0.00027819706381843794 batch: 15 
epochs: 1 val loss: 0.828135384453668  val f1:0.70006  lr: 0.00027819706381843794 batch: 15
epochs: 2 train loss: 0.12652327301346253  train f1: 0.84475  lr: 0.00027819706381843794 batch: 15 
epochs: 2 val loss: 0.6834150950113937  val f1:0.74492  lr: 0.00027819706381843794 batch: 15
epochs: 3 train loss: 0.08740413968808197  train f1: 0.88851  lr: 0.00027819706381843794 batch: 15 
epochs: 3 val loss: 0.7430787616305881  val f1:0.76077  lr: 0.00027819706381843794 batch: 15
epochs: 4 train loss: 0.08554884568553106  train f1: 0.89747  lr: 0.00027819706381843794 batch: 15 
epochs: 4 val loss: 0.6480365329318573  val f1:0.78306  lr: 0.00027819706381843794 batch: 15
epochs: 5 train loss: 0.0463549774662356  train f1: 0.94907  lr: 0.00027819706381843794 batch: 15 
epochs: 5 val loss: 0.7883746226628621  val f1:0.79447  lr: 0.00027819706381843794 batch: 15
epochs: 6 train loss: 0.05923011690099662  train f1: 0.93187  lr: 0.00027819706381843794 batch: 15 
epochs: 6 val loss: 0.8689453336927622  val f1:0.75099  lr: 0.00027819706381843794 batch: 15
epochs: 7 train loss: 0.05228837502894003  train f1: 0.94623  lr: 0.00027819706381843794 batch: 15 
epochs: 7 val loss: 0.7870746188693577  val f1:0.76374  lr: 0.00027819706381843794 batch: 15
epochs: 8 train loss: 0.04050157546440011  train f1: 0.95814  lr: 0.00027819706381843794 batch: 15 
epochs: 8 val loss: 0.774820327758789  val f1:0.78611  lr: 0.00027819706381843794 batch: 15
epochs: 9 train loss: 0.04700006572442636  train f1: 0.94946  lr: 0.00027819706381843794 batch: 15 
epochs: 9 val loss: 0.8392446140448251  val f1:0.80506  lr: 0.00027819706381843794 batch: 15
epochs: 10 train loss: 0.03133204558463857  train f1: 0.96865  lr: 0.00027819706381843794 batch: 15 
epochs: 10 val loss: 0.8615932199690082  val f1:0.77422  lr: 0.00027819706381843794 batch: 15
epochs: 11 train loss: 0.03731838523227479  train f1: 0.96104  lr: 0.00027819706381843794 batch: 15 
epochs: 11 val loss: 0.8069629205597776  val f1:0.81551  lr: 0.00027819706381843794 batch: 15
epochs: 12 train loss: 0.037034646164034034  train f1: 0.96098  lr: 0.00027819706381843794 batch: 15 
epochs: 12 val loss: 0.8982353806495669  val f1:0.79485  lr: 0.00027819706381843794 batch: 15
epochs: 13 train loss: 0.029384287370142533  train f1: 0.97264  lr: 0.00027819706381843794 batch: 15 
epochs: 13 val loss: 0.9549050761593711  val f1:0.79537  lr: 0.00027819706381843794 batch: 15
epochs: 14 train loss: 0.02591651267258918  train f1: 0.97104  lr: 0.00027819706381843794 batch: 15 
epochs: 14 val loss: 0.8842286401324807  val f1:0.79835  lr: 0.00027819706381843794 batch: 15
epochs: 15 train loss: 0.02949171701324321  train f1: 0.97356  lr: 0.00027819706381843794 batch: 15 
epochs: 15 val loss: 1.1335894664128616  val f1:0.78910  lr: 0.00027819706381843794 batch: 15
epochs: 16 train loss: 0.03426304236750736  train f1: 0.96829  lr: 0.00027819706381843794 batch: 15 
epochs: 16 val loss: 1.1939403216044109  val f1:0.74348  lr: 0.00027819706381843794 batch: 15
epochs: 17 train loss: 0.036101523612704245  train f1: 0.96703  lr: 0.00027819706381843794 batch: 15 
epochs: 17 val loss: 1.039567748705545  val f1:0.77963  lr: 0.00027819706381843794 batch: 15
epochs: 18 train loss: 0.023149160929372355  train f1: 0.98047  lr: 0.00027819706381843794 batch: 15 
epochs: 18 val loss: 0.9506358454624818  val f1:0.80980  lr: 0.00027819706381843794 batch: 15
epochs: 19 train loss: 0.028298140964775457  train f1: 0.97487  lr: 0.00027819706381843794 batch: 15 
epochs: 19 val loss: 1.0839596589406335  val f1:0.77459  lr: 0.00027819706381843794 batch: 15
epochs: 20 train loss: 0.028995401739517115  train f1: 0.97162  lr: 0.00027819706381843794 batch: 15 
epochs: 20 val loss: 1.0837254954708948  val f1:0.77311  lr: 0.00027819706381843794 batch: 15
epochs: 21 train loss: 0.016803314404509877  train f1: 0.98197  lr: 0.00027819706381843794 batch: 15 
epochs: 21 val loss: 0.9702802155580786  val f1:0.79828  lr: 0.00027819706381843794 batch: 15
epochs: 22 train loss: 0.021439082502761737  train f1: 0.97734  lr: 0.00027819706381843794 batch: 15 
epochs: 22 val loss: 0.9356091088718839  val f1:0.80993  lr: 0.00027819706381843794 batch: 15
epochs: 0 train loss: 0.6202723244640315  train f1: 0.40660  lr: 0.00027819706381843794 batch: 15 
epochs: 0 val loss: 0.9074808756510421  val f1:0.55161  lr: 0.00027819706381843794 batch: 15
epochs: 0 train loss: 0.6081165113948529  train f1: 0.41184  lr: 0.0003 batch: 16 
epochs: 0 val loss: 0.9075014467592598  val f1:0.53561  lr: 0.0003 batch: 16
epochs: 1 train loss: 0.2043084979354592  train f1: 0.73368  lr: 0.0003 batch: 16 
epochs: 1 val loss: 0.8847952383535878  val f1:0.69070  lr: 0.0003 batch: 16
epochs: 2 train loss: 0.13413461128672458  train f1: 0.84065  lr: 0.0003 batch: 16 
epochs: 2 val loss: 0.7561076694064667  val f1:0.74470  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.09752142994183857  train f1: 0.88612  lr: 0.0003 batch: 16 
epochs: 3 val loss: 0.7163777386700667  val f1:0.76978  lr: 0.0003 batch: 16
epochs: 4 train loss: 0.06692578548802403  train f1: 0.91787  lr: 0.0003 batch: 16 
epochs: 4 val loss: 0.7380194769965279  val f1:0.77991  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.05900929411153253  train f1: 0.93823  lr: 0.0003 batch: 16 
epochs: 5 val loss: 0.698652253327546  val f1:0.79289  lr: 0.0003 batch: 16
epochs: 6 train loss: 0.06401075121767794  train f1: 0.93055  lr: 0.0003 batch: 16 
epochs: 6 val loss: 0.8333649388066042  val f1:0.79149  lr: 0.0003 batch: 16
epochs: 7 train loss: 0.05000481552019383  train f1: 0.93704  lr: 0.0003 batch: 16 
epochs: 7 val loss: 0.9700586672182431  val f1:0.73424  lr: 0.0003 batch: 16
epochs: 8 train loss: 0.04095790823201593  train f1: 0.95622  lr: 0.0003 batch: 16 
epochs: 8 val loss: 0.8320730068065503  val f1:0.76834  lr: 0.0003 batch: 16
epochs: 9 train loss: 0.04664653286969574  train f1: 0.95057  lr: 0.0003 batch: 16 
epochs: 9 val loss: 0.8140006277296278  val f1:0.79986  lr: 0.0003 batch: 16
epochs: 10 train loss: 0.0319373032398652  train f1: 0.95966  lr: 0.0003 batch: 16 
epochs: 10 val loss: 0.8584280084680624  val f1:0.79010  lr: 0.0003 batch: 16
epochs: 11 train loss: 0.048127175566561514  train f1: 0.94919  lr: 0.0003 batch: 16 
epochs: 11 val loss: 0.8601793077256946  val f1:0.77750  lr: 0.0003 batch: 16
epochs: 12 train loss: 0.032248951476113744  train f1: 0.96880  lr: 0.0003 batch: 16 
epochs: 12 val loss: 1.0533456307870372  val f1:0.75303  lr: 0.0003 batch: 16
epochs: 13 train loss: 0.031458753377124817  train f1: 0.96964  lr: 0.0003 batch: 16 
epochs: 13 val loss: 0.9912550255104345  val f1:0.77666  lr: 0.0003 batch: 16
epochs: 14 train loss: 0.034042778232151114  train f1: 0.96368  lr: 0.0003 batch: 16 
epochs: 14 val loss: 0.9113708116390087  val f1:0.76593  lr: 0.0003 batch: 16
epochs: 15 train loss: 0.036175664597913194  train f1: 0.96917  lr: 0.0003 batch: 16 
epochs: 15 val loss: 0.8856304627877691  val f1:0.76421  lr: 0.0003 batch: 16
epochs: 16 train loss: 0.02539617261684444  train f1: 0.97885  lr: 0.0003 batch: 16 
epochs: 16 val loss: 0.7699442068735758  val f1:0.81341  lr: 0.0003 batch: 16
epochs: 17 train loss: 0.030727981108977002  train f1: 0.96477  lr: 0.0003 batch: 16 
epochs: 17 val loss: 0.8990627730334245  val f1:0.78611  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.203125  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.7578125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.767578125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.6640625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.9912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5078125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 1.1279296875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3828125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 5 train loss: 0.18212890625  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 5 val loss: 4.2265625  val f1:0.14286  lr: 0.0003 batch: 16
epochs: 0 train loss: 4.203125  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 0 val loss: 4.8125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 1 train loss: 4.25  train f1: 0.00000  lr: 0.0003 batch: 16 
epochs: 1 val loss: 4.7578125  val f1:0.00000  lr: 0.0003 batch: 16
epochs: 2 train loss: 2.767578125  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 2 val loss: 4.6640625  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 3 train loss: 0.9912109375  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 3 val loss: 4.5078125  val f1:0.12500  lr: 0.0003 batch: 16
epochs: 4 train loss: 1.1279296875  train f1: 1.00000  lr: 0.0003 batch: 16 
epochs: 4 val loss: 4.3828125  val f1:0.12500  lr: 0.0003 batch: 16
